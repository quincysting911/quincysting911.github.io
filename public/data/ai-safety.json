{
  "lastUpdated": "2026-02-19T06:45:45.902Z",
  "category": "ai-safety",
  "totalItems": 29,
  "items": [
    {
      "id": "aws-news-66dfe66bb907",
      "title": "AWS Clean Rooms announces support for remote Apache Iceberg REST catalogs",
      "description": "AWS Clean Rooms now supports catalog federation for remote Iceberg catalogs. This capability simplifies clean room setup by providing direct, secure access to Iceberg tables stored in Amazon S3 and cataloged in remote catalogs—without requiring table metadata replication. Organizations can now use AWS Glue catalog federation to provide direct access to their existing Iceberg REST catalog in a Clean Rooms collaboration. For example, a media publisher with data cataloged in the AWS Glue Data Catalog and an advertiser with data cataloged in a remote Iceberg catalog can analyze their collective datasets to evaluate advertising spend—without having to build ETL data pipelines or share underlying data with one another.\n  AWS Clean Rooms helps companies and their partners easily analyze and collaborate on their collective datasets without revealing or copying one another’s underlying data. For more information about the AWS Regions where AWS Clean Rooms is available, see the AWS Regions table. To learn more about collaborating with AWS Clean Rooms, visit AWS Clean Rooms.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-clean-rooms-remote-iceberg-catalogs",
      "pubDate": "2026-02-18T12:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "glue",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "s3",
        "glue",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-6c4b40553766",
      "title": "AWS Glue 5.1 is now available in 18 additional regions",
      "description": "AWS Glue 5.1 is now available in eighteen additional AWS Regions: Africa (Cape Town), Asia Pacific (Hyderabad, Jakarta, Melbourne, Osaka, Seoul, Taipei), Canada (Calgary, Central), Europe (London, Milan, Paris, Zurich), Israel (Tel Aviv), Mexico (Central), Middle East (Bahrain, UAE), and US West (N. California).\n \nAWS Glue is a serverless, scalable data integration service that simplifies discovering, preparing, moving, and integrating data from multiple sources. AWS Glue 5.1 upgrades core engines to Apache Spark 3.5.6, Python 3.11, and Scala 2.12.18, bringing performance and security enhancements. It also updates support for open table format libraries, including Apache Hudi 1.0.2, Apache Iceberg 1.10.0, and Delta Lake 3.3.2. Additionally, AWS Glue 5.1 introduces support for Apache Iceberg format version 3.0, adding default column values, deletion vectors for merge-on-read tables, multi-argument transforms, and row lineage tracking. This release also extends AWS Lake Formation fine-grained access control to write operations (both DML and DDL) for Spark DataFrames and Spark SQL. Previously, this capability was limited to read operations only. AWS Glue 5.1 also adds full-table access control in Apache Spark for Apache Hudi and Delta Lake tables, providing more comprehensive security options for your data.\n  With this expansion, AWS Glue 5.1 is now available in thirty-three AWS Regions.\n \nYou can get started with AWS Glue 5.1 using AWS Glue APIs, AWS Command Line Interface (CLI), AWS Software Development Kit (SDK), AWS Glue Studio, or Amazon SageMaker Unified Studio. To learn more, visit the AWS Glue product page and our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-glue-5-1-eighteen-additional-regions",
      "pubDate": "2026-02-16T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "glue"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "glue",
        "ga",
        "now-available",
        "update",
        "enhancement",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-a41a75592569",
      "title": "AWS Backup announces PrivateLink support for SAP HANA on AWS",
      "description": "AWS Backup now supports AWS PrivateLink for SAP HANA systems running on Amazon EC2. This enables customers to route all backup traffic through private network connections without traversing the public internet, helping organizations meet security and compliance requirements for regulated workloads.\n \nCustomers in regulated industries such as financial services, healthcare, and government agencies often require that all traffic remain on private networks. Previously, while SAP HANA application workloads could use AWS PrivateLink for secure, private communication with AWS services, backup traffic to AWS Backup had to traverse public endpoints. With this release, you can now use AWS PrivateLink for AWS Backup storage endpoints, ensuring your SAP HANA workloads on EC2 maintain end-to-end private connectivity for both application traffic and backup data. This helps organizations subject to HIPAA, EU/US Privacy Shield, and PCI DSS regulations implement fully private data protection strategies.\n \nThis feature is available in all AWS Regions where AWS Backup supports SAP HANA databases on EC2. To get started, update your Backint agent and add the backup-storage VPCE to your VPC.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-announces-privatelink-sap-hana-aws/",
      "pubDate": "2026-02-16T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-48e777b8ef81",
      "title": "AWS expands Resource Control Policies support to Amazon DynamoDB",
      "description": "AWS Resource Control Policies (RCPs) now support Amazon DynamoDB. RCPs are a type of organization policy that you can use to manage permissions in your organization. RCPs offer central control over the maximum available permissions for resources in your organization.\n \nWith this expansion, you can now use RCPs to manage permissions for Amazon DynamoDB. For example, you can create policies that prevent identities outside your organization from accessing DynamoDB, helping you build a data perimeter and enforce baseline security standards across your AWS environment.  \n \nRCPs are available in all AWS commercial Regions and AWS GovCloud (US) Regions. To learn more about RCPs and view the full list of supported AWS services, visit the Resource control policies (RCPs) documentation in the AWS Organizations User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-expands-resource-control-policies-amazon",
      "pubDate": "2026-02-12T20:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "dynamodb",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "dynamodb",
        "rds",
        "organizations",
        "ga",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-fc86dccc391a",
      "title": "Amazon RDS for PostgreSQL supports minor versions  18.2, 17.8, 16.12, 15.16 and 14.21",
      "description": "Amazon Relational Database Service (RDS) for PostgreSQL now supports the latest minor versions 18.2, 17.8, 16.12, 15.16, and 14.21. We recommend that you upgrade to the latest minor versions to fix known security vulnerabilities in prior versions of PostgreSQL, and to benefit from the bug fixes added by the PostgreSQL community. This release also includes new extension pg_stat_monitor that enables you to collect performance metrics and evaluate query performance insights in a unified view.\n  You can upgrade your databases during scheduled maintenance windows using automatic minor version upgrades. To simplify operations at scale, enable automatic minor version upgrades and use the AWS Organizations Upgrade Rollout Policy to orchestrate thousands of upgrades in phases, first to development environments before upgrading production systems. You can also use Amazon RDS Blue/Green deployments with physical replication to minimize downtime for minor version upgrades.\n  Amazon RDS for PostgreSQL makes it simple to set up, operate, and scale PostgreSQL deployments in the cloud. See Amazon RDS for PostgreSQL Pricing for pricing details and regional availability. Create or update a fully managed Amazon RDS database in the Amazon RDS Management Console or by using the AWS Command Line Interface (CLI).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-minor-version-18-2-17-8-16-12-15-16-14-21",
      "pubDate": "2026-02-12T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-6a19d601fcb1",
      "title": "Amazon Connect  launches granular access controls for analytics dashboards",
      "description": "Amazon Connect dashboards now provides granular access controls for analytics dashboards. This enables you to apply resource tags that control who is able to see metrics for specific resources such as agents, queues, and routing profiles. You can now filter metrics using tags to view aggregate metrics for agents or queues that share the same tags. For example, you can tag agents with Department:Customer Service to restrict dashboard metrics visibility to Customer Service team managers.\n \n\n Amazon Connect dashboards are available in all AWS commercial and AWS GovCloud (US-West) regions where Amazon Connect is offered. To learn more about dashboards, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-launches-granular-access",
      "pubDate": "2026-02-12T07:26:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-f20129c0b05f",
      "title": "AWS Payment Cryptography Achieves Cartes Bancaires Approval",
      "description": "Today, AWS Payment Cryptography has become one of the first cloud-based payment cryptography services to obtain approval from Groupement des Cartes Bancaires (CB), France's national card payment network. This CB approval, combined with existing compliance credentials, enables customers to run payment workloads in AWS while helping customers maintain CB compliance.\n  Organizations such as acquirers, payment facilitators, networks, switches, processors, and issuing banks that are moving workloads to the cloud can rely on AWS Payment Cryptography’s CB approval as part of their compliance frameworks. Organizations processing card payments typically require Hardware Security Modules (HSM) to perform cryptography in a compliant manner. AWS Payment Cryptography provides equivalent functionality in an elastic, scalable service, eliminating the operational burden of procuring and manage standalone payment HSMs. Customers can leverage the service’s shared responsibility model with PCI PIN, PCI P2PE, PCI 3DS, PCI DSS, SOC-2, CSA STAR and ISO27001 certifications as well as the additional CB approval.\n  AWS Payment Cryptography is available in the following AWS Regions: Canada (Montreal), US East (Ohio, N. Virginia), US West (Oregon), Europe (Ireland, Frankfurt, London, Paris), Africa (Cape Town) and Asia Pacific (Singapore, Tokyo, Osaka, Mumbai, Hyderabad, Sydney).\n  To start using the service, please download the latest AWS CLI/SDK and see the AWS Payment Cryptography user guide for more information including further compliance details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/payment-cryptography-cartes-bancaires",
      "pubDate": "2026-02-11T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-b81c3d11b6ea",
      "title": "AWS Lake Formation enhances cross-account sharing",
      "description": "AWS Lake Formation now enhances cross-account sharing, allowing you to share hundreds of thousands of tables across accounts. You can centralize permissions in Lake Formation for resources such as catalogs, databases, and tables for multi-account analytics environments that require fine-grained access controls at scale.\n  You can share Data Catalog resources (databases, tables, and columns) with external IAM principals, AWS accounts, AWS Organizations, and organizational units (OUs). Lake Formation sets up a single AWS Resource Access Manager resource share for an unlimited number of tables to another account, eliminating previous resource association limits per resource type. To get started, upgrade to cross-account version 5 through the Lake Formation console or API. Any new cross-account permission grants will automatically use wildcard patterns in the AWS Resource Access Manager resource shares instead of individual resource associations. All existing cross-account shares continue to function, and all existing Lake Formation APIs remain compatible.\n \nTo learn more, visit the AWS Lake Formation product page and documentation. For AWS Lake Formation Region availability, please see the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-lake-formation-cross-account-sharing",
      "pubDate": "2026-02-11T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "iam",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-39b93afa34c1",
      "title": "Amazon Bedrock AgentCore Browser now supports proxy configuration",
      "description": "Amazon Bedrock AgentCore Browser now supports customer-provided proxy configuration, enabling customers to route browser sessions through their own proxy infrastructure for geo-targeting, regional content access, and compliance requirements. Organizations can access geo-restricted content, verify region-specific pricing, and validate localized application behavior across markets. Customers in regulated industries such as healthcare and financial services can route traffic through corporate proxy infrastructure to meet security policies while automating critical business processes.\n  Browser proxies help eliminate re-authentication cycles due to rotating IPs, while providing stable, controllable egress addresses for IP allowlisting requirements. The feature currently supports both HTTP and HTTPS protocols with secure credential management through AWS Secrets Manager. This enhancement is particularly valuable for healthcare organizations accessing portals with strict IP allowlisting, financial services companies with rigorous egress policies, and enterprises routing traffic through corporate proxy infrastructure that provides auditing and security policy enforcement.\n  This feature is available in all fourteen AWS Regions where Amazon Bedrock AgentCore Browser is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), and Europe (Stockholm).\n  To learn more, visit the Browser Proxies documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/bedrock-agentcore-browser-proxy",
      "pubDate": "2026-02-11T06:16:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "secrets manager",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "secrets manager",
        "organizations",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-2baacc65d7a9",
      "title": "Amazon OpenSearch Serverless now supports Collection Groups",
      "description": "Amazon OpenSearch Serverless now supports Collection Groups, a new capability that enables you to share OpenSearch Compute Units (OCUs) across collections with different AWS KMS keys. This new capability delivers enhanced cost optimization through a shared compute model that reduces overall OCU expenses while maintaining collection-level security and access controls. Additionally, Collection Groups introduce the ability to specify minimum OCU allocations alongside maximum OCU limits, allowing you to provision compute capacity upfront at startup for more predictable performance.\n  Collection Groups are particularly valuable for multi-tenant workloads where different tenants require data encryption with separate KMS keys while still benefiting from shared compute resources. By grouping collections together, you can optimize OCU utilization across workloads, reduce costs through resource sharing, and maintain the security isolation required by different encryption keys. The minimum OCU setting ensures your collections have guaranteed baseline capacity from the moment they start, eliminating cold start delays and providing consistent performance for latency-sensitive applications.\n  Collection groups are available in all regions where Amazon OpenSearch Serverless is currently available. To learn more about configuring and managing collection groups, visit the Amazon OpenSearch Serverless documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-opensearch-serverless-supports-collection-groups/",
      "pubDate": "2026-02-10T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "opensearch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-326540a6a823",
      "title": "Using Amazon SageMaker Unified Studio Identity center (IDC) and IAM-based domains together",
      "description": "In this post, we demonstrate how to access an Amazon SageMaker Unified Studio IDC-based domain with a new IAM-based domain using role reuse and attribute-based access control.",
      "link": "https://aws.amazon.com/blogs/big-data/using-amazon-sagemaker-unified-studio-identity-center-idc-and-iam-based-domains-together/",
      "pubDate": "2026-02-09T22:27:10.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam"
      ]
    },
    {
      "id": "aws-news-9164d1ec8b97",
      "title": "Amazon Neptune Analytics is now available in 7 additional regions",
      "description": "Amazon Neptune Analytics is now available in Middle East (Bahrain), Middle East (UAE), Israel (Tel Aviv), Africa (Cape Town), Canada (Calgary), Asia Pacific (Malaysia), and Europe (Zurich) regions. You can now create and manage Neptune Analytics graphs in these new regions and run advanced graph analytics.\n  Amazon Neptune is a serverless graph database for connected data, improves the accuracy of AI applications, and lowers operational burden and costs. Neptune instantly scales graph workloads removing the need to manage capacity. By modeling data as a graph, Neptune captures context that improves accuracy and explainability of generative AI applications. To make AI application development easier, Neptune offers fully managed GraphRAG with Amazon Bedrock Knowledge Bases, and integrations with Strands AI Agents SDK and popular agentic memory tools. It also easily analyzes tens of billions of relationships across structured and unstructured data within seconds delivering strategic insights. Neptune is the only database and analytics engine that gives you the power of connected data with the enterprise capabilities and value of AWS.\n  To get started, you can create a new Neptune Analytics graphs using the AWS Management Console, or AWS CLI. For more information on pricing and region availability, refer to the Neptune pricing page and AWS Region Table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-neptune-analytics-in-seven-additional-regions",
      "pubDate": "2026-02-09T21:45:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "ga",
        "now-available",
        "integration",
        "new-region"
      ]
    },
    {
      "id": "aws-news-b8494c694c0a",
      "title": "AWS Builder ID now supports Sign in with Apple",
      "description": "AWS Builder ID, your profile for accessing AWS applications including AWS Builder Center, AWS Training and Certification, AWS re:Post, AWS Startups, and Kiro, now supports Sign in with Apple as a social login provider. This expansion of sign-in options builds on the existing Sign in with Google capability, providing Apple users with a streamlined way to access AWS resources without managing separate credentials on AWS.\n \n  \nWith Sign in with Apple integration, developers and builders can now enjoy access to their AWS Builder ID profile using their Apple Account credentials. This enhancement eliminates password management complexity, reduces forgotten password issues, and provides a frictionless experience for both new user registration and returning user sign-ins. Whether you're accessing development resources in AWS Builder Center, enrolling in certification programs, participating in community discussions on AWS re:Post, exploring startup resources, or using Kiro to code your next app, your Apple Account now serves as a secure gateway to your builder AWS journey. \n \n  \nTo learn more about AWS Builder ID and get started with Sign in with Apple, visit the AWS Builder ID documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-builder-id-sign-in-apple",
      "pubDate": "2026-02-05T19:20:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "ga",
        "enhancement",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-c39359ee94ef",
      "title": "AWS Glue launches native REST API connector for universal data integration",
      "description": "AWS Glue now offers a native REST-based connector that enables customers to easily read data from any source with a REST-based API. Customers can now create custom connectors to any REST-enabled data source and seamlessly integrate that data into their AWS Glue ETL (Extract, Transform, and Load) jobs. This capability extends AWS Glue's existing connectivity to 100+ non-AWS data sources through 60+ native connectors and additional options on AWS Marketplace.\n  Previously, connecting to proprietary systems or emerging platforms required customers to build custom connectors by providing specialized JARs with the necessary libraries. The new native REST API connector eliminates this complexity, making it easier to integrate data from any REST-enabled source. It reduces operational overhead by eliminating the need to install, update, or manage custom libraries, freeing teams from maintenance burdens. The connector also enhances flexibility, enabling organizations to quickly adapt to new data sources as business needs evolve. It also streamlines ETL management by allowing data engineers to focus on data transformation and business logic rather than spending time building and maintaining connector infrastructure.\n  The AWS Glue REST API connector is available in all AWS commercial regions where AWS Glue is available.\n  You can start using the AWS Glue REST API connector using AWS Glue APIs, AWS Command Line Interface (CLI), or AWS Software Development Kit (SDK). To get started, see AWS Glue documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-glue-rest-api-connector",
      "pubDate": "2026-02-05T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "glue",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "glue",
        "organizations",
        "launch",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-3d65b6979e0c",
      "title": "Amazon EC2 capacity blocks for ML can be shared across multiple accounts",
      "description": "Amazon Web Services (AWS) is announcing the general availability of cross-account sharing for Amazon EC2 Capacity Blocks for ML. This capability allows organizations to share reserved GPU capacity across AWS accounts using AWS Resource Access Manager (RAM), helping optimize utilization and reduce costs.\n \nOrganizations can now purchase Capacity Blocks and provision them across multiple accounts, allowing different workloads to access a pool of reserved capacity at no additional cost. This capability helps teams coordinate ML infrastructure investments and keeps reserved GPU capacity in continuous use across different workloads.\n \nThis feature is available for all Instance Capacity Blocks in AWS Regions where EC2 Capacity Blocks for ML are offered. For a complete list of supported regions, refer to Capacity Blocks Supported Regions documentation. \n \nTo get started, create a Resource Share through AWS Resource Access Manager, add your Capacity Blocks for ML resources, and specify the target accounts you wish to share with. For more details, please refer to the Capacity Block Guide",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-capacity-blocks-multiple-accounts",
      "pubDate": "2026-02-05T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-c64424ec98ad",
      "title": "Amazon EC2 and VPC now display related resources for security groups",
      "description": "Amazon Web Services (AWS) is announcing the general availability of the \"Related resources\" tab for security groups in the Amazon EC2 and VPC consoles. This new feature provides customers with a consolidated view of all resources that depend on a specific security group, eliminating the need to manually check multiple services before making configuration changes. Security groups act as virtual firewalls that control inbound and outbound traffic for AWS resources, and understanding their dependencies is critical for maintaining secure and stable infrastructure.\n  Previously, customers managing complex security group configurations had to navigate through multiple AWS services individually to identify dependencies before modifying or deleting security groups. This manual process required checking EC2 instances, Elastic Network Interfaces, ElastiCache clusters, RDS databases, and other services one by one, making it time-consuming and error-prone. The \"Related resources\" tab streamlines this workflow by displaying all dependent resources in a single location, enabling customers to quickly assess the impact of proposed changes and make informed decisions with confidence. This enhancement is beneficial for organizations managing large-scale deployments where security groups may be attached to dozens or hundreds of resources across different services.\n  This feature is now available in all AWS commercial regions at no additional cost.\n  To learn more about managing security groups and viewing the \"Related resources\" tab in the Amazon EC2 and VPC consoles, see the Amazon EC2 User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-console-related-resources-generally-available",
      "pubDate": "2026-02-04T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "ec2",
        "rds",
        "organizations",
        "ga",
        "now-available",
        "new-feature",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-aead7f5f943e",
      "title": "Amazon Redshift now supports autonomics for multi-cluster environments",
      "description": "Amazon Redshift now supports autonomics—automatic optimization features—for multi-cluster environments. Database administrators managing distributed Amazon Redshift workloads can now benefit from autonomics that work intelligently across multiple warehouses, eliminating manual performance tuning across consumer clusters.\n  This launch extends Amazon Redshift's autonomics capabilities, including Automatic Table Optimization (ATO), Automatic Table Sorting (ATS), Auto Vacuum, and Auto Analyze, to consider query patterns from all consumer clusters when managing table layouts and maintenance operations. Organizations where multiple business units access shared data can benefit from holistic optimization that considers all workload patterns, reducing manual optimization processes. This launch also includes a denylist feature, allowing you to exclude specific endpoints or AWS accounts from influencing optimization decisions—particularly useful for cross-organizational data sharing scenarios. These enhanced autonomics features are available at no additional cost for Amazon Redshift customers.\n  This feature is available in all AWS Regions that support Amazon Redshift. To learn more, see the Amazon Redshift Management Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-redshift-autonomics-for-multi-cluster",
      "pubDate": "2026-02-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "redshift",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "redshift",
        "organizations",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-b99ec838c4f5",
      "title": "AWS Batch now provides Array Job Status Summary in ListJobs API",
      "description": "AWS Batch now includes a status summary for Array Jobs in the ListJobs API response, giving you immediate visibility into the distribution of child job statuses without additional API calls. This enhancement helps you monitor large-scale workloads more efficiently.\n  When you call the ListJobs API for Array Jobs, the response now includes a statusSummary field that shows the count of child jobs in each state: SUBMITTED, PENDING, RUNNABLE, STARTING, RUNNING, SUCCEEDED, and FAILED. Previously, statusSummary field was only available in the response of DescribeJobs API call. Using the new field you can now monitor the progress of multiple array jobs in your queue with a single API call.. The response also includes a statusSummaryLastUpdatedAt timestamp, allowing you to assess the freshness of the status information. This transparency helps you make informed decisions about your workload management and troubleshooting.\n  This feature is particularly valuable for high-scale batch processing workloads in financial services, automotive, and other industries where monitoring thousands of parallel jobs is critical for operational visibility. Available today in all AWS Regions where AWS Batch is available. For more information, see the ListJobs API page in AWS Batch API Reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-batch-array-job-status-summary/",
      "pubDate": "2026-02-03T22:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-2d2cff21bbac",
      "title": "Amazon DynamoDB global tables now support replication across multiple AWS accounts",
      "description": "Amazon DynamoDB global tables now support replication across multiple AWS accounts. DynamoDB global tables is a fully managed, serverless, multi-Region, and multi-active database used by tens of thousands of customers to power business-critical applications. With this new capability, you can replicate tables across AWS accounts and Regions to improve resiliency, isolate workloads at the account level, and apply distinct security and governance controls.\n  For multi-account global tables, DynamoDB automatically replicates tables across AWS accounts and Regions. This capability allows you to strengthen fault tolerance and helps ensure applications remain highly available even during account-level disruptions, while allowing customers to align data placement with organizational and security requirements. Multi-account global tables are ideal for customers that adopt multi-account strategies or use AWS Organizations to improve security isolation, enforce data perimeter guardrails, implement disaster recovery (DR), or separate workloads by business unit.\n  Multi-account global tables is available in all AWS Regions and is billed according to existing global tables pricing.\n  To get started, see the DynamoDB global tables documentation, and visit the AWS developer guide to learn more about the benefits of using a multi-account strategy for your AWS environment.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/dynamodb-gt-multi-account/",
      "pubDate": "2026-02-03T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "dynamodb",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "dynamodb",
        "organizations",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-9f38d8860c00",
      "title": "AWS Marketplace introduces localized billing for Professional Services from AWS EMEA",
      "description": "AWS Marketplace now offers a more localized experience for Europe, Middle East, and Africa (EMEA) customers purchasing Professional Service solutions via AWS EMEA Marketplace Operator.\n  Customers can now procure Professional Services using localized payment methods and receive invoices from AWS EMEA. This removes previous procurement barriers caused by complex payment remittance processes between different AWS entities, which made it difficult for EMEA customers to purchase Professional Services through AWS Marketplace.\n  Key benefits include support for SEPA (Single Euro Payment Area) payment methods and invoicing consistency from the same AWS entity covering all AWS Marketplace purchases via AWS EMEA Marketplace Operator. This capability is ideal for EMEA customers purchasing consulting, implementation, or managed services through AWS Marketplace. It also benefits organizations that prefer local payment methods such as SEPA direct debit, want to consolidate AWS and Marketplace billing, or are seeking a simpler procurement experience for Professional Services.\n  This capability is available for EMEA customers who purchase professional services solutions in AWS Marketplace, with AWS EMEA as the Marketplace Operator. To learn more about purchasing Professional Services products in AWS Marketplace and receive invoices issued by AWS EMEA, visit the AWS Marketplace Buyer Guide and AWS EMEA Marketplace FAQs. For more information on how to add a bank account for SEPA, see Managing Your SEPA Direct Debit Payment Method in the AWS Billing and Cost Management user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-marketplace-localized-billing-professional/",
      "pubDate": "2026-02-03T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-9d73697199bf",
      "title": "Sovereign failover – Design for digital sovereignty using the AWS European Sovereign Cloud",
      "description": "This post explores the architectural patterns, challenges, and best practices for building cross-partition failover, covering network connectivity, authentication, and governance. By understanding these constraints, you can design resilient cloud-native applications that balance regulatory compliance with operational continuity.",
      "link": "https://aws.amazon.com/blogs/architecture/sovereign-failover-design-for-digital-sovereignty-using-the-aws-european-sovereign-cloud/",
      "pubDate": "2026-01-30T19:09:35.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": []
    },
    {
      "id": "aws-news-56b859ccdae9",
      "title": "Build a trusted foundation for data and AI using Alation and Amazon SageMaker Unified Studio",
      "description": "The Alation and SageMaker Unified Studio integration helps organizations bridge the gap between fast analytics and ML development and the governance requirements most enterprises face. By cataloging metadata from SageMaker Unified Studio in Alation, you gain a governed, discoverable view of how assets are created and used. In this post, we demonstrate who benefits from this integration, how it works, the specific metadata it synchronizes, and provide a complete deployment guide for your environment.",
      "link": "https://aws.amazon.com/blogs/big-data/build-a-trusted-foundation-for-data-and-ai-using-alation-and-amazon-sagemaker-unified-studio/",
      "pubDate": "2026-01-29T23:33:30.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "organizations",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-6ae9097450e3",
      "title": "Optimizing storage performance for Amazon EKS on AWS Outposts",
      "description": "Amazon Elastic Kubernetes Service (Amazon EKS) on \nAWS Outposts brings the power of managed \nKubernetes to your on-premises infrastructure. Use Amazon EKS on Outposts rack to create hybrid cloud deployments that maintain consistent AWS experiences across environments. As organizations increasingly adopt edge computing and hybrid architectures, storage optimization and performance tuning become critical for successful workload deployment.",
      "link": "https://aws.amazon.com/blogs/compute/optimizing-storage-performance-for-amazon-eks-on-aws-outposts/",
      "pubDate": "2026-01-13T18:57:12.000Z",
      "source": "computeBlog",
      "services": [
        "eks",
        "organizations",
        "outposts"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "eks",
        "organizations",
        "outposts",
        "ga"
      ]
    },
    {
      "id": "aws-news-0dbe89f3f79b",
      "title": "Orchestrating large-scale document processing with AWS Step Functions and Amazon Bedrock batch inference",
      "description": "Organizations often have large volumes of documents containing valuable information that remains locked away and unsearchable. This solution addresses the need for a \nscalable, automated text extraction and knowledge base pipeline that transforms static document collections into intelligent, searchable repositories for generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-large-scale-document-processing-with-aws-step-functions-and-amazon-bedrock-batch-inference/",
      "pubDate": "2025-11-26T21:41:51.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock",
        "step functions",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "step functions",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-e5767083a6d4",
      "title": "Optimize unused capacity with Amazon EC2 interruptible capacity reservations",
      "description": "Organizations running critical workloads on Amazon Elastic Compute Cloud (Amazon EC2) reserve compute capacity using On-Demand Capacity Reservations (ODCR) to have availability when needed. However, reserved capacity can intermittently sit idle during off-peak periods, between deployments, or when workloads scale down. This unused capacity represents a missed opportunity for cost optimization and resource efficiency across the organization.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-unused-capacity-with-amazon-ec2-interruptible-capacity-reservations/",
      "pubDate": "2025-11-25T01:09:16.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-9150859a247c",
      "title": "Building an AI gateway to Amazon Bedrock with Amazon API Gateway",
      "description": "In this post, we'll explore a reference architecture that helps enterprises govern their Amazon Bedrock implementations using Amazon API Gateway. This pattern enables key capabilities like authorization controls, usage quotas, and real-time response streaming. We'll examine the architecture, provide deployment steps, and discuss potential enhancements to help you implement AI governance at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/building-an-ai-gateway-to-amazon-bedrock-with-amazon-api-gateway/",
      "pubDate": "2025-11-19T23:33:41.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "api gateway"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "api gateway",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-4934fd40d9d8",
      "title": "Architecting for AI excellence: AWS launches three Well-Architected Lenses at re:Invent 2025",
      "description": "At re:Invent 2025, we introduce one new lens and two significant updates to the AWS Well-Architected Lenses specifically focused on AI workloads: the Responsible AI Lens, the Machine Learning (ML) Lens, and the Generative AI Lens. Together, these lenses provide comprehensive guidance for organizations at different stages of their AI journey, whether you're just starting to experiment with machine learning or already deploying complex AI applications at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-for-ai-excellence-aws-launches-three-well-architected-lenses-at-reinvent-2025/",
      "pubDate": "2025-11-19T19:36:31.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-61647c9310e0",
      "title": "Announcing the updated AWS Well-Architected Generative AI Lens",
      "description": "We are delighted to announce an update to the AWS Well-Architected Generative AI Lens. This update features several new sections of the Well-Architected Generative AI Lens, including new best practices, advanced scenario guidance, and improved preambles on responsible AI, data architecture, and agentic workflows.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-generative-ai-lens/",
      "pubDate": "2025-11-19T19:36:28.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-7e2f23dd38ac",
      "title": "Simplify multi-tenant encryption with a cost-conscious AWS KMS key strategy",
      "description": "In this post, we explore an efficient approach to managing encryption keys in a multi-tenant SaaS environment through centralization, addressing challenges like key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. We demonstrate how implementing a centralized key management strategy using a single AWS KMS key per tenant can maintain security and compliance while reducing operational overhead as organizations scale.",
      "link": "https://aws.amazon.com/blogs/architecture/simplify-multi-tenant-encryption-with-a-cost-conscious-aws-kms-key-strategy/",
      "pubDate": "2025-08-21T21:54:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    }
  ]
}