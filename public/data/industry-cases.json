{
  "lastUpdated": "2025-11-17T06:16:48.608Z",
  "category": "industry-cases",
  "totalItems": 18,
  "items": [
    {
      "id": "aws-news-10a8671badc2",
      "title": "Amazon Connect now provides metrics on completion of agent performance evaluations by managers",
      "description": "Amazon Connect now provides metrics that measure completion of agent performance evaluations, improving manager productivity and evaluation consistency. Businesses can monitor if the required number of evaluations for their agents have been completed, ensuring compliance with internal policies (e.g., complete 5 evaluations per agent per month), regulatory requirements, and labor union agreements. Additionally, businesses can analyze evaluation scoring patterns across different managers, to identify opportunities to improve evaluation consistency and accuracy. These insights are available in real-time through analytics dashboards in the Connect UI, and APIs.\n  This feature is available in all regions where Amazon Connect is offered. To learn more, please visit our documentation and our webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-metrics-completion-agent-performance-evaluations",
      "pubDate": "2025-11-13T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds"
      ]
    },
    {
      "id": "aws-news-e646eb813934",
      "title": "Amazon Managed Service for Prometheus collector integrates with Amazon Managed Streaming for Apache Kafka",
      "description": "Amazon Managed Service for Prometheus collector, a fully-managed agentless collector for Prometheus metrics, now enables you to discover and collect Prometheus metrics from your Amazon Managed Streaming for Apache Kafka cluster while ensuring high availability and scalability.\n \nSo far, customers who were seeking to benefit from open monitoring in an Amazon Managed Streaming for Apache Kafka cluster had to set up dedicated infrastructure and deploy, right-size, and scale agents to discover and scrape the Prometheus metrics in the cluster. With this launch, you can configure a Amazon Managed Service for Prometheus collector to scrape metrics from the JMX exporter and the Node exporter, covering metrics including host-level, JVM-level, as well as broker-related metrics to implement use cases such as message queue health and partition balancing.\n \nAmazon Managed Service for Prometheus collector is available in all commercial regions where Amazon Managed Service for Prometheus is available. To learn more about Amazon Managed Service for Prometheus collector, visit the user guide or product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-managed-prometheus-kafka/",
      "pubDate": "2025-11-12T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kafka"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kafka",
        "launch"
      ]
    },
    {
      "id": "aws-news-a7184d7c3c1a",
      "title": "Introducing the Amazon OpenSearch Lens for the AWS Well-Architected Framework",
      "description": "In this post, we show you how to use the Amazon OpenSearch Service Lens to evaluate your OpenSearch Service workloads against architectural best practices.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-the-amazon-opensearch-lens-for-the-aws-well-architected-framework/",
      "pubDate": "2025-11-12T01:07:02.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "ga"
      ]
    },
    {
      "id": "aws-news-a104392c9b46",
      "title": "Analyzing Amazon EC2 Spot instance interruptions by using event-driven architecture",
      "description": "In this post, you'll learn how to build this comprehensive monitoring solution step-by-step. You'll gain practical experience designing an event-driven pipeline, implementing data processing workflows, and creating insightful dashboards that help you track interruption trends, optimize ASG configurations, and improve the resilience of your Spot Instance workloads.",
      "link": "https://aws.amazon.com/blogs/big-data/analyzing-amazon-ec2-spot-instance-interruptions-by-using-event-driven-architecture/",
      "pubDate": "2025-11-10T22:05:20.000Z",
      "source": "bigDataBlog",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ec2",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-2bb659aa2d5a",
      "title": "Amazon CloudWatch Database Insights expands anomaly detection in on-demand analysis",
      "description": "Amazon CloudWatch Database Insights now detects anomalies on additional metrics through its on-demand analysis experience. Database Insights is a monitoring and diagnostics solution that helps database administrators and application developers optimize database performance by providing comprehensive visibility into database metrics, query performance, and resource utilization patterns. The on-demand analysis feature utilizes machine learning to help identify anomalies and performance bottlenecks during the selected time period, and gives advice on what to do next.\n  The Database Insights on-demand analysis feature now offers enhanced anomaly detection capabilities. Previously, database administrators could analyze database performance and correlate metrics based on database load. Now, the on-demand analysis report also identifies anomalies in database-level and operating system-level counter metrics for the database instance, as well as per-SQL metrics for the top SQL statements contributing to database load. The feature automatically compares your selected time period against normal baseline performance, identifies anomalies, and provides specific remediation advice while reducing mean time to diagnosis. Through intuitive visualizations and clear explanations, you can quickly identify performance issues and receive step-by-step guidance for resolution.\n  You can get started with on-demand analysis by enabling the Advanced mode of CloudWatch Database Insights on your Amazon Aurora or RDS databases using the AWS management console, AWS APIs, or AWS CloudFormation. Please refer to RDS documentation and Aurora documentation for information regarding the availability of Database Insights across different regions, engines, and instance classes.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-database-insights-anomaly-detection/",
      "pubDate": "2025-11-05T21:58:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudformation",
        "cloudwatch"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds",
        "cloudformation",
        "cloudwatch",
        "ga"
      ]
    },
    {
      "id": "aws-news-e1b9bc0ad451",
      "title": "AWS Marketplace now open for India-based sellers supporting transactions in Indian Rupees (INR)",
      "description": "Buyers and sellers in India can now transact locally in AWS Marketplace, with invoicing in Indian Rupees (INR), and with simplified tax compliance through AWS India. With this launch, India-based sellers can now register to sell in AWS Marketplace and offer paid subscriptions to buyers in India. India-based sellers will be able to create private offers in US dollars (USD) or INR. Buyers in India purchasing paid offerings in AWS Marketplace from India-based sellers will receive invoices in INR, helping to simplify invoicing with consistency across AWS Cloud and AWS Marketplace purchases. Sellers based in India can begin selling paid offerings in AWS Marketplace and can work with India-based Channel Partners to sell to customers.\n  AWS India will facilitate the issuance of tax-compliant invoices in INR to buyers, with the independent software vendor (ISV) or Channel Partner as the seller of record. AWS India will automate the collection and remittance of Withholding Tax (WHT) and GST-Tax Collected at Source (GST-TCS) to the relevant tax authorities, fulfilling compliance requirements for buyers. During this phase, non-India based sellers can continue to sell directly to buyers in India through AWS Inc., in USD or through AWS India by working through authorized distributors.\n  To learn more and explore solutions available from India-based sellers, visit this page. To get started as a seller, India-based ISVs and Channel Partners can register in the AWS Marketplace Management Portal. For more information about buying or selling using AWS Marketplace in India, visit the India FAQs page and help guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-marketplace-india-based-sellers-transactions-inr",
      "pubDate": "2025-11-05T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-a14aa54b7cee",
      "title": "Orchestrating big data processing with AWS Step Functions Distributed Map",
      "description": "In this post, you'll learn how to use AWS Step Functions Distributed Map to process Amazon Athena data manifest and Parquet files through a step-by-step demonstration.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-big-data-processing-with-aws-step-functions-distributed-map/",
      "pubDate": "2025-11-04T23:42:01.000Z",
      "source": "computeBlog",
      "services": [
        "athena",
        "step functions"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "athena",
        "step functions"
      ]
    },
    {
      "id": "aws-news-2e8f1dc21abc",
      "title": "Amazon Kinesis Data Streams launches On-demand Advantage mode",
      "description": "Amazon Kinesis Data Streams launches On-demand Advantage, so customers can warm on-demand streams to handle instant throughput increases up to 10GB or 10 million events per second, eliminating the need to over-provision or build custom scaling solutions. Amazon Kinesis Data Streams is a serverless streaming data service that makes it easy to capture, process, and store data streams at any scale. On-demand streams automatically scale capacity based on data usage, and now you can warm write capacity ad hoc. On-demand Advantage also provides a simpler pricing structure that removes the fixed, per-stream charge, so customers only pay for data usage at better rates.\n  On-demand Advantage offers data usage with 60% lower pricing compared to On-demand Standard, with data ingest at $0.032/GB and data retrieval at $0.016/GB in the US East (N. Virginia) region. The price of Enhanced fan-out data retrieval is the same as shared-throughput retrievals, making higher fan-out use cases more cost effective. The mode also decreases the price of extended retention by 77% from $0.10/GB-month to $0.023/GB-month. Once you enable On-demand Advantage mode, the account will be billed for a minimum of 25MB/s of data ingest and 25MB/s of data retrieval at the lower rates across all on-demand streams. The new pricing means On-demand Advantage is the most cost effective way to stream with Kinesis Data Streams when you ingest at least 10MB/s in aggregate, fan out to more than two consumer applications, or have hundreds of streams in a region. You can check directly in the Kinesis console and the pricing page if On-demand Advantage is a good fit for your account.\n  On-demand Advantage is available in all AWS regions where Kinesis Data Streams is available, including AWS GovCloud (US) and China regions. To learn more, see the launch blog and the Kinesis Data Streams User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-kinesis-data-streams-ondemand-advantage",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kinesis"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kinesis",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-5625caee948f",
      "title": "Amazon Kinesis Data Streams launches On-demand Advantage for instant throughput increases and streaming at scale",
      "description": "Today, AWS announced the new Amazon Kinesis Data Streams On-demand Advantage mode, which includes warm throughput capability and an updated pricing structure. With this feature you can enable instant scaling for traffic surges while optimizing costs for consistent streaming workloads. In this post, we explore this new feature, including key use cases, configuration options, pricing considerations, and best practices for optimal performance.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-kinesis-data-streams-launches-on-demand-advantage-for-instant-throughput-increases-and-streaming-at-scale/",
      "pubDate": "2025-11-03T22:00:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "kinesis"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kinesis",
        "launch",
        "new-feature",
        "update"
      ]
    },
    {
      "id": "aws-news-1998e227992a",
      "title": "Scaling data governance with Amazon DataZone: Covestro success story",
      "description": "In this post, we show you how Covestro transformed its data architecture by implementing Amazon DataZone and AWS Serverless Data Lake Framework, transitioning from a centralized data lake to a data mesh architecture. The implementation enabled streamlined data access, better data quality, and stronger governance at scale, achieving a 70% reduction in time-to-market for over 1,000 data pipelines.",
      "link": "https://aws.amazon.com/blogs/big-data/scaling-data-governance-with-amazon-datazone-covestro-success-story/",
      "pubDate": "2025-11-03T21:02:06.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-b147351ed9fa",
      "title": "Upgrade from Amazon Redshift DC2 node type to Amazon Redshift Serverless",
      "description": "In this post, we show you the upgrade process from DC2 instances to Amazon Redshift Serverless. By using Amazon Redshift Serverless, you can run and scale analytics without managing data warehouse infrastructure.",
      "link": "https://aws.amazon.com/blogs/big-data/upgrade-from-amazon-redshift-dc2-node-type-to-amazon-redshift-serverless/",
      "pubDate": "2025-10-22T21:04:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "redshift"
      ]
    },
    {
      "id": "aws-news-11031ecd9926",
      "title": "Zero downtime blue/green deployments with Amazon API Gateway",
      "description": "In this post, you learn how to implement blue/green deployments by using Amazon API Gateway for your APIs. For this post, we use AWS Lambda functions on the backend. However, you can follow the same strategy for other backend implementations of the APIs. All the required infrastructure is deployed by using AWS Serverless Application Model (AWS SAM).",
      "link": "https://aws.amazon.com/blogs/compute/zero-downtime-blue-green-deployments-with-amazon-api-gateway/",
      "pubDate": "2025-10-16T19:01:22.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-1cf24c6b0f9d",
      "title": "Deploying AI models for inference with AWS Lambda using zip packaging",
      "description": "Users usually package their function code as container images when using machine learning (ML) models that are larger than 250 MB, which is the Lambda deployment package size limit for zip files. In this post, we demonstrate an approach that downloads ML models directly from Amazon S3 into your function’s memory so that you can continue packaging your function code using zip files.",
      "link": "https://aws.amazon.com/blogs/compute/deploying-ai-models-for-inference-with-aws-lambda-using-zip-packaging/",
      "pubDate": "2025-10-02T22:11:33.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "s3"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "s3"
      ]
    },
    {
      "id": "aws-news-1d55d1ad4c56",
      "title": "How to export to Amazon S3 Tables by using AWS Step Functions Distributed Map",
      "description": "In this post, we show how to use Step Functions Distributed Map to process Amazon S3 objects and export results to Amazon S3 Tables, creating a scalable and maintainable data processing pipeline.",
      "link": "https://aws.amazon.com/blogs/compute/how-to-export-to-amazon-s3-tables-by-using-aws-step-functions-distributed-map/",
      "pubDate": "2025-10-01T16:44:18.000Z",
      "source": "computeBlog",
      "services": [
        "s3",
        "step functions"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-0eb6b4032c21",
      "title": "Enhance the local testing experience for serverless applications with LocalStack",
      "description": "Today, we’re excited to announce new capabilities that further simplify the local testing experience for Lambda functions and serverless applications through integration with LocalStack, an AWS Partner, in the AWS Toolkit for Visual Studio Code. In this post, we will show you how you can enhance your local testing experience for serverless applications with LocalStack using AWS Toolkit.",
      "link": "https://aws.amazon.com/blogs/compute/enhance-the-local-testing-experience-for-serverless-applications-with-localstack/",
      "pubDate": "2025-09-17T17:51:30.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "localstack"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "localstack",
        "integration"
      ]
    },
    {
      "id": "aws-news-9e63742dd9e4",
      "title": "How Zapier runs isolated tasks on AWS Lambda and upgrades functions at scale",
      "description": "In this post, you’ll learn how Zapier has built their serverless architecture focusing on three key aspects: using Lambda functions to build isolated Zaps, operating over a hundred thousand Lambda functions through Zapier's control plane infrastructure, and enhancing security posture while reducing maintenance efforts by introducing automated function upgrades and cleanup workflows into their platform architecture.",
      "link": "https://aws.amazon.com/blogs/architecture/how-zapier-runs-isolated-tasks-on-aws-lambda-and-upgrades-functions-at-scale/",
      "pubDate": "2025-07-25T13:30:06.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-9eb0f60de1a7",
      "title": "How Scale to Win uses AWS WAF to block DDoS events",
      "description": "In this post, you'll learn how Scale to Win configured their network topology and AWS WAF to protect against DDoS events that reached peaks of over 2 million requests per second during the 2024 US presidential election campaign season. The post details how they implemented comprehensive DDoS protection by segmenting human and machine traffic, using tiered rate limits with CAPTCHA, and preventing CAPTCHA token reuse through AWS WAF Bot Control.",
      "link": "https://aws.amazon.com/blogs/architecture/how-scale-to-win-uses-aws-waf-to-block-ddos-events/",
      "pubDate": "2025-07-14T19:12:38.000Z",
      "source": "architectureBlog",
      "services": [
        "waf"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "waf",
        "ga"
      ]
    },
    {
      "id": "aws-news-8ab7f94aaf5b",
      "title": "Migrate and modernize VMware workloads with AWS Transform for VMware",
      "description": "AWS Transform for VMware is a service that tackles cloud migration challenges by significantly reducing manual effort and accelerating the migration of critical VMware workloads to AWS Cloud. In this post, we highlight its comprehensive capabilities, including streamlined discovery and assessment, intelligent network conversion, enhanced security and compliance, and orchestrated migration execution.",
      "link": "https://aws.amazon.com/blogs/architecture/migrate-and-modernize-vmware-workloads-with-aws-transform-for-vmware/",
      "pubDate": "2025-07-08T20:37:49.000Z",
      "source": "architectureBlog",
      "services": [
        "transform for vmware"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "transform for vmware"
      ]
    }
  ]
}