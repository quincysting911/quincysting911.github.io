{
  "lastUpdated": "2025-09-29T06:16:29.521Z",
  "category": "industry-cases",
  "totalItems": 67,
  "items": [
    {
      "id": "aws-news-c959ef8c3720",
      "title": "Building health care agents using Amazon Bedrock AgentCore",
      "description": "In this solution, we demonstrate how the user (a parent) can interact with a Strands or LangGraph agent in conversational style and get information about the immunization history and schedule of their child, inquire about the available slots, and book appointments. With some changes, AI agents can be made event-driven so that they can automatically send reminders, book appointments, and so on.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-health-care-agents-using-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-26T16:03:41.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-72cd9c93cdeb",
      "title": "Build multi-agent site reliability engineering assistants with Amazon Bedrock AgentCore",
      "description": "In this post, we demonstrate how to build a multi-agent SRE assistant using Amazon Bedrock AgentCore, LangGraph, and the Model Context Protocol (MCP). This system deploys specialized AI agents that collaborate to provide the deep, contextual intelligence that modern SRE teams need for effective incident response and infrastructure management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-multi-agent-site-reliability-engineering-assistants-with-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-26T15:58:34.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-1510ce03e38b",
      "title": "How PropHero built an intelligent property investment advisor with continuous evaluation using Amazon Bedrock",
      "description": "In this post, we explore how we built a multi-agent conversational AI system using Amazon Bedrock that delivers knowledge-grounded property investment advice. We explore the agent architecture, model selection strategy, and comprehensive continuous evaluation system that facilitates quality conversations while facilitating rapid iteration and improvement.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-prophero-built-an-intelligent-property-investment-advisor-with-continuous-evaluation-using-amazon-bedrock/",
      "pubDate": "2025-09-25T19:25:23.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "improvement"
      ]
    },
    {
      "id": "aws-news-daeb8d6f30a5",
      "title": "Accelerate benefits claims processing with Amazon Bedrock Data Automation",
      "description": "In the benefits administration industry, claims processing is a vital operational pillar that makes sure employees and beneficiaries receive timely benefits, such as health, dental, or disability payments, while controlling costs and adhering to regulations like HIPAA and ERISA. In this post, we examine the typical benefit claims processing workflow and identify where generative AI-powered automation can deliver the greatest impact.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-benefits-claims-processing-with-amazon-bedrock-data-automation/",
      "pubDate": "2025-09-25T19:20:16.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-3abb6c3c190b",
      "title": "AWS X-Ray introduces Adaptive Sampling for automatic optimized error detection",
      "description": "AWS X-Ray, a service that helps developers analyze and debug distributed applications by providing request tracing capabilities, now offers adaptive sampling to solve a common challenge for DevOps teams, Site Reliability Engineers (SREs), and application developers. These customers often face a difficult trade-off: setting sampling rates too low risks missing critical traces during incidents, while setting them too high unnecessarily increases observability costs during normal operations.            \n Today, with adaptive sampling, you can automatically adjust sampling rates within user-defined limits to ensure you capture the most important traces precisely when you need them. This helps development teams reduce mean time to resolution (MTTR) during incidents by providing comprehensive trace data for root cause analysis, while maintaining cost-efficient sampling rates during normal operations. Adaptive sampling supports two approaches, Sampling Boost and Anomaly Span Capture. These can be applied independently or can be combined together. Customers can use Sampling Boost to temporarily increase sampling rates when anomalies are detected to capture complete traces and Anomaly Span Capture to ensures anomaly-related spans are always captured, even when the full trace isn't sampled.\n Adaptive sampling is currently available in all commercial regions where AWS X-Ray is offered. For more information, see the X-Ray documentation. and CloudWatch pricing page for X-ray pricing details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-x-ray-adaptive-sampling-automatic-error/",
      "pubDate": "2025-09-25T07:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-64ef1d1304dd",
      "title": "Optimize Amazon EMR runtime for Apache Spark with EMR S3A",
      "description": "With the Amazon EMR 7.10 runtime, Amazon EMR has introduced EMR S3A, an improved implementation of the open source S3A file system connector. In this post, we showcase the enhanced read and write performance advantages of using Amazon EMR 7.10.0 runtime for Apache Spark with EMR S3A as compared to EMRFS and the open source S3A file system connector.",
      "link": "https://aws.amazon.com/blogs/big-data/optimize-amazon-emr-runtime-for-apache-spark-with-emr-s3a/",
      "pubDate": "2025-09-24T20:51:44.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-a7de025172a6",
      "title": "Amazon OpenSearch Serverless monitoring: A CloudWatch setup guide",
      "description": "In this post, we explore commonly used Amazon CloudWatch metrics and alarms for OpenSearch Serverless, walking through the process of selecting relevant metrics, setting appropriate thresholds, and configuring alerts. This guide will provide you with a comprehensive monitoring strategy that complements the serverless nature of your OpenSearch deployment while maintaining full operational visibility.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-opensearch-serverless-monitoring-a-cloudwatch-setup-guide/",
      "pubDate": "2025-09-24T16:50:25.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "ai-services",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-3f039c67eb3a",
      "title": "Accelerating SQL analytics with Amazon Redshift MCP server",
      "description": "In this post, we walk through setting up the Amazon Redshift MCP server and demonstrate how a data analyst can efficiently explore Redshift data warehouses and perform data analysis using natural language queries.",
      "link": "https://aws.amazon.com/blogs/big-data/accelerating-sql-analytics-with-amazon-redshift-mcp-server/",
      "pubDate": "2025-09-23T21:04:01.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-b648bd753ce9",
      "title": "Integrate tokenization with Amazon Bedrock Guardrails for secure data handling",
      "description": "In this post, we show you how to integrate Amazon Bedrock Guardrails with third-party tokenization services to protect sensitive data while maintaining data reversibility. By combining these technologies, organizations can implement stronger privacy controls while preserving the functionality of their generative AI applications and related systems.",
      "link": "https://aws.amazon.com/blogs/machine-learning/integrate-tokenization-with-amazon-bedrock-guardrails-for-secure-data-handling/",
      "pubDate": "2025-09-23T17:31:04.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "ai-safety",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "ga"
      ]
    },
    {
      "id": "aws-news-b8a7a01ed381",
      "title": "Accelerate AI agent development with the Nova Act IDE extension",
      "description": "The Nova Act extension is a new IDE-integrated tool that enables developers to create browser automation agents using natural language through the Nova Act model, offering features like Builder Mode, chat capabilities, and predefined templates while streamlining the development process without leaving their preferred development environment.",
      "link": "https://aws.amazon.com/blogs/aws/accelerate-ai-agent-development-with-the-nova-act-ide-extension/",
      "pubDate": "2025-09-23T16:01:04.000Z",
      "source": "newsBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "news",
        "industry-cases"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-2d74e91ea4b5",
      "title": "Amazon Nova Act extension: Build and test AI agents within your IDE",
      "description": "We’re excited today to announce the Amazon Nova Act extension - a tool that transforms how you build with Nova Act by bringing the entire agent development experience directly into IDEs like Visual Studio Code, Kiro, and Cursor. The Nova Act extension consolidates natural language based script creation, granular scripting precision, and robust browser testing into a single, unified user interface, eliminating the need to switch between multiple tools across development, validation, and iteration.\n  The Nova Act extension is built on top of the Nova Act SDK, available in research preview since March 2025. The Nova Act extension addresses feedback we have received from developers and consolidates the agent development lifecycle, from ideation to production, into one unified user interface within your IDE.\n  The Nova Act extension is available today from your IDE’s extension marketplace. The Nova Act GitHub repository includes documentation and examples to get started.\n  Learn more about the Nova Act extension and see the Nova Act extension in action at our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-nova-act-extension-build-test-ai-agents-ide/",
      "pubDate": "2025-09-23T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "preview"
      ]
    },
    {
      "id": "aws-news-bcbd7977a81b",
      "title": "AWS announces EC2 instance attestation",
      "description": "AWS announces the general availability of EC2 instance attestation to make it easier for customers to validate that only trusted software is running on their EC2 instances, including instances with AI chips and GPUs.\n  Before this, customers could configure their EC2 instances to remove operator access from their own administrators and users, but there was no way for customers to verify that a target EC2 instance had that configuration. With EC2 instance attestation, customers can cryptographically verify that their EC2 instances are running trusted configurations and software.\n  EC2 instance attestation is powered by Nitro Trusted Platform Module (NitroTPM) and Attestable Amazon Machine Images (AMIs). Customers can build an AMI that includes a cryptographic measurement representing all the contents of that AMI. Using NitroTPM, customers can then verify whether a target EC2 instance has the same measurement as the reference measurement generated by the AMI. EC2 instance attestation integrates with AWS Key Management Service (KMS), allowing customers to restrict key operations to instances that pass specific attestation conditions.\n  EC2 instance attestation is available in all AWS Commercial Regions, including the AWS GovCloud (US) Regions.\n  To get started with EC2 instance attestation, see this user guide. To build an Amazon Linux 2023 Attested AMI, see this user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-announces-ec2-instance-attestation",
      "pubDate": "2025-09-23T07:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-services",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-7936fe1cc8d5",
      "title": "Rapid ML experimentation for enterprises with Amazon SageMaker AI and Comet",
      "description": "In this post, we showed how to use SageMaker and Comet together to spin up fully managed ML environments with reproducibility and experiment tracking capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/rapid-ml-experimentation-for-enterprises-with-amazon-sagemaker-ai-and-comet/",
      "pubDate": "2025-09-22T17:12:33.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-c3a063adc2ba",
      "title": "Amazon Connect Contact Lens now provides sensitive data redaction in 7 additional languages",
      "description": "Amazon Connect Contact Lens now provides sensitive data redaction from voice and chat conversational analytics in French (France, Canada), Portuguese (Portugal, Brazil), Italian, German, and Spanish (Spain). Automatic redaction of sensitive data redaction helps you protect your customer's privacy by removing personally identifiable information (PII), financial account numbers and PINs, and Internet access details (URLs, usernames, passwords) from conversation transcripts and audio files. You can choose to redact selected or all sensitive data entities, and whether they are replaced with a generic placeholder (e.g., [PII]) or an entity-specific placeholder (e.g., [NAME]) to indicate the type of information redacted.\n  Amazon Connect is an AI-powered application that provides one seamless experience for your contact center customers and users. Contact Lens provides conversational analytics that enable you to monitor, measure, and continuously improve contact quality and agent performance for a better overall customer experience.\n  Sensitive data redaction is available in all AWS Regions where Amazon Connect is available. For more information, refer to the following list of resources:\n  \n \n \nAmazon Connect Contact Lens and pricing\n \n \nEnable redaction of sensitive information\n \n \nSupported languages",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-connect-contact-lens-redaction-7-languages/",
      "pubDate": "2025-09-22T17:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety",
        "industry-cases"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-33355eceeb89",
      "title": "Use Apache Airflow workflows to orchestrate data processing on Amazon SageMaker Unified Studio",
      "description": "Orchestrating machine learning pipelines is complex, especially when data processing, training, and deployment span multiple services and tools. In this post, we walk through a hands-on, end-to-end example of developing, testing, and running a machine learning (ML) pipeline using workflow capabilities in Amazon SageMaker, accessed through the Amazon SageMaker Unified Studio experience. These workflows are powered by Amazon Managed Workflows for Apache Airflow.",
      "link": "https://aws.amazon.com/blogs/big-data/use-apache-airflow-workflows-to-orchestrate-data-processing-on-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-09-22T16:56:56.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "lex"
      ],
      "categories": [
        "machine-learning",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "lex"
      ]
    },
    {
      "id": "aws-news-d5a772368a74",
      "title": "Move your AI agents from proof of concept to production with Amazon Bedrock AgentCore",
      "description": "This post explores how Amazon Bedrock AgentCore helps you transition your agentic applications from experimental proof of concept to production-ready systems. We follow the journey of a customer support agent that evolves from a simple local prototype to a comprehensive, enterprise-grade solution capable of handling multiple concurrent users while maintaining security and performance standards.",
      "link": "https://aws.amazon.com/blogs/machine-learning/move-your-ai-agents-from-proof-of-concept-to-production-with-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-19T16:09:26.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "experimental",
        "support"
      ]
    },
    {
      "id": "aws-news-caff1135364c",
      "title": "Trellix achieved 35% cost savings and enhanced security with Amazon OpenSearch Service",
      "description": "Trellix, a global leader in cybersecurity solutions, emerged in 2022 from the merger of McAfee Enterprise and FireEye. To address exponential log growth across their multi-tenant, multi-Region infrastructure, Trellix used Amazon OpenSearch Service, Amazon OpenSearch Ingestion, and Amazon S3 to modernize their log infrastructure. In this post, we share how, by adopting these AWS solutions, Trellix enhanced their system’s performance, availability, and scalability while reducing operational overhead.",
      "link": "https://aws.amazon.com/blogs/big-data/trellix-achieved-35-cost-savings-and-enhanced-security-with-amazon-opensearch-service/",
      "pubDate": "2025-09-19T15:48:17.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-9d7331019a86",
      "title": "Integrate Tableau and PingFederate with Amazon Redshift using AWS IAM Identity Center",
      "description": "In this post, we outline a comprehensive guide for setting up single sign-on from Tableau desktop to Amazon Redshift using integration with IAM Identity Center and PingFederate as the identity provider (IdP) with an LDAP based data store, AWS Directory Service for Microsoft Active Directory.",
      "link": "https://aws.amazon.com/blogs/big-data/integrate-tableau-and-pingfederate-with-amazon-redshift-using-aws-iam-identity-center/",
      "pubDate": "2025-09-18T22:02:45.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "integration"
      ]
    },
    {
      "id": "aws-news-151bf1dc2ea9",
      "title": "DeepSeek-V3.1 model now available in Amazon Bedrock",
      "description": "AWS launches DeepSeek-V3.1 as a fully managed models in Amazon Bedrock. DeepSeek-V3.1 is a hybrid open weight model that switches between thinking mode for detailed step-by-step analysis and non-thinking mode for faster responses.",
      "link": "https://aws.amazon.com/blogs/aws/deepseek-v3-1-now-available-in-amazon-bedrock/",
      "pubDate": "2025-09-18T21:49:48.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "news",
        "generative-ai",
        "foundation-models",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-3150c633eaf5",
      "title": "Stability AI Image Services now available in Amazon Bedrock",
      "description": "Amazon Bedrock announces the availability of Stability AI Image Services, a comprehensive suite of 9 specialized image editing tools designed to accelerate professional creative workflows. Stability AI Image Services enable granular control over image editing with a range of tools designed to work with your creative process, allowing you to take a single concept from ideation to finished product with precision and flexibility.\n  Stability AI Image Services offers two categories of image editing capabilities: Edit tools: Remove Background, Erase Object, Search and Replace, Search and Recolor, and Inpaint let you make targeted modifications to specific parts of your images. Control tools: Structure, Sketch, Style Guide, and Style Transfer give you powerful ways to generate variations based on existing images or sketches.\n  Stability AI Image Services is now available in Amazon Bedrock through the API and is supported in US West (Oregon), US East (N. Virginia), and US East (Ohio). For more information on supported regions, visit the Amazon Bedrock Model Support by Regions guide. For more details about Stability AI Image Services and its capabilities, visit the Stability AI product page and Stability AI documentation page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/stability-ai-image-services-generally-available-amazon-bedrock",
      "pubDate": "2025-09-18T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-804168525168",
      "title": "Monitor Amazon Bedrock batch inference using Amazon CloudWatch metrics",
      "description": "In this post, we explore how to monitor and manage Amazon Bedrock batch inference jobs using Amazon CloudWatch metrics, alarms, and dashboards to optimize performance, cost, and operational efficiency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/monitor-amazon-bedrock-batch-inference-using-amazon-cloudwatch-metrics/",
      "pubDate": "2025-09-18T15:33:07.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-6c3d5ab4ad37",
      "title": "Use AWS Deep Learning Containers with Amazon SageMaker AI managed MLflow",
      "description": "In this post, we show how to integrate AWS DLCs with MLflow to create a solution that balances infrastructure control with robust ML governance. We walk through a functional setup that your team can use to meet your specialized requirements while significantly reducing the time and resources needed for ML lifecycle management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/use-aws-deep-learning-containers-with-amazon-sagemaker-ai-managed-mlflow/",
      "pubDate": "2025-09-18T15:29:35.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-914f37d8d608",
      "title": "Build Agentic Workflows with OpenAI GPT OSS on Amazon SageMaker AI and Amazon Bedrock AgentCore",
      "description": "In this post, we show how to deploy gpt-oss-20b model to SageMaker managed endpoints and demonstrate a practical stock analyzer agent assistant example with LangGraph, a powerful graph-based framework that handles state management, coordinated workflows, and persistent memory systems.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-agentic-workflows-with-openai-gpt-oss-on-amazon-sagemaker-ai-and-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-17T19:31:44.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-0eb6b4032c21",
      "title": "Enhance the local testing experience for serverless applications with LocalStack",
      "description": "Today, we’re excited to announce new capabilities that further simplify the local testing experience for Lambda functions and serverless applications through integration with LocalStack, an AWS Partner, in the AWS Toolkit for Visual Studio Code. In this post, we will show you how you can enhance your local testing experience for serverless applications with LocalStack using AWS Toolkit.",
      "link": "https://aws.amazon.com/blogs/compute/enhance-the-local-testing-experience-for-serverless-applications-with-localstack/",
      "pubDate": "2025-09-17T17:51:30.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "integration"
      ]
    },
    {
      "id": "aws-news-83fa28b776e6",
      "title": "Amazon Corretto 25 is now generally available",
      "description": "Amazon Corretto 25, a Long Term Support (LTS) version, is now generally available. Amazon Corretto is a no-cost, multi-platform, production-ready distribution of OpenJDK. You can download Corretto 25 for Linux, Windows, and macOS from our downloads page.\n  Amazon Corretto 25 new features include:\n  \n \n \nTwo features that were initially released as experimental in JDK 24 are now LTS production-ready in JDK 25:\n Compact Object Headers: designed to lower heap memory usage by shrinking object headers from 96-128 bits down to 64 bits.\n Generational Shenandoah GC: engineered to provide sustainable throughput and lower p99 pause times or similar pause times with a smaller heap and reduced CPU usage.\n \n \nAhead-of-Time (AOT) Caching: designed to improve cold-start and warm-up time by reusing pre-parsed pre-linked classes and compilation profiles between training and production runs.\n \n \nLanguage improvements: primitive types in patterns, flexible constructors, module‑wide imports, compact source files, scoped values for thread-local variables, stable values for immutable data, all designed to cut boilerplate, keep everyday code shorter and safer.\n \n \nObservability: JDK Flight Recorder gains CPU‑time sampling, cooperative sampling and method‑trace events for low‑overhead production profiling.\n \n \nStructured Concurrency: designed to provide coordinated task management, allowing related tasks fail or finish together.\n \n \nVector API: developed to provide computations that compile to optimal vector instructions on supported CPUs.\n \n \nVirtual Thread pinning improvements: reduces thread pinning in synchronized blocks for better scalability.\n \n \nA detailed description of these features can be found on the OpenJDK 25 Project page. Amazon Corretto 25 is distributed by Amazon under an open source license and will be supported through October 2032.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-corretto-25-generally-available",
      "pubDate": "2025-09-17T17:18:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "experimental",
        "generally-available",
        "ga",
        "new-feature",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-f07ca5eaf4e9",
      "title": "Announcing availability of second-generation AWS Outposts racks in 52 more countries",
      "description": "Second-generation AWS Outposts racks can now be shipped and installed at your data center and on-premises locations in Australia, Bahrain, Brazil, Brunei, Chile, Costa Rica, Egypt, European Union countries, Iceland, Indonesia, Israel, Japan, Jordan, Kenya, the Kingdom of Saudi Arabia, Kuwait, Malaysia, New Zealand, Peru, the Philippines, Singapore, Trinidad and Tobago, Türkiye, the United Arab Emirates (UAE), the United Kingdom, and Vietnam.\n \nOutposts racks extend AWS infrastructure, AWS services, APIs, and tools to virtually any on-premises data center or colocation space for a truly consistent hybrid experience. Outposts racks are ideal for workloads that require low-latency access to on-premises systems, local data processing, and migration of applications with local system interdependencies. Outposts racks can also help meet data residency requirements. Second-generation Outposts racks support the latest generation of x86-powered Amazon Elastic Compute Cloud (Amazon EC2) instances, starting with C7i, M7i, and R7i instances. These instances provide up to 40% better performance compared to C5, M5, and R5 instances on first-generation Outposts racks. Second-generation Outposts racks also offer simplified network scaling and configuration, and support a new category of accelerated networking Amazon EC2 instances optimized for ultra-low latency and high throughput needs.\n \nWith the availability of second-generation Outposts racks in the above countries, you can use AWS services to run your workloads and data in country in your on-premises facilities and connect to the nearest available AWS Region for management and operations.\n \nTo learn more about second-generation Outposts racks, read this blog post and the user guide. For the most updated list of countries and territories and the AWS Regions where second-generation Outposts racks are supported, check out the Outposts racks FAQs page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/second-generation-aws-outposts-racks-more-countries",
      "pubDate": "2025-09-17T16:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-bb092a4052ee",
      "title": "Get started with Amazon OpenSearch Service: T-shirt size your domain for log analytics",
      "description": "When you’re spinning up your Amazon OpenSearch Service domain, you need to figure out the storage, instance types, and instance count; decide the sharding strategies and whether to use a cluster manager; and enable zone awareness. Generally, we consider storage as a guideline for determining instance count, but not other parameters. In this post, we […]",
      "link": "https://aws.amazon.com/blogs/big-data/get-started-with-amazon-opensearch-service-t-shirt-size-your-domain-for-log-analytics/",
      "pubDate": "2025-09-16T20:26:45.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-03c530faae0c",
      "title": "Amazon EKS introduces a new catalog of community add-ons in the AWS GovCloud (US) Regions",
      "description": "Today, Amazon Elastic Kubernetes Service (EKS) announced a new catalog of community add-ons that includes metrics-server, kube-state-metrics, cert-manager, prometheus-node-exporter, fluent-bit, and external-dns. This enables you to easily find, select, configure, and manage popular open-source Kubernetes add-ons directly through EKS. Each add-on has been packaged, scanned, and validated for compatibility by EKS, with container images securely hosted in an EKS-owned private Amazon Elastic Container Registry (ECR) repository.\n  To make Kubernetes clusters production-ready, you need to integrate various operational tools and add-ons. These add-ons can come from various sources including AWS and open-source community repositories. Now, EKS makes it easy for you to access a broader selection of add-ons, providing a unified management experience for AWS and community add-ons. You can view available add-ons, compatible versions, configuration options, and install and manage them directly through the EKS Console, API, CLI, eksctl, or IaC tools like AWS CloudFormation.\n  This feature is available in all AWS GovCloud (US) Regions. To learn more visit the EKS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-eks-community-addons-govcloud",
      "pubDate": "2025-09-16T17:49:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-15d87cb93331",
      "title": "Streamline access to ISO-rating content changes with Verisk rating insights and Amazon Bedrock",
      "description": "In this post, we dive into how Verisk Rating Insights, powered by Amazon Bedrock, large language models (LLM), and Retrieval Augmented Generation (RAG), is transforming the way customers interact with and access ISO ERC changes.",
      "link": "https://aws.amazon.com/blogs/machine-learning/streamline-access-to-iso-rating-content-changes-with-verisk-rating-insights-and-amazon-bedrock/",
      "pubDate": "2025-09-16T16:43:42.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-431447666038",
      "title": "Unified multimodal access layer for Quora’s Poe using Amazon Bedrock",
      "description": "In this post, we explore how the AWS Generative AI Innovation Center and Quora collaborated to build a unified wrapper API framework that dramatically accelerates the deployment of Amazon Bedrock FMs on Quora’s Poe system. We detail the technical architecture that bridges Poe’s event-driven ServerSentEvents protocol with Amazon Bedrock REST-based APIs, demonstrate how a template-based configuration system reduced deployment time from days to 15 minutes, and share implementation patterns for protocol translation, error handling, and multi-modal capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/unified-multimodal-access-layer-for-quoras-poe-using-amazon-bedrock/",
      "pubDate": "2025-09-16T16:40:11.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-7f6d11754731",
      "title": "Amazon EC2 supports detailed performance stats on all NVMe local volumes",
      "description": "Today, Amazon announced the availability of detailed performance statistics for Amazon EC2 instance store NVMe volumes. This new capability delivers real-time visibility into the performance of your AWS Nitro System-based EC2 instance store NVMe volumes, making it easier to monitor storage health and quickly resolve application performance issues.\n \nWith EC2 detailed performance statistics, you can access 11 comprehensive metrics at one second granularity to monitor input/output (I/O) statistics of your locally attached NVMe volumes, including queue length measurements, IOPS, throughput, and detailed I/O latency histograms. These metrics are similar to the detailed performance statistics available for EBS volumes, providing a consistent monitoring experience across both storage types. The granular visibility provided by these metrics helps you identify specific workloads affected by performance variations, and optimize your application's IO patterns for maximum efficiency. Additionally, the metrics include latency histograms broken down by IO size, providing even more detailed insights into performance patterns.\n  Detailed performance statistics for EC2 instance store NVMe volumes are available by default for all Nitro-based EC2 instances with locally attached NVMe volumes across all AWS Commercial and China Regions, at no additional charge.\n \nTo learn more about the EC2 instance store NVMe detailed performance statistics and how to access them, please visit the documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-detailed-performance-stats-nvme-local-volumes/",
      "pubDate": "2025-09-16T16:30:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-0adb2ef82e71",
      "title": "Amazon MSK Replicator and MirrorMaker2: Choosing the right replication strategy for Apache Kafka disaster recovery and migrations",
      "description": "In this post, we walk through the different considerations for using Amazon MSK Replicator over Apache Kafka’s MirrorMaker 2, and help you choose the right replication solution for your use case. We also discuss how to make applications using Amazon Managed Streaming for Apache Kafka (Amazon MSK) resilient to disasters using a multi-Region Kafka architecture using MSK Replicator.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-msk-replicator-and-mirrormaker2-choosing-the-right-replication-strategy-for-apache-kafka-disaster-recovery-and-migrations/",
      "pubDate": "2025-09-16T15:41:13.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-43f352818bda",
      "title": "Break down data silos and seamlessly query Iceberg tables in Amazon SageMaker from Snowflake",
      "description": "This blog post discusses how to create a seamless integration between Amazon SageMaker Lakehouse and Snowflake for modern data analytics. It specifically demonstrates how organizations can enable Snowflake to access tables in AWS Glue Data Catalog (stored in S3 buckets) through SageMaker Lakehouse Iceberg REST Catalog, with security managed by AWS Lake Formation. The post provides a detailed technical walkthrough of implementing this integration, including creating IAM roles and policies, configuring Lake Formation access controls, setting up catalog integration in Snowflake, and managing data access permissions. While four different patterns exist for accessing Iceberg tables from Snowflake, the blog focuses on the first pattern using catalog integration with SigV4 authentication and Lake Formation credential vending.",
      "link": "https://aws.amazon.com/blogs/big-data/break-down-data-silos-and-seamlessly-query-iceberg-tables-in-amazon-sagemaker-from-snowflake/",
      "pubDate": "2025-09-15T20:12:22.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-bd724f32f406",
      "title": "Amazon SageMaker HyperPod announces health monitoring agent support for Slurm clusters",
      "description": "Today, Amazon SageMaker HyperPod announces the general availability of the health monitoring agent for Slurm clusters. SageMaker HyperPod helps you provision resilient clusters for running machine learning (ML) workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs). The health monitoring agent performs passive, background health checks of instances to identify problems in key areas without impact on application behavior or performance, flags failures instantly, and replaces any unhealthy instances to keep your training jobs running smoothly. \n \nThe agent runs continuously on all GPU- or Trainium-based nodes in your HyperPod cluster, watching for hardware issues such as unresponsive GPUs or NVLink error counters. When a fault is detected, it marks the node as unhealthy and automatically reboots or replaces it with a healthy node, keeping your jobs running without requiring manual intervention. The agent also follows a co-ordinated approach to handling failures with the job auto-resume functionality available with Slurm clusters. For example, jobs with auto-resume enabled will continue from the last saved checkpoint once nodes are replaced by the agent. This hands-free recovery—already available on HyperPod clusters orchestrated with Amazon EKS—now gives Slurm clusters the same resilient environment, helping teams train large models for weeks without disruption and reclaim time and costs that would otherwise be lost to mid-run failures. In addition, customers can now also reboot their nodes using a simple command in case of intermittent issues such as GPU driver issues requiring reset. \n \nHealth monitoring agent for Slurm is available in all regions where HyperPod is generally available. The agent is auto-enabled on all newly created Slurm clusters; to enable it on an existing cluster, simply upgrade to the latest HyperPod AMI by calling the UpdateClusterSoftware API. To learn more, visit the Amazon SageMaker HyperPod documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-sagemaker-hyperpod-health-monitoring-agent-slurm/",
      "pubDate": "2025-09-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "trainium"
      ],
      "categories": [
        "foundation-models",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "trainium",
        "generally-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-6cabd2dd13f5",
      "title": "Schedule topology-aware workloads using Amazon SageMaker HyperPod task governance",
      "description": "In this post, we introduce topology-aware scheduling with SageMaker HyperPod task governance by submitting jobs that represent hierarchical network information. We provide details about how to use SageMaker HyperPod task governance to optimize your job efficiency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/schedule-topology-aware-workloads-using-amazon-sagemaker-hyperpod-task-governance/",
      "pubDate": "2025-09-15T17:15:20.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-3e8ef7c7d01f",
      "title": "Automate and orchestrate Amazon EMR jobs using AWS Step Functions and Amazon EventBridge",
      "description": "In this post, we discuss how to build a fully automated, scheduled Spark processing pipeline using Amazon EMR on EC2, orchestrated with Step Functions and triggered by EventBridge. We walk through how to deploy this solution using AWS CloudFormation, processes COVID-19 public dataset data in Amazon Simple Storage Service (Amazon S3), and store the aggregated results in Amazon S3.",
      "link": "https://aws.amazon.com/blogs/big-data/automate-and-orchestrate-amazon-emr-jobs-using-aws-step-functions-and-amazon-eventbridge/",
      "pubDate": "2025-09-15T17:10:24.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-713759a8235e",
      "title": "Streamline Spark application development on Amazon EMR with the Data Solutions Framework on AWS",
      "description": "In this post, we explore how to use Amazon EMR, the AWS Cloud Development Kit (AWS CDK), and the Data Solutions Framework (DSF) on AWS to streamline the development process, from setting up a local development environment to deploying serverless Spark infrastructure, and implementing a CI/CD pipeline for automated testing and deployment.",
      "link": "https://aws.amazon.com/blogs/big-data/streamline-spark-application-development-on-amazon-emr-with-the-data-solutions-framework-on-aws/",
      "pubDate": "2025-09-15T17:05:43.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-591c4b0afb89",
      "title": "How msg enhanced HR workforce transformation with Amazon Bedrock and msg.ProfileMap",
      "description": "In this post, we share how msg automated data harmonization for msg.ProfileMap, using Amazon Bedrock to power its large language model (LLM)-driven data enrichment workflows, resulting in higher accuracy in HR concept matching, reduced manual workload, and improved alignment with compliance requirements under the EU AI Act and GDPR.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-msg-enhanced-hr-workforce-transformation-with-amazon-bedrock-and-msg-profilemap/",
      "pubDate": "2025-09-15T17:05:18.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-94338f4e0c14",
      "title": "AWS Weekly Roundup: Strands Agents 1M+ downloads, Cloud Club Captain, AI Agent Hackathon, and more (September 15, 2025)",
      "description": "Last week, Strands Agents, AWS open source for agentic AI SDK just hit 1 million downloads and earned 3,000+ GitHub Stars less than 4 months since launching as a preview in May 2025. With Strands Agents, you can build production-ready, multi-agent AI systems in a few lines of code. We’ve continuously improved features including support […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-strands-agents-1m-downloads-cloud-club-captain-ai-agent-hackathon-and-more-september-15-2025/",
      "pubDate": "2025-09-15T16:45:14.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news",
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-79795044339d",
      "title": "Automate advanced agentic RAG pipeline with Amazon SageMaker AI",
      "description": "In this post, we walk through how to streamline your RAG development lifecycle from experimentation to automation, helping you operationalize your RAG solution for production deployments with Amazon SageMaker AI, helping your team experiment efficiently, collaborate effectively, and drive continuous improvement.",
      "link": "https://aws.amazon.com/blogs/machine-learning/automate-advanced-agentic-rag-pipeline-with-amazon-sagemaker-ai/",
      "pubDate": "2025-09-12T17:36:19.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "improvement"
      ]
    },
    {
      "id": "aws-news-276d02ef0edc",
      "title": "Accelerate your data and AI workflows by connecting to Amazon SageMaker Unified Studio from Visual Studio Code",
      "description": "In this post, we demonstrate how to connect your local VS Code to SageMaker Unified Studio so you can build complete end-to-end data and AI workflows while working in your preferred development environment.",
      "link": "https://aws.amazon.com/blogs/big-data/accelerate-your-data-and-ai-workflows-by-connecting-to-amazon-sagemaker-unified-studio-from-visual-studio-code/",
      "pubDate": "2025-09-12T15:59:57.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "unified studio"
      ]
    },
    {
      "id": "aws-news-1d6dabcf2cd0",
      "title": "Announcing general availability of Amazon EC2 M4 and M4 Pro Mac instances",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) M4 and M4 Pro Mac instances are now generally available (GA). M4 Mac instances offer up to 20% better application build performance compared to M2 Mac instances, while M4 Pro Mac instances deliver up to 15% better application build performance compared to M2 Pro Mac instances. These instances are ideal for building and testing applications for Apple platforms such as iOS, macOS, iPadOS, tvOS, watchOS, visionOS, and Safari.\n  M4 and M4 Pro Mac instances are powered by the AWS Nitro System, providing up to 10 Gbps network bandwidth and 8 Gbps of Amazon Elastic Block Store (Amazon EBS) storage bandwidth. M4 Mac instances are built on Apple M4 Mac Mini computers featuring 10‑core CPU, 10‑core GPU, 24GB unified memory, and 16‑core Neural Engine. M4 Pro Mac instances feature a 14‑core CPU, 20‑core GPU, 48GB unified memory, and 16‑core Neural Engine. Both instance families come with a new 2TB instance store volume per EC2 Mac Dedicated Host, providing low latency storage for improved caching and build/test performance.\n  M4 and M4 Pro Mac instances enable Apple developers to migrate their most demanding build and test workloads onto AWS and run significantly more tests in parallel using multiple Xcode simulators. This accelerates application iterations and reduces time to market. Customers now have access to the most advanced Apple silicon Macs on AWS to meet their requirements, while also enabling them to modernize their Apple CI/CD with dozens of AWS services. M4 and M4 Pro Mac instances support macOS Sequoia version 15.6 and newer AMIs (Amazon Machine Images).\n \nAmazon EC2 M4 and M4 Pro Mac instances are available in US East (N. Virginia) and US West (Oregon). To learn more or get started, see our launch blog, Amazon EC2 Mac Instances or visit the EC2 Mac documentation reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-m4-pro-mac-instances-generally-available",
      "pubDate": "2025-09-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5f7dcd4b3fbc",
      "title": "Amazon SageMaker Unified Studio supports remote connection from VS Code",
      "description": "Today, AWS announces remote connection from Visual Studio Code (VS Code) to Amazon SageMaker Unified Studio. This new capability allows developers to leverage their VS Code setup while accessing the scalable compute resources of Amazon SageMaker. By connecting VS Code to SageMaker Unified Studio, you can maintain your existing development workflows and configurations within a unified environment for AWS analytics and AI/ML services.\n  SageMaker Unified Studio, part of the next generation of Amazon SageMaker, offers a broad set of fully managed cloud interactive development environments (IDE), including JupyterLab and Code Editor based on Code-OSS (Open Source Software) like VS Code. Starting today, you can use your customized local VS Code setup while accessing your compute resources and data in Amazon SageMaker. Authentication is simple and secure using the AWS Toolkit extension in VS Code. This integration provides a streamlined path from your local development environment to scalable infrastructure for running data processing, SQL analytics, and ML workflows.\n  This feature is available in all Regions where Amazon SageMaker Unified Studio is available. To learn more, refer to the Administrator Guide and User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/sagemaker-unified-studio-vs-code/",
      "pubDate": "2025-09-12T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-40512a4b4f37",
      "title": "Migrating from API keys to service account tokens in Grafana dashboards using Terraform",
      "description": "In this blog post, we walk through how to migrate from API keys to service account tokens when automating Amazon Managed Grafana resource management. We will also show how to securely store tokens using AWS Secrets Manager and automate token rotation with AWS Lambda.",
      "link": "https://aws.amazon.com/blogs/big-data/migrating-from-api-keys-to-service-account-tokens-in-grafana-dashboards-using-terraform/",
      "pubDate": "2025-09-11T20:39:53.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-b67cea3d5f00",
      "title": "Accelerate serverless testing with LocalStack integration in VS Code IDE",
      "description": "AWS is announcing integrated LocalStack support in the AWS Toolkit for Visual Studio Code that makes it easier than ever for developers to test and debug serverless applications locally. This enhancement builds upon our recent improvements to the Lambda development experience, including the console to IDE integration and remote debugging capabilities we launched in July 2025, continuing our commitment to simplify serverless development on AWS.",
      "link": "https://aws.amazon.com/blogs/aws/accelerate-serverless-testing-with-localstack-integration-in-vs-code-ide/",
      "pubDate": "2025-09-11T18:06:05.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "improvement",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-f34706a16172",
      "title": "Build a streaming data mesh using Amazon Kinesis Data Streams",
      "description": "AWS provides two primary solutions for streaming ingestion and storage: Amazon Managed Streaming for Apache Kafka (Amazon MSK) or Amazon Kinesis Data Streams. These services are key to building a streaming mesh on AWS. In this post, we explore how to build a streaming mesh using Kinesis Data Streams.",
      "link": "https://aws.amazon.com/blogs/big-data/build-a-streaming-data-mesh-using-amazon-kinesis-data-streams/",
      "pubDate": "2025-09-10T16:50:11.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-94928335a663",
      "title": "Accessing private Amazon API Gateway endpoints through custom Amazon CloudFront distribution using VPC Origins",
      "description": "This post demonstrates how you can connect CloudFront with a Private REST API in Amazon REST API Gateway using a VPC origin.",
      "link": "https://aws.amazon.com/blogs/compute/accessing-private-amazon-api-gateway-endpoints-through-custom-amazon-cloudfront-distribution-using-vpc-origins/",
      "pubDate": "2025-09-09T17:58:21.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-8acfb46eaaa9",
      "title": "Serverless generative AI architectural patterns – Part 2",
      "description": "This post explores two complementary approaches for non-real-time scenarios: buffered asynchronous processing for time-intensive individual requests, and batch processing for scheduled or event-driven workflows.",
      "link": "https://aws.amazon.com/blogs/compute/part-2-serverless-generative-ai-architectural-patterns/",
      "pubDate": "2025-09-04T21:46:26.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-a04bdd57b5ee",
      "title": "Serverless generative AI architectural patterns – Part 1",
      "description": "This two-part series explores the different architectural patterns, best practices, code implementations, and design considerations essential for successfully integrating generative AI solutions into both new and existing applications. In this post, we focus on patterns applicable for architecting real-time generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-generative-ai-architectural-patterns/",
      "pubDate": "2025-09-04T21:45:47.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-df07ccc46610",
      "title": "Implementing advanced AWS Graviton adoption strategies across AWS Regions",
      "description": "When expanding your Graviton deployment across multiple AWS Regions, careful planning helps you navigate considerations around regional instance type availability and capacity optimization. This post shows how to implement advanced configuration strategies for Graviton-enabled EC2 Auto Scaling groups across multiple Regions, helping you maximize instance availability, reduce costs, and maintain consistent application performance even in AWS Regions with limited Graviton instance type availability.",
      "link": "https://aws.amazon.com/blogs/compute/implementing-advanced-aws-graviton-adoption-strategies-across-aws-regions/",
      "pubDate": "2025-08-26T18:26:26.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-7e2f23dd38ac",
      "title": "Simplify multi-tenant encryption with a cost-conscious AWS KMS key strategy",
      "description": "In this post, we explore an efficient approach to managing encryption keys in a multi-tenant SaaS environment through centralization, addressing challenges like key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. We demonstrate how implementing a centralized key management strategy using a single AWS KMS key per tenant can maintain security and compliance while reducing operational overhead as organizations scale.",
      "link": "https://aws.amazon.com/blogs/architecture/simplify-multi-tenant-encryption-with-a-cost-conscious-aws-kms-key-strategy/",
      "pubDate": "2025-08-21T21:54:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-0b47e55e58e4",
      "title": "AWS named as a Leader in 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for 15 years in a row",
      "description": "AWS is recognized as a Leader in the 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for the fifteenth consecutive year. In the report, Gartner once again placed AWS highest on the “Ability to Execute” axis. We believe this reflects our ongoing commitment to giving customers the broadest and deepest set of capabilities to accelerate innovation as well as unparalleled security, reliability, and performance they can trust for their most critical applications.",
      "link": "https://aws.amazon.com/blogs/aws/aws-named-as-a-leader-in-2025-gartner-magic-quadrant-for-strategic-cloud-platform-services-for-15-years-in-a-row/",
      "pubDate": "2025-08-15T16:59:11.000Z",
      "source": "newsBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "news",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "foundation-models",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-81c6c3e233a5",
      "title": "AWS Weekly Roundup: OpenAI models, Automated Reasoning checks, Amazon EVS, and more (August 11, 2025)",
      "description": "AWS Summits in the northern hemisphere have mostly concluded but the fun and learning hasn’t yet stopped for those of us in other parts of the globe. The community, customers, partners, and colleagues enjoyed a day of learning and networking last week at the AWS Summit Mexico City and the AWS Summit Jakarta. Last week’s […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-openai-models-automated-reasoning-checks-amazon-evs-and-more-august-11-2025/",
      "pubDate": "2025-08-11T16:05:01.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-158c07987a55",
      "title": "Improving network observability with new AWS Outposts racks network metrics",
      "description": "With AWS Outposts racks, you can extend AWS infrastructure, services, APIs, and tools to on-premises locations. Providing performant, stable, and resilient network connections to both the parent AWS Region as well as the local network is essential to maintaining uninterrupted service. The release of two new Amazon CloudWatch metrics, VifConnectionStatus and VifBgpSessionState, gives you greater visibility into the operational status of the Outpost network connections. In this post, we discuss how to use these metrics to quickly identify network disruptions, using additional data points that can help reduce time to resolution.",
      "link": "https://aws.amazon.com/blogs/compute/improving-network-observability-with-new-aws-outposts-racks-network-metrics/",
      "pubDate": "2025-08-06T17:30:30.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-9e63742dd9e4",
      "title": "How Zapier runs isolated tasks on AWS Lambda and upgrades functions at scale",
      "description": "In this post, you’ll learn how Zapier has built their serverless architecture focusing on three key aspects: using Lambda functions to build isolated Zaps, operating over a hundred thousand Lambda functions through Zapier's control plane infrastructure, and enhancing security posture while reducing maintenance efforts by introducing automated function upgrades and cleanup workflows into their platform architecture.",
      "link": "https://aws.amazon.com/blogs/architecture/how-zapier-runs-isolated-tasks-on-aws-lambda-and-upgrades-functions-at-scale/",
      "pubDate": "2025-07-25T13:30:06.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-11d98a88cbe1",
      "title": "Implement monitoring for Amazon EKS with managed services",
      "description": "In this post, we show you how to implement comprehensive monitoring for Amazon Elastic Kubernetes Service (Amazon EKS) workloads using AWS managed services. This solution demonstrates building an EKS platform that combines flexible compute options with enterprise-grade observability using AWS native services and OpenTelemetry.",
      "link": "https://aws.amazon.com/blogs/architecture/implement-monitoring-for-amazon-eks-with-managed-services/",
      "pubDate": "2025-07-18T15:47:13.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-b0328ad8bafd",
      "title": "Deploying external boot volumes with AWS Outposts",
      "description": "Building on our previous announcement, AWS Outposts third-party storage integration for data volumes, AWS is expanding its collaboration with third-party storage solutions by introducing support for boot volumes backed by external storage arrays. In this post we show you how to boot Amazon Elastic Compute Cloud (Amazon EC2) instances on Outposts directly from NetApp on-premise […]",
      "link": "https://aws.amazon.com/blogs/compute/deploying-external-boot-volumes-with-aws-outposts/",
      "pubDate": "2025-07-17T21:18:52.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "integration",
        "support",
        "announcement"
      ]
    },
    {
      "id": "aws-news-9eb0f60de1a7",
      "title": "How Scale to Win uses AWS WAF to block DDoS events",
      "description": "In this post, you'll learn how Scale to Win configured their network topology and AWS WAF to protect against DDoS events that reached peaks of over 2 million requests per second during the 2024 US presidential election campaign season. The post details how they implemented comprehensive DDoS protection by segmenting human and machine traffic, using tiered rate limits with CAPTCHA, and preventing CAPTCHA token reuse through AWS WAF Bot Control.",
      "link": "https://aws.amazon.com/blogs/architecture/how-scale-to-win-uses-aws-waf-to-block-ddos-events/",
      "pubDate": "2025-07-14T19:12:38.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-8ab7f94aaf5b",
      "title": "Migrate and modernize VMware workloads with AWS Transform for VMware",
      "description": "AWS Transform for VMware is a service that tackles cloud migration challenges by significantly reducing manual effort and accelerating the migration of critical VMware workloads to AWS Cloud. In this post, we highlight its comprehensive capabilities, including streamlined discovery and assessment, intelligent network conversion, enhanced security and compliance, and orchestrated migration execution.",
      "link": "https://aws.amazon.com/blogs/architecture/migrate-and-modernize-vmware-workloads-with-aws-transform-for-vmware/",
      "pubDate": "2025-07-08T20:37:49.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-7a855eaafa04",
      "title": "Simplifying sustainability reporting using AWS and generative AI in banking",
      "description": "In this post, you learn how you can use generative AI services on Amazon Web Services (AWS) to automate your sustainability reporting requirements, reduce manual effort, and improve accuracy. You do this by implementing an automated solution for extracting, processing, and validating data from corporate reports.",
      "link": "https://aws.amazon.com/blogs/architecture/simplifying-sustainability-reporting-using-aws-and-generative-ai-in-banking/",
      "pubDate": "2025-06-26T17:54:46.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-2355834bf9d4",
      "title": "Amazon Bedrock baseline architecture in an AWS landing zone",
      "description": "In this post, we explore the Amazon Bedrock baseline architecture and how you can secure and control network access to your various Amazon Bedrock capabilities within AWS network services and tools. We discuss key design considerations, such as using Amazon VPC Lattice auth policies, Amazon Virtual Private Cloud (Amazon VPC) endpoints, and AWS Identity and Access Management (IAM) to restrict and monitor access to your Amazon Bedrock capabilities.",
      "link": "https://aws.amazon.com/blogs/architecture/amazon-bedrock-baseline-architecture-in-an-aws-landing-zone/",
      "pubDate": "2025-06-23T18:36:51.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-8035da78b9bd",
      "title": "Analyze media content using AWS AI services",
      "description": "Organizations managing large audio and video archives face significant challenges in extracting value from their media content. Consider a radio network with thousands of broadcast hours across multiple stations and the challenges they face to efficiently verify ad placements, identify interview segments, and analyze programming patterns. In this post, we demonstrate how you can automatically transform unstructured media files into searchable, analyzable content.",
      "link": "https://aws.amazon.com/blogs/architecture/analyze-media-content-using-aws-ai-services/",
      "pubDate": "2025-06-02T16:25:10.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-46a5eae9af95",
      "title": "How Launchpad from Pega enables secure SaaS extensibility with AWS Lambda",
      "description": "In this post, we share how Pegasystems (Pega) built Launchpad, its new SaaS development platform, to solve a core challenge in multi-tenant environments: enabling secure customer customization. By running tenant code in isolated environments with AWS Lambda, Launchpad offers its customers a secure, scalable foundation, eliminating the need for bespoke code customizations.",
      "link": "https://aws.amazon.com/blogs/architecture/how-launchpad-from-pega-enables-secure-saas-extensibility-with-aws-lambda/",
      "pubDate": "2025-05-30T18:30:49.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-312b490ab1a6",
      "title": "Improving platform resilience at Cash App",
      "description": "Cash App, a leading peer-to-peer payments and digital wallet service from Block, Inc., has implemented resilience improvements across the entire technology stack. In this post, we discuss how Cash App improved the resilience of its compute platform built on Amazon Elastic Kubernetes Service (Amazon EKS) by implementing a dual-cluster topology to reduce single points of failure. We also discuss how Cash App used AWS Fault Injection Service (AWS FIS) to conduct an Availability Zone power interruption scenario in non-production environments, preparing the platform team for real-world failures and ongoing",
      "link": "https://aws.amazon.com/blogs/architecture/improving-platform-resilience-at-cash-app/",
      "pubDate": "2025-05-29T15:10:40.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "improvement"
      ]
    },
    {
      "id": "aws-news-6a09dfeff5cf",
      "title": "Optimizing fleet operations using Amazon SageMaker AI and Amazon Bedrock",
      "description": "In this post, we'll explore how to maximize the value of dashcam footage through best practices for implementing and managing Computer Vision systems in commercial fleet operations. We'll demonstrate how to build and deploy edge-based machine learning models that provide real-time alerts for distracted driving behaviors, while effectively collecting, processing, and analyzing footage to train these AI models.",
      "link": "https://aws.amazon.com/blogs/architecture/optimizing-fleet-operations-using-amazon-sagemaker-ai-and-amazon-bedrock/",
      "pubDate": "2025-05-28T18:29:26.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "sagemaker"
      ]
    }
  ]
}