{
  "lastUpdated": "2025-11-11T06:16:06.337Z",
  "category": "industry-cases",
  "totalItems": 18,
  "items": [
    {
      "id": "aws-news-a104392c9b46",
      "title": "Analyzing Amazon EC2 Spot instance interruptions by using event-driven architecture",
      "description": "In this post, you'll learn how to build this comprehensive monitoring solution step-by-step. You'll gain practical experience designing an event-driven pipeline, implementing data processing workflows, and creating insightful dashboards that help you track interruption trends, optimize ASG configurations, and improve the resilience of your Spot Instance workloads.",
      "link": "https://aws.amazon.com/blogs/big-data/analyzing-amazon-ec2-spot-instance-interruptions-by-using-event-driven-architecture/",
      "pubDate": "2025-11-10T22:05:20.000Z",
      "source": "bigDataBlog",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ec2",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-2bb659aa2d5a",
      "title": "Amazon CloudWatch Database Insights expands anomaly detection in on-demand analysis",
      "description": "Amazon CloudWatch Database Insights now detects anomalies on additional metrics through its on-demand analysis experience. Database Insights is a monitoring and diagnostics solution that helps database administrators and application developers optimize database performance by providing comprehensive visibility into database metrics, query performance, and resource utilization patterns. The on-demand analysis feature utilizes machine learning to help identify anomalies and performance bottlenecks during the selected time period, and gives advice on what to do next.\n  The Database Insights on-demand analysis feature now offers enhanced anomaly detection capabilities. Previously, database administrators could analyze database performance and correlate metrics based on database load. Now, the on-demand analysis report also identifies anomalies in database-level and operating system-level counter metrics for the database instance, as well as per-SQL metrics for the top SQL statements contributing to database load. The feature automatically compares your selected time period against normal baseline performance, identifies anomalies, and provides specific remediation advice while reducing mean time to diagnosis. Through intuitive visualizations and clear explanations, you can quickly identify performance issues and receive step-by-step guidance for resolution.\n  You can get started with on-demand analysis by enabling the Advanced mode of CloudWatch Database Insights on your Amazon Aurora or RDS databases using the AWS management console, AWS APIs, or AWS CloudFormation. Please refer to RDS documentation and Aurora documentation for information regarding the availability of Database Insights across different regions, engines, and instance classes.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-database-insights-anomaly-detection/",
      "pubDate": "2025-11-05T21:58:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudformation",
        "cloudwatch"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds",
        "cloudformation",
        "cloudwatch",
        "ga"
      ]
    },
    {
      "id": "aws-news-e1b9bc0ad451",
      "title": "AWS Marketplace now open for India-based sellers supporting transactions in Indian Rupees (INR)",
      "description": "Buyers and sellers in India can now transact locally in AWS Marketplace, with invoicing in Indian Rupees (INR), and with simplified tax compliance through AWS India. With this launch, India-based sellers can now register to sell in AWS Marketplace and offer paid subscriptions to buyers in India. India-based sellers will be able to create private offers in US dollars (USD) or INR. Buyers in India purchasing paid offerings in AWS Marketplace from India-based sellers will receive invoices in INR, helping to simplify invoicing with consistency across AWS Cloud and AWS Marketplace purchases. Sellers based in India can begin selling paid offerings in AWS Marketplace and can work with India-based Channel Partners to sell to customers.\n  AWS India will facilitate the issuance of tax-compliant invoices in INR to buyers, with the independent software vendor (ISV) or Channel Partner as the seller of record. AWS India will automate the collection and remittance of Withholding Tax (WHT) and GST-Tax Collected at Source (GST-TCS) to the relevant tax authorities, fulfilling compliance requirements for buyers. During this phase, non-India based sellers can continue to sell directly to buyers in India through AWS Inc., in USD or through AWS India by working through authorized distributors.\n  To learn more and explore solutions available from India-based sellers, visit this page. To get started as a seller, India-based ISVs and Channel Partners can register in the AWS Marketplace Management Portal. For more information about buying or selling using AWS Marketplace in India, visit the India FAQs page and help guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-marketplace-india-based-sellers-transactions-inr",
      "pubDate": "2025-11-05T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-a14aa54b7cee",
      "title": "Orchestrating big data processing with AWS Step Functions Distributed Map",
      "description": "In this post, you'll learn how to use AWS Step Functions Distributed Map to process Amazon Athena data manifest and Parquet files through a step-by-step demonstration.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-big-data-processing-with-aws-step-functions-distributed-map/",
      "pubDate": "2025-11-04T23:42:01.000Z",
      "source": "computeBlog",
      "services": [
        "athena",
        "step functions"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "athena",
        "step functions"
      ]
    },
    {
      "id": "aws-news-2e8f1dc21abc",
      "title": "Amazon Kinesis Data Streams launches On-demand Advantage mode",
      "description": "Amazon Kinesis Data Streams launches On-demand Advantage, so customers can warm on-demand streams to handle instant throughput increases up to 10GB or 10 million events per second, eliminating the need to over-provision or build custom scaling solutions. Amazon Kinesis Data Streams is a serverless streaming data service that makes it easy to capture, process, and store data streams at any scale. On-demand streams automatically scale capacity based on data usage, and now you can warm write capacity ad hoc. On-demand Advantage also provides a simpler pricing structure that removes the fixed, per-stream charge, so customers only pay for data usage at better rates.\n  On-demand Advantage offers data usage with 60% lower pricing compared to On-demand Standard, with data ingest at $0.032/GB and data retrieval at $0.016/GB in the US East (N. Virginia) region. The price of Enhanced fan-out data retrieval is the same as shared-throughput retrievals, making higher fan-out use cases more cost effective. The mode also decreases the price of extended retention by 77% from $0.10/GB-month to $0.023/GB-month. Once you enable On-demand Advantage mode, the account will be billed for a minimum of 25MB/s of data ingest and 25MB/s of data retrieval at the lower rates across all on-demand streams. The new pricing means On-demand Advantage is the most cost effective way to stream with Kinesis Data Streams when you ingest at least 10MB/s in aggregate, fan out to more than two consumer applications, or have hundreds of streams in a region. You can check directly in the Kinesis console and the pricing page if On-demand Advantage is a good fit for your account.\n  On-demand Advantage is available in all AWS regions where Kinesis Data Streams is available, including AWS GovCloud (US) and China regions. To learn more, see the launch blog and the Kinesis Data Streams User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-kinesis-data-streams-ondemand-advantage",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kinesis"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kinesis",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-5625caee948f",
      "title": "Amazon Kinesis Data Streams launches On-demand Advantage for instant throughput increases and streaming at scale",
      "description": "Today, AWS announced the new Amazon Kinesis Data Streams On-demand Advantage mode, which includes warm throughput capability and an updated pricing structure. With this feature you can enable instant scaling for traffic surges while optimizing costs for consistent streaming workloads. In this post, we explore this new feature, including key use cases, configuration options, pricing considerations, and best practices for optimal performance.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-kinesis-data-streams-launches-on-demand-advantage-for-instant-throughput-increases-and-streaming-at-scale/",
      "pubDate": "2025-11-03T22:00:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "kinesis"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kinesis",
        "launch",
        "new-feature",
        "update"
      ]
    },
    {
      "id": "aws-news-1998e227992a",
      "title": "Scaling data governance with Amazon DataZone: Covestro success story",
      "description": "In this post, we show you how Covestro transformed its data architecture by implementing Amazon DataZone and AWS Serverless Data Lake Framework, transitioning from a centralized data lake to a data mesh architecture. The implementation enabled streamlined data access, better data quality, and stronger governance at scale, achieving a 70% reduction in time-to-market for over 1,000 data pipelines.",
      "link": "https://aws.amazon.com/blogs/big-data/scaling-data-governance-with-amazon-datazone-covestro-success-story/",
      "pubDate": "2025-11-03T21:02:06.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-a02cdaaf7b2d",
      "title": "Mountpoint for Amazon S3 and Mountpoint for Amazon S3 CSI driver add monitoring capability",
      "description": "You can now monitor Mountpoint operations in observability tools such as Amazon CloudWatch, Prometheus, and Grafana. With this launch, Mountpoint emits near real-time metrics such as request count or request latency using OpenTelemetry Protocol (OTLP), an open source data transmission protocol. This means you can use applications such as CloudWatch agent or the OpenTelemetry (OTel) collector to publish the metrics into observability tools and create dashboards for monitoring and troubleshooting.\n  Previously, Mountpoint emitted operational data into log files, and you needed to create custom tools to parse the log files for insights. Now, when you mount your Amazon S3 bucket, you can configure Mountpoint to publish the metrics to an observability tool to proactively monitor issues that might impact your applications. For example, you can check if an application is unable to access S3 due to permission issues by analyzing the S3 request error metric that provides error types at an Amazon EC2 instance granularity.\n  Follow the step-by-step instructions to set up the CloudWatch agent or the OTel collector and configure Mountpoint to publish metrics into an observability tool. For more information, visit the Mountpoint for Amazon S3 GitHub repository, Mountpoint product page, and Mountpoint for Amazon S3 CSI driver GitHub page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/mountpoint-amazon-s3-csi-driver-monitoring-capability",
      "pubDate": "2025-11-03T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "ec2",
        "rds",
        "cloudwatch",
        "grafana"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "s3",
        "ec2",
        "rds",
        "cloudwatch",
        "grafana",
        "launch"
      ]
    },
    {
      "id": "aws-news-ecd42bafa0a3",
      "title": "Introducing the Capacity Reservation Topology API for AI, ML, and HPC instance types",
      "description": "AWS announces the general availability of the Amazon Elastic Compute Cloud (EC2) Capacity Reservation Topology API. It joins the Instance Topology API in enabling customers to efficiently manage capacity, schedule jobs, and rank nodes for Artificial Intelligence, Machine Learning, and High-Performance Computing distributed workloads. The Capacity Reservation Topology API gives customers a unique per-account hierarchical view of the relative location of their capacity reservations.\n \nCustomers running distributed parallel workloads are managing thousands of instances across tens to hundreds of capacity reservations. With the Capacity Reservation Topology API, customers can describe the topology of their reservations as a network node set, which will show the relative proximity of their capacity without the need to launch an instance. This enables efficient capacity planning and management as customers provision workloads on tightly coupled capacity. Customers can then use the Instance Topology API, which provides consistent network nodes from the Capacity Reservation Topology API with further granularity, enabling a consistent and seamless way to schedule jobs and rank nodes for optimal performance in distributed parallel workloads.\n \nThe Capacity Reservation Topology API is available in the following AWS regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Africa (Cape Town), Asia Pacific (Jakarta), Asia Pacific (Hong Kong), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Asia Pacific (Mumbai), Asia Pacific (Osaka), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Spain), Europe (Stockholm), Europe (Zurich), Middle East (Bahrain), Middle East (UAE), and South America (São Paulo), and it is supported on all instances available with the Instance Topology API.\n \nTo learn more, please visit the latest EC2 user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/capacity-reservation-topology-api-ai-ml-hpc-instance-type",
      "pubDate": "2025-10-30T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ec2",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-9063c25bf316",
      "title": "Amazon DocumentDB (with MongoDB compatibility) announces upgraded query planner that can run queries up to 10x faster",
      "description": "Today, Amazon DocumentDB (with MongoDB compatibility) announces a new query planner, featuring advanced query optimization capabilities and improved performance. PlannerVersion 2.0 for Amazon DocumentDB (with MongoDB compatibility) 5.0 delivers up to 10x performance improvement over the prior version when using find and update operators with indexes. Performance improvements primarily come from using more optimal index plans and enabling index scan support for operators such as negation operators ($neq, $nin) and nested $elementMatch. PlannerVersion 2.0 queries run faster through better cost estimation techniques, optimized algorithms, and enhanced stability.\n \nPlannerVersion 2.0 also simplifies query syntax. For example, you no longer need to provide explicit hints for $regex queries to utilize indexes.\n \nPlannerVersion 2.0 is available in all AWS Regions where Amazon DocumentDB 5.0 is supported. You can enable it by simply modifying the corresponding parameter in your cluster parameter group. The change does not require a cluster restart or cause any downtime. If needed, you can easily revert to using the legacy query planner. To learn more about the new query planner, see Getting Started with New Query Planner.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/new-query-planner",
      "pubDate": "2025-10-28T07:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-b147351ed9fa",
      "title": "Upgrade from Amazon Redshift DC2 node type to Amazon Redshift Serverless",
      "description": "In this post, we show you the upgrade process from DC2 instances to Amazon Redshift Serverless. By using Amazon Redshift Serverless, you can run and scale analytics without managing data warehouse infrastructure.",
      "link": "https://aws.amazon.com/blogs/big-data/upgrade-from-amazon-redshift-dc2-node-type-to-amazon-redshift-serverless/",
      "pubDate": "2025-10-22T21:04:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "redshift"
      ]
    },
    {
      "id": "aws-news-11031ecd9926",
      "title": "Zero downtime blue/green deployments with Amazon API Gateway",
      "description": "In this post, you learn how to implement blue/green deployments by using Amazon API Gateway for your APIs. For this post, we use AWS Lambda functions on the backend. However, you can follow the same strategy for other backend implementations of the APIs. All the required infrastructure is deployed by using AWS Serverless Application Model (AWS SAM).",
      "link": "https://aws.amazon.com/blogs/compute/zero-downtime-blue-green-deployments-with-amazon-api-gateway/",
      "pubDate": "2025-10-16T19:01:22.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-1cf24c6b0f9d",
      "title": "Deploying AI models for inference with AWS Lambda using zip packaging",
      "description": "Users usually package their function code as container images when using machine learning (ML) models that are larger than 250 MB, which is the Lambda deployment package size limit for zip files. In this post, we demonstrate an approach that downloads ML models directly from Amazon S3 into your function’s memory so that you can continue packaging your function code using zip files.",
      "link": "https://aws.amazon.com/blogs/compute/deploying-ai-models-for-inference-with-aws-lambda-using-zip-packaging/",
      "pubDate": "2025-10-02T22:11:33.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "s3"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "s3"
      ]
    },
    {
      "id": "aws-news-1d55d1ad4c56",
      "title": "How to export to Amazon S3 Tables by using AWS Step Functions Distributed Map",
      "description": "In this post, we show how to use Step Functions Distributed Map to process Amazon S3 objects and export results to Amazon S3 Tables, creating a scalable and maintainable data processing pipeline.",
      "link": "https://aws.amazon.com/blogs/compute/how-to-export-to-amazon-s3-tables-by-using-aws-step-functions-distributed-map/",
      "pubDate": "2025-10-01T16:44:18.000Z",
      "source": "computeBlog",
      "services": [
        "s3",
        "step functions"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-0eb6b4032c21",
      "title": "Enhance the local testing experience for serverless applications with LocalStack",
      "description": "Today, we’re excited to announce new capabilities that further simplify the local testing experience for Lambda functions and serverless applications through integration with LocalStack, an AWS Partner, in the AWS Toolkit for Visual Studio Code. In this post, we will show you how you can enhance your local testing experience for serverless applications with LocalStack using AWS Toolkit.",
      "link": "https://aws.amazon.com/blogs/compute/enhance-the-local-testing-experience-for-serverless-applications-with-localstack/",
      "pubDate": "2025-09-17T17:51:30.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "localstack"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "localstack",
        "integration"
      ]
    },
    {
      "id": "aws-news-9e63742dd9e4",
      "title": "How Zapier runs isolated tasks on AWS Lambda and upgrades functions at scale",
      "description": "In this post, you’ll learn how Zapier has built their serverless architecture focusing on three key aspects: using Lambda functions to build isolated Zaps, operating over a hundred thousand Lambda functions through Zapier's control plane infrastructure, and enhancing security posture while reducing maintenance efforts by introducing automated function upgrades and cleanup workflows into their platform architecture.",
      "link": "https://aws.amazon.com/blogs/architecture/how-zapier-runs-isolated-tasks-on-aws-lambda-and-upgrades-functions-at-scale/",
      "pubDate": "2025-07-25T13:30:06.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-9eb0f60de1a7",
      "title": "How Scale to Win uses AWS WAF to block DDoS events",
      "description": "In this post, you'll learn how Scale to Win configured their network topology and AWS WAF to protect against DDoS events that reached peaks of over 2 million requests per second during the 2024 US presidential election campaign season. The post details how they implemented comprehensive DDoS protection by segmenting human and machine traffic, using tiered rate limits with CAPTCHA, and preventing CAPTCHA token reuse through AWS WAF Bot Control.",
      "link": "https://aws.amazon.com/blogs/architecture/how-scale-to-win-uses-aws-waf-to-block-ddos-events/",
      "pubDate": "2025-07-14T19:12:38.000Z",
      "source": "architectureBlog",
      "services": [
        "waf"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "waf",
        "ga"
      ]
    },
    {
      "id": "aws-news-8ab7f94aaf5b",
      "title": "Migrate and modernize VMware workloads with AWS Transform for VMware",
      "description": "AWS Transform for VMware is a service that tackles cloud migration challenges by significantly reducing manual effort and accelerating the migration of critical VMware workloads to AWS Cloud. In this post, we highlight its comprehensive capabilities, including streamlined discovery and assessment, intelligent network conversion, enhanced security and compliance, and orchestrated migration execution.",
      "link": "https://aws.amazon.com/blogs/architecture/migrate-and-modernize-vmware-workloads-with-aws-transform-for-vmware/",
      "pubDate": "2025-07-08T20:37:49.000Z",
      "source": "architectureBlog",
      "services": [
        "transform for vmware"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "transform for vmware"
      ]
    }
  ]
}