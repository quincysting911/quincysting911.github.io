{
  "lastUpdated": "2025-09-28T12:08:45.898Z",
  "category": "industry-cases",
  "totalItems": 29,
  "items": [
    {
      "id": "aws-news-c959ef8c3720",
      "title": "Building health care agents using Amazon Bedrock AgentCore",
      "description": "In this solution, we demonstrate how the user (a parent) can interact with a Strands or LangGraph agent in conversational style and get information about the immunization history and schedule of their child, inquire about the available slots, and book appointments. With some changes, AI agents can be made event-driven so that they can automatically send reminders, book appointments, and so on.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-health-care-agents-using-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-26T16:03:41.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-72cd9c93cdeb",
      "title": "Build multi-agent site reliability engineering assistants with Amazon Bedrock AgentCore",
      "description": "In this post, we demonstrate how to build a multi-agent SRE assistant using Amazon Bedrock AgentCore, LangGraph, and the Model Context Protocol (MCP). This system deploys specialized AI agents that collaborate to provide the deep, contextual intelligence that modern SRE teams need for effective incident response and infrastructure management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-multi-agent-site-reliability-engineering-assistants-with-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-26T15:58:34.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-1510ce03e38b",
      "title": "How PropHero built an intelligent property investment advisor with continuous evaluation using Amazon Bedrock",
      "description": "In this post, we explore how we built a multi-agent conversational AI system using Amazon Bedrock that delivers knowledge-grounded property investment advice. We explore the agent architecture, model selection strategy, and comprehensive continuous evaluation system that facilitates quality conversations while facilitating rapid iteration and improvement.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-prophero-built-an-intelligent-property-investment-advisor-with-continuous-evaluation-using-amazon-bedrock/",
      "pubDate": "2025-09-25T19:25:23.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "improvement"
      ]
    },
    {
      "id": "aws-news-daeb8d6f30a5",
      "title": "Accelerate benefits claims processing with Amazon Bedrock Data Automation",
      "description": "In the benefits administration industry, claims processing is a vital operational pillar that makes sure employees and beneficiaries receive timely benefits, such as health, dental, or disability payments, while controlling costs and adhering to regulations like HIPAA and ERISA. In this post, we examine the typical benefit claims processing workflow and identify where generative AI-powered automation can deliver the greatest impact.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-benefits-claims-processing-with-amazon-bedrock-data-automation/",
      "pubDate": "2025-09-25T19:20:16.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-b648bd753ce9",
      "title": "Integrate tokenization with Amazon Bedrock Guardrails for secure data handling",
      "description": "In this post, we show you how to integrate Amazon Bedrock Guardrails with third-party tokenization services to protect sensitive data while maintaining data reversibility. By combining these technologies, organizations can implement stronger privacy controls while preserving the functionality of their generative AI applications and related systems.",
      "link": "https://aws.amazon.com/blogs/machine-learning/integrate-tokenization-with-amazon-bedrock-guardrails-for-secure-data-handling/",
      "pubDate": "2025-09-23T17:31:04.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "ga"
      ]
    },
    {
      "id": "aws-news-b8a7a01ed381",
      "title": "Accelerate AI agent development with the Nova Act IDE extension",
      "description": "The Nova Act extension is a new IDE-integrated tool that enables developers to create browser automation agents using natural language through the Nova Act model, offering features like Builder Mode, chat capabilities, and predefined templates while streamlining the development process without leaving their preferred development environment.",
      "link": "https://aws.amazon.com/blogs/aws/accelerate-ai-agent-development-with-the-nova-act-ide-extension/",
      "pubDate": "2025-09-23T16:01:04.000Z",
      "source": "news-blog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-2d74e91ea4b5",
      "title": "Amazon Nova Act extension: Build and test AI agents within your IDE",
      "description": "We’re excited today to announce the Amazon Nova Act extension - a tool that transforms how you build with Nova Act by bringing the entire agent development experience directly into IDEs like Visual Studio Code, Kiro, and Cursor. The Nova Act extension consolidates natural language based script creation, granular scripting precision, and robust browser testing into a single, unified user interface, eliminating the need to switch between multiple tools across development, validation, and iteration.\n  The Nova Act extension is built on top of the Nova Act SDK, available in research preview since March 2025. The Nova Act extension addresses feedback we have received from developers and consolidates the agent development lifecycle, from ideation to production, into one unified user interface within your IDE.\n  The Nova Act extension is available today from your IDE’s extension marketplace. The Nova Act GitHub repository includes documentation and examples to get started.\n  Learn more about the Nova Act extension and see the Nova Act extension in action at our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-nova-act-extension-build-test-ai-agents-ide/",
      "pubDate": "2025-09-23T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "preview"
      ]
    },
    {
      "id": "aws-news-7936fe1cc8d5",
      "title": "Rapid ML experimentation for enterprises with Amazon SageMaker AI and Comet",
      "description": "In this post, we showed how to use SageMaker and Comet together to spin up fully managed ML environments with reproducibility and experiment tracking capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/rapid-ml-experimentation-for-enterprises-with-amazon-sagemaker-ai-and-comet/",
      "pubDate": "2025-09-22T17:12:33.000Z",
      "source": "ml-blog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-c3a063adc2ba",
      "title": "Amazon Connect Contact Lens now provides sensitive data redaction in 7 additional languages",
      "description": "Amazon Connect Contact Lens now provides sensitive data redaction from voice and chat conversational analytics in French (France, Canada), Portuguese (Portugal, Brazil), Italian, German, and Spanish (Spain). Automatic redaction of sensitive data redaction helps you protect your customer's privacy by removing personally identifiable information (PII), financial account numbers and PINs, and Internet access details (URLs, usernames, passwords) from conversation transcripts and audio files. You can choose to redact selected or all sensitive data entities, and whether they are replaced with a generic placeholder (e.g., [PII]) or an entity-specific placeholder (e.g., [NAME]) to indicate the type of information redacted.\n  Amazon Connect is an AI-powered application that provides one seamless experience for your contact center customers and users. Contact Lens provides conversational analytics that enable you to monitor, measure, and continuously improve contact quality and agent performance for a better overall customer experience.\n  Sensitive data redaction is available in all AWS Regions where Amazon Connect is available. For more information, refer to the following list of resources:\n  \n \n \nAmazon Connect Contact Lens and pricing\n \n \nEnable redaction of sensitive information\n \n \nSupported languages",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-connect-contact-lens-redaction-7-languages/",
      "pubDate": "2025-09-22T17:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-d5a772368a74",
      "title": "Move your AI agents from proof of concept to production with Amazon Bedrock AgentCore",
      "description": "This post explores how Amazon Bedrock AgentCore helps you transition your agentic applications from experimental proof of concept to production-ready systems. We follow the journey of a customer support agent that evolves from a simple local prototype to a comprehensive, enterprise-grade solution capable of handling multiple concurrent users while maintaining security and performance standards.",
      "link": "https://aws.amazon.com/blogs/machine-learning/move-your-ai-agents-from-proof-of-concept-to-production-with-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-19T16:09:26.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "experimental",
        "support"
      ]
    },
    {
      "id": "aws-news-151bf1dc2ea9",
      "title": "DeepSeek-V3.1 model now available in Amazon Bedrock",
      "description": "AWS launches DeepSeek-V3.1 as a fully managed models in Amazon Bedrock. DeepSeek-V3.1 is a hybrid open weight model that switches between thinking mode for detailed step-by-step analysis and non-thinking mode for faster responses.",
      "link": "https://aws.amazon.com/blogs/aws/deepseek-v3-1-now-available-in-amazon-bedrock/",
      "pubDate": "2025-09-18T21:49:48.000Z",
      "source": "news-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-3150c633eaf5",
      "title": "Stability AI Image Services now available in Amazon Bedrock",
      "description": "Amazon Bedrock announces the availability of Stability AI Image Services, a comprehensive suite of 9 specialized image editing tools designed to accelerate professional creative workflows. Stability AI Image Services enable granular control over image editing with a range of tools designed to work with your creative process, allowing you to take a single concept from ideation to finished product with precision and flexibility.\n  Stability AI Image Services offers two categories of image editing capabilities: Edit tools: Remove Background, Erase Object, Search and Replace, Search and Recolor, and Inpaint let you make targeted modifications to specific parts of your images. Control tools: Structure, Sketch, Style Guide, and Style Transfer give you powerful ways to generate variations based on existing images or sketches.\n  Stability AI Image Services is now available in Amazon Bedrock through the API and is supported in US West (Oregon), US East (N. Virginia), and US East (Ohio). For more information on supported regions, visit the Amazon Bedrock Model Support by Regions guide. For more details about Stability AI Image Services and its capabilities, visit the Stability AI product page and Stability AI documentation page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/stability-ai-image-services-generally-available-amazon-bedrock",
      "pubDate": "2025-09-18T16:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-804168525168",
      "title": "Monitor Amazon Bedrock batch inference using Amazon CloudWatch metrics",
      "description": "In this post, we explore how to monitor and manage Amazon Bedrock batch inference jobs using Amazon CloudWatch metrics, alarms, and dashboards to optimize performance, cost, and operational efficiency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/monitor-amazon-bedrock-batch-inference-using-amazon-cloudwatch-metrics/",
      "pubDate": "2025-09-18T15:33:07.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-6c3d5ab4ad37",
      "title": "Use AWS Deep Learning Containers with Amazon SageMaker AI managed MLflow",
      "description": "In this post, we show how to integrate AWS DLCs with MLflow to create a solution that balances infrastructure control with robust ML governance. We walk through a functional setup that your team can use to meet your specialized requirements while significantly reducing the time and resources needed for ML lifecycle management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/use-aws-deep-learning-containers-with-amazon-sagemaker-ai-managed-mlflow/",
      "pubDate": "2025-09-18T15:29:35.000Z",
      "source": "ml-blog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-914f37d8d608",
      "title": "Build Agentic Workflows with OpenAI GPT OSS on Amazon SageMaker AI and Amazon Bedrock AgentCore",
      "description": "In this post, we show how to deploy gpt-oss-20b model to SageMaker managed endpoints and demonstrate a practical stock analyzer agent assistant example with LangGraph, a powerful graph-based framework that handles state management, coordinated workflows, and persistent memory systems.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-agentic-workflows-with-openai-gpt-oss-on-amazon-sagemaker-ai-and-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-17T19:31:44.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "agentcore",
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-83fa28b776e6",
      "title": "Amazon Corretto 25 is now generally available",
      "description": "Amazon Corretto 25, a Long Term Support (LTS) version, is now generally available. Amazon Corretto is a no-cost, multi-platform, production-ready distribution of OpenJDK. You can download Corretto 25 for Linux, Windows, and macOS from our downloads page.\n  Amazon Corretto 25 new features include:\n  \n \n \nTwo features that were initially released as experimental in JDK 24 are now LTS production-ready in JDK 25:\n Compact Object Headers: designed to lower heap memory usage by shrinking object headers from 96-128 bits down to 64 bits.\n Generational Shenandoah GC: engineered to provide sustainable throughput and lower p99 pause times or similar pause times with a smaller heap and reduced CPU usage.\n \n \nAhead-of-Time (AOT) Caching: designed to improve cold-start and warm-up time by reusing pre-parsed pre-linked classes and compilation profiles between training and production runs.\n \n \nLanguage improvements: primitive types in patterns, flexible constructors, module‑wide imports, compact source files, scoped values for thread-local variables, stable values for immutable data, all designed to cut boilerplate, keep everyday code shorter and safer.\n \n \nObservability: JDK Flight Recorder gains CPU‑time sampling, cooperative sampling and method‑trace events for low‑overhead production profiling.\n \n \nStructured Concurrency: designed to provide coordinated task management, allowing related tasks fail or finish together.\n \n \nVector API: developed to provide computations that compile to optimal vector instructions on supported CPUs.\n \n \nVirtual Thread pinning improvements: reduces thread pinning in synchronized blocks for better scalability.\n \n \nA detailed description of these features can be found on the OpenJDK 25 Project page. Amazon Corretto 25 is distributed by Amazon under an open source license and will be supported through October 2032.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-corretto-25-generally-available",
      "pubDate": "2025-09-17T17:18:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "experimental",
        "generally-available",
        "ga",
        "new-feature",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-f07ca5eaf4e9",
      "title": "Announcing availability of second-generation AWS Outposts racks in 52 more countries",
      "description": "Second-generation AWS Outposts racks can now be shipped and installed at your data center and on-premises locations in Australia, Bahrain, Brazil, Brunei, Chile, Costa Rica, Egypt, European Union countries, Iceland, Indonesia, Israel, Japan, Jordan, Kenya, the Kingdom of Saudi Arabia, Kuwait, Malaysia, New Zealand, Peru, the Philippines, Singapore, Trinidad and Tobago, Türkiye, the United Arab Emirates (UAE), the United Kingdom, and Vietnam.\n \nOutposts racks extend AWS infrastructure, AWS services, APIs, and tools to virtually any on-premises data center or colocation space for a truly consistent hybrid experience. Outposts racks are ideal for workloads that require low-latency access to on-premises systems, local data processing, and migration of applications with local system interdependencies. Outposts racks can also help meet data residency requirements. Second-generation Outposts racks support the latest generation of x86-powered Amazon Elastic Compute Cloud (Amazon EC2) instances, starting with C7i, M7i, and R7i instances. These instances provide up to 40% better performance compared to C5, M5, and R5 instances on first-generation Outposts racks. Second-generation Outposts racks also offer simplified network scaling and configuration, and support a new category of accelerated networking Amazon EC2 instances optimized for ultra-low latency and high throughput needs.\n \nWith the availability of second-generation Outposts racks in the above countries, you can use AWS services to run your workloads and data in country in your on-premises facilities and connect to the nearest available AWS Region for management and operations.\n \nTo learn more about second-generation Outposts racks, read this blog post and the user guide. For the most updated list of countries and territories and the AWS Regions where second-generation Outposts racks are supported, check out the Outposts racks FAQs page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/second-generation-aws-outposts-racks-more-countries",
      "pubDate": "2025-09-17T16:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-15d87cb93331",
      "title": "Streamline access to ISO-rating content changes with Verisk rating insights and Amazon Bedrock",
      "description": "In this post, we dive into how Verisk Rating Insights, powered by Amazon Bedrock, large language models (LLM), and Retrieval Augmented Generation (RAG), is transforming the way customers interact with and access ISO ERC changes.",
      "link": "https://aws.amazon.com/blogs/machine-learning/streamline-access-to-iso-rating-content-changes-with-verisk-rating-insights-and-amazon-bedrock/",
      "pubDate": "2025-09-16T16:43:42.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-431447666038",
      "title": "Unified multimodal access layer for Quora’s Poe using Amazon Bedrock",
      "description": "In this post, we explore how the AWS Generative AI Innovation Center and Quora collaborated to build a unified wrapper API framework that dramatically accelerates the deployment of Amazon Bedrock FMs on Quora’s Poe system. We detail the technical architecture that bridges Poe’s event-driven ServerSentEvents protocol with Amazon Bedrock REST-based APIs, demonstrate how a template-based configuration system reduced deployment time from days to 15 minutes, and share implementation patterns for protocol translation, error handling, and multi-modal capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/unified-multimodal-access-layer-for-quoras-poe-using-amazon-bedrock/",
      "pubDate": "2025-09-16T16:40:11.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-7f6d11754731",
      "title": "Amazon EC2 supports detailed performance stats on all NVMe local volumes",
      "description": "Today, Amazon announced the availability of detailed performance statistics for Amazon EC2 instance store NVMe volumes. This new capability delivers real-time visibility into the performance of your AWS Nitro System-based EC2 instance store NVMe volumes, making it easier to monitor storage health and quickly resolve application performance issues.\n \nWith EC2 detailed performance statistics, you can access 11 comprehensive metrics at one second granularity to monitor input/output (I/O) statistics of your locally attached NVMe volumes, including queue length measurements, IOPS, throughput, and detailed I/O latency histograms. These metrics are similar to the detailed performance statistics available for EBS volumes, providing a consistent monitoring experience across both storage types. The granular visibility provided by these metrics helps you identify specific workloads affected by performance variations, and optimize your application's IO patterns for maximum efficiency. Additionally, the metrics include latency histograms broken down by IO size, providing even more detailed insights into performance patterns.\n  Detailed performance statistics for EC2 instance store NVMe volumes are available by default for all Nitro-based EC2 instances with locally attached NVMe volumes across all AWS Commercial and China Regions, at no additional charge.\n \nTo learn more about the EC2 instance store NVMe detailed performance statistics and how to access them, please visit the documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-detailed-performance-stats-nvme-local-volumes/",
      "pubDate": "2025-09-16T16:30:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-bd724f32f406",
      "title": "Amazon SageMaker HyperPod announces health monitoring agent support for Slurm clusters",
      "description": "Today, Amazon SageMaker HyperPod announces the general availability of the health monitoring agent for Slurm clusters. SageMaker HyperPod helps you provision resilient clusters for running machine learning (ML) workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs). The health monitoring agent performs passive, background health checks of instances to identify problems in key areas without impact on application behavior or performance, flags failures instantly, and replaces any unhealthy instances to keep your training jobs running smoothly. \n \nThe agent runs continuously on all GPU- or Trainium-based nodes in your HyperPod cluster, watching for hardware issues such as unresponsive GPUs or NVLink error counters. When a fault is detected, it marks the node as unhealthy and automatically reboots or replaces it with a healthy node, keeping your jobs running without requiring manual intervention. The agent also follows a co-ordinated approach to handling failures with the job auto-resume functionality available with Slurm clusters. For example, jobs with auto-resume enabled will continue from the last saved checkpoint once nodes are replaced by the agent. This hands-free recovery—already available on HyperPod clusters orchestrated with Amazon EKS—now gives Slurm clusters the same resilient environment, helping teams train large models for weeks without disruption and reclaim time and costs that would otherwise be lost to mid-run failures. In addition, customers can now also reboot their nodes using a simple command in case of intermittent issues such as GPU driver issues requiring reset. \n \nHealth monitoring agent for Slurm is available in all regions where HyperPod is generally available. The agent is auto-enabled on all newly created Slurm clusters; to enable it on an existing cluster, simply upgrade to the latest HyperPod AMI by calling the UpdateClusterSoftware API. To learn more, visit the Amazon SageMaker HyperPod documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-sagemaker-hyperpod-health-monitoring-agent-slurm/",
      "pubDate": "2025-09-15T18:00:00.000Z",
      "source": "whats-new",
      "services": [
        "sagemaker",
        "hyperpod",
        "trainium"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "trainium",
        "generally-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-6cabd2dd13f5",
      "title": "Schedule topology-aware workloads using Amazon SageMaker HyperPod task governance",
      "description": "In this post, we introduce topology-aware scheduling with SageMaker HyperPod task governance by submitting jobs that represent hierarchical network information. We provide details about how to use SageMaker HyperPod task governance to optimize your job efficiency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/schedule-topology-aware-workloads-using-amazon-sagemaker-hyperpod-task-governance/",
      "pubDate": "2025-09-15T17:15:20.000Z",
      "source": "ml-blog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-591c4b0afb89",
      "title": "How msg enhanced HR workforce transformation with Amazon Bedrock and msg.ProfileMap",
      "description": "In this post, we share how msg automated data harmonization for msg.ProfileMap, using Amazon Bedrock to power its large language model (LLM)-driven data enrichment workflows, resulting in higher accuracy in HR concept matching, reduced manual workload, and improved alignment with compliance requirements under the EU AI Act and GDPR.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-msg-enhanced-hr-workforce-transformation-with-amazon-bedrock-and-msg-profilemap/",
      "pubDate": "2025-09-15T17:05:18.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-94338f4e0c14",
      "title": "AWS Weekly Roundup: Strands Agents 1M+ downloads, Cloud Club Captain, AI Agent Hackathon, and more (September 15, 2025)",
      "description": "Last week, Strands Agents, AWS open source for agentic AI SDK just hit 1 million downloads and earned 3,000+ GitHub Stars less than 4 months since launching as a preview in May 2025. With Strands Agents, you can build production-ready, multi-agent AI systems in a few lines of code. We’ve continuously improved features including support […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-strands-agents-1m-downloads-cloud-club-captain-ai-agent-hackathon-and-more-september-15-2025/",
      "pubDate": "2025-09-15T16:45:14.000Z",
      "source": "news-blog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-79795044339d",
      "title": "Automate advanced agentic RAG pipeline with Amazon SageMaker AI",
      "description": "In this post, we walk through how to streamline your RAG development lifecycle from experimentation to automation, helping you operationalize your RAG solution for production deployments with Amazon SageMaker AI, helping your team experiment efficiently, collaborate effectively, and drive continuous improvement.",
      "link": "https://aws.amazon.com/blogs/machine-learning/automate-advanced-agentic-rag-pipeline-with-amazon-sagemaker-ai/",
      "pubDate": "2025-09-12T17:36:19.000Z",
      "source": "ml-blog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "improvement"
      ]
    },
    {
      "id": "aws-news-1d6dabcf2cd0",
      "title": "Announcing general availability of Amazon EC2 M4 and M4 Pro Mac instances",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) M4 and M4 Pro Mac instances are now generally available (GA). M4 Mac instances offer up to 20% better application build performance compared to M2 Mac instances, while M4 Pro Mac instances deliver up to 15% better application build performance compared to M2 Pro Mac instances. These instances are ideal for building and testing applications for Apple platforms such as iOS, macOS, iPadOS, tvOS, watchOS, visionOS, and Safari.\n  M4 and M4 Pro Mac instances are powered by the AWS Nitro System, providing up to 10 Gbps network bandwidth and 8 Gbps of Amazon Elastic Block Store (Amazon EBS) storage bandwidth. M4 Mac instances are built on Apple M4 Mac Mini computers featuring 10‑core CPU, 10‑core GPU, 24GB unified memory, and 16‑core Neural Engine. M4 Pro Mac instances feature a 14‑core CPU, 20‑core GPU, 48GB unified memory, and 16‑core Neural Engine. Both instance families come with a new 2TB instance store volume per EC2 Mac Dedicated Host, providing low latency storage for improved caching and build/test performance.\n  M4 and M4 Pro Mac instances enable Apple developers to migrate their most demanding build and test workloads onto AWS and run significantly more tests in parallel using multiple Xcode simulators. This accelerates application iterations and reduces time to market. Customers now have access to the most advanced Apple silicon Macs on AWS to meet their requirements, while also enabling them to modernize their Apple CI/CD with dozens of AWS services. M4 and M4 Pro Mac instances support macOS Sequoia version 15.6 and newer AMIs (Amazon Machine Images).\n \nAmazon EC2 M4 and M4 Pro Mac instances are available in US East (N. Virginia) and US West (Oregon). To learn more or get started, see our launch blog, Amazon EC2 Mac Instances or visit the EC2 Mac documentation reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-m4-pro-mac-instances-generally-available",
      "pubDate": "2025-09-12T15:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5f7dcd4b3fbc",
      "title": "Amazon SageMaker Unified Studio supports remote connection from VS Code",
      "description": "Today, AWS announces remote connection from Visual Studio Code (VS Code) to Amazon SageMaker Unified Studio. This new capability allows developers to leverage their VS Code setup while accessing the scalable compute resources of Amazon SageMaker. By connecting VS Code to SageMaker Unified Studio, you can maintain your existing development workflows and configurations within a unified environment for AWS analytics and AI/ML services.\n  SageMaker Unified Studio, part of the next generation of Amazon SageMaker, offers a broad set of fully managed cloud interactive development environments (IDE), including JupyterLab and Code Editor based on Code-OSS (Open Source Software) like VS Code. Starting today, you can use your customized local VS Code setup while accessing your compute resources and data in Amazon SageMaker. Authentication is simple and secure using the AWS Toolkit extension in VS Code. This integration provides a streamlined path from your local development environment to scalable infrastructure for running data processing, SQL analytics, and ML workflows.\n  This feature is available in all Regions where Amazon SageMaker Unified Studio is available. To learn more, refer to the Administrator Guide and User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/sagemaker-unified-studio-vs-code/",
      "pubDate": "2025-09-12T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "sagemaker",
        "unified studio"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-0b47e55e58e4",
      "title": "AWS named as a Leader in 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for 15 years in a row",
      "description": "AWS is recognized as a Leader in the 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for the fifteenth consecutive year. In the report, Gartner once again placed AWS highest on the “Ability to Execute” axis. We believe this reflects our ongoing commitment to giving customers the broadest and deepest set of capabilities to accelerate innovation as well as unparalleled security, reliability, and performance they can trust for their most critical applications.",
      "link": "https://aws.amazon.com/blogs/aws/aws-named-as-a-leader-in-2025-gartner-magic-quadrant-for-strategic-cloud-platform-services-for-15-years-in-a-row/",
      "pubDate": "2025-08-15T16:59:11.000Z",
      "source": "news-blog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-81c6c3e233a5",
      "title": "AWS Weekly Roundup: OpenAI models, Automated Reasoning checks, Amazon EVS, and more (August 11, 2025)",
      "description": "AWS Summits in the northern hemisphere have mostly concluded but the fun and learning hasn’t yet stopped for those of us in other parts of the globe. The community, customers, partners, and colleagues enjoyed a day of learning and networking last week at the AWS Summit Mexico City and the AWS Summit Jakarta. Last week’s […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-openai-models-automated-reasoning-checks-amazon-evs-and-more-august-11-2025/",
      "pubDate": "2025-08-11T16:05:01.000Z",
      "source": "news-blog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    }
  ]
}