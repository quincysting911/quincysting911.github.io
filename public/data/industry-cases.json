{
  "lastUpdated": "2025-09-28T11:49:35.878Z",
  "category": "industry-cases",
  "totalItems": 68,
  "items": [
    {
      "id": "aws-news-c959ef8c3720",
      "title": "Building health care agents using Amazon Bedrock AgentCore",
      "description": "In this solution, we demonstrate how the user (a parent) can interact with a Strands or LangGraph agent in conversational style and get information about the immunization history and schedule of their child, inquire about the available slots, and book appointments. With some changes, AI agents can be made event-driven so that they can automatically send reminders, book appointments, and so on.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-health-care-agents-using-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-26T16:03:41.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-13a535dc87a5",
      "title": "Amazon EBS increases the maximum size and provisioned performance of General Purpose (gp3) volumes",
      "description": "Amazon Elastic Block Store (Amazon EBS) now supports higher volume-level limits for its General Purpose (gp3) volumes. With this update, gp3 volumes can scale up to 64 TiB in size (4X the previous 16 TiB limit), up to 80,000 IOPS (5X the previous 16,000 IOPS limit), and up to 2,000 MiB/s throughput (2X the previous 1,000 MiB/s limit).\n  These expanded limits help reduce operational complexity for storage-intensive workloads by enabling gp3 volumes with larger capacity and higher performance. You can consolidate multiple striped volumes into a single gp3 volume, streamline architectures, and lower management overhead. The increased limits particularly benefit customers running containerized workloads with limited support for striping multiple volumes, applications that rely on single-volume architectures, and growing workloads approaching current gp3 limits. The pricing model remains unchanged: you pay for storage plus any additional IOPS and throughput provisioned beyond the baseline performance.\n  The new gp3 limits are available in all AWS Commercial Regions and AWS GovCloud (US) Regions where gp3 volumes are available. To get started and learn more, please visit the Amazon EBS user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ebs-size-provisioned-performance-gp3-volumes/",
      "pubDate": "2025-09-26T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-00c28150b946",
      "title": "AWS WAF Targeted Bot Control, Fraud & DDoS Prevention Rule Group available in 3 more regions",
      "description": "Starting today, AWS WAF’s Targeted Bot Control, Fraud, and DDoS Prevention Rule Group are available in the AWS Asia Pacific (Taipei), Asia Pacific (Bangkok), and Mexico (Central) regions. These features help customers to stay protected against sophisticated bots, application layer DDoS and account takeover attacks.\n \nAWS WAF is a web application firewall that helps you protect your web application resources against common web exploits and bots that can affect availability, compromise security, or consume excessive resources. \n \nTo see the full list of regions where AWS WAF is currently available, visit the AWS Region Table. For more information about the service, visit the AWS WAF page. For more information about pricing, visit the AWS WAF Pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-waf-targeted-bot-control-fraud-ddos-regions-expansion",
      "pubDate": "2025-09-26T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-daeb8d6f30a5",
      "title": "Accelerate benefits claims processing with Amazon Bedrock Data Automation",
      "description": "In the benefits administration industry, claims processing is a vital operational pillar that makes sure employees and beneficiaries receive timely benefits, such as health, dental, or disability payments, while controlling costs and adhering to regulations like HIPAA and ERISA. In this post, we examine the typical benefit claims processing workflow and identify where generative AI-powered automation can deliver the greatest impact.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-benefits-claims-processing-with-amazon-bedrock-data-automation/",
      "pubDate": "2025-09-25T19:20:16.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-b54db45a9ae5",
      "title": "Amazon Bedrock AgentCore Runtime, Browser, and Code Interpreter add support for VPC, AWS PrivateLink, CloudFormation, and tagging",
      "description": "Amazon Bedrock AgentCore Runtime, Browser, and Code Interpreter services now support Amazon Virtual Private Cloud (VPC) connectivity, AWS PrivateLink, AWS CloudFormation, and resource tagging, enabling developers to deploy AI agents with enhanced enterprise security and infrastructure automation capabilities. AgentCore Runtime enables you to deploy and scale dynamic AI agents securely using any framework, protocol, or model. AgentCore Browser enables web-based interactions such as form filling, data extraction, and QA testing, while AgentCore Code Interpreter provides secure execution of agent-generated code.\n  With VPC support, you can now securely connect AgentCore Runtime, Browser, and Code Interpreter services to private resources such as databases, internal APIs, and services within your VPC without internet exposure. AWS PrivateLink provides private connectivity between your VPC and Amazon Bedrock AgentCore services, while CloudFormation support enables automated resource provisioning through infrastructure as code. Resource tagging allows you to implement comprehensive cost allocation, access control, and resource organization across your AgentCore deployments.\n  Amazon Bedrock AgentCore is currently in preview and available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Frankfurt).\n  To learn more, see Configuring VPC for AgentCore and Use Interface VPC endpoints (AWS PrivateLink) with AgentCore. For CloudFormation resources, visit the AgentCore CloudFormation Reference, and to get started with tagging, see the Tagging AgentCore resources.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-bedrock-agentcore-runtime-browser-code-interpreter-vpc-privatelink-cloudformation-tagging",
      "pubDate": "2025-09-25T18:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "preview",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-7a5d69e1edad",
      "title": "Amazon EC2 I7i instances now available in AWS Europe (Milan) and AWS US West (N. California)",
      "description": "AWS is announcing the availability of high performance Storage optimized Amazon EC2 I7i instances in AWS Europe (Milan) and US West (N. California) regions. Powered by 5th Gen Intel Xeon Processors with an all-core turbo frequency of 3.2 GHz, these new instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances. Powered by 3rd generation AWS Nitro SSDs, I7i instances offer up to 45TB of NVMe storage with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances.\n  I7i instances offer compute and storage performance for x86-based storage optimized instances in Amazon EC2 ideal for I/O intensive and latency-sensitive workloads that demand very high random IOPS performance with real-time latency to access the small to medium size datasets. Additionally, torn write prevention feature support up to 16KB block sizes, enabling customers to eliminate database performance bottlenecks.\n  I7i instances are available in eleven sizes - nine virtual sizes up to 48xlarge and two bare metal sizes - delivering up to 100Gbps of network bandwidth and 60Gbps of Amazon Elastic Block Store (EBS) bandwidth. To learn more, visit the I7i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-i7i-instances-available-in-milan-california/",
      "pubDate": "2025-09-25T17:01:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-c79d309fcc1d",
      "title": "Amazon Redshift Concurrency Scaling is now available in 10 additional AWS regions",
      "description": "Amazon Redshift Concurrency Scaling is now available in the AWS Africa (Cape Town), Asia Pacific (Hong Kong), Asia Pacific (Hyderabad), Asia Pacific (Jakarta), Asia Pacific (Osaka), Asia Pacific (Thailand), Europe (Milan), Middle East (Bahrain), Mexico (Central) and AWS GovCloud (US-West) regions. With the Amazon Redshift Concurrency Scaling feature, you can now support thousands of concurrent users and concurrent queries, with consistently fast query performance.\n  Amazon Redshift Concurrency Scaling elastically scales query processing power to provide consistently fast performance for hundreds of concurrent queries. Concurrency Scaling resources are added to your Redshift cluster transparently in seconds, allowing for increased concurrency to process queries with minimal wait time. Amazon Redshift customers with an active Redshift cluster earn up to one hour of free Concurrency Scaling credits, which is sufficient for the concurrency needs of most customers. Concurrency scaling enables you to specify usage control, providing customers with predictable month-to-month costs, even during periods of fluctuating analytical demand.\n  To enable Amazon Redshift Concurrency Scaling, set the Concurrency Scaling Mode to Auto in your Amazon Web Services Management Console. You can allocate Concurrency Scaling usage to specific user groups and workloads, control the number of Concurrency Scaling clusters that can be used, and monitor Amazon CloudWatch performance and usage metrics.\n  To learn more about concurrency scaling including regional-availability, see our documentation and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-redshift-concurrency-scaling-additional-aws-regions",
      "pubDate": "2025-09-25T17:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-6ff42c19e362",
      "title": "AWS Network Firewall enhances application layer traffic controls",
      "description": "AWS Network Firewall, a managed service that makes it easy to deploy essential network protections for your Amazon VPCs, now provides enhanced default rules to handle TLS client hellos, and HTTP requests split across multiple packets. This update introduces new application layer drop and alert established default stateful actions, enabling customers to maintain security controls while supporting modern TLS implementations and large HTTP requests.\n  These enhancements help customers implement robust security policies without writing complex custom rules. Security teams can now effectively inspect and filter traffic where key information is segmented across multiple packets, while maintaining visibility through detailed logging options, making it easier to secure applications using modern protocols and encryption standards.\n  This capability is available in all AWS Regions where AWS Network Firewall is supported.\n  To learn more, refer to AWS Network Firewall service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-network-firewall-enhances-application-layer-traffic-controls",
      "pubDate": "2025-09-25T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-9a877ca57412",
      "title": "Research and Engineering Studio on AWS 2025.09 is now available",
      "description": "Today we’re announcing Research and Engineering Studio (RES) on AWS 2025.09, which brings support for fractional GPUs, simplified AMI management, and enhanced deployment flexibility. This release also expands regional availability to include four additional AWS commercial Regions.\n  Research and Engineering Studio on AWS is an open source solution that provides a web-based portal for administrators to create and manage secure cloud-based research and engineering environments. RES enables scientists and engineers to access powerful Windows and Linux virtual desktops with pre-installed applications and shared resources, without requiring cloud expertise.\n  Version 2025.09 adds support for Amazon EC2 g6f instances, enabling GPU fractionalization for more efficient resource utilization in graphics-intensive workloads. The release also introduces Systems Manager Parameter Alias support for AMI IDs, simplifying the management of project-specific images, and enables integration with existing Amazon Cognito user pools for streamlined authentication setup during deployment. Administrators can now also customize CIDR ranges in the AWS CloudFormation external resources template for better network planning and integration with existing resources.\n  This release expands regional availability to include Asia Pacific (Osaka), Asia Pacific (Jakarta), Middle East (UAE), and South America (São Paulo). To learn more about RES 2025.09, including detailed release notes and deployment instructions, visit the Research and Engineering Studio documentation or check out the RES GitHub repository.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/research-engineering-studio-aws-2025-09-now-available",
      "pubDate": "2025-09-25T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "now-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-e7d9cf4c2ebe",
      "title": "Billing View now supports cost management data from multiple organizations",
      "description": "Today, AWS announces the general availability of new capabilities within AWS Billing and Cost Management that enable customers to manage their AWS spend across multiple organizations through a single AWS account. Customers can now share custom billing views containing cost management data with other AWS accounts outside their organization. Additionally, customers can combine multiple custom billing views to create new consolidated views. These features enable FinOps teams to create custom billing views containing cost management data for multiple organizations. These views can then be used to access cost management data across multiple organizations through Cost Explorer or set up budgets to monitor AWS costs.\n \nWith the new custom billing view capabilities, you can create consolidated views of cost management data spanning multiple organizations that can be accessed using AWS Cost Explorer and AWS Budgets, allowing you to monitor, analyze, and forecast spending patterns across multiple organizations. This helps customers operating multiple subsidiaries or business units as separate organizations on AWS manage their AWS spend through a single AWS account.\n \nSupport for custom billing views containing cost management data for multiple organizations is available in all AWS Regions, excluding AWS GovCloud Regions and the AWS China Regions. To get started with custom billing views, visit Billing View within the Cost Management Preferences page in the AWS Billing and Cost Management console and create a new custom billing view. To get started visit the Billing View user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/billing-view-cost-management-multiple-organizations",
      "pubDate": "2025-09-25T12:00:00.000Z",
      "source": "whats-new",
      "services": [
        "forecast"
      ],
      "categories": [
        "personalization",
        "industry-cases"
      ],
      "tags": [
        "forecast",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-4240934578e0",
      "title": "Amazon CloudWatch now supports resource tags when monitoring vended metrics",
      "description": "Today, Amazon CloudWatch announces support for a new tag-based telemetry experience to help customers monitor their metrics and set up their alarms using AWS resources tags. This new capability simplifies monitoring cloud infrastructure at scale by automatically adapting alarms and metrics analysis as resources change. DevOps engineers and cloud administrators can now create dynamic monitoring views that align with their organizational structure using their existing AWS resource tags.\n  Tag-based querying filtering eliminates the manual overhead of updating alarms and dashboards after deployments, freeing teams to focus on innovation rather than maintenance. This provides faster, targeted insights that match how teams organize their systems. Teams can query AWS default metrics using their existing resource tags, making it easier to troubleshoot issues and maintain operational visibility while focusing on core business initiatives.\n  CloudWatch tag-based filtering is available in the following regions: US East (N. Virginia); US East (Ohio); US West (N. California); US West (Oregon); Asia Pacific (Tokyo); Asia Pacific (Seoul); Asia Pacific (Singapore); Asia Pacific (Sydney); Asia Pacific (Mumbai); Asia Pacific (Osaka); Canada (Central); Europe (Frankfurt); Europe (Ireland); Europe (London); Europe (Paris); Europe (Stockholm) and South America (São Paulo).\n  To get started, simply enable tag enriched telemetry with one click in the Amazon CloudWatch Settings, or through the AWS Command Line Interface (AWS CLI), and AWS SDKs to use your existing AWS resource tags to monitor your infrastructure. Learn more on the Amazon CloudWatch documentation page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-cloudwatch-tags-observability",
      "pubDate": "2025-09-25T09:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-e6de0a2f563d",
      "title": "Amazon Route 53 Resolver Query Logging now available in Asia Pacific (New Zealand)",
      "description": "Today, we are announcing the availability of Route 53 Resolver Query Logging in Asia Pacific (New Zealand), enabling you to log DNS queries that originate in your Amazon Virtual Private Cloud (Amazon VPC). With query logging enabled, you can see which domain names have been queried, the AWS resources from which the queries originated - including source IP and instance ID - and the responses that were received. \n  Route 53 Resolver is the Amazon provided DNS server that is available by default in all Amazon VPCs. Route 53 Resolver responds to DNS queries from AWS resources within a VPC for public DNS records, Amazon VPC-specific DNS names, and Amazon Route 53 private hosted zones. With Route 53 Resolver Query Logging, customers can log DNS queries and responses for queries originating from within their VPCs, whether those queries are answered locally by Route 53 Resolver, or are resolved over the public internet, or are forwarded to on-premises DNS servers via Resolver Endpoints. You can share your query logging configurations across multiple accounts using AWS Resource Access Manager (RAM). You can also choose to send your query logs to Amazon S3, Amazon CloudWatch Logs, or Amazon Data Firehose. \n  There is no additional charge to use Route 53 Resolver Query Logging, although you may incur usage charges from Amazon S3, Amazon CloudWatch, or Amazon Data Firehose. To learn more about Route 53 Resolver Query Logging or to get started, visit the Route 53 Resolver product page or the Route 53 documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-route-53-resolver-query-logging-available-asia-pacific-nz",
      "pubDate": "2025-09-24T07:34:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-81485b9af5b7",
      "title": "Amazon GameLift Servers launches a new Local Zone in Dallas, Texas",
      "description": "Amazon GameLift Servers now supports a new AWS Local Zone in Dallas, Texas (us-east-1-dfw-2). You can use this Local Zone to deploy GameLift Fleets with EC2 C6gn, C6i, C6in, M6g, M6i, M6in, M8g, and R6i instances. Local Zones place AWS services closer to major player population and IT centers where no AWS region exists. From the Amazon GameLift Servers Console, you can enable the Dallas Local Zone and add it to your fleets, just as you would with any other Region or Local Zone.\n  With this launch, game studios can run latency-sensitive workloads such as real-time multiplayer gaming, responsive AR/VR experiences, and competitive tournaments closer to players in the Dallas metro area. Local Zones help deliver single-digit millisecond latency, giving players a smoother, more responsive experience by reducing network distance between your servers and players.\n  For more information on AWS Local Zones, please see here. To see a complete list of supported regions and local zones for Amazon GameLift Servers, visit the Amazon GameLift Servers documentation. For pricing, please visit the Amazon GameLift Servers Instance Pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-gamelift-servers-local-zone-dallas-texas/",
      "pubDate": "2025-09-24T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-36218ab4636b",
      "title": "AWS announces unlimited network burst duration on EC2 I8g and I7i instances",
      "description": "Today, AWS eliminated the networking bandwidth burst duration limitations for Amazon EC2 I7i and I8g instances on sizes larger than 4xlarge. This update doubles the Network Bandwidth available at all times for i7i and i8g instances on sizes larger than 4xlarge. Previously, these instance sizes had a baseline bandwidth and used a network I/O credit mechanism to burst beyond their baseline bandwidth on a best effort basis. Today these instance sizes can sustain their maximum performance indefinitely. With this improvement, customers running memory and network intensive workloads on larger instance sizes can now consistently maintain their maximum network bandwidth without interruption, delivering more predictable performance for applications that require sustained high-throughput network connectivity. This change applies only to instance sizes larger than 4xlarge, while smaller instances will continue to operate with their existing baseline and burst bandwidth configurations.\n \nAmazon EC2 I7i and I8g instances are designed for I/O intensive workloads that require rapid data access and real-time latency from storage. These instances excel at handling transactional, real-time, distributed databases, including MySQL, PostgreSQL, Hbase and NoSQL solutions like Aerospike, MongoDB, ClickHouse, and Apache Druid. They're also optimized for real-time analytics platforms such as Apache Spark, data lakehouse, and AI LLM pre-processing for training. These instances have up to 1.5 TiB of memory, and 45 TB local instance storage. They deliver up to 100 Gbps of network performance bandwidth, and 60 Gbps of dedicated bandwidth for Amazon Elastic Block Store (EBS).\n \nTo learn more, see Amazon EC2 I7i and I8g instances. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-announces-unlimited-network-burst-duration-i8g-i7i",
      "pubDate": "2025-09-24T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "update",
        "improvement"
      ]
    },
    {
      "id": "aws-news-f76fdca33bd0",
      "title": "Running deep research AI agents on Amazon Bedrock AgentCore",
      "description": "AI agents are evolving beyond basic single-task helpers into more powerful systems that can plan, critique, and collaborate with other agents to solve complex problems. Deep Agents—a recently introduced framework built on LangGraph—bring these capabilities to life, enabling multi-agent workflows that mirror real-world team dynamics. The challenge, however, is not just building such agents but […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/running-deep-research-ai-agents-on-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-23T20:35:23.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex"
      ]
    },
    {
      "id": "aws-news-86dbb31f2325",
      "title": "Amazon DataZone is now available in 3 additional commercial regions",
      "description": "Amazon DataZone is now available in AWS Asia Pacific (Hong Kong), Asia Pacific (Malaysia) and Europe (Zurich) Regions.\n  Amazon DataZone is a fully managed data management service to catalog, discover, analyze, share, and govern data between data producers and consumers in your organization. With Amazon DataZone, data producers populate the business data catalog with structured data assets from AWS Glue Data Catalog and Amazon Redshift tables. Data consumers search and subscribe to data assets in the data catalog and share with other collaborators working on the same business use case. Consumers can analyze their subscribed data assets with tools—such as Amazon Redshift or Amazon Athena query editors—that are directly accessed from the Amazon DataZone portal. The integrated publishing and subscription workflow provides access to auditing capabilities across projects.\n  For more information on AWS Regions where Amazon DataZone is available in preview, see supported regions.\n \nAdditionally, Amazon DataZone powers governance in the next generation of Amazon SageMaker, which simplifies the discovery, governance, and collaboration of data and AI across your lakehouse, AI models, and GenAI applications. With Amazon SageMaker Catalog (built on Amazon DataZone), users can securely discover and access approved data and models using semantic search with generative AI–created metadata, or they could just ask Amazon Q Developer using natural language to find their data. For more information on AWS Regions where the next generation of SageMaker is available, see supported regions. To learn more about the next generation of SageMaker, visit the product webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-datazone-additional-regions/",
      "pubDate": "2025-09-23T18:00:00.000Z",
      "source": "whats-new",
      "services": [
        "amazon q",
        "q developer",
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "search",
        "industry-cases"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "sagemaker",
        "preview",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-dfd512c25522",
      "title": "AWS License Manager now supports shared AWS Managed Active Directory",
      "description": "AWS License Manager announces support for shared AWS Managed Active Directory across multiple AWS accounts, simplifying Microsoft license management on AWS. Customers can now centralize user subscriptions of Microsoft Office, Visual Studio, and Remote Desktop Service instances running in their AWS Organization while maintaining clear visibility across AWS accounts.\n  With this launch, customers are no longer required to setup a Managed Active Directory instance for each AWS Account, reducing duplicate directories and IT overhead. Customers can now manage licenses through a single admin account where users subscribe once, and their subscriptions will extend to directory consumer accounts. The new feature is available in all commercial regions where License Manager user subscription is supported.\n  To get started, customers can onboard their shared AWS Managed Active Directory through AWS License Manager console. For more information and to begin using this feature, visit the AWS License Manager page or AWS License Manager User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-license-manager-shared-managed-active-directory",
      "pubDate": "2025-09-23T14:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-c72f98e3d935",
      "title": "AWS IAM Identity Center organization instances now support customer-managed KMS keys for encryption at rest",
      "description": "IAM Identity Center now supports customer-managed AWS Key Management Service (KMS) keys for encrypting workforce identity data, including user and group attributes. While AWS-owned keys are used by default, customer-managed keys (CMKs) provide granular control over identity data access, enhancing security and compliance capabilities. IAM Identity Center helps you securely create, or connect, your workforce identities and manage their access centrally across AWS applications and accounts.\n  You create a CMK and manage its lifecycle and usage permissions in AWS KMS. You can configure the CMK in your IAM Identity Center instance either while enabling a new organization instance or on an existing one. You can then use AWS CloudTrail to monitor and audit the usage of your CMK for access to identity data in IAM Identity Center.\n  Support for CMKs in organization instances of IAM Identity Center is now available for access to accounts and select AWS applications in all AWS Regions where IAM Identity Center is available. Standard AWS KMS charges apply to storing and using CMKs. IAM Identity Center is provided at no additional cost.\n  To learn more about IAM Identity Center, visit the product detail page. To get started with using CMKs, please refer to the IAM Identity Center User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-iam-identity-center-organization-customer-managed-kms-keys-encryption-at-rest/",
      "pubDate": "2025-09-23T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-2d74e91ea4b5",
      "title": "Amazon Nova Act extension: Build and test AI agents within your IDE",
      "description": "We’re excited today to announce the Amazon Nova Act extension - a tool that transforms how you build with Nova Act by bringing the entire agent development experience directly into IDEs like Visual Studio Code, Kiro, and Cursor. The Nova Act extension consolidates natural language based script creation, granular scripting precision, and robust browser testing into a single, unified user interface, eliminating the need to switch between multiple tools across development, validation, and iteration.\n  The Nova Act extension is built on top of the Nova Act SDK, available in research preview since March 2025. The Nova Act extension addresses feedback we have received from developers and consolidates the agent development lifecycle, from ideation to production, into one unified user interface within your IDE.\n  The Nova Act extension is available today from your IDE’s extension marketplace. The Nova Act GitHub repository includes documentation and examples to get started.\n  Learn more about the Nova Act extension and see the Nova Act extension in action at our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-nova-act-extension-build-test-ai-agents-ide/",
      "pubDate": "2025-09-23T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "preview"
      ]
    },
    {
      "id": "aws-news-6bac89759fe3",
      "title": "Amazon Connect now supports you to associate custom attributes with interaction segments",
      "description": "Amazon Connect now supports you to associate custom attributes with interaction segments, ensuring reporting and analytics always reflect the true customer journey. Attributes such as business unit name, account type, or contact reason can be centrally managed with predetermined values and applied to contact records through flows or the UpdateContact API. This approach preserves accurate business context throughout customer journeys, particularly during transfers and multi-party communications. For example, a customer engagement that originates in the Support business unit and transitions to Sales: each distinct interaction segment maintains its precise business unit name, creating an accurate and comprehensive record of the customer journey.\n  This feature is available in all AWS regions where Amazon Connect is available. To learn more about using predefined attributes as contact segment attributes, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS contact center as a service solution on the cloud, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-connect-associate-custom-attributes-interaction-segments/",
      "pubDate": "2025-09-23T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-7936fe1cc8d5",
      "title": "Rapid ML experimentation for enterprises with Amazon SageMaker AI and Comet",
      "description": "In this post, we showed how to use SageMaker and Comet together to spin up fully managed ML environments with reproducibility and experiment tracking capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/rapid-ml-experimentation-for-enterprises-with-amazon-sagemaker-ai-and-comet/",
      "pubDate": "2025-09-22T17:12:33.000Z",
      "source": "ml-blog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-c3a063adc2ba",
      "title": "Amazon Connect Contact Lens now provides sensitive data redaction in 7 additional languages",
      "description": "Amazon Connect Contact Lens now provides sensitive data redaction from voice and chat conversational analytics in French (France, Canada), Portuguese (Portugal, Brazil), Italian, German, and Spanish (Spain). Automatic redaction of sensitive data redaction helps you protect your customer's privacy by removing personally identifiable information (PII), financial account numbers and PINs, and Internet access details (URLs, usernames, passwords) from conversation transcripts and audio files. You can choose to redact selected or all sensitive data entities, and whether they are replaced with a generic placeholder (e.g., [PII]) or an entity-specific placeholder (e.g., [NAME]) to indicate the type of information redacted.\n  Amazon Connect is an AI-powered application that provides one seamless experience for your contact center customers and users. Contact Lens provides conversational analytics that enable you to monitor, measure, and continuously improve contact quality and agent performance for a better overall customer experience.\n  Sensitive data redaction is available in all AWS Regions where Amazon Connect is available. For more information, refer to the following list of resources:\n  \n \n \nAmazon Connect Contact Lens and pricing\n \n \nEnable redaction of sensitive information\n \n \nSupported languages",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-connect-contact-lens-redaction-7-languages/",
      "pubDate": "2025-09-22T17:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-77e33a4e16c4",
      "title": "Amazon Connect flow designer now supports analytics mode",
      "description": "Amazon Connect now offers new enhanced analytics in the drag-and-drop flow designer that help you make data-driven decisions when building and optimizing your flows. Amazon Connect flows allow you to create end-to-end self-service and automated customer experiences such as interactive voice response (IVR), step-by-step guides, and back office processes and tasks. With this launch, you can now view aggregate metrics on how customers move through each step in the flow including where they run into errors or abandon the experience. For example, you can see how many conversational AI interactions result in transfers to agent queues or when customers end up in the wrong queue because an error in the flow configuration. These new capabilities help you identify behavioral patterns and evaluate root causes, allowing you to deliver better outcomes for customers.\n  This new capability is included with Amazon Connect (with unlimited AI) pricing. To learn more about this feature, see the Amazon Connect Administrator Guide. This feature is available in all AWS regions that offers Amazon Connect. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-connect-flow-designer-analytics-mode/",
      "pubDate": "2025-09-22T16:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-dc64f251f262",
      "title": "Amazon OpenSearch Ingestion now supports cross-account ingestion",
      "description": "Amazon OpenSearch Ingestion now supports cross-account ingestion for push-based sources such as HTTP and OpenTelemetry (OTel). With this launch, customers can easily share OpenSearch Ingestion pipelines across AWS accounts without relying on additional configurations like VPC peering or AWS Transit Gateway.\n \nThis capability makes it simpler for organizations with multiple accounts to centralize observability and analytics workflows. For example, a central logging team can create ingestion pipelines and grant access to development teams across different accounts, enabling them to ingest logs, metrics, and traces directly into OpenSearch domains or OpenSearch Serverless collections. This reduces operational overhead and lowers the cost of sharing ingestion pipelines across accounts.\n \nCross-account ingestion for Amazon OpenSearch Ingestion is available today in all AWS regions where OpenSearch Ingestion is offered. Customers can get started by creating resource policies in the AWS Management Console or using the AWS CLI, and then enabling pipeline endpoints from their VPCs to ingest data seamlessly.\n \nTo learn more about this feature, see the Amazon OpenSearch Service Developer Guide and the launch blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-opensearch-ingestion-cross-account-ingestion/",
      "pubDate": "2025-09-19T17:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "search",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-d5a772368a74",
      "title": "Move your AI agents from proof of concept to production with Amazon Bedrock AgentCore",
      "description": "This post explores how Amazon Bedrock AgentCore helps you transition your agentic applications from experimental proof of concept to production-ready systems. We follow the journey of a customer support agent that evolves from a simple local prototype to a comprehensive, enterprise-grade solution capable of handling multiple concurrent users while maintaining security and performance standards.",
      "link": "https://aws.amazon.com/blogs/machine-learning/move-your-ai-agents-from-proof-of-concept-to-production-with-amazon-bedrock-agentcore/",
      "pubDate": "2025-09-19T16:09:26.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "experimental",
        "support"
      ]
    },
    {
      "id": "aws-news-9c6439e1f1c9",
      "title": "Amazon RDS for MySQL announces Innovation Release 9.4 in Amazon RDS Database Preview Environment",
      "description": "Amazon RDS for MySQL now supports community MySQL Innovation Release 9.4 in the Amazon RDS Database Preview Environment, allowing you to evaluate the latest Innovation Release on Amazon RDS for MySQL. You can deploy MySQL 9.4 in the Amazon RDS Database Preview Environment which provides the benefits of a fully managed database, making it simpler to set up, operate, and monitor databases.\n  MySQL 9.4 is the latest Innovation Release from the MySQL community. MySQL Innovation releases include bug fixes, security patches, as well as new features. MySQL Innovation releases are supported by the community until the next innovation minor, whereas MySQL Long Term Support (LTS) Releases, such as MySQL 8.0 and MySQL 8.4, are supported by the community for up to eight years. Please refer to the MySQL 9.4 release notes and Amazon RDS MySQL release notes for more details.\n  Amazon RDS Database Preview Environment supports both Single-AZ and Multi-AZ deployments on the latest generation of instance classes. Amazon RDS Database Preview Environment database instances are retained for a maximum of 60 days and are automatically deleted after the retention period. Amazon RDS database snapshots created in the Preview Environment can only be used to create or restore database instances within the Preview Environment.\n  Amazon RDS Database Preview Environment database instances are priced the same as production RDS instances created in the US East (Ohio) Region. For further information, see Working with the Database Preview Environment. To get started with the Preview Environment from the RDS console, navigate here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-rds-mysql-innovation-release-94-database-preview-environment/",
      "pubDate": "2025-09-19T15:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "preview",
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-d073fb3f6dab",
      "title": "Announcing AWS Neuron SDK 2.26.0",
      "description": "Today, AWS announces the general availability of Neuron SDK 2.26.0, delivering improvements for deep learning workloads on AWS Inferentia and Trainium-based instances. This release introduces support for PyTorch 2.8 and JAX 0.6.2, along with enhanced inference capabilities on Trainium2 (Trn2) instances. These updates enable developers to leverage the latest frameworks while benefiting from improved model deployment flexibility and performance optimizations.\n  With Neuron SDK 2.26.0, customers can now deploy FLUX.1-dev image generation model, along with Llama 4 Scout and Maverick variants (beta) on Trn2 instances. The release introduces expert parallelism support (beta) for efficient distribution of Mixture-of-Experts (MoE) models across multiple NeuronCores, and adds new capabilities through new Neuron Kernel Interface (NKI) APIs. The updated Neuron Profiler provides improved capabilities, including system profile grouping for distributed workloads.\n  The new SDK version is available in all AWS Regions supporting Inferentia and Trainium instances, offering enhanced performance and monitoring capabilities for machine learning workloads.\n  To learn more and for a full list of new features and enhancements, see:\n  \n \n \nAWS Neuron 2.26.0 release notes\n \n \nTrn2 Instances\n \n \nTrn1 Instances\n \n \nInf2 Instances",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-neuron-2-26-announce/",
      "pubDate": "2025-09-19T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex",
        "trainium",
        "inferentia",
        "neuron"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "trainium",
        "inferentia",
        "neuron",
        "beta",
        "new-feature",
        "update",
        "improvement",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-3105df2f3e57",
      "title": "Qwen models are now available in Amazon Bedrock",
      "description": "Amazon Bedrock has expanded its model offerings with the addition of Qwen 3 foundation models enabling users to access and deploy them in a fully managed, serverless environment. These models feature both mixture-of-experts (MoE) and dense architectures to support diverse use cases including advanced code generation, multi-tool business automation, and cost-optimized AI reasoning.",
      "link": "https://aws.amazon.com/blogs/aws/qwen-models-are-now-available-in-amazon-bedrock/",
      "pubDate": "2025-09-18T22:02:11.000Z",
      "source": "news-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "specialized",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-c753ba529f3a",
      "title": "Scale visual production using Stability AI Image Services in Amazon Bedrock",
      "description": "This post was written with Alex Gnibus of Stability AI. Stability AI Image Services are now available in Amazon Bedrock, offering ready-to-use media editing capabilities delivered through the Amazon Bedrock API. These image editing tools expand on the capabilities of Stability AI’s Stable Diffusion 3.5 models (SD3.5) and Stable Image Core and Ultra models, which […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/scale-visual-production-using-stability-ai-image-services-in-amazon-bedrock/",
      "pubDate": "2025-09-18T21:25:49.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available"
      ]
    },
    {
      "id": "aws-news-4b3b3aab825a",
      "title": "Amazon Kinesis Data Streams expands Internet Protocol version 6 support to the AWS GovCloud (US) Regions",
      "description": "Amazon Kinesis Data Streams now allows customers to make API requests over Internet Protocol version 6 (IPv6) in the AWS GovCloud (US) Regions. Customers have the option of using either IPv6 or IPv4 when sending requests over dual-stack public or VPC endpoints. The new endpoints have also been validated under the Federal Information Processing Standard (FIPS) 140-3 program.\n  Kinesis Data Streams allows users to capture, process, and store data streams in real time at any scale. IPv6 increases the number of available addresses by several orders of magnitude, so customers will no longer need to manage overlapping address spaces. Many devices and networks today already use IPv6, and now they can easily write to and read from data streams. FIPS-compliant endpoints help companies contracting with the US federal governments meet the FIPS security requirement to encrypt sensitive data in supported Regions.\n  Support for IPv6 with Kinesis Data Streams is now available in all Regions where Kinesis Data Streams is available, including AWS GovCloud (US) and China Regions. See here for a full listing of our Regions. To learn more about Kinesis Data Streams, please refer to our Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-kinesis-data-streams-ipv6-govcloud",
      "pubDate": "2025-09-18T17:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b61969a232f9",
      "title": "Second-generation AWS Outposts racks now supported in the AWS Canada (Central) and US West (N. California) Regions",
      "description": "Second-generation AWS Outposts racks are now supported in the AWS Canada (Central) and US West (N. California) Regions. Outposts racks extend AWS infrastructure, AWS services, APIs, and tools to virtually any on-premises data center or colocation space for a truly consistent hybrid experience.\n \nOrganizations from startups to enterprises and the public sector in and outside of Canada and the US can now order their Outposts racks connected to these two new supported Regions, optimizing for their latency and data residency needs. Outposts allows customers to run workloads that need low-latency access to on-premises systems locally while connecting back to their home Region for application management. Customers can also use Outposts and AWS services to manage and process data that needs to remain on-premises to meet data residency requirements. This regional expansion provides additional flexibility in the AWS Regions that customers’ Outposts can connect to.\n \nTo learn more about second-generation Outposts racks, read this blog post and user guide. For the most updated list of countries and territories and the AWS Regions where second-generation Outposts racks are supported, check out the Outposts racks FAQs page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/second-generation-outposts-racks-canada-us-west-regions",
      "pubDate": "2025-09-18T17:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "ga",
        "update",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-6c3d5ab4ad37",
      "title": "Use AWS Deep Learning Containers with Amazon SageMaker AI managed MLflow",
      "description": "In this post, we show how to integrate AWS DLCs with MLflow to create a solution that balances infrastructure control with robust ML governance. We walk through a functional setup that your team can use to meet your specialized requirements while significantly reducing the time and resources needed for ML lifecycle management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/use-aws-deep-learning-containers-with-amazon-sagemaker-ai-managed-mlflow/",
      "pubDate": "2025-09-18T15:29:35.000Z",
      "source": "ml-blog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-966a8a4d6e6a",
      "title": "OpenAI open weight models expand to new regions on Amazon Bedrock",
      "description": "Today, AWS announces the expansion of OpenAI open weight models on Amazon Bedrock to eight new regions. This expansion brings these powerful AI models closer to customers in various parts of the world, enabling lower latency and improved performance for a wide range of AI-powered applications.\n  With this expansion, the OpenAI open weight models are now available in the following AWS Regions: US East (N. Virginia), Asia Pacific (Tokyo), Europe (Stockholm), Asia Pacific (Mumbai), Europe (Ireland), South America (São Paulo), Europe (London), and Europe (Milan), in addition to the previously supported region of US West (Oregon). This broader availability allows more customers to leverage these state-of-the-art AI models while keeping their data within their preferred geographic locations, helping to address data residency requirements and reduce network latency.\n  To learn more about OpenAI open weight models on Amazon Bedrock and how to get started, visit the Amazon Bedrock console or check out our documentation. For more information about the initial release of these models on Amazon Bedrock, refer to our previous blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/open-ai-open-weight-models-new-regions-amazon-bedrock",
      "pubDate": "2025-09-18T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "now-available",
        "support",
        "new-region",
        "expansion"
      ]
    },
    {
      "id": "aws-news-b2e219fc1dd9",
      "title": "DeepSeek-V3.1 model now available fully managed in Amazon Bedrock",
      "description": "DeepSeek-V3.1 is now available as a fully managed foundation model in Amazon Bedrock. This advanced open weight model allows you to switch between thinking mode for detailed step-by-step analysis and non-thinking mode for quicker responses. With comprehensive multilingual support, it delivers enhanced accuracy and reduced hallucinations compared to previous DeepSeek models, while maintaining visibility into its decision-making process.\n  You can use DeepSeek-V3.1's enterprise-grade capabilities across critical business functions, from state-of-the-art software development to complex mathematical reasoning and data analysis. The model excels at sophisticated problem-solving tasks, demonstrating strong performance in coding benchmarks and technical challenges. Its enhanced tool-calling capabilities and seamless workflow integration make it ideal for building AI agents and automating enterprise processes, while its transparent reasoning approach helps teams understand and trust its outputs.\n  \n DeepSeek-V3.1 is now available in the US West (Oregon), Asia Paciﬁc (Tokyo), Asia Paciﬁc (Mumbai), Europe (London), and Europe (Stockholm) AWS Regions. To learn more, read the blog, product page, Amazon Bedrock pricing, and documentation. To get started with DeepSeek in Amazon Bedrock, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/deepseek-v3-1-model-fully-managed-amazon-bedrock",
      "pubDate": "2025-09-18T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-7d8f6bbc8755",
      "title": "AWS Step Functions now supports IPv6 with dual-stack endpoints",
      "description": "AWS Step Functions adds supports for IPv6. You can now send IPV6 traffic to AWS Step Functions via new dual-stack IPv4 and IPv6 endpoints. AWS Step Functions is a visual workflow service that enables customers to build distributed applications, automate IT and business processes, and build data and machine learning pipelines using AWS services. This enhancement addresses the growing need for IP addresses as the internet continues to expand, providing a larger address space than the traditional IPv4 format.\n  With IPv6 support, organizations modernizing their applications can now build serverless workflows without being constrained by limited IPv4 address space. The new dual-stack endpoints support both IPv4 and IPv6 protocols while maintaining backwards compatibility with existing IPv4 endpoints. Step Functions also supports IPv6 connectivity through PrivateLink interface Virtual Private Cloud (VPC) endpoints, enabling you to access the service privately without traversing the public internet. This enables organizations operating in IPv6 environments to natively integrate with Step Functions without requiring complex translation mechanisms between IPv6 and IPv4.\n  IPv6 support for AWS Step Functions is now generally available in US East (Ohio), US East (N. Virginia), US West (Oregon), US West (N. California) as well as AWS GovCloud (US-East), and AWS GovCloud (US-West) Regions, where AWS Step Functions is available.\n  To learn more about IPv6 support on AWS, visit the documentation page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-step-functions-ipv6-dual-stack-endpoints/",
      "pubDate": "2025-09-18T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "generally-available",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-ab65551d4b6c",
      "title": "Amazon OpenSearch Serverless now supports Disk-Optimized Vectors",
      "description": "We are excited to announce the launch of disk-optimized vector support for Amazon OpenSearch Serverless, offering customers a cost-effective solution for vector search operations without compromising on accuracy and recall rates. This new feature enables organizations to implement high-quality vector search capabilities while significantly reducing operational costs.\n  With the introduction of Disk Optimized Vectors, customers can now choose between memory-optimized and disk-optimized vector storage options. The disk-optimized option delivers the same high accuracy and recall rates as memory-optimized vectors at lower cost. While this option may introduce slightly higher latency, it's ideal for use cases where sub-millisecond response times aren't critical such as semantic search applications, recommendation systems, and other AI-powered search scenarios.\n  Amazon OpenSearch Serverless, our fully managed deployment option, eliminates the complexities of infrastructure management for search and analytics workloads. The service automatically scales compute capacity, measured in OpenSearch Compute Units (OCUs), based on your workload demands.\n \nPlease refer to the AWS Regional Services List for more information about Amazon OpenSearch Service availability. To learn more about OpenSearch Serverless, see the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/opensearch-serverless-disk-optimized-vectors",
      "pubDate": "2025-09-18T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "search",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "launch",
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-1506e98066da",
      "title": "Amazon SageMaker HyperPod now supports autoscaling using Karpenter",
      "description": "Amazon SageMaker HyperPod now supports managed node autoscaling using Karpenter, enabling customers to automatically scale their clusters to meet dynamic inference and training demands. Real-time inference workloads require automatic scaling to address unpredictable traffic patterns and maintain service level agreements, while optimizing costs. However, organizations often struggle with the operational overhead of installing, configuring, and maintaining complex autoscaling solutions. HyperPod-managed node autoscaling eliminates the undifferentiated heavy lifting of Karpenter setup and maintenance, while providing integrated resilience and fault tolerance capabilities.\n  Autoscaling on HyperPod with Karpenter enables customers to achieve just-in-time provisioning that rapidly adapts GPU compute for inference traffic spikes. Customers can scale to zero nodes during low-demand periods without maintaining dedicated controller infrastructure and benefit from workload-aware node selection that optimizes instance types and costs. For inference workloads, this provides automatic capacity scaling to handle production traffic bursts, cost reduction through intelligent node consolidation during idle periods, and seamless integration with event-driven pod autoscalers like KEDA. Training workloads also benefit from automatic resource optimization during model development cycles. You can enable autoscaling on HyperPod using the UpdateCluster API with AutoScaling mode set to \"Enable\" and AutoScalerType set to \"Karpenter\".\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod EKS clusters are supported. To learn more about autoscaling on SageMaker HyperPod with Karpenter, see the user guide and blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/sagemaker-hyperpod-autoscaling/",
      "pubDate": "2025-09-18T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "sagemaker",
        "hyperpod",
        "lex"
      ],
      "categories": [
        "machine-learning",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "lex",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-83fa28b776e6",
      "title": "Amazon Corretto 25 is now generally available",
      "description": "Amazon Corretto 25, a Long Term Support (LTS) version, is now generally available. Amazon Corretto is a no-cost, multi-platform, production-ready distribution of OpenJDK. You can download Corretto 25 for Linux, Windows, and macOS from our downloads page.\n  Amazon Corretto 25 new features include:\n  \n \n \nTwo features that were initially released as experimental in JDK 24 are now LTS production-ready in JDK 25:\n Compact Object Headers: designed to lower heap memory usage by shrinking object headers from 96-128 bits down to 64 bits.\n Generational Shenandoah GC: engineered to provide sustainable throughput and lower p99 pause times or similar pause times with a smaller heap and reduced CPU usage.\n \n \nAhead-of-Time (AOT) Caching: designed to improve cold-start and warm-up time by reusing pre-parsed pre-linked classes and compilation profiles between training and production runs.\n \n \nLanguage improvements: primitive types in patterns, flexible constructors, module‑wide imports, compact source files, scoped values for thread-local variables, stable values for immutable data, all designed to cut boilerplate, keep everyday code shorter and safer.\n \n \nObservability: JDK Flight Recorder gains CPU‑time sampling, cooperative sampling and method‑trace events for low‑overhead production profiling.\n \n \nStructured Concurrency: designed to provide coordinated task management, allowing related tasks fail or finish together.\n \n \nVector API: developed to provide computations that compile to optimal vector instructions on supported CPUs.\n \n \nVirtual Thread pinning improvements: reduces thread pinning in synchronized blocks for better scalability.\n \n \nA detailed description of these features can be found on the OpenJDK 25 Project page. Amazon Corretto 25 is distributed by Amazon under an open source license and will be supported through October 2032.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-corretto-25-generally-available",
      "pubDate": "2025-09-17T17:18:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "experimental",
        "generally-available",
        "ga",
        "new-feature",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-d5cfabcbf84e",
      "title": "Amazon CloudWatch launches Cross-Account and Cross-Region Log Centralization",
      "description": "Amazon CloudWatch now offers cross-account and cross-region log centralization, allowing customers to copy log data from multiple AWS accounts and regions into a single destination account. This capability seamlessly integrates with AWS Organizations, enabling efficient aggregation of logs from workloads that span multiple accounts and regions into a single account without the need to manage custom solutions.\n  The log centralization feature provides the ability to scope the centralization rules to copy log data from their entire organization, specific organizational units, or selected accounts into a single account. To maintain source context and data lineage, log events are enriched with new system fields (@aws.account and @aws.region) that identify the original source account and region. Additional capabilities include selective log group copying, automatic merging of same-named log groups in the destination account, and optional backup region setup, simplifying centralized log management.\n  Log centralization is available in US East (Ohio), US East (N. Virginia), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Osaka), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), and South America (São Paulo).\n  To learn more, visit the Amazon CloudWatch documentation. Customers can centralize one copy of logs for free. Additional copies are charged at $0.05/GB of logs centralized (the backup region feature is considered an additional copy). For details, visit the CloudWatch Pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-cloudwatch-cross-account-cross-region-log-centralization",
      "pubDate": "2025-09-17T15:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-468eb40781e1",
      "title": "Amazon EventBridge extends Customer Managed Key support to rule filter patterns and input transformers",
      "description": "Amazon EventBridge now extends AWS Key Management Service (KMS) customer managed key support to event bus rule filter patterns and input transformers. This capability enables you to use your own encryption keys to protect sensitive information in your event filtering and transformation logic to meet stringent security and compliance requirements while maintaining full control over your encryption keys.\n  Amazon EventBridge is a serverless event router that enables you to create scalable event-driven applications by routing events between your applications, third-party SaaS applications, and AWS services. Filter patterns determine which events match your rules, while input transformers allow you to customize the event data before sending it to targets. By encrypting these components with customer managed keys, you can help meet your organization's compliance and governance requirements and use AWS CloudTrail to audit and track encryption key usage.\n  This feature is available in all commercial AWS Regions. Using this feature incurs no additional cost, but standard AWS KMS pricing applies. To learn more, visit the EventBridge documentation and AWS KMS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-eventbridge-customer-managed-key-support-filter-patterns-input-transformers",
      "pubDate": "2025-09-17T14:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-6aa4a1e461b7",
      "title": "AWS Network Firewall enhances console, monitoring, and security features",
      "description": "AWS Network Firewall now offers enhancements to its console, monitoring dashboard, and security controls. These improvements include expanded monitoring insights and advanced TLS Inspection features. These updates provide customers with enhanced visibility into their firewall's performance and stronger security measures for outbound connections.\n  The monitoring dashboard now provides deeper insights into traffic going to AWS services such as Amazon S3, Amazon DynamoDB, and AWS Backup, which can be sent over PrivateLink endpoints. The dashboard also gives visibility into top source and destination IP addresses based on packets and bytes processed. Customers can filter the dashboard based on IP addresses and protocol, enabling more targeted analysis of network traffic patterns.\n  To further strengthen security, AWS Network Firewall has introduced session holding for TLS Inspection. This feature prevents any TCP and TLS establishment packets from reaching destination servers until TLS protocol rules matching on Server Name Indication (SNI) have been evaluated. This enhancement provides stronger security controls for outbound traffic and helps protect against connections to potentially malicious targets. These new features are available in all AWS Regions where AWS Network Firewall is offered.\n  To learn more about these new features and other AWS Network Firewall capabilities, visit the AWS Network Firewall product page and the service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-network-firewall-enhances-console-monitoring-security-features",
      "pubDate": "2025-09-17T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "new-feature",
        "update",
        "improvement",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-284b40fb9a60",
      "title": "Amazon EC2 I7i instances now available in South America (São Paulo), Canada West (Calgary) regions",
      "description": "Amazon Web Services (AWS) announces the availability of high performance Storage Optimized Amazon EC2 I7i instances in the AWS South America (São Paulo), Canada West (Calgary) regions. Powered by 5th generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.2 GHz, these new instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances. Powered by 3rd generation AWS Nitro SSDs, I7i instances offer up to 45TB of NVMe storage with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances.\n  I7i instances offer the best compute and storage performance for x86-based storage optimized instances in Amazon EC2, ideal for I/O intensive and latency-sensitive workloads that demand very high random IOPS performance with real-time latency to access the small to medium size datasets (multi-TBs). Additionally, torn write prevention feature support up to 16KB block sizes, enabling customers to eliminate database performance bottlenecks.\n  I7i instances are available in eleven sizes - nine virtual sizes up to 48xlarge and two bare metal sizes - delivering up to 100Gbps of network bandwidth and 60Gbps of Amazon Elastic Block Store (EBS) bandwidth.\n To learn more, visit the I7i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-i7i-instances-sao-paulo-calgary-regions/",
      "pubDate": "2025-09-16T17:30:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f789b4eea2b5",
      "title": "Amazon Lex provides generative AI based enhanced natural language understanding in eight new languages",
      "description": "Amazon Lex now allows you to leverage large language models (LLMs) to improve the natural language understanding of your deterministic conversational AI bots in eight new languages: Chinese, Japanese, Korean, Portuguese, Catalan, French, Italian, and German. With this capability, your voice- and chat-bots can better handle complex utterances, maintain accuracy despite spelling errors, and extract key information from verbose inputs to fulfill the customer’s request. For example, a customer could say ‘Hi I want to book a flight for my wife, my two kids and myself’, and the LLM will properly identify to book flight tickets for four people.\n \nThis feature is available in 10 commercial AWS Regions where Amazon Connect is available: Europe (Ireland), Europe (Frankfurt), US East (N. Virginia), Asia Pacific (Seoul), Europe (London), Asia Pacific (Tokyo), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central). To learn more about this feature, visit Amazon Lex documentation or to learn how Amazon Connect and Amazon Lex deliver cloud-based conversational AI experiences for contact centers, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-lex-generative-ai-natural-language-eight-languages/",
      "pubDate": "2025-09-16T17:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-26d7a1c18ba9",
      "title": "New fault action in AWS FIS to inject I/O latency on Amazon EBS volumes",
      "description": "Today, Amazon EBS announced a new latency injection action in AWS Fault Injection Service (FIS), a fully managed service for running fault injection experiments. You can now use this action to inject I/O latency on your volumes as part of a controlled testing experiment to understand how your mission-critical applications respond to storage faults. With the new fault action, you can test your architecture against elevated storage latency, allowing you to observe application behavior and fine-tune your monitoring and recovery processes to ensure high availability.\n  EBS volumes are designed to meet the needs of highly available, latency-sensitive applications such as Oracle, SAP HANA, and Microsoft SQL Server. The latency injection action simulates degraded I/O performance on your volume to replicate the real-world signals, such as Amazon CloudWatch alarms and operating system timeouts, that occur during storage performance issues. Using this action, you can build confidence that your application can withstand and quickly recover from disruptions that cause high I/O latency on your EBS volume. To get started, you can directly use the pre-defined latency injection experiment templates available in the EBS and FIS consoles. Alternatively, you can customize these experiment templates or create your own experiment templates to meet your application-specific testing needs. You can integrate these latency injection experiments into your existing chaos engineering tests, continuous integration, and release testing, as well as combine multiple FIS actions in one experiment.\n  This new action is available in all AWS Regions where AWS FIS is available. To learn more, visit the EBS FIS actions user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-fis-action-inject-io-latency-on-ebs/",
      "pubDate": "2025-09-16T17:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-15d87cb93331",
      "title": "Streamline access to ISO-rating content changes with Verisk rating insights and Amazon Bedrock",
      "description": "In this post, we dive into how Verisk Rating Insights, powered by Amazon Bedrock, large language models (LLM), and Retrieval Augmented Generation (RAG), is transforming the way customers interact with and access ISO ERC changes.",
      "link": "https://aws.amazon.com/blogs/machine-learning/streamline-access-to-iso-rating-content-changes-with-verisk-rating-insights-and-amazon-bedrock/",
      "pubDate": "2025-09-16T16:43:42.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-431447666038",
      "title": "Unified multimodal access layer for Quora’s Poe using Amazon Bedrock",
      "description": "In this post, we explore how the AWS Generative AI Innovation Center and Quora collaborated to build a unified wrapper API framework that dramatically accelerates the deployment of Amazon Bedrock FMs on Quora’s Poe system. We detail the technical architecture that bridges Poe’s event-driven ServerSentEvents protocol with Amazon Bedrock REST-based APIs, demonstrate how a template-based configuration system reduced deployment time from days to 15 minutes, and share implementation patterns for protocol translation, error handling, and multi-modal capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/unified-multimodal-access-layer-for-quoras-poe-using-amazon-bedrock/",
      "pubDate": "2025-09-16T16:40:11.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-caf42165b637",
      "title": "AWS Storage Gateway now supports IPv6",
      "description": "AWS Storage Gateway announces Internet Protocol version 6 (IPv6) support for AWS Storage Gateway endpoints, APIs, and gateway appliance interfaces. This enhancement enables both IPv6 and IPv4 access to our new dual-stack endpoints. The existing AWS Storage Gateway endpoints supporting IPv4 only will remain available for backwards compatibility.\n  AWS Storage Gateway provides on-premises access to data stored in AWS storage. With this launch, customers can standardize their applications and workflows for managing their AWS Storage Gateway resources on IPv6 while maintaining backward compatibility with IPv4 clients. By using the new dual-stack capabilities in the Storage Gateway appliances, service endpoints, and APIs, customers can transition from IPv4 to IPv6 gradually without needed to switch all their networking at once.\n  AWS Storage Gateway support for IPv6 is available in all AWS Regions where the service is offered. To learn more, visit the AWS Storage Gateway user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-storage-gateway-ipv6",
      "pubDate": "2025-09-16T14:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-acef894cb19a",
      "title": "Amazon Aurora PostgreSQL Limitless Database is now available in the AWS GovCloud (US-East, US-West) Regions",
      "description": "Aurora PostgreSQL Limitless Database, now available in AWS GovCloud (US-East, US-West) Regions, makes it easy for you to scale your relational database workloads by providing a serverless endpoint that automatically distributes data and queries across multiple Amazon Aurora Serverless instances while maintaining the transactional consistency of a single database. Aurora PostgreSQL Limitless Database offers capabilities such as distributed query planning and transaction management, removing the need for you to create custom solutions or manage multiple databases to scale. As your workloads increase, Aurora PostgreSQL Limitless Database adds additional compute resources while staying within your specified budget, so there is no need to provision for peak, and compute automatically scales down when demand is low.\n  Aurora PostgreSQL Limitless Database is available with PostgreSQL 16.6, 16.8, and 16.9 compatibility in these regions.\n  For pricing details and Region availability, visit Amazon Aurora pricing. To learn more, read the Aurora PostgreSQL Limitless Database documentation and get started by creating an Aurora PostgreSQL Limitless Database in only a few steps in the Amazon RDS console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-aurora-postgresql-limitless-database-aws-govcloud-regions",
      "pubDate": "2025-09-16T14:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-c8de345f941d",
      "title": "Amazon EC2 R8i and R8i-flex instances are now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8i and R8i-flex instances are available in the Asia Pacific (Malaysia, Singapore) and Europe (Frankfurt) regions. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. The R8i and R8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver 20% better performance than R7i instances, with even higher gains for specific workloads. They are up to 30% faster for PostgreSQL databases, up to 60% faster for NGINX web applications, and up to 40% faster for AI deep learning recommendation models compared to R7i.\n  R8i-flex, our first memory-optimized Flex instances, are the easiest way to get price performance benefits for a majority of memory-intensive workloads. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  R8i instances are a great choice for all memory-intensive workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. R8i instances offer 13 sizes including 2 bare metal and the new 96xlarge size for the largest applications. R8i instances are SAP-certified and deliver 142,100 aSAPS, the highest among all comparable machines in on-premises and cloud environments, delivering exceptional performance for mission-critical SAP workloads.\n  To get started, sign in to the AWS Management Console. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information about the new R8i and R8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-r8i-r8i-flex-additional-regions/",
      "pubDate": "2025-09-16T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-5429585a0e6f",
      "title": "AWS Transfer Family is now available in AWS Asia Pacific (Taipei) region",
      "description": "Customers in AWS Asia Pacific (Taipei) Region can now use AWS Transfer Family for file transfers over Secure File Transfer Protocol (SFTP), File Transfer Protocol (FTP), FTP over SSL (FTPS) and Applicability Statement 2 (AS2).\n  AWS Transfer Family provides fully managed file transfers for Amazon Simple Storage Service (Amazon S3) and Amazon Elastic File System (Amazon EFS) over SFTP, FTP, FTPS and AS2 protocols. In addition to file transfers, Transfer Family enables common file processing and event-driven automation for managed file transfer (MFT) workflows, helping customers to modernize and migrate their business-to-business file transfers to AWS.\n  To learn more about AWS Transfer Family, visit our product page and user-guide. See the AWS Region Table for complete regional availability information.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-transfer-family-asia-pacific-taipei-region/",
      "pubDate": "2025-09-16T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-13e62f3b3518",
      "title": "Amazon OpenSearch Service announces Star-Tree Index",
      "description": "OpenSearch has introduced Star-Tree Index, a new feature that significantly improves aggregation performance for high-cardinality and multi-dimensional queries. This index pre-aggregates data across configured dimensions and metrics at ingestion time, enabling sub-second response times for frequent aggregations like terms, histogram, and range.\n  Star-Tree Index is designed for real-time analytics and requires no changes to query syntax; OpenSearch automatically uses the optimized path when supported queries are detected. Early benchmarks show faster aggregation performance on large datasets. This makes it ideal for use cases such as observability, personalization, and time-series dashboards. It works best with append-only data and builds during segment refresh/merge, with minimal impact on ingestion throughput.\n  Star-Tree Index is available in all regions where OpenSearch 3.1 is supported. The feature is opt-in and can be enabled at index creation time using composite index settings.\n  Please refer to the AWS Regional Services List for more information about Amazon OpenSearch Service availability. To learn more about Star-Tree Index, see the OpenSearch Documentation",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-opensearch-star-tree-index/",
      "pubDate": "2025-09-16T04:30:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4bc44e9f4d66",
      "title": "Amazon S3 Batch Operations now supports managing buckets or prefixes in a single step in AWS Management Console",
      "description": "Amazon S3 Batch Operations now supports managing objects within an S3 bucket, prefix, suffix, or more, in a single step in AWS Management Console. When creating an S3 Batch Operation, customers can specify the objects on which to perform the operation. With this feature, you have the option to instead specify an entire bucket, prefix, suffix, creation date, or storage class. Amazon S3 Batch Operations will then quickly apply the operation to all the matching objects and notify you when the job completes.\n \nS3 Batch Operations lets you easily perform one-time or recurring batch workloads such as copying objects between staging and production buckets, restoring archived backups from S3 Glacier storage classes, or computing objects checksum to verify the content of stored datasets, at any scale. After starting your job, S3 Batch Operations automatically processes all of the objects that match your filtering criteria. You will receive a detailed completion report with the status of each object once the job completes.\n  This feature of S3 Batch Operations is available in all AWS Regions. You can get started through AWS Management Console, AWS Command Line Interface (CLI), or the AWS Software Development Kit (SDK) client. For pricing information, please visit the Management & Insights tab of the Amazon S3 pricing page. To learn more about S3 Batch Operations, visit the S3 User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-s3-batch-operations-managing-buckets-console",
      "pubDate": "2025-09-15T21:30:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-bd724f32f406",
      "title": "Amazon SageMaker HyperPod announces health monitoring agent support for Slurm clusters",
      "description": "Today, Amazon SageMaker HyperPod announces the general availability of the health monitoring agent for Slurm clusters. SageMaker HyperPod helps you provision resilient clusters for running machine learning (ML) workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs). The health monitoring agent performs passive, background health checks of instances to identify problems in key areas without impact on application behavior or performance, flags failures instantly, and replaces any unhealthy instances to keep your training jobs running smoothly. \n \nThe agent runs continuously on all GPU- or Trainium-based nodes in your HyperPod cluster, watching for hardware issues such as unresponsive GPUs or NVLink error counters. When a fault is detected, it marks the node as unhealthy and automatically reboots or replaces it with a healthy node, keeping your jobs running without requiring manual intervention. The agent also follows a co-ordinated approach to handling failures with the job auto-resume functionality available with Slurm clusters. For example, jobs with auto-resume enabled will continue from the last saved checkpoint once nodes are replaced by the agent. This hands-free recovery—already available on HyperPod clusters orchestrated with Amazon EKS—now gives Slurm clusters the same resilient environment, helping teams train large models for weeks without disruption and reclaim time and costs that would otherwise be lost to mid-run failures. In addition, customers can now also reboot their nodes using a simple command in case of intermittent issues such as GPU driver issues requiring reset. \n \nHealth monitoring agent for Slurm is available in all regions where HyperPod is generally available. The agent is auto-enabled on all newly created Slurm clusters; to enable it on an existing cluster, simply upgrade to the latest HyperPod AMI by calling the UpdateClusterSoftware API. To learn more, visit the Amazon SageMaker HyperPod documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-sagemaker-hyperpod-health-monitoring-agent-slurm/",
      "pubDate": "2025-09-15T18:00:00.000Z",
      "source": "whats-new",
      "services": [
        "sagemaker",
        "hyperpod",
        "trainium"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "trainium",
        "generally-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-e7c29bbdeaf8",
      "title": "Amazon OpenSearch Service now supports AI-powered forecasting",
      "description": "You can now generate AI-powered forecasts and visualizations on time-series data that has been indexed into Amazon OpenSearch domains.\n  Forecasts can be used to enhance various analytics use cases to power insights into trending infrastructure utilization and events, application or business metrics, and more. They can help you anticipate upcoming changes in areas such as business metrics, website traffic, system performance, and more. You can easily get started with this feature by setting up forecasts within OpenSearch dashboards or the OpenSearch UI. No data science or AI expertise is required.\n  AI-powered forecasts are available in all Amazon OpenSearch Service regions that support OpenSearch 3.1+ domains. Learn more from the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-opensearch-service-ai-forecasting",
      "pubDate": "2025-09-15T17:40:00.000Z",
      "source": "whats-new",
      "services": [
        "forecast"
      ],
      "categories": [
        "personalization",
        "industry-cases"
      ],
      "tags": [
        "forecast",
        "support"
      ]
    },
    {
      "id": "aws-news-591c4b0afb89",
      "title": "How msg enhanced HR workforce transformation with Amazon Bedrock and msg.ProfileMap",
      "description": "In this post, we share how msg automated data harmonization for msg.ProfileMap, using Amazon Bedrock to power its large language model (LLM)-driven data enrichment workflows, resulting in higher accuracy in HR concept matching, reduced manual workload, and improved alignment with compliance requirements under the EU AI Act and GDPR.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-msg-enhanced-hr-workforce-transformation-with-amazon-bedrock-and-msg-profilemap/",
      "pubDate": "2025-09-15T17:05:18.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-94338f4e0c14",
      "title": "AWS Weekly Roundup: Strands Agents 1M+ downloads, Cloud Club Captain, AI Agent Hackathon, and more (September 15, 2025)",
      "description": "Last week, Strands Agents, AWS open source for agentic AI SDK just hit 1 million downloads and earned 3,000+ GitHub Stars less than 4 months since launching as a preview in May 2025. With Strands Agents, you can build production-ready, multi-agent AI systems in a few lines of code. We’ve continuously improved features including support […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-strands-agents-1m-downloads-cloud-club-captain-ai-agent-hackathon-and-more-september-15-2025/",
      "pubDate": "2025-09-15T16:45:14.000Z",
      "source": "news-blog",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-217d740871a7",
      "title": "Announcing on-demand deployment for custom Meta Llama models in Amazon Bedrock",
      "description": "Starting today, customers can use the on-demand deployment option in Amazon Bedrock for their Meta Llama 3.3 models that have been fine-tuned or distilled in Bedrock. Models customized on or after September 15, 2025 will be eligible.\n  This enables Bedrock customers to reduce costs by processing requests in real time without requiring pre-provisioned compute resources. Customers only pay for what they use, eliminating the need for an always-on infrastructure.\n  Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models from leading AI companies via a single API. Amazon Bedrock also provides a broad set of capabilities customers need to build generative AI applications with security, privacy, and responsible AI built in.\n  To get started, visit documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/on-demand-deployment-custom-meta-llama-models-amazon-bedrock",
      "pubDate": "2025-09-15T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-9647db854f84",
      "title": "AWS Organizations now provides account state information for member accounts",
      "description": "AWS Organizations provides a new State field in the AWS Organizations Console and APIs (DescribeAccount, ListAccounts, and ListAccountsForParent) to enhance AWS account lifecycle visibility. With this launch, the account state, a new State field replaced the existing account status, Status field in the AWS Organizations Console, however both Status and State fields will remain available in the APIs until September 9, 2026.\n  This launch allows you to have a more granular account state information such as, 'SUSPENDED' for AWS-enforced suspension, 'PENDING_CLOSURE' for in-process closure requests, and 'CLOSED' for accounts in their 90-day reinstatement window, and more. After September, 2026 the Status field will be fully deprecated. Customers using account vending pipelines should update their implementations to reference the State field before the Status field deprecation date. This feature is available in all AWS commercial and AWS GovCloud (US) Regions. To get started managing your accounts, please see the blog post and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-organizations-provides-account-state-information-member-accounts",
      "pubDate": "2025-09-15T14:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-339b3a3ddf03",
      "title": "Amazon Managed Service for Prometheus now available in 11 additional AWS Regions",
      "description": "Amazon Managed Service for Prometheus is now available in Asia Pacific (Jakarta), Asia Pacific (Hyderabad), Asia Pacific (Osaka), Asia Pacific (Melbourne), Asia Pacific (Taipei), Canada West (Calgary), Europe (Spain), Israel (Tel Aviv), Mexico (Central), Middle East (Bahrain), and US West (N. California). Amazon Managed Service for Prometheus is a fully managed Prometheus-compatible monitoring service that makes it easy to monitor and alarm on operational metrics at scale.\n \nThe list of all supported regions where Amazon Managed Service for Prometheus is generally available can be found in the user guide. Customers can send up to 1 billion active metrics to a single workspace and can create multiple workspaces per account, where a workspace is a logical space dedicated to the storage and querying of Prometheus metrics.\n \nTo learn more about Amazon Managed Service for Prometheus, visit the user guide or product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-managed-service-prometheus-11-regions/",
      "pubDate": "2025-09-15T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "generally-available",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-79795044339d",
      "title": "Automate advanced agentic RAG pipeline with Amazon SageMaker AI",
      "description": "In this post, we walk through how to streamline your RAG development lifecycle from experimentation to automation, helping you operationalize your RAG solution for production deployments with Amazon SageMaker AI, helping your team experiment efficiently, collaborate effectively, and drive continuous improvement.",
      "link": "https://aws.amazon.com/blogs/machine-learning/automate-advanced-agentic-rag-pipeline-with-amazon-sagemaker-ai/",
      "pubDate": "2025-09-12T17:36:19.000Z",
      "source": "ml-blog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "improvement"
      ]
    },
    {
      "id": "aws-news-175801ccccab",
      "title": "AWS Direct Connect support for 4-byte Autonomous System numbers for Virtual interfaces",
      "description": "AWS Direct Connect now supports 4-byte Autonomous System (AS) numbers for virtual interfaces. Direct Connect uses the standard Border Gateway Protocol to provide customers with private connectivity to the AWS global network. However, customers with complex, multi-tenant network topologies or who need to maintain consistent AS numbering across their entire network can run into challenges with the maximum limit of 65,536 possible 2-byte AS numbers. With 4-byte AS numbers, customers can now use the entire range supported by RFC 6793, up to 4,294,967,294.\n Support for 4-byte AS numbers is now available in all AWS regions globally and on all Direct Connect virtual interface types. To get started, visit the AWS Direct Connect Console or use the updated APIs to create virtual interfaces with the new 4-byte AS numbers. For more information, check out the AWS Direct Connect documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-direct-connect-4-byte-autonomous-system-numbers/",
      "pubDate": "2025-09-12T17:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "lex",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-1d6dabcf2cd0",
      "title": "Announcing general availability of Amazon EC2 M4 and M4 Pro Mac instances",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) M4 and M4 Pro Mac instances are now generally available (GA). M4 Mac instances offer up to 20% better application build performance compared to M2 Mac instances, while M4 Pro Mac instances deliver up to 15% better application build performance compared to M2 Pro Mac instances. These instances are ideal for building and testing applications for Apple platforms such as iOS, macOS, iPadOS, tvOS, watchOS, visionOS, and Safari.\n  M4 and M4 Pro Mac instances are powered by the AWS Nitro System, providing up to 10 Gbps network bandwidth and 8 Gbps of Amazon Elastic Block Store (Amazon EBS) storage bandwidth. M4 Mac instances are built on Apple M4 Mac Mini computers featuring 10‑core CPU, 10‑core GPU, 24GB unified memory, and 16‑core Neural Engine. M4 Pro Mac instances feature a 14‑core CPU, 20‑core GPU, 48GB unified memory, and 16‑core Neural Engine. Both instance families come with a new 2TB instance store volume per EC2 Mac Dedicated Host, providing low latency storage for improved caching and build/test performance.\n  M4 and M4 Pro Mac instances enable Apple developers to migrate their most demanding build and test workloads onto AWS and run significantly more tests in parallel using multiple Xcode simulators. This accelerates application iterations and reduces time to market. Customers now have access to the most advanced Apple silicon Macs on AWS to meet their requirements, while also enabling them to modernize their Apple CI/CD with dozens of AWS services. M4 and M4 Pro Mac instances support macOS Sequoia version 15.6 and newer AMIs (Amazon Machine Images).\n \nAmazon EC2 M4 and M4 Pro Mac instances are available in US East (N. Virginia) and US West (Oregon). To learn more or get started, see our launch blog, Amazon EC2 Mac Instances or visit the EC2 Mac documentation reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-ec2-m4-pro-mac-instances-generally-available",
      "pubDate": "2025-09-12T15:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "launch",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-c1f00f103971",
      "title": "Amazon SageMaker notebooks now support P6-B200 instance type",
      "description": "We are pleased to announce general availability of Amazon EC2 P6-B200 instances on SageMaker notebooks.\n  Amazon EC2 P6-B200 instances are powered by 8 NVIDIA Blackwell GPUs with 1440 GB of high-bandwidth GPU memory and 5th Generation Intel Xeon processors (Emerald Rapids). These instances deliver up to 2x better performance compared to P5en instances for AI training. Customers can use P6-B200 instances to interactively develop and fine-tune large foundation models, including LLMs, mixture of experts models, and multi-modal reasoning models. These instances enable efficient experimentation with larger models directly in JupyterLab or CodeEditor environments for generative AI applications such as enterprise copilots and content generation across text, images, and video.\n  Amazon EC2 P6-B200 instances are available for SageMaker notebooks in the AWS US East (Ohio) and US West (Oregon) regions.\n  Visit developer guides for instructions on setting up and using JupyterLab and CodeEditor applications on SageMaker Studio and SageMaker notebook instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-sagemaker-notebooks-p6-b200-instance-type",
      "pubDate": "2025-09-12T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-4e6baf0adce0",
      "title": "Deadline Cloud is now available in Asia Pacific (Seoul) and Europe (London)",
      "description": "We are excited to announce that AWS Deadline Cloud is now available in Asia Pacific (Seoul) and Europe (London). Deadline Cloud is a fully managed service that simplifies render management for teams creating computer-generated graphics and visual effects for films, television, broadcasting, web content, and design. Customers can now use Deadline Cloud to scale their render farms in regions that are close to their creative teams, enabling better integration with existing AWS services and creative pipelines.\n  Deadline Cloud is now available in 10 AWS regions worldwide: US East (N. Virginia and Ohio), US West (Oregon), Asia Pacific (Seoul, Singapore, Sydney and Tokyo), and Europe (Frankfurt, Ireland, and London). For more information about AWS Regions and where Deadline Cloud is available, see the AWS Region table. To learn more about AWS Deadline Cloud and its regional availability, visit the AWS Deadline Cloud product page or refer to the AWS Regional Services List.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/deadline-cloud-in-asia-pacific-seoul-europe-london/",
      "pubDate": "2025-09-12T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-e23b7dbed26b",
      "title": "Malware Protection for S3 Expands File Size and Archive Scanning Limits",
      "description": "Today, AWS announces enhanced scanning capabilities for GuardDuty Malware Protection for Amazon S3. This launch increases scanning capabilities by raising the maximum file size limit from 5GB to 100 GB. Additionally, the archive processing capacity has been expanded to handle up to 10,000 files per archive, up from the previous limit of 1,000 files.\n  GuardDuty Malware Protection for S3 is a fully managed threat detection service that automatically scans objects uploaded to S3 buckets and alerts customers of malware, viruses, and other malicious code before they can impact workloads or downstream processes. With this launch, GuardDuty S3 malware scanning now offers customers even better protection for large files and comprehensive archive collections stored in Amazon S3.\n  The enhanced scanning capabilities are automatically enabled in all AWS Regions where GuardDuty Malware Protection for S3 is supported. To learn more about GuardDuty Malware Protection for S3 and its features, please visit the AWS Documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/malware-protection-s3-file-size-archive-scanning-limits/",
      "pubDate": "2025-09-12T07:00:00.000Z",
      "source": "whats-new",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-6e94e435ee43",
      "title": "AWS Weekly Roundup: Single GPU P5 instances, Advanced Go Driver, Amazon SageMaker HyperPod and more (August 18, 2025)",
      "description": "Let me start this week’s update with something I’m especially excited about – the upcoming BeSA (Become a Solutions Architect) cohort. BeSA is a free mentoring program that I host along with a few other AWS employees on a volunteer basis to help people excel in their cloud careers. Last week, the instructors’ lineup was […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-single-gpu-p5-instances-advanced-go-driver-amazon-sagemaker-hyperpod-and-more-august-18-2025/",
      "pubDate": "2025-08-18T15:39:10.000Z",
      "source": "news-blog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "update"
      ]
    },
    {
      "id": "aws-news-0b47e55e58e4",
      "title": "AWS named as a Leader in 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for 15 years in a row",
      "description": "AWS is recognized as a Leader in the 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for the fifteenth consecutive year. In the report, Gartner once again placed AWS highest on the “Ability to Execute” axis. We believe this reflects our ongoing commitment to giving customers the broadest and deepest set of capabilities to accelerate innovation as well as unparalleled security, reliability, and performance they can trust for their most critical applications.",
      "link": "https://aws.amazon.com/blogs/aws/aws-named-as-a-leader-in-2025-gartner-magic-quadrant-for-strategic-cloud-platform-services-for-15-years-in-a-row/",
      "pubDate": "2025-08-15T16:59:11.000Z",
      "source": "news-blog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-81c6c3e233a5",
      "title": "AWS Weekly Roundup: OpenAI models, Automated Reasoning checks, Amazon EVS, and more (August 11, 2025)",
      "description": "AWS Summits in the northern hemisphere have mostly concluded but the fun and learning hasn’t yet stopped for those of us in other parts of the globe. The community, customers, partners, and colleagues enjoyed a day of learning and networking last week at the AWS Summit Mexico City and the AWS Summit Jakarta. Last week’s […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-openai-models-automated-reasoning-checks-amazon-evs-and-more-august-11-2025/",
      "pubDate": "2025-08-11T16:05:01.000Z",
      "source": "news-blog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    }
  ]
}