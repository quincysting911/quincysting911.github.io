{
  "lastUpdated": "2025-12-21T06:15:55.321Z",
  "category": "machine-learning",
  "totalItems": 7,
  "items": [
    {
      "id": "aws-news-5461a4240f23",
      "title": "Introducing SOCI indexing for Amazon SageMaker Studio: Faster container startup times for AI/ML workloads",
      "description": "Today, we are excited to introduce a new feature for SageMaker Studio: SOCI (Seekable Open Container Initiative) indexing. SOCI supports lazy loading of container images, where only the necessary parts of an image are downloaded initially rather than the entire container.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-soci-indexing-for-amazon-sagemaker-studio-faster-container-startup-times-for-ai-ml-workloads/",
      "pubDate": "2025-12-19T18:23:50.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-ca2965bf0697",
      "title": "Amazon SageMaker Studio now supports SOCI indexing for faster container startup times",
      "description": "Today, AWS announces SOCI (Seekable Open Container Initiative) indexing support for Amazon SageMaker Studio, reducing container startup times by 30-50% when using custom images. Amazon SageMaker Studio is a fully integrated, browser-based environment for end-to-end machine learning development. SageMaker Studio provides pre-built container images for popular ML frameworks like TensorFlow, PyTorch, and Scikit-learn that enable quick environment setup. However, when data scientists need to tailor environments for specific use cases with additional libraries, dependencies, or configurations, they can build and register custom container images with pre-configured components to ensure consistency across projects. As ML workloads become increasingly complex, these custom container images have grown in size, leading to startup times of several minutes that create a bottlenecks in iterative ML development where quick experimentation and rapid prototyping are essential.\n  SOCI indexing addresses this challenge by enabling lazy loading of container images, downloading only the necessary components to start applications with additional files loaded on-demand as needed. Instead of waiting several minutes for complete custom image downloads, users can begin productive work in seconds while the environment completes initialization in the background. To use SOCI indexing, create a SOCI index for your custom container image using tools like Finch CLI, nerdctl, or Docker with SOCI CLI, push the indexed image to Amazon Elastic Container Registry (ECR), and reference the image index URI when creating SageMaker Image resources.\n  SOCI indexing is available in all AWS Regions where Amazon SageMaker Studio is available. To learn more about implementing SOCI indexing for your SageMaker Studio custom images, see Bring your own SageMaker image in the Amazon SageMaker Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-nbi-soci/",
      "pubDate": "2025-12-19T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-13a0ca971134",
      "title": "Track machine learning experiments with MLflow on Amazon SageMaker using Snowflake integration",
      "description": "In this post, we demonstrate how to integrate Amazon SageMaker managed MLflow as a central repository to log these experiments and provide a unified system for monitoring their progress.",
      "link": "https://aws.amazon.com/blogs/machine-learning/track-machine-learning-experiments-with-mlflow-on-amazon-sagemaker-using-snowflake-integration/",
      "pubDate": "2025-12-17T16:50:57.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "integration"
      ]
    },
    {
      "id": "aws-news-ea7c0f3a27c5",
      "title": "Reference guide for building a self-service analytics solution with Amazon SageMaker",
      "description": "In this post, we show how to use Amazon SageMaker Catalog to publish data from multiple sources, including Amazon S3, Amazon Redshift, and Snowflake. This approach enables self-service access while ensuring robust data governance and metadata management.",
      "link": "https://aws.amazon.com/blogs/big-data/reference-guide-for-building-a-self-service-analytics-solution-with-amazon-sagemaker/",
      "pubDate": "2025-12-16T21:47:23.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "s3",
        "redshift"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "redshift"
      ]
    },
    {
      "id": "aws-news-eea5558b8e2f",
      "title": "Amazon SageMaker AI is now available in Asia Pacific (New Zealand)",
      "description": "Starting today, you can build, train, and deploy machine learning (ML) models in Asia Pacific (New Zealand).\n  Amazon SageMaker AI is a fully managed platform that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker AI removes the heavy lifting from each step of the machine learning process to make it easier to develop high quality models.\n \nTo learn more and get started, see SageMaker AI documentation and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-ai-asia-pacific-new-zealand",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "now-available"
      ]
    },
    {
      "id": "aws-news-f91bea5e9dd1",
      "title": "Checkpointless training on Amazon SageMaker HyperPod: Production-scale training with faster fault recovery",
      "description": "In this post, we introduce checkpointless training on Amazon SageMaker HyperPod, a paradigm shift in model training that reduces the need for traditional checkpointing by enabling peer-to-peer state recovery. Results from production-scale validation show 80–93% reduction in recovery time (from 15–30 minutes or more to under 2 minutes) and enables up to 95% training goodput on cluster sizes with thousands of AI accelerators.",
      "link": "https://aws.amazon.com/blogs/machine-learning/checkpointless-training-on-amazon-sagemaker-hyperpod-production-scale-training-with-faster-fault-recovery/",
      "pubDate": "2025-12-15T19:45:50.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-aa5650a9d9d2",
      "title": "SAP data ingestion and replication with AWS Glue zero-ETL",
      "description": "AWS Glue zero-ETL with SAP now supports data ingestion and replication from SAP data sources such as Operational Data Provisioning (ODP) managed SAP Business Warehouse (BW) extractors, Advanced Business Application Programming (ABAP), Core Data Services (CDS) views, and other non-ODP data sources. Zero-ETL data replication and schema synchronization writes extracted data to AWS services like Amazon Redshift, Amazon SageMaker lakehouse, and Amazon S3 Tables, alleviating the need for manual pipeline development. In this post, we show how to create and monitor a zero-ETL integration with various ODP and non-ODP SAP sources.",
      "link": "https://aws.amazon.com/blogs/big-data/sap-data-ingestion-and-replication-with-aws-glue-zero-etl/",
      "pubDate": "2025-12-08T23:11:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "s3",
        "redshift",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "redshift",
        "glue",
        "integration",
        "support"
      ]
    }
  ]
}