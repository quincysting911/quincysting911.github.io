{
  "lastUpdated": "2025-12-09T06:17:04.390Z",
  "category": "machine-learning",
  "totalItems": 14,
  "items": [
    {
      "id": "aws-news-aa5650a9d9d2",
      "title": "SAP data ingestion and replication with AWS Glue zero-ETL",
      "description": "AWS Glue zero-ETL with SAP now supports data ingestion and replication from SAP data sources such as Operational Data Provisioning (ODP) managed SAP Business Warehouse (BW) extractors, Advanced Business Application Programming (ABAP), Core Data Services (CDS) views, and other non-ODP data sources. Zero-ETL data replication and schema synchronization writes extracted data to AWS services like Amazon Redshift, Amazon SageMaker lakehouse, and Amazon S3 Tables, alleviating the need for manual pipeline development. In this post, we show how to create and monitor a zero-ETL integration with various ODP and non-ODP SAP sources.",
      "link": "https://aws.amazon.com/blogs/big-data/sap-data-ingestion-and-replication-with-aws-glue-zero-etl/",
      "pubDate": "2025-12-08T23:11:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "s3",
        "redshift",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "redshift",
        "glue",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-4d9478a7f155",
      "title": "Amazon SageMaker now supports self-service migration of Notebook instances to latest platform versions",
      "description": "Amazon SageMaker Notebook instance now supports self-service migration, allowing you to update your notebook instance platform identifier through the UpdateNotebookInstance API. This enables you to seamlessly transition from unsupported platform identifiers (notebook-al1-v1, notebook-al2-v1, notebook-al2-v2) to supported versions (notebook-al2-v3, notebook-al2023-v1).\n  With the new PlatformIdentifier parameter in the UpdateNotebookInstance API, you can update to newer versions of the Notebook instance platform while preserving your existing data and configurations. The platform identifier determines which Operating System and JupyterLab version combination your notebook instance runs. This self-service capability simplifies the migration process and helps you keep your notebook instances current.\n  This feature is supported through AWS CLI (version 2.31.27 or newer) and SDK, and is available in all AWS Regions where Amazon SageMaker Notebook instances are supported. To learn more, see Update a Notebook Instance in the Amazon SageMaker Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-self-service-migration-notebook-instances",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-54eab717f389",
      "title": "Amazon SageMaker HyperPod now supports checkpointless training",
      "description": "Amazon SageMaker HyperPod now supports checkpointless training, a new foundational model training capability that mitigates the need for a checkpoint-based job-level restart for fault recovery. Checkpointless training maintains forward training momentum despite failures, reducing recovery time from hours to minutes. This represents a fundamental shift from traditional checkpoint-based recovery, where failures require pausing the entire training cluster, diagnosing issues manually, and restoring from saved checkpoints, a process that can leave expensive AI accelerators idle for hours, costing your organization wasted compute.\n \nCheckpointless training transforms this paradigm by preserving the model training state across the distributed cluster, automatically swapping out faulty training nodes on the fly and using peer-to-peer state transfer from healthy accelerators for failure recovery. By mitigating checkpoint dependencies during recovery, checkpointless training can help your organization save on idle AI accelerator costs and accelerate time. Even at larger scales, checkpointless training on Amazon SageMaker HyperPod enables upwards of 95% training goodput on cluster sizes with thousands of AI accelerators.\n \nCheckpointless training on SageMaker HyperPod is available in all AWS Regions where Amazon SageMaker HyperPod is currently available. You can enable checkpointless training with zero code changes using HyperPod recipes for popular publicly available models such as Llama and GPT OSS. For custom model architectures, you can integrate checkpointless training components with minimal modifications for PyTorch-based workflows, making it accessible to your teams regardless of their distributed training expertise.\n \nTo get started, visit the Amazon SageMaker HyperPod product page and see the checkpointless training GitHub page for implementation guidance.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-hyperpod-checkpointless-training",
      "pubDate": "2025-12-03T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "rds"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "rds",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-e19574de6969",
      "title": "Amazon SageMaker AI announces serverless MLflow capability for faster AI development",
      "description": "Amazon SageMaker AI now offers a serverless MLflow capability that dynamically scales to support AI model development tasks. With MLflow, AI developers can begin tracking, comparing, and evaluating experiments without waiting for infrastructure setup.\n  As customers across industries accelerate AI development, they require capabilities to track experiments, observe behavior, and evaluate the performance of AI models, applications and agents. However, managing MLflow infrastructure requires administrators to continuously maintain and scale tracking servers, make complex capacity planning decisions, and deploy separate instances for data isolation. This infrastructure burden diverts resources away from core AI development and creates bottlenecks that impact team productivity and cost effectiveness.\n  With this update, MLflow now scales dynamically to deliver fast performance for demanding and unpredictable model development tasks, then scales down during idle time. Administrators can also enhance productivity by setting up cross-account access via Resource Access Manager (RAM) to simplify collaboration across organizational boundaries.\n  The serverless MLflow capability on Amazon SageMaker AI is offered at no additional charge and works natively with familiar Amazon SageMaker AI model development capabilities like SageMaker AI JumpStart, SageMaker Model Registry and SageMaker Pipelines. Customers can access the latest version of MLflow on Amazon SageMaker AI with automatic version updates.\n  Amazon SageMaker AI with MLflow is now available in select AWS Regions. To learn more, see the Amazon SageMaker AI user guide and the AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/sagemaker-ai-serverless-mlflow-ai-development/",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "lex",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-c803298e7651",
      "title": "AWS Clean Rooms supports synthetic dataset generation training custom ML training",
      "description": "AWS Clean Rooms now enables you and your partners to generate privacy-enhancing synthetic datasets from your collective data to train regression and classification machine learning (ML) models.\n \nSynthetic dataset generation allows you and your partners to create training datasets with similar statistical properties to the original data, without the training code having access to real records. This new capability de-identifies subjects—such as people or entities about whom data has been collected—in the original data, mitigating the risk that a model will memorize information about individuals in the training data. This unlocks new ML model training use cases that were previously restricted by privacy concerns, such as campaign optimization, fraud detection, and medical research. For example, an airline with a proprietary algorithm wants to collaborate with a hotel brand to offer joint promotions to high-value customers, but neither organization wants to share sensitive consumer data. Using AWS Clean Rooms ML, they can generate a synthetic version of their collective dataset to train the model without exposing raw data—enabling more accurate promotions targeting while protecting customer privacy.\n \nFor more information about the AWS Regions where AWS Clean Rooms ML is available, see the AWS Regions table. To learn more, visit AWS Clean Rooms ML.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-clean-rooms-synthetic-dataset-generation-custom-ml",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "rds",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-e81021595cbc",
      "title": "AWS Glue now supports Apache Iceberg based materialized views",
      "description": "AWS Glue now supports materialized views, a new capability that makes it easier for data teams to transform data and accelerate query performance. Materialized views are managed tables in the AWS Glue Data Catalog that store precomputed query results in Apache Iceberg format and automatically keep them up to date as source data changes. This feature is designed to make it easy for data engineers and analytics teams to transform data through multiple stages, from raw data to final analytical tables while reducing engineering effort and operational overhead.\n  Customers can now create materialized views using standard Spark SQL syntax with a data refresh schedule. The service automatically handles the refresh schedule, change detection, incremental updates, and compute infrastructure management. Spark engines across Amazon Athena, Amazon EMR, and AWS Glue intelligently rewrite queries to use these materialized views, accelerating performance by up to 8x while reducing compute costs. You can use SQL query engines like Athena and Redshift to access the materialized views as Iceberg tables from SQL editors and Amazon SageMaker notebooks.\n  Materialized views in AWS Glue are available in Europe (Stockholm), Asia Pacific (Thailand), Asia Pacific (Mumbai), Europe (Paris), US East (Ohio),Europe (Ireland), Europe (Frankfurt), South America (Sao Paulo), Asia Pacific (Hong Kong), US East (N. Virginia), Asia Pacific (Seoul), Asia Pacific (Malaysia), Europe (London), Asia Pacific (Tokyo), US West (Oregon), US West (N. California), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central), and Europe (Spain). To learn more, visit Working with Materialized Views in the AWS Glue developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-apache-iceberg-based-materialized-views",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "emr",
        "redshift",
        "glue",
        "athena",
        "ga",
        "update",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-70a75d3e1cfa",
      "title": "Medidata’s journey to a modern lakehouse architecture on AWS",
      "description": "In this post, we show you how Medidata created a unified, scalable, real-time data platform that serves thousands of clinical trials worldwide with AWS services, Apache Iceberg, and a modern lakehouse architecture.",
      "link": "https://aws.amazon.com/blogs/big-data/medidatas-journey-to-a-modern-lakehouse-architecture-on-aws/",
      "pubDate": "2025-11-27T01:00:46.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": []
    },
    {
      "id": "aws-news-e771ae5d8453",
      "title": "Managed Tiered KV Cache and Intelligent Routing for Amazon SageMaker HyperPod",
      "description": "In this post, we introduce Managed Tiered KV Cache and Intelligent Routing for Amazon SageMaker HyperPod, new capabilities that can reduce time to first token by up to 40% and lower compute costs by up to 25% for long context prompts and multi-turn conversations. These features automatically manage distributed KV caching infrastructure and intelligent request routing, making it easier to deploy production-scale LLM inference workloads with enterprise-grade performance while significantly reducing operational overhead.",
      "link": "https://aws.amazon.com/blogs/machine-learning/managed-tiered-kv-cache-and-intelligent-routing-for-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-11-27T00:50:04.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-a7bab8231d01",
      "title": "Orchestrating data processing tasks with a serverless visual workflow in Amazon SageMaker Unified Studio",
      "description": "In this post, we show how to use the new visual workflow experience in SageMaker Unified Studio IAM-based domains to orchestrate an end-to-end machine learning workflow. The workflow ingests weather data, applies transformations, and generates predictions—all through a single, intuitive interface, without writing any orchestration code.",
      "link": "https://aws.amazon.com/blogs/big-data/orchestrating-data-processing-tasks-with-a-serverless-visual-workflow-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-25T23:08:05.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam"
      ]
    },
    {
      "id": "aws-news-ba4b2b5742c2",
      "title": "Train custom computer vision defect detection model using Amazon SageMaker",
      "description": "In this post, we demonstrate how to migrate computer vision workloads from Amazon Lookout for Vision to Amazon SageMaker AI by training custom defect detection models using pre-trained models available on AWS Marketplace. We provide step-by-step guidance on labeling datasets with SageMaker Ground Truth, training models with flexible hyperparameter configurations, and deploying them for real-time or batch inference—giving you greater control and flexibility for automated quality inspection use cases.",
      "link": "https://aws.amazon.com/blogs/machine-learning/train-custom-computer-vision-defect-detection-model-using-amazon-sagemaker/",
      "pubDate": "2025-11-25T22:44:22.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lookout for vision",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "lookout for vision",
        "lex"
      ]
    },
    {
      "id": "aws-news-e78bda25ea6d",
      "title": "Introducing bidirectional streaming for real-time inference on Amazon SageMaker AI",
      "description": "We're introducing bidirectional streaming for Amazon SageMaker AI Inference, which transforms inference from a transactional exchange into a continuous conversation. This post shows you how to build and deploy a container with bidirectional streaming capability to a SageMaker AI endpoint. We also demonstrate how you can bring your own container or use our partner Deepgram's pre-built models and containers on SageMaker AI to enable bi-directional streaming feature for real-time inference.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-bidirectional-streaming-for-real-time-inference-on-amazon-sagemaker-ai/",
      "pubDate": "2025-11-25T19:09:59.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-7612920ee216",
      "title": "Physical AI in practice: Technical foundations that fuel human-machine interactions",
      "description": "In this post, we explore the complete development lifecycle of physical AI—from data collection and model training to edge deployment—and examine how these intelligent systems learn to understand, reason, and interact with the physical world through continuous feedback loops. We illustrate this workflow through Diligent Robotics' Moxi, a mobile manipulation robot that has completed over 1.2 million deliveries in hospitals, saving nearly 600,000 hours for clinical staff while transforming healthcare logistics and returning valuable time to patient care.",
      "link": "https://aws.amazon.com/blogs/machine-learning/physical-ai-in-practice-technical-foundations-that-fuel-human-machine-interactions/",
      "pubDate": "2025-11-25T17:00:25.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": []
    },
    {
      "id": "aws-news-c2a79337519c",
      "title": "Enforce business glossary classification rules in Amazon SageMaker Catalog",
      "description": "Amazon SageMaker Catalog now supports metadata enforcement rules for glossary terms classification (tagging) at the asset level. With this capability, administrators can require that assets include specific business terms or classifications. Data producers must apply required glossary terms or classifications before an asset can be published. In this post, we show how to enforce business glossary classification rules in SageMaker Catalog.",
      "link": "https://aws.amazon.com/blogs/big-data/enforce-business-glossary-classification-rules-in-amazon-sagemaker-catalog/",
      "pubDate": "2025-11-20T18:39:41.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-e3fa9789b76a",
      "title": "Getting started with Amazon S3 Tables in Amazon SageMaker Unified Studio",
      "description": "In this post, you learn how to integrate SageMaker Unified Studio with S3 Tables and query your data using Amazon Athena, Amazon Redshift, or Apache Spark in EMR and AWS Glue.",
      "link": "https://aws.amazon.com/blogs/big-data/getting-started-with-amazon-s3-tables-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-19T23:26:57.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ]
    }
  ]
}