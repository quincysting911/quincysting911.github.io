{
  "lastUpdated": "2026-01-08T06:17:51.127Z",
  "category": "machine-learning",
  "totalItems": 8,
  "items": [
    {
      "id": "aws-news-b48ec1c4c2b7",
      "title": "Optimizing LLM inference on Amazon SageMaker AI with BentoML’s LLM- Optimizer",
      "description": "In this post, we demonstrate how to optimize large language model (LLM) inference on Amazon SageMaker AI using BentoML's LLM-Optimizer to systematically identify the best serving configurations for your workload.",
      "link": "https://aws.amazon.com/blogs/machine-learning/optimizing-llm-inference-on-amazon-sagemaker-ai-with-bentomls-llm-optimizer/",
      "pubDate": "2025-12-24T17:17:44.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-94c37ba8a77f",
      "title": "Advancing ADHD diagnosis: How Qbtech built a mobile AI assessment Model Using Amazon SageMaker AI",
      "description": "In this post, we explore how Qbtech streamlined their machine learning (ML) workflow using Amazon SageMaker AI, a fully managed service to build, train and deploy ML models, and AWS Glue, a serverless service that makes data integration simpler, faster, and more cost effective. This new solution reduced their feature engineering time from weeks to hours, while maintaining the high clinical standards required by healthcare providers.",
      "link": "https://aws.amazon.com/blogs/machine-learning/advancing-adhd-diagnosis-how-qbtech-built-a-mobile-ai-assessment-model-using-amazon-sagemaker-ai/",
      "pubDate": "2025-12-23T17:11:30.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "rds",
        "eks",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "rds",
        "eks",
        "glue",
        "integration"
      ]
    },
    {
      "id": "aws-news-4ed9fe1d2855",
      "title": "Unifying governance and metadata across Amazon SageMaker Unified Studio and Atlan",
      "description": "In this post, we show you how to unify governance and metadata across Amazon SageMaker Unified Studio and Atlan through a comprehensive bidirectional integration. You’ll learn how to deploy the necessary AWS infrastructure, configure secure connections, and set up automated synchronization to maintain consistent metadata across both platforms.",
      "link": "https://aws.amazon.com/blogs/big-data/unifying-governance-and-metadata-across-amazon-sagemaker-unified-studio-and-atlan/",
      "pubDate": "2025-12-22T18:17:06.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "integration"
      ]
    },
    {
      "id": "aws-news-c3947de50d26",
      "title": "Announcing AWS Neuron SDK 2.27.0",
      "description": "Today, AWS announces Neuron SDK 2.27.0, introducing support for Trainium3 UltraServer with expanded open source components. Neuron also introduces the Neuron Explorer tools suite, Enhanced NKI with open source NKI Compiler built on MLIR (private beta), the NKI Library of optimized kernels, native PyTorch support through TorchNeuron (private beta), and Neuron DRA for Kubernetes-native resource management (private beta).\n  These updates enable standard frameworks to run unchanged on Trainium, removing barriers for researchers to experiment and innovate. For developers requiring deeper control, the enhanced Neuron Kernel Interface (NKI) Beta 2 provides direct access to hardware-level optimizations, enabling customers to scale AI workloads with improved performance. If you're interested in early access to new NKI features and improvements, you can join the Neuron private beta program.\n  The new SDK version is available in all AWS Regions supporting Inferentia and Trainium instances, offering enhanced performance and monitoring capabilities for machine learning workloads.\n  For more details, see:\n  \n \n \nWhat’s New in Neuron\n \n \nAWS Neuron 2.27.0 Release Notes\n \n \nAWS Trainium",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/announcing-aws-neuron-2-27",
      "pubDate": "2025-12-22T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "trainium",
        "trainium3",
        "inferentia",
        "neuron"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "nova",
        "trainium",
        "trainium3",
        "inferentia",
        "neuron",
        "beta",
        "early-access",
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-5461a4240f23",
      "title": "Introducing SOCI indexing for Amazon SageMaker Studio: Faster container startup times for AI/ML workloads",
      "description": "Today, we are excited to introduce a new feature for SageMaker Studio: SOCI (Seekable Open Container Initiative) indexing. SOCI supports lazy loading of container images, where only the necessary parts of an image are downloaded initially rather than the entire container.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-soci-indexing-for-amazon-sagemaker-studio-faster-container-startup-times-for-ai-ml-workloads/",
      "pubDate": "2025-12-19T18:23:50.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-ca2965bf0697",
      "title": "Amazon SageMaker Studio now supports SOCI indexing for faster container startup times",
      "description": "Today, AWS announces SOCI (Seekable Open Container Initiative) indexing support for Amazon SageMaker Studio, reducing container startup times by 30-50% when using custom images. Amazon SageMaker Studio is a fully integrated, browser-based environment for end-to-end machine learning development. SageMaker Studio provides pre-built container images for popular ML frameworks like TensorFlow, PyTorch, and Scikit-learn that enable quick environment setup. However, when data scientists need to tailor environments for specific use cases with additional libraries, dependencies, or configurations, they can build and register custom container images with pre-configured components to ensure consistency across projects. As ML workloads become increasingly complex, these custom container images have grown in size, leading to startup times of several minutes that create a bottlenecks in iterative ML development where quick experimentation and rapid prototyping are essential.\n  SOCI indexing addresses this challenge by enabling lazy loading of container images, downloading only the necessary components to start applications with additional files loaded on-demand as needed. Instead of waiting several minutes for complete custom image downloads, users can begin productive work in seconds while the environment completes initialization in the background. To use SOCI indexing, create a SOCI index for your custom container image using tools like Finch CLI, nerdctl, or Docker with SOCI CLI, push the indexed image to Amazon Elastic Container Registry (ECR), and reference the image index URI when creating SageMaker Image resources.\n  SOCI indexing is available in all AWS Regions where Amazon SageMaker Studio is available. To learn more about implementing SOCI indexing for your SageMaker Studio custom images, see Bring your own SageMaker image in the Amazon SageMaker Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-nbi-soci/",
      "pubDate": "2025-12-19T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-ea7c0f3a27c5",
      "title": "Reference guide for building a self-service analytics solution with Amazon SageMaker",
      "description": "In this post, we show how to use Amazon SageMaker Catalog to publish data from multiple sources, including Amazon S3, Amazon Redshift, and Snowflake. This approach enables self-service access while ensuring robust data governance and metadata management.",
      "link": "https://aws.amazon.com/blogs/big-data/reference-guide-for-building-a-self-service-analytics-solution-with-amazon-sagemaker/",
      "pubDate": "2025-12-16T21:47:23.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "s3",
        "redshift"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "redshift"
      ]
    },
    {
      "id": "aws-news-eea5558b8e2f",
      "title": "Amazon SageMaker AI is now available in Asia Pacific (New Zealand)",
      "description": "Starting today, you can build, train, and deploy machine learning (ML) models in Asia Pacific (New Zealand).\n  Amazon SageMaker AI is a fully managed platform that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker AI removes the heavy lifting from each step of the machine learning process to make it easier to develop high quality models.\n \nTo learn more and get started, see SageMaker AI documentation and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-ai-asia-pacific-new-zealand",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "now-available"
      ]
    }
  ]
}