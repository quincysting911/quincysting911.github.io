{
  "lastUpdated": "2025-12-18T06:17:40.053Z",
  "category": "generative-ai",
  "totalItems": 55,
  "items": [
    {
      "id": "aws-news-5d22d44eeb20",
      "title": "Now generally available: Amazon EC2 M8gn and M8gb instances",
      "description": "Today, AWS announces the general availability of the new Amazon Elastic Compute Cloud (Amazon EC2) M8gn and M8gb instances. These instances are powered by AWS Graviton4 processors to deliver up to 30% better compute performance than AWS Graviton3 processors. M8gn instances feature the latest 6th generation AWS Nitro Cards, and offer up to 600 Gbps network bandwidth, the highest network bandwidth among network optimized EC2 instances. M8gb offer up to 150 Gbps of EBS bandwidth to provide higher EBS performance compared to same-sized equivalent Graviton4-based instances.\n  M8gn are ideal for network-intensive workloads such as high-performance file systems, distributed web scale in-memory caches, caching fleets, real-time big data analytics, and Telco applications such as 5G User Plane Function (UPF). M8gb are ideal for workloads requiring high block storage performance such as high performance databases and NoSQL databases.\n \nM8gn instances offer instance sizes up to 48xlarge, up to 768 GiB of memory, up to 600 Gbps of networking bandwidth, and up to 60 Gbps of bandwidth to Amazon Elastic Block Store (EBS). They also support EFA networking on the 16xlarge, 24xlarge, and 48xlarge sizes.\n  M8gb instances offer sizes up to 24xlarge, up to 768 GiB of memory, up to 150 Gbps of EBS bandwidth, and up to 200 Gbps of networking bandwidth. They support Elastic Fabric Adapter (EFA) networking on the 16xlarge and 24xlarge sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n \nThe new instances are available in the following AWS Regions: US East (N. Virginia), and US West (Oregon).\n  To learn more, see Amazon EC2 M8gn and M8gb Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/generally-available-amazon-ec2-m8gn-m8gb-instances",
      "pubDate": "2025-12-17T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "graviton",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-c8e1d411e6b8",
      "title": "Amazon EC2 C8g, M8g, R8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8g and M8g instances are available in AWS GovCloud (US-West) and R8g and M8g instances are available in AWS GovCloud (US-East) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. They are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon C8g, M8g and R8g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. C8g and R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 C8g Instances, Amazon EC2 M8g Instances, and Amazon EC2 R8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS GovCloud (US) Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-c8g-m8g-r8g-instances-additional-regions",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-e1072d090a34",
      "title": "Amazon EC2 C8g instances now available in Europe (Zurich)",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8g instances are available in AWS Europe (Zurich) region. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 C8g instances are built for compute-intensive workloads, such as high performance computing (HPC), batch processing, gaming, video encoding, scientific modeling, distributed analytics, CPU-based machine learning (ML) inference, and ad serving. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon C7g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. C8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 C8g Instances. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-c8g-instances-europe-zurich",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-41d288f2de9f",
      "title": "Amazon OpenSearch Service announces new OI2 instances",
      "description": "Amazon OpenSearch Service introduces OI2 instances, expanding the OpenSearch Optimized Instance family. The new OI2 instances delivers up to 9% higher indexing throughput compared to OR2 instances and up to 33% over I8g instances in our internal benchmarks.\n \nThe new OI2 OpenSearch Optimized instances use the same architecture as the OR2 instances, leveraging best-in-class cloud technologies like Amazon S3, to provide high durability, and improved price-performance for higher indexing throughput better for indexing heavy workload. Each OpenSearch Optimized instance is provisioned with compute, 3rd generation AWS Nitro SSDs for caching, and remote Amazon S3-based managed storage. OI2 offers pay-as-you-go pricing and reserved instances, with a simple hourly rate for the instance including the NVMe storage, as well as managed storage provisioned. OI2 instances come in sizes ‘large’ through ‘24xlarge’, and offer compute, memory, and up to 22.5 TB storage. Please refer to the Amazon OpenSearch Service pricing page for pricing details.\n  OI2 instance family is now available on Amazon OpenSearch Service across 12 regions globally: US East (N. Virginia, Ohio), US West (Oregon), Canada (Central), Asia Pacific (Mumbai, Singapore, Sydney, Tokyo), Europe (Frankfurt, Ireland, London, Spain).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-opensearch-service-oi2-instances/",
      "pubDate": "2025-12-17T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a4d885726005",
      "title": "Amazon EC2 M8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) M8g instances are available in Asia Pacific (Thailand, Jakarta, Melbourne), and AWS Middle East (UAE) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 M8g instances are built for general-purpose workloads, such as application servers, microservices, gaming servers, midsize data stores, and caching fleets. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon M7g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. M8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 M8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-m8g-additional-regions/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-3d31af0ecae0",
      "title": "Amazon EC2 R8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8g instances are available in AWS Europe (Paris), and Asia Pacific (Hyderabad) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 R8g instances are ideal for memory-intensive workloads such as databases, in-memory caches, and real-time big data analytics. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. AWS Graviton4-based R8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 1.5TB) than Graviton3-based R7g instances. These instances are up to 30% faster for web applications, 40% faster for databases, and 45% faster for large Java applications compared to AWS Graviton3-based R7g instances. R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 R8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-r8g-instances-additional-regions/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a159bd5150c4",
      "title": "Amazon OpenSearch Service now offers a new multi-tier storage",
      "description": "Amazon OpenSearch Service now offers a new multi-tier storage option powered by OpenSearch Optimized Instances. This new architecture combines Amazon S3 cloud technology with local instance storage to deliver improved durability and performance. The new multi-tier architecture features two tiers: hot and warm. The hot tier handles frequently accessed data, while the warm tier leverages Amazon S3 for cost-effective storage of less frequently accessed data. \n  Until now, Amazon OpenSearch Service supported a warm tier through UltraWarm, which provided cost-effective storage for read-only data. The new warm tier powered by OpenSearch Optimized instances supports write operations, providing greater flexibility for data management. You can automate rotating data from hot to warm as it ages using Index State Management feature.\n \nFor warm tier deployments, customers can use OpenSearch Optimized (OI2) instances (size ‘large’ to ‘8xlarge’), with addressable warm of up to five times the local cache size. tandard Managed Storage charges apply for warm data. The new Multi-tier experience is available on OpenSearch 3.3 and above. For more information please refer to the documentation.\n  New Multi-Tier experience on OI2 instance family is now available on Amazon OpenSearch Service across 12 regions globally: US East (N. Virginia, Ohio), US West (Oregon), Canada (Central), Asia Pacific (Mumbai, Singapore, Sydney, Tokyo), Europe (Frankfurt, Ireland, London, Spain).  Please refer to the Amazon OpenSearch Service pricing page for pricing details",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/writeable-warm-tier-opensearch-optimized-instances/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f8f0c1cb093c",
      "title": "AWS IAM Identity Center is now available in the Asia Pacific (Taipei) AWS Region",
      "description": "You can now deploy AWS IAM Identity Center in 37 AWS Regions, including Asia Pacific (Taipei).\n  IAM Identity Center is the recommended service for managing workforce access to AWS applications. It enables you to connect your existing source of workforce identities to AWS once and offer your users single sign on experience across AWS. It powers the personalized experiences offered by AWS applications, such as Amazon Q, and the ability to define and audit user-aware access to data in AWS services, such as Amazon Redshift. It can also help you manage access to multiple AWS accounts from a central place. IAM Identity Center is available at no additional cost in these AWS Regions.\n  To learn more about IAM Identity Center, visit the product detail page. To get started, see the IAM Identity Center user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-iam-identity-center-asia-pacific-taipei-region/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center",
        "now-available"
      ]
    },
    {
      "id": "aws-news-3721792acb1c",
      "title": "Governance by design: The essential guide for successful AI scaling",
      "description": "Picture this: Your enterprise has just deployed its first generative AI application. The initial results are promising, but as you plan to scale across departments, critical questions emerge. How will you enforce consistent security, prevent model bias, and maintain control as AI applications multiply?",
      "link": "https://aws.amazon.com/blogs/machine-learning/governance-by-design-the-essential-guide-for-successful-ai-scaling/",
      "pubDate": "2025-12-16T21:18:54.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-ee18d02e7e8f",
      "title": "How Tata Power CoE built a scalable AI-powered solar panel inspection solution with Amazon SageMaker AI and Amazon Bedrock",
      "description": "In this post, we explore how Tata Power CoE and Oneture Technologies use AWS services to automate the inspection process end-to-end.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-tata-power-coe-built-a-scalable-ai-powered-solar-panel-inspection-solution-with-amazon-sagemaker-ai-and-amazon-bedrock/",
      "pubDate": "2025-12-16T18:55:36.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-06b34c0d447a",
      "title": "AWS Artifact enables access to previous versions of compliance reports",
      "description": "AWS Artifact now enables direct access to previous versions of AWS compliance reports, eliminating the need to contact AWS Support or account representatives. This self-service capability helps customers efficiently manage their compliance documentation requirements, particularly during audits and vendor assessments that require historical compliance evidence.\n  To access previous report versions, you need the \"artifact:ListReportVersions\" IAM permission, which is included in the AWS managed policy \"AWSArtifactReportsReadOnlyAccess\". If you're unable to view previous versions of reports in the AWS Artifact console, please contact your AWS account administrator to request this permission.\n  Once authorized, you can access previous versions of compliance reports (such as SOC, ISO, and C5) directly through the AWS Artifact console. Simply navigate to the reports page and select any report to view its available versions. The availability of previous report versions varies by compliance program, with some reports offering versions from multiple prior years while others may have more limited historical coverage.\n  This feature is now generally available in US East (N. Virginia) and AWS GovCloud (US-West) Regions.\n  To learn more about accessing previous versions of compliance reports, visit the AWS Artifact documentation. For general information about AWS Artifact, see the AWS Artifact product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-artifact-access-previous-versions-compliance-reports",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "iam",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f12f19beadac",
      "title": "AWS Security Incident Response introduces integration with Slack",
      "description": "AWS Security Incident Response now offers integration with the cloud-based team collaboration platform Slack, enabling you to prepare for, respond to, and recover from security events faster and more effectively while maintaining your existing notification and communication workflows. With the bidirectional integration, you can create and update cases in both the Security Incident Response console and Slack with automatic data replication. Each Security Incident Response case is represented as a dedicated Slack channel, while comments and attachments sync instantly. This gives responders immediate access to critical case information and enables more efficient collaboration regardless of tool preference.\n  The integration helps security teams engage faster and accelerate response times by automatically adding Security Incident Response watchers to the corresponding Slack channel. This integration is available as an open-source solution on GitHub, providing customers and partners the opportunity to customize and extend the functionality. The integration leverages EventBridge which allows customers to continue using their existing security incident management and notification tooling, while leveraging AWS Security Incident Response capabilities. The solution features a modular architecture, and includes guidance on how to use Amazon Q Developer, Kiro, or similar AI assistants that help make it easy to add new integration targets beyond Slack.\n  To get started with the AWS Security Incident Response Slack integration, visit our GitHub repository. Visit our technical documentation for Slack for implementation details. Learn more about AWS Security Incident Response in the service’s User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-security-incident-response-integration-slack",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "eventbridge"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "eventbridge",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-5ba02da780e9",
      "title": "Amazon Quick Suite now supports memory for chat agents",
      "description": "We are announcing memory for chat agents in Amazon Quick Suite – a feature that allows users to get personalized responses based on their previous conversations. With this feature, Quick Suite remembers the preferences users specify in chat and generate responses that are tailored to them. Users can also view their inferred preferences and remove any memory they don’t want Quick chat agents to use.\n  Previously, chat users needed to repeat their preferences around response format, acronyms, dashboards, and integrations in every conversation. They also had to clarify ambiguous topics and entities in chat, increasing the tedious back and forth needed to get accurate and insightful responses. Memory addresses this pain point by remembering facts and details about users in a way that ensures responses provided to users continuously learn and improve. Users also control what Quick Suite remembers about them – all the memories are viewable and removable by users, and users have the choice to start chat in Private Mode in which conversations are not used to infer memories.\n  Memory in Quick Suite chat agents is available in US East (N. Virginia) and US West (Oregon). To learn more, visit the Amazon Quick Suite User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-quick-suite-memory-chat-agents/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "rds",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-143d7e18abbc",
      "title": "Amazon Quick Suite browser extension now supports Quick Flows",
      "description": "Amazon Quick Suite browser extension now supports Amazon Quick Flows, enabling you to run workflows directly within your web browser, eliminating the need to manually extract information from each web page. You can invoke workflows that you've created or that have been shared with you, and pass web page content as input—all without leaving your browser.\n  This capability is great for completing routine tasks such as analyzing contract documents to extract key terms, or generating weekly reports from project dashboards that automatically notify stakeholders.\n  Quick Flows in browser extension is available now in US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland). There are no additional charges for using the browser extension beyond standard Quick Flows usage.\n  To get started, visit your Chrome, Firefox or Edge store page to install browser extension and sign in with your Quick Suite account. Once you sign in, look for the Flows icon below the chat box to invoke your flows. To learn more about invoking Quick Flows in browser extension, please visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/quick-suite-browser-extension-quick-flows/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-d57b77f74852",
      "title": "Amazon Elastic VMware Service (Amazon EVS) is now available in additional Regions",
      "description": "Today, we're announcing that Amazon Elastic VMware Service (Amazon EVS) is now available in all availability zones in the US West (N. California), Asia Pacific (Hyderabad), Asia Pacific (Malaysia), Canada West (Calgary), Europe (Milan), Mexico (Central), and South America (São Paulo) Regions. This expansion provides more options to leverage the scale and flexibility of AWS for running your VMware workloads in the cloud.\n  Amazon EVS lets you run VMware Cloud Foundation (VCF) directly within your Amazon Virtual Private Cloud (VPC) on EC2 bare-metal instances, powered by AWS Nitro. Using either our step-by-step configuration workflow or the AWS Command Line Interface (CLI) with automated deployment capabilities, you can set up a complete VCF environment in just a few hours. This rapid deployment enables faster workload migration to AWS, helping you eliminate aging infrastructure, reduce operational risks, and meet critical timelines for exiting your data center.\n  The added availability in these Regions gives your VMware workloads lower latency through closer proximity to your end users, compliance with data residency or sovereignty requirements, and additional high availability and resiliency options for your enhanced redundancy strategy.\n  To get started, visit the Amazon EVS product detail page and user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-evs-available-in-additional-regions/",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available",
        "expansion"
      ]
    },
    {
      "id": "aws-news-563e37119679",
      "title": "Amazon Managed Service for Apache Flink is now available in AWS Asia Pacific (Auckland) Region",
      "description": "Starting today, customers can use Amazon Managed Service for Apache Flink in Asia Pacific (Auckland) Region to build real-time stream processing applications.\n  Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon Simple Storage Service (Amazon S3), custom integrations, and more using built-in connectors.\n  You can learn more about Amazon Managed Service for Apache Flink here. For Amazon Managed Service for Apache Flink region availability, refer to the AWS Region Table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-managed-service-apache-flink-aws-asia-pacific-auckland-region/",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-29dfac7f5a0b",
      "title": "Announcing cost allocation using users’ attributes",
      "description": "AWS announces a new cost allocation feature that uses existing workforce user attributes like cost center, division, organization, and department to track and analyze AWS application usage and cost. This new capability enables customers to allocate per-user monthly subscription and on-demand fees of AWS applications, such as Amazon Q Business, Amazon Q Developer, and Amazon QuickSight, to respective internal business units.\n  Customers should import their workforce users’ attributes to IAM Identity Center, the recommended service for managing workforce access to AWS applications. After importing the attributes, customers can enable one or more of these attributes as cost allocation tags from the AWS Billing and Cost Management console. When users access AWS applications, their usage and cost are automatically recorded with selected attributes. Cloud Financial Operations (FinOps) professionals can view and analyze costs in AWS Cost Explorer and AWS CUR 2.0, gaining visibility into how different teams drive AWS usage and costs.\n  Support for cost allocation using user attributes is generally available in all AWS Regions, excluding GovCloud (US) Regions and China (Beijing) and China (Ningxia) Regions.\n  To learn more, see organizing and tracking cost using AWS cost allocation tags.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/cost-allocation-using-users-attributes",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "q business",
        "iam",
        "iam identity center",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "q business",
        "iam",
        "iam identity center",
        "quicksight",
        "generally-available",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-91e426ea990a",
      "title": "Customize agent workflows with advanced orchestration techniques using Strands Agents",
      "description": "In this post, we explore two powerful orchestration patterns implemented with Strands Agents. Using a common set of travel planning tools, we demonstrate how different orchestration strategies can solve the same problem through distinct reasoning approaches,",
      "link": "https://aws.amazon.com/blogs/machine-learning/customize-agent-workflows-with-advanced-orchestration-techniques-using-strands-agents/",
      "pubDate": "2025-12-15T17:35:47.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-7790bd8307b4",
      "title": "Amazon EKS introduces enhanced network security policies",
      "description": "Today, we’re announcing enhanced network policy capabilities in Amazon Elastic Kubernetes Service (EKS), allowing customers to improve the network security posture for their Kubernetes workloads and their integrations with cluster-external destinations. This enhancement builds on network segmentation features previously supported in EKS. Now you can centrally enforce network access filters across the entire cluster, as well as leverage Domain Name System (DNS) based policies to secure egress traffic from your cluster’s environment.\n  As customers continue to scale their application environments using EKS, network traffic isolation is increasingly fundamental for preventing unauthorized access to resources inside and outside the cluster. To address this, EKS introduced support for Kubernetes NetworkPolicies in the Amazon VPC Container Network Interface (VPC CNI) plugin, allowing you to segment pod-to-pod communication at a namespace level. Now you can further strengthen the defensive posture for your Kubernetes network environment by centrally managing network filters for the whole cluster. Also, cluster admins now have a more stable and predictable approach for preventing unauthorized access to cluster-external resources in the cloud or on-prem using egress rules that filter traffic to external endpoints based on their Fully Qualified Domain Name (FQDN).\n  These new network security features are available in all commercial AWS Regions for new EKS clusters running Kubernetes version 1.29 or later, with support for existing clusters to follow in the coming weeks. ClusterNetworkPolicy is available in all EKS cluster launch modes using VPC CNI v1.21.0 or later. DNS-based policies are only supported in EKS Auto Mode-launched EC2 instances. To learn more, visit the Amazon EKS documentation or read the launch blog post here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-eks-enhanced-network-security-policies",
      "pubDate": "2025-12-15T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "eks",
        "launch",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-145bc0082f15",
      "title": "How Bayer transforms Pharma R&D with a cloud-based data science ecosystem using Amazon SageMaker",
      "description": "In this post, we discuss how Bayer AG used the next generation of Amazon SageMaker to build a cloud-based Pharma R&D Data Science Ecosystem (DSE) that unified data ingestion, storage, analytics, and AI/ML workflows.",
      "link": "https://aws.amazon.com/blogs/big-data/how-bayer-transforms-pharma-rd-with-a-cloud-based-data-science-ecosystem-using-amazon-sagemaker/",
      "pubDate": "2025-12-12T23:06:25.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-36722fddcb63",
      "title": "Building zero trust generative AI applications in healthcare with AWS Nitro Enclaves",
      "description": "In healthcare, generative AI is transforming how \nmedical professionals analyze data, \nsummarize clinical notes, and \ngenerate insights to improve patient outcomes. From \nautomating medical documentation to assisting in \ndiagnostic reasoning, large language models (LLMs) have the potential to augment clinical workflows and accelerate research. However, these innovations also introduce significant privacy, security, and intellectual property challenges.",
      "link": "https://aws.amazon.com/blogs/compute/building-zero-trust-generative-ai-applications-in-healthcare-with-aws-nitro-enclaves/",
      "pubDate": "2025-12-12T19:06:03.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-bf9d1270943d",
      "title": "AWS DataSync increases scalability and performance for on-premises file transfers",
      "description": "AWS DataSync Enhanced mode now supports data transfers between on-premises file servers and Amazon S3, enabling customers to transfer datasets that scale to virtually unlimited numbers of files at higher levels of performance than DataSync Basic mode.\n  AWS DataSync is a secure, high-speed file transfer service that optimizes data movement over a network. Enhanced mode uses parallel processing to deliver higher performance and scalability for datasets of any size, while removing file count limitations and providing detailed transfer metrics for better monitoring and management. Previously, Enhanced mode was available for data transfers between Amazon S3 locations and for multicloud transfers. This launch extends the capabilities of Enhanced mode to support transfers between on-premises NFS or SMB file servers, and Amazon S3. Using Enhanced mode, customers can accelerate generative AI workloads by rapidly moving training datasets to AWS, power data lake analytics by synchronizing on-premises data with cloud-based pipelines, and drive large-scale migrations for archival and cloud modernization.\n  This new capability is available in all AWS Regions where AWS DataSync is offered. To get started, visit the AWS DataSync console. For more information, see the AWS DataSync documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-datasync-scalability-performance-on-premises-file-transfers",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "launch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-e86106073841",
      "title": "AWS Shield network security director now supports multi-account analysis",
      "description": "Today, AWS Shield announces multi-account network security management and automated network analysis for network security director, which is currently in preview. AWS Shield network security director provides visibility into the AWS resources in your AWS organization, identifies missing or misconfigured network security services, and recommends remediation steps.\n  With network security director, you can specify a delegated administrator account from which you can start continuous network analysis for multiple accounts or organizational units in your AWS Organization. You can then centrally view each account’s network topology, network security findings, and recommended remediations for missing or misconfigured network security services. You can also easily summarize and report on the network security misconfigurations identified by AWS Shield network security director from within Amazon Q Developer in the AWS Management Console and chat applications.\n  AWS Shield network security director is also now available in five additional AWS regions: Europe (Ireland), Europe (Frankfurt), Asia Pacific (Hong Kong), Asia Pacific (Singapore), and Australia (Sydney).\n  To learn more, visit the overview page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-shield-network-security-director-multi-account-analysis",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "preview",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-fe825be28e53",
      "title": "Scaling MLflow for enterprise AI: What’s New in SageMaker AI with MLflow",
      "description": "Today we’re announcing Amazon SageMaker AI with MLflow, now including a serverless capability that dynamically manages infrastructure provisioning, scaling, and operations for artificial intelligence and machine learning (AI/ML) development tasks. In this post, we explore how these new capabilities help you run large MLflow workloads—from generative AI agents to large language model (LLM) experimentation—with improved performance, automation, and security using SageMaker AI with MLflow.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scaling-mlflow-for-enterprise-ai-whats-new-in-sagemaker-ai-with-mlflow/",
      "pubDate": "2025-12-11T18:16:19.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-a1e0e42d9e9a",
      "title": "Amazon Bedrock AgentCore Observability with Langfuse",
      "description": "In this post, we explain how to integrate Langfuse observability with Amazon Bedrock AgentCore to gain deep visibility into an AI agent's performance, debug issues faster, and optimize costs. We walk through a complete implementation using Strands agents deployed on AgentCore Runtime followed by step-by-step code examples.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-observability-with-langfuse/",
      "pubDate": "2025-12-11T18:12:48.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "ga"
      ]
    },
    {
      "id": "aws-news-b56aaf668b93",
      "title": "Architecting conversational observability for cloud applications",
      "description": "In this post, we walk through building a generative AI–powered troubleshooting assistant for Kubernetes. The goal is to give engineers a faster, self-service way to diagnose and resolve cluster issues, cut down Mean Time to Recovery (MTTR), and reduce the cycles experts spend finding the root cause of issues in complex distributed systems.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-conversational-observability-for-cloud-applications/",
      "pubDate": "2025-12-11T15:59:39.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-f5227466de55",
      "title": "Amazon Aurora PostgreSQL now supports integration with Kiro powers",
      "description": "Today, AWS announces Amazon Aurora PostgreSQL-Compatible Edition integration with Kiro powers, enabling developers to build Aurora PostgreSQL backed applications faster with AI agent-assisted development using Kiro. Kiro powers is a repository of curated and pre-packaged Model Context Protocol (MCP) servers, steering files, and hooks validated by Kiro partners to accelerate specialized software development and deployment use cases. Kiro power for Aurora PostgreSQL packages the MCP server with targeted database development guidance, giving the Kiro agent instant expertise in Aurora PostgreSQL operations and schema design.\n  Kiro power for Aurora PostgreSQL bundles direct database connectivity through the Aurora PostgreSQL MCP server for data plane operations (queries, table creation, schema management), and control plane operations (cluster creation) and the steering file with Aurora PostgreSQL–specific best practices. When developers work on database tasks, the power dynamically loads relevant guidance – whether creating new Aurora clusters, designing schemas, or optimizing queries – so AI agents receive only the context needed for the specific task at hand.\n  Aurora PostgreSQL power is available within Kiro IDE and Kiro powers webpage for one-click installation and can create and manage Aurora PostgreSQL clusters in all AWS Regions. For more information about development use cases, read this blog post. To learn more about Aurora PostgreSQL MCP server, visit our documentation.\n  Amazon Aurora is designed for unparalleled high performance and availability at global scale with full PostgreSQL compatibility. It provides built-in security, continuous backups, serverless compute, up to 15 read replicas, and automated multi-Region replication. To get started with Amazon Aurora, visit our getting started page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-aurora-postgresql-integration-kiro-powers",
      "pubDate": "2025-12-11T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-e072615bad94",
      "title": "Amazon CloudWatch SDK supports optimized JSON, CBOR protocols",
      "description": "Amazon CloudWatch announces support for both the JSON and Concise Binary Object Representation (CBOR) protocols in the CloudWatch SDK, enabling lower latency and improved performance for CloudWatch customers. The SDK will automatically use JSON or CBOR as its new default communication protocol, offering customers a lower end-to-end processing latency as well as reduced payload sizes, application client side CPU, and memory usage.\n  Customers use the CloudWatch SDK either directly or through Infrastructure as Code solutions to manage their monitoring resources. Reducing control plane operations latency and payload size helps customer optimize their operational maintenance and resources usage and costs. JSON and the CBOR data formats are standards designed to enable better performance over the traditional AWS Query protocol.\n  The CloudWatch SDK for JSON and CBOR protocols support is available in all AWS Regions where Amazon CloudWatch is available and for all generally available AWS SDK language variants.\n  To leverage the performance improvements, customers can install the latest SDK version here. To learn more about the AWS SDK, see Amazon Developer tools.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-cloudwatch-sdk-json-cbor-protocols",
      "pubDate": "2025-12-11T12:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "cloudwatch",
        "generally-available",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-64a8f75f76c1",
      "title": "Amazon EC2 High Memory U7i instances now available in additional regions",
      "description": "Amazon EC2 High Memory U7i instances with 24TB of memory (u7in-24tb.224xlarge) are now available in AWS Europe (Frankfurt), U7i instances with 16TB of memory (u7in-16tb.224xlarge) are now available in AWS Asia Pacific (Mumbai), and U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in the AWS Europe (Paris) region. U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7in-24tb instances offer 24TiB of DDR5 memory, U7in-16tb instances offer 16TiB of DDR5 memory, and U7i-6tb instances offer 6TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n \nU7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7in-16tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 200Gbps of network bandwidth, and support ENA Express. U7in-24tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 200Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n \nTo learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-high-memory-u7i-instances-additional-regions/",
      "pubDate": "2025-12-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b09d90c01400",
      "title": "Amazon EC2 I7i instances now available in additional AWS regions",
      "description": "Amazon Web Services (AWS) announces the availability of high performance Storage Optimized Amazon EC2 I7i instances in AWS Asia Pacific (Singapore, Jakarta), Europe (Stockholm) regions. Powered by 5th generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.2 GHz, these instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances. Powered by 3rd generation AWS Nitro SSDs, I7i instances offer up to 45TB of NVMe storage with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances.\n  I7i instances are ideal for I/O intensive and latency-sensitive workloads that demand very high random IOPS performance with real-time latency to access small to medium size datasets (multi-TBs). I7i instances support torn write prevention feature with up to 16KB block sizes, enabling customers to eliminate database performance bottlenecks.\n  I7i instances are available in eleven sizes - nine virtual sizes up to 48xlarge and two bare metal sizes - delivering up to 100Gbps of network bandwidth and 60Gbps of Amazon Elastic Block Store (EBS) bandwidth.\n To learn more, visit the I7i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-i7i-instances-additional-regions/",
      "pubDate": "2025-12-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-8b2e20dd7213",
      "title": "Now generally available: Amazon EC2 C8gb instances",
      "description": "Today, AWS announces the general availability of the new Amazon Elastic Block Storage (Amazon EBS) optimized Amazon Elastic Compute Cloud (Amazon EC2) C8gb instances. These instances are powered by AWS Graviton4 processors to deliver up to 30% better compute performance than AWS Graviton3 processors. At up to 150 Gbps of EBS bandwidth, these instances offer higher EBS performance compared to same-sized equivalent Graviton4-based instances. Take advantage of the higher block storage performance offered by these new EBS optimized EC2 instances to scale the performance and throughput of workloads such as high-performance file systems, while optimizing the cost of running your workloads.\n \nFor increased scalability, these instances offer instance sizes up to 24xlarge, including a metal-24xl size, up to 192 GiB of memory, up to 150 Gbps of EBS bandwidth, up to 200 Gbps of networking bandwidth. These instances support Elastic Fabric Adapter (EFA) networking on the 16xlarge, 24xlarge, metal-24xl sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n \nThe new C8gb instances are available in US East (N. Virginia) and US West (Oregon) regions. Metal sizes are only available in US East (N. Virginia) region.\n \nTo learn more, see Amazon EC2 C8gb Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/generally-available-amazon-ec2-c8gb-instances",
      "pubDate": "2025-12-10T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-3871c2986a1d",
      "title": "Amazon Braket now supports Qiskit 2.0",
      "description": "Amazon Braket now supports Qiskit 2.0, enabling quantum developers to use the latest version of the most popular quantum software framework with native primitives and client-side compilation capabilities.\n  With this release, Braket provides native implementations of Qiskit's Sampler and Estimator primitives that leverage Braket's program sets for optimized batching, reducing execution time and costs compared to generic wrapper approaches. The native primitives handle parameter sweeps and observable measurements service-side, eliminating the need for customers to implement this logic manually. Additionally, the bidirectional circuit conversion capability enables customers to use Qiskit's extensive compilation framework for client-side transpilation before submitting to Braket devices, providing the control and reproducibility that enterprise users and researchers require for device characterization experiments and custom compilation passes.\n  Qiskit 2.0 support is available in all AWS Regions where Amazon Braket is available. To get started, see the Qiskit-Braket provider documentation and the Amazon Braket Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-braket-qiskit-2-0/",
      "pubDate": "2025-12-10T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-2847b88fac95",
      "title": "Create AI-powered chat assistants for your enterprise with Amazon Quick Suite",
      "description": "In this post, we show how to build chat agents in Amazon Quick Suite. We walk through a three-layer framework—identity, instructions, and knowledge—that transforms Quick Suite chat agents into intelligent enterprise AI assistants. In our example, we demonstrate how our chat agent guides feature discovery, use enterprise data to inform recommendations, and tailors solutions based on potential to impact and your team’s adoption readiness.",
      "link": "https://aws.amazon.com/blogs/machine-learning/create-ai-powered-chat-assistants-for-your-enterprise-with-amazon-quick-suite/",
      "pubDate": "2025-12-09T17:07:22.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q"
      ]
    },
    {
      "id": "aws-news-f90bc2468fce",
      "title": "Amazon GameLift Servers enhances AWS Console for game developers with AI powered assistance",
      "description": "Today, Amazon GameLift Servers is launching AI-powered assistance in the AWS Console, leveraging Amazon Q Developer to provide tailored guidance for game developers. This new feature integrates specialized GameLift Servers knowledge to help customers navigate complex workflows, troubleshoot issues, and optimize their game server deployments more efficiently.\n  Developers can now access AI-assisted recommendations for game server integration, fleet configuration, and performance optimization directly within the AWS Console via Amazon GameLift Servers. This enhancement aims to streamline decision making processes, reduce troubleshooting time, and improve overall resource utilization, leading to cost savings and better player experiences.\n  AI-powered assistance is now available in all Amazon GameLift Servers supported regions, except AWS China. To learn more about this new feature, visit the Amazon GameLift Servers documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/gamelift-servers-console-developers-ai-powered/",
      "pubDate": "2025-12-09T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "lex",
        "launch",
        "ga",
        "now-available",
        "new-feature",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-1f771f0e37b4",
      "title": "S&P Global Data integration expands Amazon Quick Research capabilities",
      "description": "Today, we are pleased to announce a new integration between Amazon Quick Research and S&P Global. This integration brings both S&P Global Energy news, research, and insights and S&P Global Market Intelligence data to Quick Research customers in one deep research agent. In this post, we explore S&P Global’s data sets and the solution architecture of the integration with Quick Research.",
      "link": "https://aws.amazon.com/blogs/machine-learning/sp-global-data-integration-expands-amazon-quick-research-capabilities/",
      "pubDate": "2025-12-08T16:47:17.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "integration"
      ]
    },
    {
      "id": "aws-news-8273e71b1636",
      "title": "Amazon OpenSearch Service now supports automatic semantic enrichment",
      "description": "Amazon OpenSearch Service now brings automatic semantic enrichment to managed clusters, matching the capability we launched for OpenSearch Serverless earlier this year. This feature allows you to leverage the power of semantic search with minimal configuration effort.\n  Traditional lexical search only matches exact phrases, often missing relevant content. Automatic semantic enrichment understands context and meaning, delivering more relevant results. For example, a search for \"eco-friendly transportation options\" finds matches about \"electric vehicles\" or \"public transportation\"—even when these exact terms aren't present. This new capability handles all semantic processing automatically, eliminating the need to manage machine learning models. It supports both English-only and multi-lingual variants, covering 15 languages including Arabic, French, Hindi, Japanese, Korean, and more. You pay only for actual usage during data ingestion, billed as OpenSearch Compute Unit (OCU) - Semantic Search. View the pricing page for cost details and a pricing example.\n  This feature is now available for Amazon OpenSearch Service domains running OpenSearch version 2.19 or later. Currently, this feature supports non-VPC domains in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm).\n  Get started with our documentation on automatic semantic enrichment.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/opensearch-service-automatic-semantic-enrichment/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service",
        "launch",
        "ga",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-7756d1765b26",
      "title": "TwelveLabs’ Pegasus 1.2 model now in 23 new AWS regions via Global cross-region inference",
      "description": "Amazon Bedrock introduces Global cross-Region inference for TwelveLabs' Pegasus 1.2, expanding model availability to 23 new regions in addition to the seven regions where the model was already available. You can now also access the model in all EU regions in Amazon Bedrock using Geographic cross-Region inference. Geographic cross-Region inference is ideal for workloads with data residency or compliance requirements within a specific geographic boundary, while Global cross-Region inference is recommended for applications that prioritize availability and performance across multiple geographies.\n  Pegasus 1.2 is a powerful video-first language model that can generate text based on the visual, audio, and textual content within videos. Specifically designed for long-form video, it excels at video-to-text generation and temporal understanding. With Pegasus 1.2's availability in these additional regions, you can now build video-intelligence applications closer to your data and end users, reducing latency and simplifying your architecture.\n  For a complete list of supported inference profiles and regions for Pegasus 1.2, refer to the Cross-Region Inference documentation. To get started with Pegasus 1.2, visit the Amazon Bedrock console. To learn more, read the product page and Amazon Bedrock documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/twelvelabs-pegasus-available-with-global-cross-region-inference/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-0424929cc700",
      "title": "AWS Elastic Beanstalk now supports Node.js 24 on Amazon Linux 2023",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Node.js 24 applications on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest features and improvements in Node.js while taking advantage of the enhanced security and performance of AL2023.\n \nAWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Node.js 24 on AL2023 delivers updates to the V8 JavaScript engine, npm 11, and security and performance improvements. Developers can create Elastic Beanstalk environments running Node.js 24 on AL2023 through the Elastic Beanstalk Console, CLI, or API.\n \nThis platform is available in all commercial AWS Regions where Elastic Beanstalk is available, including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n \nTo learn more about Node.js 24 on Amazon Linux 2023, see the AWS Elastic Beanstalk Developer guide. For additional information, visit the AWS Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-beanstalk-node-js-24-linux-2023/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-99629c57268b",
      "title": "Amazon Connect Customer Profiles launches new segmentation capabilities (Beta)",
      "description": "Amazon Connect Customer Profiles now offers new segmentation capabilities powered by Spark SQL (Beta), enabling you to build sophisticated customer segments using your complete Customer Profiles data with AI assistance.\n  You can:\n  \n \n \nAccess complete profile data: Use both custom objects and standard objects for segmentation\n \n \nLeverage SQL capabilities: Join objects, filter with statistical functions like percentiles, and standardize date fields for complex analysis\n \n \nBuild segments with AI assistance: Use natural language prompts with the Segment AI assistant to automatically generate segment definitions in Spark SQL, or write SQL directly\n \n \nValidate before deployment: Review AI-generated SQL, view natural language explanations, and get automatic segment estimates\n \n \nFor example, you can create segments like \"customers who called customer services more than 3 times in the past month about new purchases they made\" or \"high-value customers in the 90th percentile of lifetime spend\" to enable precise targeting for outbound campaigns and personalized customer experiences.\n  These new segmentation capabilities are offered alongside existing segmentation features. Both integrate seamlessly with segment membership calls, Flow blocks, and Outbound Campaigns, allowing you to choose the approach that best fits your use case.\n  Getting started: Enable Data store from the Customer Profiles page to use the new segmentation capabilities\n  Availability: Available in all AWS regions where Amazon Connect Customer Profiles is offered.\n  For more information, see Build customer segments in Amazon Connect in the Amazon Connect Administrator Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-connect-customer-profiles/",
      "pubDate": "2025-12-05T15:04:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "personalize"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "personalize",
        "launch",
        "beta"
      ]
    },
    {
      "id": "aws-news-5a5afa48e9ee",
      "title": "Amazon Q now can analyze SES email sending",
      "description": "Today, Amazon Q (Q) added support for analyzing email sending in Amazon Simple Email Service (SES). Now customers can ask Q questions about their SES resource setup and usage patterns, and Q will help them optimize their configuration and troubleshoot deliverability problems. This makes it easier to manage SES operational activities with less technical knowledge.\n  Previously, customers could use SES features such as Virtual Deliverability Manager to manage and explore their SES resource configuration and usage. SES provided convenient dashboard views and query tools to help customers find information, however customers needed deep understanding of email sending concepts to interact with the service. Now, customers can ask Q for help in optimizing resource configuration and troubleshooting deliverability challenges. Q will evaluate customer’s usage patterns and SES resource configuration, find the answers customers need, and help them understand the context without requiring pre-knowledge or manual exploration.\n  Q supports SES resource analysis in all AWS Regions where SES and Q are available.\n  For more information, see the Q documentation for information about interacting with SES through Q.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-q-analyze-ses-email-sending/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "support"
      ]
    },
    {
      "id": "aws-news-39665ab10ff1",
      "title": "AWS launches simplified enablement of AWS CloudTrail events in Amazon CloudWatch",
      "description": "Today, AWS launches simplified enablement of AWS CloudTrail events in Amazon CloudWatch, a monitoring and logging service that helps you collect, monitor, and analyze log data from your AWS resources and applications. With this launch, you can now centrally configure collection of CloudTrail events in CloudWatch alongside other popular AWS log sources such as Amazon VPC flow logs and Amazon EKS Control Plane Logs. CloudWatch's ingestion experience provides a consolidated view that simplifies collecting telemetry from different sources for accounts in your AWS Organization thus ensuring comprehensive monitoring and data collection across your AWS environment.\n  This new integration leverages service-linked channels (SLCs) to receive events from CloudTrail without requiring trails, and also provides additional benefits such as safety-checks and termination protection. You incur both CloudTrail event delivery charges and CloudWatch Logs ingestion fees based on custom logs pricing.\n  To learn more about enablement of CloudTrail events in CloudWatch and supported AWS regions, visit the Amazon CloudWatch documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/key-enhancements-cloudtrail-events-cloudwatch/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "cloudwatch",
        "launch",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-116745600502",
      "title": "AWS Elastic Beanstalk now supports Python 3.14 on Amazon Linux 2023",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Python 3.14 applications on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest features and improvements in Python while taking advantage of the enhanced security and performance of AL2023.\n \nAWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Python 3.14 on AL2023 delivers enhanced interactive interpreter capabilities, improved error messages, important security and API improvements. Developers can create Elastic Beanstalk environments running Python 3.14 on AL2023 through the Elastic Beanstalk Console, CLI, or API.\n \nThis platform is available in all commercial AWS Regions where Elastic Beanstalk is available, including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n \nTo learn more about Python 3.14 on Amazon Linux 2023, see the AWS Elastic Beanstalk Developer guide. For additional information, visit the AWS Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-beanstalk-python-314-linux-2023/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-509a6eaf3b64",
      "title": "Announcing new Amazon EC2 M9g instances powered by AWS Graviton5 processors (Preview)",
      "description": "Starting today, new general purpose Amazon Elastic Compute Cloud (Amazon EC2) M9g instances, powered by AWS Graviton5 processors, are available in preview. AWS Graviton5 is the latest in the Graviton family of processors that are custom designed by AWS to provide the best price performance for workloads in Amazon EC2. These instances offer up to 25% better compute performance, and higher networking and Amazon Elastic Block Store (Amazon EBS) bandwidth than AWS Graviton4-based M8g instances. They are up to 30% faster for databases, up to 35% faster web applications, and up to 35% faster for machine learning workloads compared to M8g.\n  M9g instances are built on the AWS Nitro System, a collection of hardware and software innovations designed by AWS. The AWS Nitro System enables the delivery of efficient, flexible, and secure cloud services with isolated multitenancy, private networking, and fast local storage. Amazon EC2 M9g instances are ideal for workloads such as application servers, microservices, gaming servers, midsize data stores, and caching fleets.\n  To learn more or request access to the M9g preview, see Amazon EC2 M9g instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-m9g-instances-graviton5-processors-preview/",
      "pubDate": "2025-12-04T09:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex",
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "lex",
        "ec2",
        "graviton",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-a465d0dd13ac",
      "title": "Announcing TypeScript support in Strands Agents (preview) and more",
      "description": "In May, we open sourced the Strands Agents SDK, an open source python framework that takes a model-driven approach to building and running AI agents in just a few lines of code. Today, we’re announcing that TypeScript support is available in preview. Now, developers can choose between Python and TypeScript for building Strands Agents.\n  TypeScript support in Strands has been designed to provide an idiomatic TypeScript experience with full type safety, async/await support, and modern JavaScript/TypeScript patterns. Strands can be easily run in client applications, in browsers, and server-side applications in runtimes like AWS Lambda and Bedrock AgentCore. Developers can also build their entire stack in Typescript using the AWS CDK.\n  We’re also announcing three additional updates for the Strands SDK. First, edge device support for Strands Agents is generally available, extending the SDK with bidirectional streaming and additional local model providers like llama.cpp that let you run agents on small-scale devices using local models. Second, Strands steering is now available as an experimental feature, giving developers a modular prompting mechanism that provides feedback to the agent at the right moment in its lifecycle, steering agents toward a desired outcome without rigid workflows. Finally, Strands evaluations is available in preview. Evaluations gives developers the ability to systematically validate agent behavior, measure improvements, and deploy with confidence during development cycles.\n  Head to the Strands Agents GitHub to get started building.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/typescript-strands-agents-preview",
      "pubDate": "2025-12-03T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lambda",
        "preview",
        "experimental",
        "generally-available",
        "now-available",
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-fec165d010fd",
      "title": "Announcing Amazon EC2 General purpose M8azn instances (Preview)",
      "description": "Starting today, new general purpose high-frequency high-network Amazon Elastic Compute Cloud (Amazon EC2) M8azn instances are available for preview. These instances are powered by fifth generation AMD EPYC (formerly code named Turin) processors, offering the highest maximum CPU frequency, 5GHz in the cloud. The M8azn instances offer up to 2x compute performance versus previous generation M5zn instances. These instances also deliver 24% higher performance than M8a instances.\n  M8azn instances are built on the AWS Nitro System, a collection of hardware and software innovations designed by AWS. The AWS Nitro System enables the delivery of efficient, flexible, and secure cloud services with isolated multitenancy, private networking, and fast local storage. These instances are ideal for applications such as gaming, high-performance computing, high-frequency trading (HFT), CI/CD, and simulation modeling for the automotive, aerospace, energy, and telecommunication industries.\n  To learn more or request access to the M8azn instances preview, visit the Amazon EC2 M8a page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-amazon-ec2-m8azn-preview",
      "pubDate": "2025-12-02T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "lex",
        "ec2",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-0af7d0f0d0e9",
      "title": "Amazon FSx for NetApp ONTAP now supports Amazon S3 access",
      "description": "You can now attach Amazon S3 Access Points to your Amazon FSx for NetApp ONTAP file systems so that you can access your file data as if it were in S3. With this new capability, your file data in FSx for NetApp ONTAP is effortlessly accessible for use with the broad range of artificial intelligence, machine learning, and analytics services and applications that work with S3 while your file data continues to reside in your FSx for NetApp ONTAP file system.\n  Amazon FSx for NetApp ONTAP is the first and only complete, fully managed NetApp ONTAP file system in the cloud, allowing you to migrate on-premises applications that rely on NetApp ONTAP or other NAS appliances to AWS without having to change how you manage your data. An S3 Access Point is an endpoint that helps control and simplify how different applications or users can access data. Now, with S3 Access Points for FSx for NetApp ONTAP, you can discover new insights, innovate faster, and make even better data-driven decisions with the data you migrate to AWS. For example, you can use your data to augment generative AI applications with Amazon Bedrock, train machine learning models with Amazon SageMaker, run analysis using Amazon Glue or a wide range of AWS Data and Analytics Competency Partner solutions, and run workflows using S3-based cloud-native applications.\n  Get started with this capability by creating and attaching S3 Access Points to new FSx for NetApp ONTAP file systems using the Amazon FSx console, the AWS Command Line Interface (AWS CLI), or the AWS Software Development Kit (AWS SDK). Support for existing FSx for NetApp ONTAP file systems will come in an upcoming weekly maintenance window. This new capability is available in the select AWS Regions.\n  To get started, see the following list of resources:\n  \n \n \nAmazon FSx for NetApp ONTAP\n \n \nAmazon S3 Access Points\n \n \nAWS News Blog",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-fsx-netapp-ontap-s3-access",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "sagemaker",
        "s3",
        "glue"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova",
        "sagemaker",
        "s3",
        "glue",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-bfb723928032",
      "title": "Amazon EC2 P6e-GB300 UltraServers accelerated by NVIDIA GB300 NVL72 are now generally available",
      "description": "Today, AWS announces the general availability of Amazon Elastic Compute Cloud (Amazon EC2) P6e-GB300 UltraServers. P6e-GB300 UltraServers, accelerated by NVIDIA GB300 NVL72, provide 1.5x GPU memory and 1.5x FP4 compute (without sparsity) compared to P6e-GB200. \n \nCustomers can optimize performance for the most powerful models in production with P6e-GB300 for applications that require higher context and implement emerging inference techniques like reasoning and Agentic AI.\n \nTo get started with P6e-GB300 UltraServers, please contact your AWS sales representative.\n \nTo learn more about P6e UltraServers and instances, visit Amazon EC2 P6 instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-p6e-gb300-ultraservers-nvidia-gb300-nvl72-generally-available",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}