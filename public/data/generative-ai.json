{
  "lastUpdated": "2025-11-26T06:16:32.089Z",
  "category": "generative-ai",
  "totalItems": 45,
  "items": [
    {
      "id": "aws-news-7aef8bce6a76",
      "title": "Amazon SageMaker AI introduces EAGLE based adaptive speculative decoding to accelerate generative AI inference",
      "description": "Amazon SageMaker AI now supports EAGLE-based adaptive speculative decoding, a technique that accelerates large language model inference by up to 2.5x while maintaining output quality. In this post, we explain how to use EAGLE 2 and EAGLE 3 speculative decoding in Amazon SageMaker AI, covering the solution architecture, optimization workflows using your own datasets or SageMaker's built-in data, and benchmark results demonstrating significant improvements in throughput and latency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-ai-introduces-eagle-based-adaptive-speculative-decoding-to-accelerate-generative-ai-inference/",
      "pubDate": "2025-11-26T00:29:42.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-391eb4738cdc",
      "title": "Manage Amazon SageMaker HyperPod clusters with the new Amazon SageMaker AI MCP Server",
      "description": "The Amazon SageMaker AI MCP Server now supports tools that help you setup and manage HyperPod clusters. Amazon SageMaker HyperPod removes the undifferentiated heavy lifting involved in building generative AI models by quickly scaling model development tasks such as training, fine-tuning, or deployment across a cluster of AI accelerators. The SageMaker AI MCP Server now empowers AI coding assistants to provision and operate AI/ML clusters for model training and deployment.\n  MCP servers in AWS provide a standard interface to enhance AI-assisted application development by equipping AI code assistants with real-time, contextual understanding of various AWS services. The SageMaker AI MCP server comes with tools that streamline end-to-end AI/ML cluster operations using the AI assistant of your choice—from initial setup through ongoing management. It enables AI agents to reliably setup HyperPod clusters orchestrated by Amazon EKS or Slurm complete with pre-requisites, powered by CloudFormation templates that optimize networking, storage, and compute resources. Clusters created via this MCP server are fully optimized for high-performance distributed training and inference workloads, leveraging best practice architectures to maximize throughput and minimize latency at scale. Additionally, it provides comprehensive tools for cluster and node management—including scaling operations, applying software patches, and performing various maintenance tasks. When used in conjunction with AWS API MCP Server, AWS Knowledge MCP Server, and Amazon EKS MCP Server you gain complete coverage for all SageMaker HyperPod APIs and you can effectively troubleshoot common issues, such as diagnosing why a cluster node became inaccessible. For cluster administrators, these tools streamline daily operations. For data scientists, they enable you to set up AI/ML clusters at scale without requiring infrastructure expertise, allowing you to focus on what matters most—training and deploying models.\n  You can manage your AI/ML clusters through the SageMaker AI MCP server in all regions where SageMaker HyperPod is available. To get started, visit the AWS MCP Servers documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/manage-amazon-sagemaker-hyperpod-clusters-mcp-server/",
      "pubDate": "2025-11-25T19:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "cloudformation",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-857014d66d68",
      "title": "Amazon Quick Suite introduces scheduling for Quick Flows",
      "description": "Amazon Quick Flows now supports scheduling, enabling you to automate repetitive workflows without requiring manual intervention. You can now configure Quick Flows to run automatically at specified times or intervals, improving operational efficiency and ensuring critical tasks execute consistently.\n  You can schedule Quick Flows to run daily, weekly, monthly, or on custom intervals. This capability is great for automating routine and administrative tasks such as generating recurring reports from dashboards, summarizing open items assigned to you in external services, or generating daily meeting briefings before you head out to work.\n  You can schedule any flow you have access to—whether you created it or it was shared with you. To schedule a flow, click the scheduling icon and configure your desired date, time, and frequency.\n  Scheduling in Quick Flows is available now in US East (N. Virginia), US West (Oregon), and Europe (Ireland) There are no additional charges for using scheduled execution beyond standard Quick Flows usage.\n  To learn more about configuring scheduled Quick Flows, please visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-suite-scheduling-quick-flows/",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-4f096af20c37",
      "title": "OpenSearch Service Enhances Log Analytics with New PPL Experience",
      "description": "Today, AWS announces enhanced log analytics capabilities in Amazon OpenSearch Service, making Piped Processing Language (PPL) and natural language the default experience in OpenSearch UI's Observability workspace. This update combines proven pipeline syntax with simplified workflows to deliver an intuitive observability experience, helping customers analyze growing data volumes while controlling costs. The new experience includes 35+ new commands for deep analysis, faceted exploration, and natural language querying to help customers gain deeper insights across infrastructure, security, and business metrics.\n  With this enhancement, customers can streamline their log analytics workflows using familiar pipeline syntax while leveraging advanced analytics capabilities. The solution includes enterprise-grade query capabilities, supporting advanced event correlation using natural language that help teams uncover meaningful patterns faster. Users can seamlessly move from query to visualization within a single interface, reducing mean time to detect and resolve issues. Admins can quickly stand up an end-to-end OpenTelemetry solution using OpenSearch's Get Started workflow in the AWS console. The unified workflow includes out-of-the-box OpenSearch Ingestion pipelines for OpenTelemetry data, making it easier for teams to get started quickly.\n  Amazon OpenSearch UI is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Osaka), Asia Pacific (Hong Kong), Asia Pacific (Hyderabad), Europe (Ireland), Europe (London), Europe (Frankfurt), Europe (Paris), Europe (Stockholm), Europe (Milan), Europe (Spain), Europe (Zurich), South America (São Paulo), and Canada (Central).\n  To learn more about the new OpenSearch log analytics experience, visit the OpenSearch Service observability documentation and start using these enhanced capabilities today in OpenSearch UI.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/opensearch-service-log-analytics-ppl/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch",
        "opensearch service",
        "opensearch ingestion"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "opensearch ingestion",
        "ga",
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-250fe2a963fb",
      "title": "Amazon CloudFront announces support for mutual TLS authentication",
      "description": "Amazon CloudFront announces support for mutual TLS Authentication (mTLS), a security protocol that requires both the server and client to authenticate each other using X.509 certificates, enabling customers to validate client identities at CloudFront's edge locations. Customers can now ensure only clients presenting trusted certificates can access their distributions, helping protect against unauthorized access and security threats.\n  Previously, customers had to spend ongoing effort implementing and maintaining their own client access management solutions, leading to undifferentiated heavy lifting. Now with the support for mutual TLS, customers can easily validate client identities at the AWS edge before connections are established with their application servers or APIs. Example use cases include B2B secure API integrations for enterprises and client authentication for IoT. For B2B API security, enterprises can authenticate API requests from trusted third parties and partners using mutual TLS. For IoT use cases, enterprises can validate that devices are authorized to receive proprietary content such as firmware updates. Customers can leverage their existing third-party Certificate Authorities or AWS Private Certificate Authority to sign the X.509 certificates. With Mutual TLS, customers get the performance and scale benefits of CloudFront for workloads that require client authentication.\n  Mutual TLS authentication is available to all CloudFront customers at no additional cost. Customers can configure mutual TLS with CloudFront using the AWS Management Console, CLI, SDK, CDK, and CloudFormation. For detailed implementation guidance and best practices, visit CloudFront Mutual TLS (viewer) documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudfront-mutual-tls-authentication/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "cloudfront"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudformation",
        "cloudfront",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-8b58ac2defe5",
      "title": "AWS IoT Core now supports IoT thing registry data retrieval from IoT rules",
      "description": "AWS IoT Core announces a new capability to dynamically retrieve IoT thing registry data using an IoT rule, enhancing your ability to filter, enrich, and route IoT messages. Using the new get_registry_data() inline rule function, you can access IoT thing registry data, such as device attributes, device type, and group membership and leverage this information directly in IoT rules.\n  For example, your rule can filter AWS IoT Core connectivity lifecycle events and then retrieve thing attributes (such as \"test\" or \"production\" device) to inform routing of lifecycle events to different endpoints for downstream processing. You can also use this feature to enrich or route IoT messages with registry data from other devices. For instance, you can add a sensor’s threshold temperature from IoT thing registry to the messages relayed by its gateway.\n  To get started, connect your devices to AWS IoT Core and store your IoT device data in IoT thing registry. You can then use IoT rules to retrieve your registry data. This capability is available in all AWS regions where AWS IoT Core is present. For more information refer to the developer guide and API documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-core-thing-registry-data-retrieval/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-81729f0063bd",
      "title": "Deploy GPT-OSS models with Amazon Bedrock Custom Model Import",
      "description": "In this post, we show how to deploy the GPT-OSS-20B model on Amazon Bedrock using Custom Model Import while maintaining complete API compatibility with your current applications.",
      "link": "https://aws.amazon.com/blogs/machine-learning/deploy-gpt-oss-models-with-amazon-bedrock-custom-model-import/",
      "pubDate": "2025-11-24T17:49:05.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-b70cf6c5ae33",
      "title": "Amazon U7i instances now available in Asia Pacific (Jakarta) Region",
      "description": "Starting today, Amazon EC2 High Memory U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in the Asia Pacific (Jakarta) region. U7i-6tb instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-u7i-instances-asia-pacific-jakarta-region",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-6f01ea89f53c",
      "title": "AWS Lambda announces enhanced error handling capabilities for Kafka event processing",
      "description": "AWS Lambda launches enhanced error handling capabilities for Amazon Managed Streaming for Apache Kafka (MSK) and self-managed Apache Kafka (SMK) event sources. These capabilities allow customers to build custom retry configurations, optimize retries of failed messages, and send failed events to a Kafka topic as an on-failure destination, enabling customers to build resilient Kafka workloads with robust error handling strategies.\n  Customers use Kafka event source mappings (ESM) with their Lambda functions to build their mission-critical Kafka applications. Kafka ESM offers robust error handling of failed events by retrying events with exponential backoff, and retaining failed events in on-failure destinations like Amazon SQS, Amazon S3, Amazon SNS. However, customers need customized error handling to meet stringent business and performance requirements. With this launch, developers can now exercise precise control over failed event processing and leverage Kafka topics as an additional on-failure destination when using Provisioned mode for Kafka ESM. Customers can now define specific retry limits and time boundaries for retry, automatically discarding failed records beyond these limits to customer-specified destination. They can now also set automatic retries of failed records in the batch and enhance their function code to report individual failed messages, optimizing the retry process.\n  This feature is available in all AWS Commercial Regions where AWS Lambda’s Provisioned mode for Kafka ESM is available.\n  To enable these capabilities, provide configuration parameters for your Kafka ESM in the ESM API, AWS Console, and AWS CLI. To learn more, read the Lambda ESM documentation and AWS Lambda pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-lambda-enhanced-error-handling-capabilities-kafka-event-processing",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "s3",
        "rds",
        "kafka",
        "msk",
        "sns",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "s3",
        "rds",
        "kafka",
        "msk",
        "sns",
        "sqs",
        "launch"
      ]
    },
    {
      "id": "aws-news-5caa4bd88af7",
      "title": "Amazon Quick Suite Embedded Chat is now available",
      "description": "Today, AWS announces the general availability of Amazon Quick Suite Embedded Chat, enabling you to embed Quick Suite's conversational AI, which combines structured data and unstructured knowledge in a single conversation - directly into your applications, eliminating the need to build conversational interfaces, orchestration logic, or data access layers from scratch.\n \nQuick Suite Embedded Chat solves a fundamental problem: users want answers where they work, not in another tool. Whether in a CRM, support console, or analytics portal, they need instant, contextual responses. Most conversational tools excel at either structured data or documents, analytics or knowledge bases, answering questions or performing actions—rarely all of the above. Quick Suite closes this gap. Now, users can reference a KPI, pull details from a file, check customer feedback, and trigger actions in one continuous conversation without leaving the embedded chat.\n  Embedded Chat brings this unified experience into your applications with simple integration, either through 1-click embedding or through API-based iframes for registered users with your existing authentication. You can connect your Agentic Chat to your data through connectors to search SharePoint, websites, send Slack messages, or create Jira tasks and customize the Agent with your brand colors, communication style, and personalized greetings. Security always stays under your control as you choose what the agent accesses and explicitly scope all actions.\n  Quick Suite Embedded Chat is available the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland), and we'll expand availability to additional AWS Regions over the coming months. There is no additional cost for Quick Suite Embedded Chat. Existing Quick Suite pricing is available here.\n  To learn more, see Embedding Amazon Quick Suite launch blog. To get started with Amazon Quick Suite, visit the Amazon Quick Suite product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-suite-embedded-chat",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "launch",
        "ga",
        "now-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-2a82d6f564ba",
      "title": "Amazon OpenSearch Service now supports OpenSearch version 3.3",
      "description": "You can now run OpenSearch version 3.3 in Amazon OpenSearch Service. OpenSearch 3.3 introduces several improvements in areas like search performance, observability and new functionality to make agentic AI integrations simpler and more powerful.\n \nThis launch includes several improvements in vector search capabilities. First, with agentic search, you can now achieve precise search results using natural language inputs without the need to construct complex domain-specific language (DSL) queries. Second, batch processing for semantic highlighter improves performance by reducing overhead latency and improving GPU utilization. Finally, enhancements to Neural Search plugin make semantic search more efficient and provide optimization options for your specific data, performance, and relevance needs.\n \nThis launch also introduces support for Apache Calcite as default query engine for PPL that delivers optimization capabilities, improvements to query processing efficiency, and an extensive library of new PPL commands and functions. Additionally, this launch includes enhancements to the approximation framework that improve the responsiveness of paginated search results, real-time dashboards, and applications requiring deep pagination through large time-series or numeric datasets. Finally, workload management plugin now allows you to group search traffic and isolate network resources. This prevents specific requests from overusing network resources and offers tenant-level isolation.\n \nFor information on upgrading to OpenSearch 3.3, please see the documentation. OpenSearch 3.3 is now available in all AWS Regions where Amazon OpenSearch Service is available.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-opensearch-service-opensearch-version-3-3/",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds",
        "launch",
        "now-available",
        "improvement",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-97ea49be4b86",
      "title": "Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) for generative AI tasks",
      "description": "Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) technology, enabling administrators to partition a single GPU into multiple isolated GPUs. This capability allows administrators to maximize resource utilization by running diverse, small generative AI (GenAI) tasks simultaneously on GPU partitions while maintaining performance and task isolation.\n  Administrators can choose either the easy-to-use configuration setup on the SageMaker HyperPod console or a custom setup approach to enable fine-grained, hardware-isolated resources for specific task requirements that don't require full GPU capacity. They can also allocate compute quota to ensure fair and efficient distribution of GPU partitions across teams. With real-time performance metrics and resource utilization monitoring dashboard across GPU partitions, administrators gain visibility to optimize resource allocation. Data scientists can now accelerate time-to-market by scheduling lightweight inference tasks and running interactive notebooks in parallel on GPU partitions, eliminating wait times for full GPU availability.\n  This capability is currently available for Amazon SageMaker HyperPod clusters using the EKS orchestrator across the following AWS Regions: US West (Oregon), US East (N.Virginia), US East (Ohio), US West (N. California), Canada (Central), South America (Sao Paulo), Europe (Stockholm), Europe (Spain), Europe (Ireland), Europe (Frankfurt), Europe (London), Asia Pacific (Mumbai), Asia Pacific (Jakarta), Asia Pacific (Melbourne), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Seoul), Asia Pacific (Singapore).\n  To learn more, visit SageMaker HyperPod webpage, and SageMaker HyperPod documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-hyperpod-nvidia-multi-instance-gpu/",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-e7772104dcc0",
      "title": "Streamline AI operations with the Multi-Provider Generative AI Gateway reference architecture",
      "description": "In this post, we introduce the Multi-Provider Generative AI Gateway reference architecture, which provides guidance for deploying LiteLLM into an AWS environment to streamline the management and governance of production generative AI workloads across multiple model providers. This centralized gateway solution addresses common enterprise challenges including provider fragmentation, decentralized governance, operational complexity, and cost management by offering a unified interface that supports Amazon Bedrock, Amazon SageMaker AI, and external providers while maintaining comprehensive security, monitoring, and control capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/streamline-ai-operations-with-the-multi-provider-generative-ai-gateway-reference-architecture/",
      "pubDate": "2025-11-21T20:34:56.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "sagemaker",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-0b6f140782ce",
      "title": "Amazon Aurora DSQL database clusters now support up to 256 TiB of storage volume",
      "description": "Amazon Aurora DSQL now supports a maximum storage limit of 256 TiB, doubling the previous limit of 128 TiB. Now, customers can store and manage larger datasets within a single database cluster, simplifying data management for large-scale applications. With Aurora DSQL, customers only pay for the storage they use and storage automatically scales with usage, ensuring that customers do not need to provision storage upfront.\n  All Aurora DSQL clusters by default have a storage limit of 10 TiB. Customers that desire clusters with higher storage limits can request a limit increase using either the Service Quotas console or AWS CLI. Visit the Service Quotas documentation for a step-by-step guide to requesting a quota increase.\n  The increased storage limits are available in all Regions where Aurora DSQL is available. Get started with Aurora DSQL for free with the AWS Free Tier. To learn more about Aurora DSQL, visit the webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-aurora-dsql-database-clusters-up-to-256-tib",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-098aadb29a7c",
      "title": "AWS WAF announces Web Bot Auth support",
      "description": "Today, we're excited to announce the addition of Web Bot Auth (WBA) support in AWS WAF, providing a secure and standardized way to authenticate legitimate AI agents and automated tools accessing web applications.\n \nWeb Bot Auth is an authentication method that leverages cryptographic signatures in HTTP messages to verify that a request comes from an automated bot. Web Bot Auth is used as a verification method for verified bots and signed agents. It relies on two active IETF drafts: a directory draft allowing the crawler to share their public keys, and a protocol draft defining how these keys should be used to attach crawler's identity to HTTP requests.\n \nAWS WAF now automatically allows verified AI agent traffic. Verified WBA bots will now be automatically allowed by default. Previously, Category AI blocked unverified bots; this behavior is now refined to respect WBA verification. To learn more, please review the documentation. There is no additional cost for using this feature, however standard AWS WAF charges still apply. For details, visit the AWS WAF Pricing page. \n \nThis feature is currently available only for AWS WAF customers protecting Amazon CloudFront distributions.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-waf-web-bot-auth-support",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudfront",
        "waf"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudfront",
        "waf",
        "support"
      ]
    },
    {
      "id": "aws-news-5729127e8062",
      "title": "How Wipro PARI accelerates PLC code generation using Amazon Bedrock",
      "description": "In this post, we share how Wipro implemented advanced prompt engineering techniques, custom validation logic, and automated code rectification to streamline the development of industrial automation code at scale using Amazon Bedrock. We walk through the architecture along with the key use cases, explain core components and workflows, and share real-world results that show the transformative impact on manufacturing operations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-wipro-pari-accelerates-plc-code-generation-using-amazon-bedrock/",
      "pubDate": "2025-11-21T16:10:26.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-fdac2e5fede0",
      "title": "AWS Security Incident Response now provides agentic AI-powered investigation",
      "description": "AWS Security Incident Response now provides agentic AI-powered investigation capabilities to help you prepare for, respond to, and recover from security events faster and more effectively. The new investigative agent automatically gathers evidence across multiple AWS data sources, correlates the data, then presents findings for you in clear, actionable summaries. This helps you reduce the time required to investigate and respond to potential security events, thereby minimizing business disruption.\n  When a security event case is created in the Security Incident Response console, the investigative agent immediately assesses the case details to identify missing information, such as potential indicators, resource names, and timeframes. It asks the case submitter clarifying questions to gather these details. This proactive approach helps minimize delays from back-and-forth communications that traditionally extend case resolution times. The investigative agent then collects relevant information from various data sources, such as AWS CloudTrail, AWS Identity and Access Management (IAM), Amazon EC2, and AWS Cost Explorer. It automatically correlates this data to provide you with a comprehensive analysis, reducing the need for manual evidence gathering and enabling faster investigation. Security teams can track all investigation activities directly through the AWS console and view summaries in their preferred integration tools.\n  This feature is automatically enabled for all Security Incident Response customers at no additional cost in all AWS Regions where the service is available.\n  To learn more and get started, visit the Security Incident Response overview page and console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-security-incident-response-agentic-ai-powered-investigation",
      "pubDate": "2025-11-21T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "iam",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-0539e3184387",
      "title": "Amazon EKS add-ons now supports the AWS Secrets Store CSI Driver provider",
      "description": "Today, AWS announces the general availability of the AWS Secrets Store CSI Driver provider EKS add-on. This new integration allows customers to retrieve secrets from AWS Secrets Manager and parameters from AWS Systems Manager Parameter Store and mount them as files on their Kubernetes clusters running on Amazon Elastic Kubernetes Service (Amazon EKS). The add-on installs and manages the AWS provider for the Secrets Store CSI Driver.\n  Now, with the new Amazon EKS add-on, customers can quickly and easily set up new and existing clusters using automation to leverage AWS Secrets Manager and AWS Systems Manager Parameter Store, enhancing security and simplifying secrets management. Amazon EKS add-ons are curated extensions that automate the installation, configuration, and lifecycle management of operational software for Kubernetes clusters, simplifying the process of maintaining cluster functionality and security.\n  Customers rely on AWS Secrets Manager to securely store and manage secrets such as database credentials and API keys throughout their lifecycle. To learn more about Secrets Manager, visit the documentation. For a list of regions where Secrets Manager is available, see the AWS Region table. To get started with Secrets Manager, visit the Secrets Manager home page.\n  This new Amazon EKS add-on is available in all AWS commercial and AWS GovCloud (US) Regions.\n To get started, see the following resources:\n  \n \n \nAmazon EKS add-ons user guide\n \n \nAWS Secrets Manager user guide",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-add-ons-aws-secrets-store-csi-driver-provider",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "secrets manager"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "secrets manager",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-b7916baad19a",
      "title": "AWS Control Tower now supports seven new compliance frameworks and 279 additional AWS Config rules",
      "description": "Today, AWS Control Tower announces support for an additional 279 managed Config rules in Control Catalog for various use cases such as security, cost, durability, and operations. With this launch, you can now search, discover, enable and manage these additional rules directly from AWS Control Tower and govern more use cases for your multi-account environment. AWS Control Tower also supports seven new compliance frameworks in Control Catalog. In addition to existing frameworks, most controls are now mapped to ACSC-Essential-Eight-Nov-2022, ACSC-ISM-02-Mar-2023, AWS-WAF-v10, CCCS-Medium-Cloud-Control-May-2019, CIS-AWS-Benchmark-v1.2, CIS-AWS-Benchmark-v1.3, CIS-v7.1\n  To get started, go to the Control Catalog and search for controls with the implementation filter AWS Config to view all AWS Config rules in the Catalog. You can enable relevant rules directly using the AWS Control Tower console or the ListControls, GetControl and EnableControl APIs. We've also enhanced control relationship mapping, helping you understand how different controls work together. The updated ListControlMappings API now reveals important relationships between controls - showing which ones complement each other, are alternatives, or are mutually exclusive. For instance, you can now easily identify when a Config Rule (detection) and a Service Control Policy (prevention) can work together for comprehensive security coverage.\n  These new features are available in AWS Regions where AWS Control Tower is available, including AWS GovCloud (US). Reference the list of supported regions for each Config rule to see where it can be enabled. To learn more, visit the AWS Control Tower User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-control-tower-new-compliance-frameworks-additional-aws-config-rules",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "waf"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "waf",
        "launch",
        "new-feature",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-b5fe1dd88b80",
      "title": "Amazon OpenSearch Service OR2 and OM2 now available in additional Regions",
      "description": "Amazon OpenSearch Service, expands availability of OR2 and OM2, OpenSearch Optimized Instance family to 11 additional regions. The OR2 instance delivers up to 26% higher indexing throughput compared to previous OR1 instances and 70% over R7g instances. The OM2 instance delivers up to 15% higher indexing throughput compared to OR1 instances and 66% over M7g instances in internal benchmarks.\n \nThe OpenSearch Optimized instances, leveraging best-in-class cloud technologies like Amazon S3, to provide high durability, and improved price-performance for higher indexing throughput better for indexing heavy workload. Each OpenSearch Optimized instance is provisioned with compute, local instance storage for caching, and remote Amazon S3-based managed storage. OR2 and OM2 offers pay-as-you-go pricing and reserved instances, with a simple hourly rate for the instance, local instance storage, as well as the managed storage provisioned. OR2 instances come in sizes ‘medium’ through ‘16xlarge’, and offer compute, memory, and storage flexibility. OM2 instances come in sizes ‘large’ through ‘16xlarge’ Please refer to the Amazon OpenSearch Service pricing page for pricing details.\n  OR2 instance family is now available on Amazon OpenSearch Service across 11 additional regions globally: US West (N. California), Canada (Central),  Asia Pacific (Hong Kong, Jakarta , Malaysia, Melbourne, Osaka , Seoul, Singapore), Europe (London), and South America (Sao Paulo). \n  OM2 instance family is now available on Amazon OpenSearch Service across 14 additional regions globally: US West (N. California), Canada (Central), Asia Pacific (Hong Kong, Hyderabad, Mumbai, Osaka, Seoul, Singapore, Sydney, Tokyo), Europe ( Paris, Spain), Middle East (Bahrain), South America (Sao Paulo).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-opensearch-service-or2-om2-instances-available-regions",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a6455f7a8279",
      "title": "Amazon EKS and Amazon ECS announce fully managed MCP servers in preview",
      "description": "Today, Amazon Elastic Kubernetes Service (EKS) and Amazon Elastic Container Service (ECS) announced fully managed MCP servers enabling AI powered experiences for development and operations in preview. MCP (Model Context Protocol) provides a standardized interface that enriches AI applications with real-time, contextual knowledge of EKS and ECS clusters, enabling more accurate and tailored guidance throughout the application lifecycle, from development through operations. With this launch, EKS and ECS now offer fully managed MCP servers hosted in the AWS cloud, eliminating the need for local installation and maintenance. The fully managed MCP servers provide enterprise-grade capabilities like automatic updates and patching, centralized security through AWS IAM integration, comprehensive audit logging via AWS CloudTrail, and the proven scalability, reliability, and support of AWS.\n  The fully managed Amazon EKS and ECS MCP servers enable developers to easily configure AI coding assistants like Kiro CLI, Cursor, or Cline for guided development workflows, optimized code generation, and context-aware debugging. Operators gain access to a knowledge base of best practices and troubleshooting guidance derived from extensive operational experience managing clusters at scale.\n  To learn more about the Amazon EKS MCP server preview, visit EKS MCP server documentation and launch blog post. To learn more about the Amazon ECS MCP server preview, visit ECS MCP server documentation and launch blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-ecs-fully-managed-mcp-servers-preview",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "eks",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ecs",
        "eks",
        "iam",
        "launch",
        "preview",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-138216fa99de",
      "title": "Amazon ECR now supports managed container image signing",
      "description": "Amazon ECR now supports managed container image signing to enhance your security posture and eliminate the operational overhead of setting up signing. Container image signing allows you to verify that images are from trusted sources. With managed signing, ECR simplifies setting up container image signing to just a few clicks in the ECR Console or a single API call.\n  To get started, create a signing rule with an AWS Signer signing profile that specifies parameters such as signature validity period, and which repositories ECR should sign images for. Once configured, ECR automatically signs images as they are pushed using the identity of the entity pushing the image. ECR leverages AWS Signer for signing operations, which handles key material and certificate lifecycle management including generation, secure storage, and rotation. All signing operations are logged through CloudTrail for full auditability.\n  ECR managed signing is available in all AWS Regions where AWS Signer is available. To learn more, visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ecr-managed-container-image-signing",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-9a9239214a06",
      "title": "Amazon SageMaker HyperPod now supports running IDEs and Notebooks to accelerate AI development",
      "description": "Amazon SageMaker HyperPod now supports IDEs and Notebooks, enabling AI developers to run JupyterLab, Code Editor, or connect local IDEs to run their interactive AI workloads directly on HyperPod clusters.\n  AI developers can now run IDEs and notebooks on the same persistent HyperPod EKS clusters used for training and inference. This enables developers to leverage HyperPod's scalable GPU capacity with familiar tools like HyperPod CLI, while sharing data across IDEs and training jobs through mounted file systems such as FSx, EFS, etc..\n  Administrators can maximize CPU/GPU investments through unified governance across IDEs, training, and inference workloads using HyperPod Task Governance. HyperPod Observability provides usage metrics including CPU, GPU, and memory consumption, enabling cost-efficient cluster utilization.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is currently available, excluding China and GovCloud (US) regions. To learn more, visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-hyperpod-ides-notebooks-ai/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-2c36a717bd9f",
      "title": "Amazon Lightsail expands blueprint selection with updated support for Nginx Blueprint",
      "description": "Amazon Lightsail now offers a new Nginx blueprint. This new blueprint has Instance Metadata Service Version 2 (IMDSv2) enforced by default, and supports IPv6-only instances. With just a few clicks, you can create a Lightsail virtual private server (VPS) of your preferred size that comes with Nginx preinstalled.\n  With Lightsail, you can easily get started on the cloud by choosing a blueprint and an instance bundle to build your web application. Lightsail instance bundles include instances preinstalled with your preferred operating system, storage, and monthly data transfer allowance, giving you everything you need to get up and running quickly\n  This new blueprint is now available in all AWS Regions where Lightsail is available. For more information on blueprints supported on Lightsail, see Lightsail documentation. For more information on pricing, or to get started with your free trial, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/announcing-nginx-blueprint-by-amazon-lightsail/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-6d3bb702367e",
      "title": "Amazon Bedrock Data Automation now supports synchronous image processing",
      "description": "Amazon Bedrock Data Automation (BDA) now supports synchronous API processing for images, enabling you to receive structured insights from visual content with low latency. Synchronous processing for images complements the existing asynchronous API, giving you the flexibility to choose the right approach based on your application's latency requirements.\n  BDA automates the generation of insights from unstructured multimodal content such as documents, images, audio, and videos for your GenAI-powered applications. With synchronous image processing, you can build interactive experiences—such as social media platforms that moderate user-uploaded photos, e-commerce apps that identify products from customer images, or travel applications that recognize landmarks and provide contextual information. This eliminates polling or callback handling, simplifying your application architecture and reducing development complexity. Synchronous processing supports both Standard Output for common image analysis tasks like summarization and text extraction, and Custom Output using Blueprints for industry-specific field extraction. You now get the high-quality, structured results you expect from BDA with low-latency response times that enable more responsive user experiences.\n  Amazon Bedrock Data Automation is available in 8 AWS regions: Europe (Frankfurt), Europe (London), Europe (Ireland), Asia Pacific (Mumbai), Asia Pacific (Sydney), US West (Oregon) and US East (N. Virginia), and AWS GovCloud (US-West) AWS Regions.\n  To learn more, see the Bedrock Data Automation User Guide and the Amazon Bedrock Pricing page. To get started with using Bedrock Data Automation, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/bedrock-data-automation-synchronous-image-processing/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-d574c6d1d540",
      "title": "Announcing Amazon ECS Express Mode",
      "description": "Today, AWS announces Amazon Elastic Container Service (Amazon ECS) Express Mode, a new feature that empowers developers to rapidly launch containerized applications, including web applications and APIs. ECS Express Mode makes it easy to orchestrate and manage the cloud architecture for your application, while maintaining full control over your infrastructure resources.\n  Amazon ECS Express Mode streamlines the deployment and management of containerized applications on AWS, allowing developers to focus on delivering business value through their containerized applications. Every Express Mode service automatically receives an AWS-provided domain name, making your application immediately accessible without additional configuration. Applications using ECS Express Mode incorporate AWS operational best practices, serve either public or private HTTPS requests, and scale in response to traffic patterns. Traffic is distributed through Application Load Balancer (ALB)s, and automatically consolidates up to 25 Express Mode services behind a single ALB when appropriate. ECS Express uses intelligent rule-based routing to maintain isolation between services while efficiently utilizing the ALB resource. All resources provisioned by ECS Express Mode remain fully accessible in your account, ensuring you never sacrifice control or flexibility. As your application requirements evolve, you can directly access and modify any infrastructure resource, leveraging the complete feature set of Amazon ECS and related services without disruption to your running applications.\n  To get started just provide your container image, and ECS Express Mode handles the rest by deploying your application in Amazon ECS and auto-generating a URL. Amazon ECS Express Mode is available now in all AWS Regions at no additional charge. You pay only for the AWS resources created to run your application. To deploy a new ECS Express Mode service, use the Amazon ECS Console, SDK, CLI, CloudFormation, CDK and Terraform. For more information, see the AWS News blog, or the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/announcing-amazon-ecs-express-mode",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ecs",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ecs",
        "cloudformation",
        "launch",
        "new-feature"
      ]
    },
    {
      "id": "aws-news-8b260ff8c405",
      "title": "Amazon CloudWatch Application Signals adds GitHub Action and MCP server improvements",
      "description": "AWS announces the general availability of a new GitHub Action and improvements to CloudWatch Application Signals MCP server that bring application observability into developer tools, making troubleshooting issues faster and more convenient. Previously, developers had to leave GitHub to triage production issues, look up trace data, and ensure observability coverage, often switching between consoles, dashboards, and source code. Starting today, Application observability for AWS GitHub Action helps you catch breaching SLOs or critical service errors, in GitHub workflows. In addition, now you can use the CloudWatch Application Signals MCP server in AI coding agents such as Kiro to identify the exact file, function, and line of code responsible for latency, errors, or SLO violations. Furthermore, you can get instrumentation guidance that ensures comprehensive observability coverage.\n  With this new GitHub Action, developers can mention @awsapm in GitHub Issues with prompts like \"Why is my checkout service experiencing high latency?\" and receive intelligent, observability-based responses without switching between consoles, saving time and effort. In addition, with improvements in CloudWatch Application Signals MCP server, developers can now ask questions like \"Which line of code caused the latency spike in my service?\". Furthermore, when instrumentation is missing, the MCP server can modify infrastructure-as-code (e.g., CDK, Terraform) to help teams set up OTel-based application performance monitoring for ECS, EKS, Lambda, and EC2 without requiring coding effort.\n  Together, these features bring observability into development workflows, reduce context switching, and power intelligent, agent-assisted debugging from code to production. To get started, visit Application Observability for AWS GitHub Action documentation and the CloudWatch Application Signals MCP server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-application-signals-adds-github-action-mcp-server-improvements",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "ec2",
        "rds",
        "ecs",
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "ec2",
        "rds",
        "ecs",
        "eks",
        "cloudwatch",
        "improvement"
      ]
    },
    {
      "id": "aws-news-7397a704b760",
      "title": "Amazon CloudWatch Introduces In-Console Agent Management on EC2",
      "description": "Amazon CloudWatch now offers an in-console experience for automated installation and configuration of the Amazon CloudWatch agent on EC2 instances. Amazon CloudWatch agent is used by developers and SREs to collect infrastructure and application metrics, logs, and traces from EC2 and send them to CloudWatch and AWS X-Ray. This new experience provides visibility into agent status across your EC2 fleet, performs automatic detection of supported workloads, and leverages CloudWatch observability solutions to recommend monitoring configurations based on detected workloads.\n  Customers can now deploy the CloudWatch agent through one-click installation to individual instances or by creating tag-based policies for automated fleet-wide management. The automated policies ensure newly launched instances, including those created through auto-scaling, are automatically configured with the appropriate monitoring settings. By simplifying agent deployment and providing intelligent configuration recommendations, customers can ensure consistent monitoring across their environment while reducing setup time from hours to minutes.\n  Amazon CloudWatch agent is available in the following AWS regions: Europe (Stockholm), Asia Pacific (Mumbai), Europe (Paris), US East (Ohio), Europe (Ireland), Europe (Frankfurt), South America (Sao Paulo), US East (N. Virginia), Asia Pacific (Seoul), Asia Pacific (Tokyo), US West (Oregon), US West (N. California), Asia Pacific (Singapore), Asia Pacific (Sydney), and Canada (Central).\n  To get starting with Amazon CloudWatch agent in the CloudWatch console, see Installing the CloudWatch agent in the Amazon CloudWatch User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/cloudwatch-in-console-agent-management-ec2/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-4d94683bb916",
      "title": "Amazon Simple Email Service is now available in two new AWS Regions",
      "description": "Amazon Simple Email Service (Amazon SES) is now available in the Asia Pacific (Malaysia), Canada West (Calgary) Regions. Customers can now use these new Regions to leverage Amazon SES to send emails and, if needed, to help manage data sovereignty requirements.\n  Amazon SES is a scalable, cost-effective, and flexible cloud-based email service that allows digital marketers and application developers to send marketing, notification, and transactional emails from within any application. To learn more about Amazon SES, visit this page.\n  With this launch, Amazon SES is available in 29 AWS Regions globally: US East (Virginia, Ohio), US West (N. California, Oregon), AWS GovCloud (US-West, US-East), Asia Pacific (Osaka, Mumbai, Hyderabad, Sydney, Singapore, Seoul, Tokyo, Jakarta, Malaysia), Canada (Central, Calgary), Europe (Ireland, Frankfurt, London, Paris, Stockholm, Milan, Zurich), Israel (Tel Aviv), Middle East (Bahrain, UAE), South America (São Paulo), and Africa (Cape Town).\n  For a complete list of all of the regional endpoints for Amazon SES, see AWS Service Endpoints in the AWS General Reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ses-available-in-two-new-regions",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "launch",
        "ga",
        "now-available",
        "new-region"
      ]
    },
    {
      "id": "aws-news-334b22c260de",
      "title": "Amazon ECS and Amazon EKS now offer enhanced AI-powered troubleshooting in the Console",
      "description": "Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS) now offer enhanced AI-powered troubleshooting experiences in the AWS Management Console through Amazon Q Developer. The new AI-powered experiences appear contextually alongside error or status messages in the console, helping customers root cause issues and view mitigation suggestions with a single click.\n  In the ECS Console, customers can use the new “Inspect with Amazon Q” button to troubleshoot issues such as failed tasks, container health check failures, or deployment rollbacks. Simply click the status reason on task details, task definition details, or deployment details page, and click “Inspect with Amazon Q” from the popover to start troubleshooting with context from the issue provided to the agent for you. Once clicked, Amazon Q automatically uses appropriate AI tools to analyze the issue, gather the relevant logs and metrics, help you understand the root cause, and recommend mitigation actions.\n  The Amazon EKS console integrates Amazon Q throughout the observability dashboard, enabling you to inspect and troubleshoot cluster, control plane, and node health issues with contextual AI assistance. Simply click \"Inspect with Amazon Q\" directly from tables that outline issues, or click on an issue to view details and then select \"Inspect with Amazon Q\" to begin your investigation. The Q-powered experience provides deeper understanding of cluster-level insights, such as upgrade insights, helping you proactively identify and mitigate potential issues. Amazon Q also streamlines workload troubleshooting by helping you investigate Kubernetes events on pods that indicate issues, accelerating root cause identification and resolution.\n  Amazon Q integration in the Amazon ECS and Amazon EKS consoles is now available in all AWS commercial regions. To learn more, visit the ECS developer guide and EKS user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ecs-eks-ai-powered-troubleshooting-console/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "ecs",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "ecs",
        "eks",
        "ga",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-77f3836159eb",
      "title": "AWS Backup now supports Amazon FSx Intelligent-Tiering",
      "description": "AWS Backup now supports Amazon FSx Intelligent-Tiering, a storage class which delivers fully elastic file storage that automatically scales up and down with your workloads.\n \nThe FSx Intelligent-Tiering storage class is available for FSx for Lustre and Amazon FSx for OpenZFS file systems and combines performance, pay-for-what-you-use elasticity, with automated cost optimization in a single solution. With this integration, you can now protect OpenZFS and Lustre file systems using FSx Intelligent-Tiering through AWS Backup's centralized backup management capabilities. Customers with existing backup plans for Amazon FSx do not need to make any changes, as all scheduled backups will continue to work as expected.\n \nAWS Backup support is available in all AWS Regons where FSx Intelligent Tiering is available. For a full list of supported Regions see region availability documentation for Amazon FSx for OpenZFS and Amazon FSx for Lustre.\n \nTo learn more about AWS Backup for Amazon FSx, visit the AWS Backup product page, technical documentation, and pricing page. For more information on the AWS Backup features available across AWS Regions, see AWS Backup documentation. To get started, visit the AWS Backup console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-backup-amazon-fsx-intelligent-tiering/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-bc64fccd13cf",
      "title": "AWS Application Load Balancer now supports Health Check Logs",
      "description": "AWS Application Load Balancers (ALB) now supports Health Check Logs that allows you to send detailed target health check log data directly to your designated Amazon S3 bucket. This optional feature captures comprehensive target health check status, timestamp, target identification data, and failure reasons.\n  Health Check Logs provide complete visibility into target health status with precise failure diagnostics, enabling faster troubleshooting without contacting AWS Support. You can analyze target’s health patterns over time, determine exactly why instances were marked unhealthy, and significantly reduce mean time to resolution for target health investigations. Logs are automatically delivered to your S3 bucket every 5 minutes with no additional charges beyond standard S3 storage costs.\n  This feature is available in all AWS Commercial Regions, AWS GovCloud (US) Regions and AWS China Regions where Application Load Balancer is offered. You can enable Health Check Logs through the AWS Management Console, AWS CLI, or programmatically using the AWS SDK. Learn more about Health Check Logs for ALBs in the AWS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/application-load-balancer-health-check-logs/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-fc0fa46be7cd",
      "title": "Amazon Quick Sight dashboard customization now includes tables and pivot tables",
      "description": "Amazon Quick Sight has expanded customization capabilities to include tables and pivot tables in dashboards. This update enables readers to personalize their data views by sorting, reordering, hiding/showing, and freezing columns—all without requiring updates from dashboard authors.\n  These capabilities are especially valuable for teams that need to tailor dashboard views for different analytical needs and collaborate across departments. For example, sales managers can quickly sort by revenue to identify top performers, while finance teams can freeze account columns to maintain context in large datasets.\n  These new customization features are now available in Amazon Quick Sight Enterprise Edition across all supported Amazon Quick Sight regions. Learn how to get started with these new customization features in our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-sight-dashboard-tables-pivot-tables/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "rds",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-e746385d2aa7",
      "title": "MSD explores applying generative Al to improve the deviation management process using AWS services",
      "description": "This blog post has explores how MSD is harnessing the power of generative AI and databases to optimize and transform its manufacturing deviation management process. By creating an accurate and multifaceted knowledge base of past events, deviations, and findings, the company aims to significantly reduce the time and effort required for each new case while maintaining the highest standards of quality and compliance.",
      "link": "https://aws.amazon.com/blogs/machine-learning/msd-explores-applying-generative-al-to-improve-the-deviation-management-process-using-aws-services/",
      "pubDate": "2025-11-20T18:21:49.000Z",
      "source": "mlBlog",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds"
      ]
    },
    {
      "id": "aws-news-82390b5e23c0",
      "title": "Accelerating genomics variant interpretation with AWS HealthOmics and Amazon Bedrock AgentCore",
      "description": "In this blog post, we show you how agentic workflows can accelerate the processing and interpretation of genomics pipelines at scale with a natural language interface. We demonstrate a comprehensive genomic variant interpreter agent that combines automated data processing with intelligent analysis to address the entire workflow from raw VCF file ingestion to conversational query interfaces.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerating-genomics-variant-interpretation-with-aws-healthomics-and-amazon-bedrock-agentcore/",
      "pubDate": "2025-11-20T18:18:21.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-efa2bd21663c",
      "title": "How Rufus scales conversational shopping experiences to millions of Amazon customers with Amazon Bedrock",
      "description": "Our team at Amazon builds Rufus, an AI-powered shopping assistant which delivers intelligent, conversational experiences to delight our customers. More than 250 million customers have used Rufus this year. Monthly users are up 140% YoY and interactions are up 210% YoY. Additionally, customers that use Rufus during a shopping journey are 60% more likely to […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-rufus-scales-conversational-shopping-experiences-to-millions-of-amazon-customers-with-amazon-bedrock/",
      "pubDate": "2025-11-20T18:13:39.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-c2cf5f1cc0c8",
      "title": "Claude Code deployment patterns and best practices with Amazon Bedrock",
      "description": "In this post, we explore deployment patterns and best practices for Claude Code with Amazon Bedrock, covering authentication methods, infrastructure decisions, and monitoring strategies to help enterprises deploy securely at scale. We recommend using Direct IdP integration for authentication, a dedicated AWS account for infrastructure, and OpenTelemetry with CloudWatch dashboards for comprehensive monitoring to ensure secure access, capacity management, and visibility into costs and developer productivity .",
      "link": "https://aws.amazon.com/blogs/machine-learning/claude-code-deployment-patterns-and-best-practices-with-amazon-bedrock/",
      "pubDate": "2025-11-19T23:17:38.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "rds",
        "cloudwatch",
        "integration"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}