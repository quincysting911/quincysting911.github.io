{
  "lastUpdated": "2025-11-16T06:14:27.387Z",
  "category": "generative-ai",
  "totalItems": 48,
  "items": [
    {
      "id": "aws-news-78f4b11efc59",
      "title": "Build a biomedical research agent with Biomni tools and Amazon Bedrock AgentCore Gateway",
      "description": "In this post, we demonstrate how to build a production-ready biomedical research agent by integrating Biomni's specialized tools with Amazon Bedrock AgentCore Gateway, enabling researchers to access over 30 biomedical databases through a secure, scalable infrastructure. The implementation showcases how to transform research prototypes into enterprise-grade systems with persistent memory, semantic tool discovery, and comprehensive observability for scientific reproducibility .",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-a-biomedical-research-agent-with-biomni-tools-and-amazon-bedrock-agentcore-gateway/",
      "pubDate": "2025-11-14T18:28:42.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "ga"
      ]
    },
    {
      "id": "aws-news-8f92fedafba9",
      "title": "Amazon SageMaker Catalog now supports read and write access to Amazon S3",
      "description": "Amazon SageMaker Catalog now supports read and write access to Amazon S3 general purpose buckets. This capability helps data scientists and analysts search for unstructured data, process it alongside structured datasets, and share transformed datasets with other teams. Data publishers gain additional controls to support analytics and generative AI workflows within SageMaker Unified Studio while maintaining security and governance controls over shared data. \n \nWhen approving subscription requests or directly sharing S3 data within the SageMaker Catalog, data producers can choose to grant read-only or read and write access. If granted read and write access, data consumers can process datasets in SageMaker and store the results back to the S3 bucket or folder. The data can then be published and automatically discoverable by other teams. This capability is now available in all AWS Regions where Amazon SageMaker Unified Studio is supported. To get started, you can log into SageMaker Unified Studio, or you can use the Amazon DataZone API, SDK, or AWS CLI. To learn more, see the SageMaker Unified Studio guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-catalog-read-write-access-amazon-s3/",
      "pubDate": "2025-11-14T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-dc81d0d3e70d",
      "title": "Amazon RDS Blue/Green deployments now supports Aurora Global Database",
      "description": "Amazon RDS Blue/Green deployments now support safer, simpler, and faster updates for your Aurora Global Databases. With just a few clicks, you can create a staging (green) environment that mirrors your production (blue) Aurora Global Database, including primary and all secondary regions. When you’re ready to make your staging environment the new production environment, perform a blue/green switchover. This operation transitions your primary and all secondary regions to the green environment, which now serves as the active production environment. Your application begins accessing it immediately without any configuration changes, minimizing operational overhead.\n  With Global Database, a single Aurora cluster can span multiple AWS Regions, providing disaster recovery for your applications in case of single Region impairment and enabling fast local reads for globally distributed applications. With this launch, you can perform critical database operations including major and minor version upgrades, OS updates, parameter modifications, instance type validations, and schema changes with minimal downtime. During blue/green switchover, Aurora automatically renames clusters, instances, and endpoints to match the original production environment, enabling applications to continue operating without any modifications. You can leverage this capability using the AWS Management console, SDK, or CLI.\n  This capability is available in Amazon Aurora MySQL-Compatible Edition and Amazon Aurora PostgreSQL-Compatible Edition versions that support the Aurora Global Database configuration and in all commercial AWS Regions and AWS GovCloud (US) Regions.\n  Start planning your next Global Database upgrade using RDS Blue/Green deployments by following the steps in the blog. For more details, refer to our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-rds-blue-green-deployments-aurora-global-database",
      "pubDate": "2025-11-14T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "launch",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-292e1470e111",
      "title": "Amazon EventBridge introduces enhanced visual rule builder",
      "description": "Amazon EventBridge introduces a new intuitive console based visual rule builder with a comprehensive event catalog for discovering and subscribing to events from custom applications, and over 200 AWS services. The new rule builder integrates the EventBridge Schema Registry with an updated event catalog and intuitive drag and drop canvas that simplifies building event-driven applications.\n  With enhanced rule builder, developers can browse and search through events with readily available sample payloads and schemas, eliminating the need to find and reference individual service documentation. The schema-aware visual builder guides developers through creating event filter patterns and rules, reducing syntax errors and development time.\n  The EventBridge enhanced rule builder is available today in all regions where the Schema Registry is launched. Developers can get started through the Amazon EventBridge console at no additional cost beyond standard EventBridge usage charges.\n  For more information, visit the EventBridge documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/eventbridge-enhanced-visual-rule-builder/",
      "pubDate": "2025-11-14T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "canvas",
        "eventbridge"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "canvas",
        "eventbridge",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-d9e01bf345ff",
      "title": "Announcing Amazon DocumentDB (with MongoDB compatibility) version 8.0",
      "description": "Amazon DocumentDB (with MongoDB compatibility) announces version 8.0, which now offers added support for drivers supporting the MongoDB API versions 6.0, 7.0, and 8.0. Amazon DocumentDB 8.0 also improves query latency by up to 7x and compression ratio by up to 5x, enabling you to build high-performance applications at a lower cost. \n \nThe following are features and capabilities introduced in Amazon DocumentDB 8.0:\n  \n \n \nCompatibility with MongoDB 8.0: Amazon DocumentDB 8.0 provides compatibility with MongoDB 8.0 by adding support for MongoDB 8.0 API drivers. Amazon DocumentDB 8.0 also supports applications that are built using MongoDB API versions 6.0 and 7.0.\n \n \nPlanner Version3: New query planner in Amazon DocumentDB 8.0 extends performance improvements to aggregation stage operators, along with supporting aggregation pipeline optimizations and distinct commands.\n \n \nNew aggregation stages and operators: Amazon DocumentDB 8.0 offers 6 new aggregation stages: $replaceWith, $vectorSearch, $merge, $set, $unset, $bucket, and 3 new aggregation operators $pow, $rand, $dateTrunc.\n \n \nCompression: Support for dictionary-based compression through the Zstandard compression algorithm improves compression ratio by up to 5x, thus improving storage efficiency and reducing I/O costs.\n \n \nNew capabilities: Amazon DocumentDB 8.0 supports collation and views.\n \n \nA new version of text index: Text index v2 in Amazon DocumentDB 8.0 introduces additional tokens, enhancing text search capabilities.\n \n \nVector search improvements: Through parallel vector index build, Amazon DocumentDB 8.0 reduces index build time by up to 30x.\n \n \nYou can use AWS Database Migration Service (DMS) to upgrade your Amazon DocumentDB 5.0 instance-based clusters to Amazon DocumentDB 8.0 clusters. Please see upgrading your DocumentDB cluster to learn more. Amazon DocumentDB 8.0 is available in all AWS Regions where Amazon DocumentDB is available. To learn more about Amazon DocumentDB 8.0 visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/documentdb-8-o",
      "pubDate": "2025-11-14T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-64c552f79afb",
      "title": "Amazon EC2 I8g instances now available in additional AWS regions",
      "description": "AWS is announcing the general availability of Amazon EC2 Storage Optimized I8g instances in Europe (Stockholm) and Asia Pacific (Osaka) regions. I8g instances offer the best compute performance in Amazon EC2 for storage-intensive workloads. I8g instances use the latest third generation AWS Nitro SSDs, local NVMe storage that deliver up to 65% better real-time storage performance per TB while offering up to 50% lower storage I/O latency and up to 60% lower storage I/O latency variability compared to I4g instances. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software enhancing the performance and security for your workloads.\n  Amazon EC2 I8g instances are designed for I/O intensive workloads that require rapid data access and real-time latency from storage. These instances excel at handling transactional, real-time, distributed databases, including MySQL, PostgreSQL, Hbase and NoSQL solutions like Aerospike, MongoDB, ClickHouse, and Apache Druid. They're also optimized for real-time analytics platforms such as Apache Spark, data lakehouse and AI LLM pre-processing for training. I8g instances are available in 10 different sizes with up to 48xlarge including one metal size, 1.5 TiB of memory, and 45 TB local instance storage. They deliver up to 100 Gbps of network performance bandwidth, and 60 Gbps of dedicated bandwidth for Amazon Elastic Block Store (EBS).\n  To learn more, visit Amazon EC2 I8g instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-i8g-instances-additional-aws-regions",
      "pubDate": "2025-11-13T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-97a40f5f49b3",
      "title": "AWS Health enhances Amazon EventBridge to give more flexibility and higher resilience",
      "description": "Customers using Amazon EventBridge can now setup rules for AWS Health events with multi-region redundancy, or choose a simplified path by creating a single rule to capture all Health events. With this enhancement, Health sends all events simultaneously to US West (Oregon) as well as the individual region of impact. For more information customers can go to Creating EventBridge rules for AWS Region coverage.\n  Sending Health events to two regions gives customers an option to increase the resilience of their integration by creating a backup rule. US West (Oregon) is the backup for all regions in commercial partition, while US East (N. Virginia) is the backup for US West (Oregon). Plus, this change also enables a simplified integration path, where customers can now setup a single rule in US West (Oregon) to capture all Health events from across commercial partition, as opposed to needing to configure rules in individual regions. Customers now have greater flexibility in their integration approach for receiving Health events.\n  This update is available in all AWS regions. In China, all Health events get delivered simultaneously to both China (Beijing) and China (Ningxia). In AWS GovCloud (US), all Health events get delivered to AWS GovCloud (US-West) and AWS GovCloud (US-East).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-health-amazon-eventbridge-flexibility-higher-resilience",
      "pubDate": "2025-11-13T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "eventbridge"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "eventbridge",
        "update",
        "enhancement",
        "integration"
      ]
    },
    {
      "id": "aws-news-0046759af324",
      "title": "Amazon EC2 I7i instances now available in additional AWS regions",
      "description": "Amazon Web Services (AWS) announces the availability of high performance Storage Optimized Amazon EC2 I7i instances in AWS Europe (Ireland), Asia Pacific (Seoul, Hong Kong) regions. Powered by 5th generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.2 GHz, these instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances. Powered by 3rd generation AWS Nitro SSDs, I7i instances offer up to 45TB of NVMe storage with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances.\n  I7i instances are ideal for I/O intensive and latency-sensitive workloads that demand very high random IOPS performance with real-time latency to access small to medium size datasets (multi-TBs). I7i instances support torn write prevention feature with up to 16KB block sizes, enabling customers to eliminate database performance bottlenecks.\n  I7i instances are available in eleven sizes - nine virtual sizes up to 48xlarge and two bare metal sizes - delivering up to 100Gbps of network bandwidth and 60Gbps of Amazon Elastic Block Store (EBS) bandwidth.\n \n\n To learn more, visit the I7i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-i7i-instances-additional-aws-regions",
      "pubDate": "2025-11-13T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-2cc1aa0480c0",
      "title": "AWS IoT Core adds location resolution capabilities for Amazon Sidewalk enabled devices",
      "description": "AWS IoT Core Device Location announces location resolution capabilities for Internet of Things (IoT) devices connected to Amazon Sidewalk network, enabling developers to build asset tracking and geo-fencing applications more efficiently by eliminating the need for GPS hardware in low-power devices. Amazon Sidewalk provides a secure community network through Amazon Sidewalk Gateways (compatible Amazon Echo and Ring devices) to deliver cloud connectivity for IoT devices. AWS IoT Core for Amazon Sidewalk facilitates connectivity and message transmission between Amazon Sidewalk-connected IoT devices and AWS cloud services. The integration of Amazon Sidewalk with AWS IoT Core, enables you to easily provision, onboard, and monitor your Amazon Sidewalk devices in the AWS cloud.\n  With the new enhancement, you can now use AWS IoT Core’s Device Location feature to resolve the approximate location of your Amazon Sidewalk enabled devices, using input payloads like WiFi access point, Global Navigation Satellite System data, or Bluetooth Low Energy data. AWS IoT Core Device Location uses these inputs to resolve the geo-coordinate data, and delivers the geo-coordinate data to your desired AWS IoT rules or MQTT topics for integration with backend applications. To get started, install Sidewalk SDK v1.19 (or a later version) in your Sidewalk-enabled devices, provision the devices in AWS IoT Core for Amazon Sidewalk, and enable location during the provisioning.\n  This new feature is available in AWS US-East (N. Virginia) Region of AWS cloud where AWS IoT Core for Amazon Sidewalk is available. Please note that Amazon Sidewalk network is available only in the United States of America. For more information, refer AWS developer guide, Amazon Sidewalk developer guide, and Amazon Sidewalk network coverage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-core-location-resolution-capabilities-amazon-sidewalk-enabled-devices",
      "pubDate": "2025-11-13T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "new-feature",
        "enhancement",
        "integration"
      ]
    },
    {
      "id": "aws-news-11c59e9cbf9b",
      "title": "AWS Transform automates Landing Zone Accelerator network configuration",
      "description": "AWS Transform for VMware now allows customers to automatically generate network configurations that can be directly imported into the Landing Zone Accelerator on AWS solution (LZA). Building on AWS Transform's existing support for infrastructure-as-code generation in AWS CloudFormation, AWS CDK, and Terraform formats, this new capability enables automatic transformation of VMware network environments into LZA-compatible network configuration YAML files.\n The YAML files can be deployed through LZA's deployment pipeline, streamlining the process of setting up cloud infrastructure.\n  AWS Transform for VMware is an agentic AI service that automates the discovery, planning, and migration of VMware workloads, accelerating infrastructure modernization with increased speed and confidence. Landing Zone Accelerator on AWS solution (LZA) automates the setup of a secure, multi-account AWS environment using AWS best practices. Migrating workloads to AWS traditionally requires you to manually recreate network configurations while maintaining operational and compliance consistency. The service now automates the generation of LZA network configurations, reducing manual effort and deployment time to better manage and govern your multi-account environment. \n  The LZA configuration generation capability is available in all AWS Transform target Regions.\n \nTo learn more, visit the AWS Transform for VMware product page, read the user guide, or get started in the AWS Transform web experience.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-transform-landing-zone-accelerator-network-configuration",
      "pubDate": "2025-11-13T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "transform for vmware"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudformation",
        "transform for vmware",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-5e09c58a3c0e",
      "title": "Amazon EventBridge now supports targeting SQS fair queues",
      "description": "Amazon EventBridge now supports Amazon SQS fair queues as targets, enabling you to build more responsive event-driven applications. You can now leverage SQSs improved message distribution across consumer groups and mitigate the noisy neighbor impact in multi-tenant messaging systems. This enhancement allows EventBridge to send events directly to SQS fair queues. With fair queues, multiple consumers can process messages from the same tenant at the same time, while keeping message processing times consistent across all tenants.\n  The Amazon EventBridge event bus is a serverless event broker that enables you to create scalable event-driven applications by routing events between your own applications, third-party SaaS applications, and other AWS services. SQS fair queues automatically distribute messages fairly across consumer groups, preventing any single group from monopolizing queue resources. When combined with EventBridge's event routing capabilities, this creates powerful patterns for building scalable, multi-tenant applications where different teams or services need equitable access to event streams.\n  To route events to an SQS fair queue, you can select the fair queue as a target when creating or updating EventBridge rules through the AWS Management Console, AWS CLI, or AWS SDKs. Be sure to include a MessageGroupID parameter, which can be specified with either a static value or JSON path expression.\n  Support for Fair Queue and FIFO targets is available in all AWS commercial and AWS GovCloud (US) Regions. For more information about EventBridge target support, see our documentation. For more information about SQS Fair Queues, see the SQS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eventbridge-sqs-fair-queue-targets/",
      "pubDate": "2025-11-13T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eventbridge",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eventbridge",
        "sqs",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-4f1fd69db334",
      "title": "Amazon U7i instances now available in Europe (Stockholm) Region",
      "description": "Starting today, Amazon EC2 High Memory U7i instances with 12TB of memory (u7i-12tb.224xlarge) are now available in the Europe (Stockholm) region. U7i-12tb instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-12tb instances offer 12TB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-12tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-u7i-instances-europe-stockholm-region/",
      "pubDate": "2025-11-13T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-45e98aae3ed7",
      "title": "Amazon EC2 I8g instances now available in additional AWS regions",
      "description": "AWS is announcing the general availability of Amazon EC2 Storage Optimized I8g instances in Asia Pacific (Seoul) and South America (Sao Paulo) regions. I8g instances offer the best performance in Amazon EC2 for storage-intensive workloads. I8g instances use the latest third generation AWS Nitro SSDs, local NVMe storage that deliver up to 65% better real-time storage performance per TB while offering up to 50% lower storage I/O latency and up to 60% lower storage I/O latency variability. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software enhancing the performance and security for your workloads.\n  Amazon EC2 I8g instances are designed for I/O intensive workloads that require rapid data access and real-time latency from storage. These instances excel at handling transactional, real-time, distributed databases, including MySQL, PostgreSQL, Hbase and NoSQL solutions like Aerospike, MongoDB, ClickHouse, and Apache Druid. They're also optimized for real-time analytics platforms such as Apache Spark, data lakehouse and AI LLM pre-processing for training. I8g instances are available in 10 different sizes with up to 48xlarge including one metal size, 1.5 TiB of memory, and 45 TB local instance storage. They deliver up to 100 Gbps of network performance bandwidth, and 60 Gbps of dedicated bandwidth for Amazon Elastic Block Store (EBS).\n  To learn more, visit Amazon EC2 I8g instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-i8g-instances-additional-regions/",
      "pubDate": "2025-11-13T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-f7d6707b34ce",
      "title": "Amazon Kinesis Video Streams WebRTC Multi-Viewer",
      "description": "Amazon Kinesis Video Streams now offers the ability to stream real-time audio and video to multiple concurrent viewers via WebRTC, while also recording video and audio from the session to the cloud for storage, playback, and analytical processing. With this update, developers can enable up to 3 concurrent viewers of real-time feeds from cameras or other video-producing devices without increasing compute or bandwidth utilization on the device. In addition, participants can engage in audio conversations with each other, enabling direct real-time communication between viewers during the session.\n  Developers can now build real-time peer-to-peer streaming applications by installing the Amazon Kinesis Video Streams with WebRTC SDK across security cameras, IoT devices, PCs, and mobile devices. Using the APIs, developers can create applications that stream real-time media to multiple concurrent viewers. They can develop solutions for scenarios such as home security applications sharing camera feeds with family members, remote proctoring systems with multiple monitoring operators, or robot operation control centers with audit capabilities. Developers can implement both live and on-demand video playback through session recording, and build advanced applications utilizing computer vision and video analytics by integrating with Amazon Rekognition Video and Amazon SageMaker.\n  Amazon Kinesis Video Streams WebRTC Multi-Viewer is available in all regions where Amazon Kinesis Video Streams is available, except the AWS GovCloud (US) Regions and the China (Beijing, operated by Sinnet) Region.\n  To learn more, see our Getting Started Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-kinesis-video-streams-multi-viewer/",
      "pubDate": "2025-11-13T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "rekognition",
        "kinesis"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "rekognition",
        "kinesis",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-5102075e6753",
      "title": "Amazon S3 Tables now support Amazon CloudWatch metrics",
      "description": "Amazon CloudWatch metrics are now available for S3 Tables, helping you monitor table storage, requests, and maintenance operations. You can use CloudWatch metrics to track performance, detect anomalies, and monitor the operational health of applications that use S3 Tables.\n  CloudWatch metrics for S3 Tables provide three types of metrics. Storage metrics track daily storage usage and count of objects. Table maintenance metrics track daily bytes and objects processed by compaction operations. Request metrics monitor table operations, data transfer volumes, error rates, and latency measurements at minute-level granularity. These metrics are available through the CloudWatch console, AWS CLI, and CloudWatch API at the table bucket, namespace, and individual table level.\n  CloudWatch metrics for S3 Tables are now available in all AWS Regions where S3 Tables are available. To learn more, visit the S3 Tables product page and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-s3-tables-cloudwatch-metrics",
      "pubDate": "2025-11-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "cloudwatch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-3707c061e973",
      "title": "New AWS CUR 2.0 features: EC2 ODCR and Capacity Blocks for ML monitoring",
      "description": "AWS announces addition of new columns and granularity in CUR 2.0 that provide customers better visibility into the cost and usage of their capacity reservations, such as EC2 On-Demand Capacity Reservation (ODCR) and EC2 Capacity Blocks for ML. This enables customers to easily calculate the utilization and coverage of their capacity reservations, identify unused capacity reservations for cost optimization, and attribute the cost of capacity reservations to the resource owners.\n  With this new feature, customers can easily calculate which portion of EC2 instance cost and usage is covered by which capacity reservation, down to hourly resource-level granularity. Customers can also easily calculate the coverage and utilization of each capacity reservation as CUR 2.0 labels capacity reservation-related line items as Reserved, Used, or Unused.\n  This feature is available in all commercial AWS Regions, except the AWS GovCloud (US) Regions and the China Regions.\n  To learn more about this feature, see AWS Data Exports and AWS Billing and Cost Management in the AWS Cost Management User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/ec2-odcr-capacity-blocks-ml-monitoring/",
      "pubDate": "2025-11-12T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "new-feature"
      ]
    },
    {
      "id": "aws-news-457bec95c2b9",
      "title": "Introducing agent-to-agent protocol support in Amazon Bedrock AgentCore Runtime",
      "description": "In this post, we demonstrate how you can use the A2A protocol for AI agents built with different frameworks to collaborate seamlessly. You'll learn how to deploy A2A servers on AgentCore Runtime, configure agent discovery and authentication, and build a real-world multi-agent system for incident response. We'll cover the complete A2A request lifecycle, from agent card discovery to task delegation, showing how standardized protocols eliminate the complexity of multi-agent coordination.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-agent-to-agent-protocol-support-in-amazon-bedrock-agentcore-runtime/",
      "pubDate": "2025-11-11T21:32:31.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-1c72d47df373",
      "title": "AWS Parallel Computing Service (PCS) now supports Slurm CLI Filter plugins",
      "description": "AWS Parallel Computing Service (PCS) now supports Slurm CLI Filter plugins, enabling you to extend and modify how Slurm schedules and processes your high performance computing (HPC) workloads without modifying Slurm directly.\n  Using CLI Filter plugins, you can now define custom policies for job submission to your clusters. For example, you can define policies that verify certain flags or fields of jobs when users submit them, automatically reject jobs submitted without specific attributes, or even modify job parameters.\n  PCS is a managed service that makes it easier for you to run and scale your high performance computing (HPC) workloads and build scientific and engineering models on AWS using Slurm. You can use PCS to build complete environments that integrate compute, storage, networking, and visualization. PCS simplifies cluster operations with managed updates and built-in observability features, helping to remove the burden of maintenance. You can work in a familiar environment, focusing on your research and innovation instead of worrying about infrastructure.\n  This feature is now available in all AWS Regions where PCS is available. To learn more about using Slurm CLI Filter plugins with PCS, see the PCS User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-pcs-slurm-cli-filter-plugins",
      "pubDate": "2025-11-11T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-dfbba5c9b549",
      "title": "Amazon EC2 C8gd, M8gd, and R8gd instances are now available in additional AWS Regions",
      "description": "Amazon Elastic Compute Cloud (Amazon EC2) C8gd instances are now available in Europe (London), and Canada (Central) AWS Regions. Additionally, M8gd instances are available in South America (Sao Paulo) and R8gd instances are available in Europe (London) AWS Region. These instances feature up to 11.4 TB of local NVMe-based SSD block-level storage and are powered by AWS Graviton4 processors, delivering up to 30% better performance over Graviton3-based instances. They have up to 40% higher performance for I/O intensive database workloads, and up to 20% faster query results for I/O intensive real-time data analytics than comparable AWS Graviton3-based instances. These instances are built on the AWS Nitro System and are a great fit for applications that need access to high-speed, low latency local storage.\n  Each instance is available in 12 different sizes. They provide up to 50 Gbps of network bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS). Additionally, customers can now adjust the network and\n Amazon EBS bandwidth on these instances by 25% using EC2 instance bandwidth weighting conﬁguration, providing greater ﬂexibility with the allocation of bandwidth resources to better optimize workloads. These instances offer Elastic Fabric Adapter (EFA) networking on 24xlarge, 48xlarge, metal-24xl, and metal-48xl sizes.\n  To learn more, see Amazon C8gd instances, M8gd instances, R8gd instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-c8gd-m8gd-r8gd-instances-additional-regions",
      "pubDate": "2025-11-11T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-2df18dec7d1e",
      "title": "Amazon EC2 C6id and R6id instances are now available in additional regions",
      "description": "Amazon EC2 C6id instances are available in AWS Region Europe (Milan) and R6id instances are available in AWS Region Africa (Cape Town). These instances are powered by 3rd generation Intel Xeon Scalable Ice Lake processors with an all-core turbo frequency of 3.5 GHz and up to 7.6 TB of local NVMe-based SSD block-level storage. C6id and R6id are built on AWS Nitro System, a combination of dedicated hardware and lightweight hypervisor, which delivers practically all of the compute and memory resources of the host hardware to your instances for better overall performance and security. Customers can take advantage of access to high-speed, low-latency local storage to scale performance of applications such as video encoding, image manipulation, other forms of media processing, data logging, distributed web-scale in-memory caches, in-memory databases, and real-time big data analytics.\n  Customers can purchase the new instances via Savings Plans, Reserved, On-Demand, and Spot instances. To get started, visit AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit our product pages for C6id and R6id.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-c6id-r6id-instances-additional-regions",
      "pubDate": "2025-11-11T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-9fd4889ef01a",
      "title": "Amazon CloudWatch Composite Alarms adds threshold-based alerting",
      "description": "Amazon CloudWatch now enables you to create more flexible alerting policies by triggering notifications when a specific subset of your monitored resources need attention. Using CloudWatch composite alarms, you can create a rule to take action only when a certain combination of alarms is activated. This enhancement lets you choose to receive alerts only when a certain number of resources are impacted, helping you focus on meaningful incidents.\n  The new threshold function in composite alarms allows you to eliminate unnecessary alerts for minor issues while ensuring quick notification of significant problems. IT operations teams can configure alerts to trigger when, for instance, at least two out of four storage volumes are running low on capacity, or when 50% of hosts in a cluster show high CPU utilization. The feature supports both fixed numbers and percentages, making it easy to maintain effective monitoring even as your infrastructure grows or changes.\n  This capability is now available in all commercial AWS regions, the AWS GovCloud (US) Regions, and the China Regions.\n  To create a threshold-based condition in a composite alarm, simply use the AT_LEAST function in the alarm’s condition. Composite alarms’ pricing applies, see CloudWatch pricing for details. To learn more about the threshold function’s parameters, visit the Amazon CloudWatch documentation for composite alarms.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-composite-alarms-threshold-based/",
      "pubDate": "2025-11-11T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "cloudwatch",
        "now-available",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-7a926b079a4b",
      "title": "Amazon U7i instances now available in Europe (Stockholm and Ireland) Regions",
      "description": "Starting today, Amazon EC2 High Memory U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in the Europe (Stockholm and Ireland) region. U7i-6tb instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-u7i-instances-additional-regions",
      "pubDate": "2025-11-11T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-0dd4e97bb594",
      "title": "Amazon Keyspaces (for Apache Cassandra) now supports Logged Batches",
      "description": "Amazon Keyspaces (for Apache Cassandra) now supports Logged Batches, enabling you to perform multiple write operations as a single atomic transaction. With Logged Batches, you can ensure that either all operations (INSERT, UPDATE, DELETE) within a batch succeed or none of them do, maintaining data consistency across multiple rows and tables within a keyspace. This capability is particularly valuable for applications that require strong data consistency, such as financial systems, inventory management, and user profile updates that span multiple data entities.\n  Amazon Keyspaces (for Apache Cassandra) is a scalable, highly available, and managed Apache Cassandra–compatible database service. Amazon Keyspaces is serverless, so you pay for only the resources that you use and you can build applications that serve thousands of requests per second with virtually unlimited throughput and storage.\n  Logged Batches in Amazon Keyspaces provide the same atomicity guarantees as Apache Cassandra while eliminating the operational complexity of managing transaction logs across distributed clusters. It’s designed to scale automatically with your workload and maintain consistent performance regardless of transaction volume. The feature integrates seamlessly with existing Cassandra Query Language (CQL) statements, allowing for adoption in both new and existing applications.\n  Logged Batches are available today in all AWS Commercial and AWS GovCloud (US) Regions where Amazon Keyspaces is available. You pay only for the standard write operations processed within each batch. To learn more about Logged Batches, please visit our blog post or refer to our Amazon Keyspaces documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-keyspaces-apache-cassandra-logged-batches/",
      "pubDate": "2025-11-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-b793a9bb3b0c",
      "title": "Amazon EC2 I7i instances now available in additional AWS regions",
      "description": "Amazon Web Services (AWS) announces the availability of high performance Storage Optimized Amazon EC2 I7i instances in the AWS Asia Pacific (Hyderabad), Canada (Central) regions. Powered by 5th generation Intel Xeon Scalable processors with an all-core turbo frequency 3.2 GHz, these new instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances. Powered by 3rd generation AWS Nitro SSDs, I7i instances offer up to 45TB of NVMe storage with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances.\n  I7i instances offer the best compute and storage performance for x86-based storage optimized instances in Amazon EC2, ideal for I/O intensive and latency-sensitive workloads that demand very high random IOPS performance with real-time latency to access the small to medium size datasets (multi-TBs). Additionally, torn write prevention feature support up to 16KB block sizes, enabling customers to eliminate database performance bottlenecks. I7i instances also support real-time, high-resolution performance statistics for the NVMe instance store volumes attached to them. To learn more, visit the detailed NVMe performance statistics page.\n  I7i instances are available in eleven sizes - nine virtual sizes up to 48xlarge and two bare metal sizes - delivering up to 100Gbps of network bandwidth and 60Gbps of Amazon Elastic Block Store (EBS) bandwidth.\n To learn more, visit the I7i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-i7i-instances-additional-regions/",
      "pubDate": "2025-11-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-946d5548b0c3",
      "title": "How Clario automates clinical research analysis using generative AI on AWS",
      "description": "In this post, we demonstrate how Clario has used Amazon Bedrock and other AWS services to build an AI-powered solution that automates and improves the analysis of COA interviews.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-clario-automates-clinical-research-analysis-using-generative-ai-on-aws/",
      "pubDate": "2025-11-10T18:13:47.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-6edcc5b76925",
      "title": "Amazon EC2 C7i-flex instances are now available in the Middle East (UAE) Region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C7i-flex instances that deliver up to 19% better price performance compared to C6i instances, are available in the Middle East (UAE) Region. C7i-flex instances provide the easiest way for you to get price performance benefits for a majority of compute intensive workloads. The new instances are powered by the 4th generation Intel Xeon Scalable custom processors (Sapphire Rapids) that are available only on AWS, and offer 5% lower prices compared to C7i.\n  C7i-flex instances offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources. With C7i-flex instances, you can seamlessly run web and application servers, databases, caches, Apache Kafka, and Elasticsearch, and more. For compute-intensive workloads that need larger instance sizes (up to 192 vCPUs and 384 GiB memory) or continuous high CPU usage, you can leverage C7i instances.\n  To learn more, visit Amazon EC2 C7i-flex instances. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-c7i-flex-instances-middle-east-uae/",
      "pubDate": "2025-11-10T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "kafka"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "kafka",
        "now-available"
      ]
    },
    {
      "id": "aws-news-1f9cdf6c0037",
      "title": "Amazon EC2 High Memory U7i instances now available in AWS GovCloud (US) Regions",
      "description": "Amazon EC2 High Memory U7i instances with 12TB and 16TB of memory (u7i-12tb.224xlarge and u7in-16tb.224xlarge) are now available in the AWS GovCloud (US-West) region and 24TB of memory (u7in-24tb.224xlarge) are now available in the AWS GovCloud (US-East) region. U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-12tb instances offer 12TiB of DDR5 memory, U7in-16tb instances offer 16TiB of DDR5 memory, and U7in-24tb instances offer 24TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-12tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7in-16tb and U7in-24tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 200Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-high-memory-u7i-instances-govcloud/",
      "pubDate": "2025-11-10T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-ee9cf44040dd",
      "title": "Democratizing AI: How Thomson Reuters Open Arena supports no-code AI for every professional with Amazon Bedrock",
      "description": "In this blog post, we explore how TR addressed key business use cases with Open Arena, a highly scalable and flexible no-code AI solution powered by Amazon Bedrock and other AWS services such as Amazon OpenSearch Service, Amazon Simple Storage Service (Amazon S3), Amazon DynamoDB, and AWS Lambda. We'll explain how TR used AWS services to build this solution, including how the architecture was designed, the use cases it solves, and the business profiles that use it.",
      "link": "https://aws.amazon.com/blogs/machine-learning/democratizing-ai-how-thomson-reuters-open-arena-supports-no-code-ai-for-every-professional-with-amazon-bedrock/",
      "pubDate": "2025-11-07T21:51:22.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "lex",
        "lambda",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex",
        "lambda",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "support"
      ]
    },
    {
      "id": "aws-news-0e92324b3b39",
      "title": "Introducing structured output for Custom Model Import in Amazon Bedrock",
      "description": "Today, we are excited to announce the addition of structured output to Custom Model Import. Structured output constrains a model's generation process in real time so that every token it produces conforms to a schema you define. Rather than relying on prompt-engineering tricks or brittle post-processing scripts, you can now generate structured outputs directly at inference time.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-structured-output-for-custom-model-import-in-amazon-bedrock/",
      "pubDate": "2025-11-07T18:53:55.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-bde0cc69d3f1",
      "title": "Transform your MCP architecture: Unite MCP servers through AgentCore Gateway",
      "description": "Earlier this year, we introduced Amazon Bedrock AgentCore Gateway, a fully managed service that serves as a centralized MCP tool server, providing a unified interface where agents can discover, access, and invoke tools. Today, we're extending support for existing MCP servers as a new target type in AgentCore Gateway. With this capability, you can group multiple task-specific MCP servers aligned to agent goals behind a single, manageable MCP gateway interface. This reduces the operational complexity of maintaining separate gateways, while providing the same centralized tool and authentication management that existed for REST APIs and AWS Lambda functions.",
      "link": "https://aws.amazon.com/blogs/machine-learning/transform-your-mcp-architecture-unite-mcp-servers-through-agentcore-gateway/",
      "pubDate": "2025-11-06T17:43:23.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "lambda",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f2e6a41b8c65",
      "title": "AWS B2B Data Interchange is now available in AWS Europe (Ireland) Region",
      "description": "Customers in AWS Europe (Ireland) Region can now use AWS B2B Data Interchange to build highly customizable, scalable and cost-efficient EDI workloads.\n  AWS B2B Data Interchange automates validation, transformation, and generation of EDI files such as ANSI X12 documents to and from JSON and XML data formats. With this launch, you can use AWS B2B Data Interchange to process your EDI documents in AWS Europe (Ireland) Region, which enables you to meet your compliance and data sovereignty obligations while modernizing your B2B integration workloads. As part of this launch, the AWS B2B Data Interchange generative AI mapping capability will also become available in AWS Europe (Ireland) Region, simplifying mapping code development and ultimately expediting trading partners onboarding.\n  To learn more about AWS B2B Data Interchange visit our product page, user-guide or take our self-paced workshop. See the AWS Region Table for complete regional availability.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-b2b-data-interchange-europe-ireland-region",
      "pubDate": "2025-11-06T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "ga",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-4cdb33674ab0",
      "title": "Amazon Elastic VMware Service (Amazon EVS) is now available in additional Regions",
      "description": "Today, we're announcing that Amazon Elastic VMware Service (Amazon EVS) is now available in all availability zones in the Asia Pacific (Mumbai), Asia Pacific (Sydney), Canada (Central) and Europe (Paris) Regions. This expansion provides more options to leverage the scale and flexibility of AWS for running your VMware workloads in the cloud.\n  Amazon EVS lets you run VMware Cloud Foundation (VCF) directly within your Amazon Virtual Private Cloud (VPC) on EC2 bare-metal instances, powered by AWS Nitro. Using either our step-by-step configuration workflow or the AWS Command Line Interface (CLI) with automated deployment capabilities, you can set up a complete VCF environment in just a few hours. This rapid deployment enables faster workload migration to AWS, helping you eliminate aging infrastructure, reduce operational risks, and meet critical timelines for exiting your data center.\n  The added availability in the Asia Pacific (Mumbai), Asia Pacific (Sydney), Canada (Central) and Europe (Paris) Regions gives your VMware workloads lower latency through closer proximity to your end users, compliance with data residency or sovereignty requirements, and additional high availability and resiliency options for your enhanced redundancy strategy.\n  To get started, visit the Amazon EVS product detail page and user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-evs-additional-regions",
      "pubDate": "2025-11-06T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "now-available",
        "expansion"
      ]
    },
    {
      "id": "aws-news-c2cb92ded76a",
      "title": "AWS IoT Greengrass v2.16 introduces system log forwarder and TPM2.0 capabilities",
      "description": "AWS announces the release of AWS IoT Greengrass v2.16, introducing new core components for nucleus and nucleus lite. AWS IoT Greengrass is an Internet of Things (IoT) edge runtime and cloud service that helps customers build, deploy, and manage device software at the edge. The latest version 2.16 release includes enhanced debugging capabilities through the system log forwarder component. This component uploads system log files to AWS Cloud Watch, making it easier for developers to troubleshoot IoT edge applications.\n  The AWS IoT Greengrass v2.16 release also features a new nucleus lite version (v2.3) with TPM2.0 specification support, enabling developers to manage edge device security for their resource constrained devices using hardware-based root of trust modules. The implementation helps developers to scale their IoT deployments with confidence while providing secure storage for secrets and streamlined device authentication.\n  AWS IoT Greengrass v2.16 is available in all AWS Regions where AWS IoT Greengrass is offered. To learn more about AWS IoT Greengrass v2.16 and its new features, visit the AWS IoT Greengrass documentation. Follow the Getting Started guide for a quick introduction to AWS IoT Greengrass.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-greengrass-v2-16-system-log-forwarder-tpm-2-0-capabilities",
      "pubDate": "2025-11-06T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-e85ab9e07aac",
      "title": "How Amazon Search increased ML training twofold using AWS Batch for Amazon SageMaker Training jobs",
      "description": "In this post, we show you how Amazon Search optimized GPU instance utilization by leveraging AWS Batch for SageMaker Training jobs. This managed solution enabled us to orchestrate machine learning (ML) training workloads on GPU-accelerated instance families like P5, P4, and others. We will also provide a step-by-step walkthrough of the use case implementation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-search-increased-ml-training-twofold-using-aws-batch-for-amazon-sagemaker-training-jobs/",
      "pubDate": "2025-11-05T17:15:35.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-610aae9a57eb",
      "title": "Amazon CloudWatch Application Signals adds AI-powered Synthetics debugging",
      "description": "Amazon CloudWatch Application Signals Model Context Protocol or MCP Server for Application Performance Monitoring (APM) now integrates CloudWatch Synthetics canary monitoring directly into its audit framework, enabling automated, AI-powered debugging of synthetic monitoring failures. DevOps teams and developers can now use natural language questions like 'Why is my checkout canary failing?' in compatible AI assistants such as Amazon Q, Claude, or other supported assistants to utilize the new AI-powered debugged capabilities and quickly distinguish between canary infrastructure issues and actual service problems, addressing the significant challenge of extensive manual analysis in maintaining reliable synthetic monitoring.\n  The integration extends Application Signals' existing multi-signal (services, operations, SLOs, golden signals) analysis capabilities to include comprehensive canary diagnostics. The new feature automatically correlates canary failures with service health metrics, traces, and dependencies through an intelligent audit pipeline. Starting from natural language prompts from users, the system performs multi-layered diagnostic analysis across six major areas: Network Issues, Authentication Failures, Performance Problems, Script Errors, Infrastructure Issues, and Service Dependencies. This analysis includes automated comparison of HTTP Archive or HAR files, CloudWatch logs analysis, S3 artifact examination, and configuration validation, significantly reducing the time needed to identify and resolve synthetic monitoring issues.\n Customers can then access these insights through natural language interactions with supported AI assistants.\n  This feature is available in all commercial AWS regions where Amazon CloudWatch Synthetics is offered. Customers will need access to a compatible AI agent such as Amazon Q, Claude, or other supported AI assistants to utilize the AI-powered debugging capabilities.\n  To learn more about implementing AI-based debugging for your synthetic monitoring, visit the CloudWatch Application Signals MCP Server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/application-signals-ai-powered-synthetics/",
      "pubDate": "2025-11-05T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "s3",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "s3",
        "cloudwatch",
        "new-feature",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-4c55d57ac45a",
      "title": "Iterate faster with Amazon Bedrock AgentCore Runtime direct code deployment",
      "description": "Amazon Bedrock AgentCore is an agentic platform for building, deploying, and operating effective agents securely at scale. Amazon Bedrock AgentCore Runtime is a fully managed service of Bedrock AgentCore, which provides low latency serverless environments to deploy agents and tools. It provides session isolation, supports multiple agent frameworks including popular open-source frameworks, and handles multimodal […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/iterate-faster-with-amazon-bedrock-agentcore-runtime-direct-code-deployment/",
      "pubDate": "2025-11-04T18:30:44.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "support"
      ]
    },
    {
      "id": "aws-news-dd03fcd2c480",
      "title": "AWS Config launches 42 new managed rules",
      "description": "AWS Config announces launch of an additional 42 managed Config rules for various use cases such as security, cost, durability, and operations. You can now search, discover, enable and manage these additional rules directly from AWS Config and govern more use cases for your AWS environment.\n \nWith this launch, you can now enable these controls across your account or across your organization. For example, you can evaluate your tagging strategies across Amazon EKS Fargate profiles, Amazon EC2 Network Insight Analyses, AWS Glue Machine learning transforms. Or you can assess your security posture across Amazon Cognito Identity pools, Amazon Lightsail buckets, AWS Amplify apps and more. Additionally, you can leverage Conformance Packs to group these new controls and deploy across an account or across organization, streamlining your multi-account governance.\n \nFor the full list of recently released rules, visit the AWS Config developer guide. For description of each rule and the AWS Regions in which it is available, please refer our Config managed rules documentation. To start using Config rules, please refer our documentation.\n  New Rules Launched:\n  \n \n \nAMPLIFY_APP_NO_ENVIRONMENT_VARIABLES\n \n \nAMPLIFY_BRANCH_DESCRIPTION\n \n \nAPIGATEWAY_STAGE_DESCRIPTION\n \n \nAPIGATEWAYV2_STAGE_DESCRIPTION\n \n \nAPI_GWV2_STAGE_DEFAULT_ROUTE_DETAILED_METRICS_ENABLED\n \n \nAPIGATEWAY_STAGE_ACCESS_LOGS_ENABLED\n \n \nAPPCONFIG_DEPLOYMENT_STRATEGY_MINIMUM_FINAL_BAKE_TIME\n \n \nAPPCONFIG_DEPLOYMENT_STRATEGY_TAGGED\n \n \nAPPFLOW_FLOW_TRIGGER_TYPE_CHECK\n \n \nAPPMESH_VIRTUAL_NODE_CLOUD_MAP_IP_PREF_CHECK\n \n \nAPPMESH_VIRTUAL_NODE_DNS_IP_PREF_CHECK\n \n \nAPPRUNNER_SERVICE_IP_ADDRESS_TYPE_CHECK\n \n \nAPPRUNNER_SERVICE_MAX_UNHEALTHY_THRESHOLD\n \n \nAPS_RULE_GROUPS_NAMESPACE_TAGGED\n \n \nAUDITMANAGER_ASSESSMENT_TAGGED\n \n \nBATCH_MANAGED_COMPUTE_ENV_ALLOCATION_STRATEGY_CHECK\n \n \nBATCH_MANAGED_SPOT_COMPUTE_ENVIRONMENT_MAX_BID\n \n \nCOGNITO_IDENTITY_POOL_UNAUTHENTICATED_LOGINS\n \n \nCOGNITO_USER_POOL_PASSWORD_POLICY_CHECK\n \n \nCUSTOMERPROFILES_DOMAIN_TAGGED\n \n \nDEVICEFARM_PROJECT_TAGGED\n \n \nDEVICEFARM_TEST_GRID_PROJECT_TAGGED\n \n \nDMS_REPLICATION_INSTANCE_MULTI_AZ_ENABLED\n \n \nEC2_LAUNCH_TEMPLATES_EBS_VOLUME_ENCRYPTED\n \n \nEC2_NETWORK_INSIGHTS_ANALYSIS_TAGGED\n \n \nEKS_FARGATE_PROFILE_TAGGED\n \n \nGLUE_ML_TRANSFORM_TAGGED\n \n \nIOT_SCHEDULED_AUDIT_TAGGED\n \n \nIOT_PROVISIONING_TEMPLATE_DESCRIPTION\n \n \nIOT_PROVISIONING_TEMPLATE_JITP\n \n \nIOT_PROVISIONING_TEMPLATE_TAGGED\n \n \nKINESIS_VIDEO_STREAM_MINIMUM_DATA_RETENTION\n \n \nLAMBDA_FUNCTION_DESCRIPTION\n \n \nLIGHTSAIL_BUCKET_ALLOW_PUBLIC_OVERRIDES_DISABLED\n \n \nRDS_MYSQL_CLUSTER_COPY_TAGS_TO_SNAPSHOT_CHECK\n \n \nRDS_PGSQL_CLUSTER_COPY_TAGS_TO_SNAPSHOT_CHECK\n \n \nROUTE53_RESOLVER_FIREWALL_DOMAIN_LIST_TAGGED\n \n \nROUTE53_RESOLVER_FIREWALL_RULE_GROUP_ASSOCIATION_TAGGED\n \n \nROUTE53_RESOLVER_FIREWALL_RULE_GROUP_TAGGED\n \n \nROUTE53_RESOLVER_RESOLVER_RULE_TAGGED\n \n \nRUM_APP_MONITOR_TAGGED\n \n \nRUM_APP_MONITOR_CLOUDWATCH_LOGS_ENABLED",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-config-launches-42-new-managed-rules/",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "ec2",
        "rds",
        "eks",
        "fargate",
        "kinesis",
        "glue",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "ec2",
        "rds",
        "eks",
        "fargate",
        "kinesis",
        "glue",
        "cloudwatch",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-bcdec442f542",
      "title": "Amazon Bedrock AgentCore Runtime now supports direct code deployment",
      "description": "Amazon Bedrock AgentCore Runtime now supports two deployment methods for AI agents: container-based deployment and direct code upload. Developers can now choose between direct code-zip file upload for rapid prototyping and iteration, or leverage advanced container-based options for complex use cases requiring custom configurations.\n  AgentCore Runtime provides a serverless, framework and model agnostic runtime for running agents and tools at scale. This deployment option streamlines the prototyping workflow while maintaining enterprise security and scaling capabilities for production deployments. Developers can now deploy agents using direct code-zip upload with easy drag-and-drop functionality. This enables faster iteration cycles, empowering developers to prototype quickly and focus on building innovative agent capabilities.\n  This feature is available in all nine AWS Regions where Amazon Bedrock AgentCore Runtime is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), and Europe (Ireland).\n  To learn more about AgentCore Runtime deployment options, see the AgentCore documentation and get started with the AgentCore Starter Toolkit. AgentCore offers consumption-based pricing with no upfront costs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-bedrock-agentcore-runtime-code-deployment/",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "nova",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-31cd99dbf479",
      "title": "Amazon RDS for Oracle is now available with R7i memory-optimized instances offering up to 64:1 memory-to-vCPU ratio",
      "description": "Amazon Relational Database Service (RDS) for Oracle is now available with R7i memory-optimized preconfigured instances that offer additional memory and storage I/O per vCPU. Powered by custom 4th Gen Intel Xeon Scalable processors with AWS Nitro System and DDR5 memory for high performance, these instances provide up to 64:1 memory-to-vCPU ratio. Many Oracle database workloads require high memory, but can safely reduce the number of vCPUs without impacting application performance. By running such Oracle database workloads on R7i pre-configured instances, customers can lower their Oracle database licensing and support costs while meeting high performance application requirements.\n  Memory optimized R7i pre-configured instances are available for Amazon RDS for Oracle with Bring Your Own License (BYOL) license model supporting both Oracle Database Enterprise Edition and Oracle Database Standard Edition 2. To learn more about Amazon RDS for Oracle R7i memory-optimized preconfigured instances, read RDS for Oracle User Guide and visit Amazon RDS for Oracle Pricing for available instance configurations, pricing details, and region availability.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-rds-oracle-r7i-memory-optimized-instances/",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-2537f16f1b31",
      "title": "Clario streamlines clinical trial software configurations using Amazon Bedrock",
      "description": "This post builds upon our previous post discussing how Clario developed an AI solution powered by Amazon Bedrock to accelerate clinical trials. Since then, Clario has further enhanced their AI capabilities, focusing on innovative solutions that streamline the generation of software configurations and artifacts for clinical trials while delivering high-quality clinical evidence.",
      "link": "https://aws.amazon.com/blogs/machine-learning/clario-streamlines-clinical-trial-software-configurations-using-amazon-bedrock/",
      "pubDate": "2025-10-31T15:49:09.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-164c0c0d28a9",
      "title": "Reduce CAPTCHAs for AI agents browsing the web with Web Bot Auth (Preview) in Amazon Bedrock AgentCore Browser",
      "description": "AI agents need to browse the web on your behalf. When your agent visits a website to gather information, complete a form, or verify data, it encounters the same defenses designed to stop unwanted bots: CAPTCHAs, rate limits, and outright blocks. Today, we are excited to share that AWS has a solution. Amazon Bedrock AgentCore […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/reduce-captchas-for-ai-agents-browsing-the-web-with-web-bot-auth-preview-in-amazon-bedrock-agentcore-browser/",
      "pubDate": "2025-10-30T21:55:03.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-4ff92cfccd7d",
      "title": "How Twilio built a multi-engine query platform using Amazon Athena and open-source Presto",
      "description": "At Twilio, we manage a 20 petabyte-scale Amazon S3 data lake that serves the analytics needs of over 1,500 users, processing 2.5 million queries monthly and scanning an average of 85 PB of data. To meet our growing demands for scalability, emerging technology support, and data mesh architecture adoption, we built Odin, a multi-engine query platform that provides an abstraction layer built on top of Presto Gateway. In this post, we discuss how we designed and built Odin, combining Amazon Athena with open-source Presto to create a flexible, scalable data querying solution.",
      "link": "https://aws.amazon.com/blogs/big-data/how-twilio-built-a-multi-engine-query-platform-using-amazon-athena-and-open-source-presto/",
      "pubDate": "2025-10-21T20:57:32.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex",
        "s3",
        "athena"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "athena",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-7a855eaafa04",
      "title": "Simplifying sustainability reporting using AWS and generative AI in banking",
      "description": "In this post, you learn how you can use generative AI services on Amazon Web Services (AWS) to automate your sustainability reporting requirements, reduce manual effort, and improve accuracy. You do this by implementing an automated solution for extracting, processing, and validating data from corporate reports.",
      "link": "https://aws.amazon.com/blogs/architecture/simplifying-sustainability-reporting-using-aws-and-generative-ai-in-banking/",
      "pubDate": "2025-06-26T17:54:46.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-2355834bf9d4",
      "title": "Amazon Bedrock baseline architecture in an AWS landing zone",
      "description": "In this post, we explore the Amazon Bedrock baseline architecture and how you can secure and control network access to your various Amazon Bedrock capabilities within AWS network services and tools. We discuss key design considerations, such as using Amazon VPC Lattice auth policies, Amazon Virtual Private Cloud (Amazon VPC) endpoints, and AWS Identity and Access Management (IAM) to restrict and monitor access to your Amazon Bedrock capabilities.",
      "link": "https://aws.amazon.com/blogs/architecture/amazon-bedrock-baseline-architecture-in-an-aws-landing-zone/",
      "pubDate": "2025-06-23T18:36:51.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "iam"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}