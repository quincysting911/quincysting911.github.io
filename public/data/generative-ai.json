{
  "lastUpdated": "2026-01-26T06:21:52.640Z",
  "category": "generative-ai",
  "totalItems": 55,
  "items": [
    {
      "id": "aws-news-424a910d5c85",
      "title": "Amazon Route 53 Domains adds support for .ai, and other top-level domains",
      "description": "Amazon Route 53 Domains now supports registration and management of ten new top-level domains (TLDs): .ai, .nz, .shop, .bot, .moi, .spot, .free, .deal, .now, and .hot. This expansion enhances Route 53's capabilities as a domain registration and DNS management service, offering customers more options to establish their online presence. With these additions, businesses and individuals can now leverage domain names tailored to specific industries, regions, or purposes directly through Amazon Web Services (AWS).\n  The new TLDs cater to various use cases. To name a few, the .ai domain, originally for Anguilla, has become popular among artificial intelligence companies. E-commerce sites can utilize .shop for their online storefronts. The .bot domain suits chatbot and AI-related services. The .now domain works well for time-sensitive services and instant delivery platforms. Users can register these domains through the Route 53 console, AWS CLI, or SDKs, enjoying integrated DNS management and automatic renewal features. This seamless integration allows for efficient domain administration alongside existing Route 53 hosted zones and DNS records.\n  To learn more about Amazon Route 53 Domains and start registering new domains, visit the Amazon Route 53 page. Domain registration pricing varies by TLD. Visit the pricing page for detailed pricing information.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/1/amazon-route-53-domains-adds-support-for-.ai-and-other-top-level-domains/",
      "pubDate": "2026-01-23T20:07:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-05211307b5cd",
      "title": "Build AI agents with Amazon Bedrock AgentCore using AWS CloudFormation",
      "description": "Amazon Bedrock AgentCore services are now being supported by various IaC frameworks such as AWS Cloud Development Kit (AWS CDK), Terraform and AWS CloudFormation Templates. This integration brings the power of IaC directly to AgentCore so developers can provision, configure, and manage their AI agent infrastructure. In this post, we use CloudFormation templates to build an end-to-end application for a weather activity planner.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-ai-agents-with-amazon-bedrock-agentcore-using-aws-cloudformation/",
      "pubDate": "2026-01-23T17:54:02.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "cloudformation",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-e69962dfe582",
      "title": "How the Amazon.com Catalog Team built self-learning generative AI at scale with Amazon Bedrock",
      "description": "In this post, we demonstrate how the Amazon Catalog Team built a self-learning system that continuously improves accuracy while reducing costs at scale using Amazon Bedrock.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-the-amazon-com-catalog-team-built-self-learning-generative-ai-at-scale-with-amazon-bedrock/",
      "pubDate": "2026-01-23T17:49:37.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-734b7da2685c",
      "title": "Announcing general availability of Amazon EC2 M4 Max Mac instances",
      "description": "Amazon Web Services announces general availability of Amazon EC2 M4 Max Mac instances, powered by the latest Mac Studio hardware. Amazon EC2 M4 Max Mac instances are the next-generation EC2 Mac instances, that enable Apple developers to migrate their most demanding build and test workloads onto AWS. These instances are ideal for building and testing applications for Apple platforms such as iOS, macOS, iPadOS, tvOS, watchOS, visionOS, and Safari.\n  Amazon EC2 M4 Max Mac instances offer up to 25% better application build performance compared to Amazon EC2 M1 Ultra Mac instances. M4 Max Mac instances are powered by the AWS Nitro System, providing up to 10 Gbps network bandwidth and 8 Gbps of Amazon Elastic Block Store (Amazon EBS) storage bandwidth. These instances are built on Apple M4 Max Mac Studio computers featuring a 16-core CPU, 40-core GPU, 16-core Neural Engine, and 128GB of unified memory. \n \nAmazon EC2 M4 Max Mac instances are available in US East (N. Virginia) and US West (Oregon).  To learn more about Amazon EC2 M4 Max Mac instances, visit the Amazon EC2 Mac page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ec2-m4-max-mac-instances-ga",
      "pubDate": "2026-01-23T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-2e90c0da2729",
      "title": "AWS Config launches 13 new managed rules",
      "description": "AWS Config announces launch of an additional 13 managed Config rules for various use cases such as security, durability, and operations. You can now search, discover, enable and manage these additional rules directly from AWS Config and govern more use cases for your AWS environment.\n  With this launch, you can now enable these controls across your account or across your organization. For example, you can assess your security posture across Amazon Cognito User pools, Amazon EBS Snapshots, AWS Cloudformation Stacks and more. Additionally, you can leverage Conformance Packs to group these new controls and deploy across an account or across organization, streamlining your multi-account governance.\n  For the full list of recently released rules, visit the AWS Config developer guide. For description of each rule and the AWS Regions in which it is available, please refer our Config managed rules documentation. To start using Config rules, please refer our documentation.\n  New Rules Launched:\n  \n \n \nAURORA_GLOBAL_DATABASE_ENCRYPTION_AT_REST\n \n \nCLOUDFORMATION_STACK_SERVICE_ROLE_CHECK\n \n \nCLOUDFORMATION_TERMINATION_PROTECTION_CHECK\n \n \nCLOUDFRONT_DISTRIBUTION_KEY_GROUP_ENABLED\n \n \nCOGNITO_USER_POOL_DELETE_PROTECTION_ENABLED\n \n \nCOGNITO_USER_POOL_MFA_ENABLED\n \n \nCOGNITO_USERPOOL_CUST_AUTH_THREAT_FULL_CHECK\n \n \nEBS_SNAPSHOT_BLOCK_PUBLIC_ACCESS\n \n \nECS_CAPACITY_PROVIDER_TERMINATION_CHECK\n \n \nECS_TASK_DEFINITION_EFS_ENCRYPTION_ENABLED\n \n \nECS_TASK_DEFINITION_LINUX_USER_NON_ROOT\n \n \nECS_TASK_DEFINITION_WINDOWS_USER_NON_ADMIN\n \n \nSES_SENDING_TLS_REQUIRED",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-config-launches-new-rules/",
      "pubDate": "2026-01-22T18:06:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "cloudformation",
        "cloudfront"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ecs",
        "cloudformation",
        "cloudfront",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-dc8581a23cb5",
      "title": "How PDI built an enterprise-grade RAG system for AI applications with AWS",
      "description": "PDI Technologies is a global leader in the convenience retail and petroleum wholesale industries. In this post, we walk through the PDI Intelligence Query (PDIQ) process flow and architecture, focusing on the implementation details and the business outcomes it has helped PDI achieve.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-pdi-built-an-enterprise-grade-rag-system-for-ai-applications-with-aws/",
      "pubDate": "2026-01-22T17:11:47.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-aec69f206941",
      "title": "How CLICKFORCE accelerates data-driven advertising with Amazon Bedrock Agents",
      "description": "In this post, we demonstrate how CLICKFORCE used AWS services to build Lumos and transform advertising industry analysis from weeks-long manual work into an automated, one-hour process.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-clickforce-accelerates-data-driven-advertising-with-amazon-bedrock-agents/",
      "pubDate": "2026-01-22T17:04:04.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "eks"
      ]
    },
    {
      "id": "aws-news-f4d657f0df55",
      "title": "Now available: 48xlarge and metal-48xl sizes for EBS optimized Amazon EC2 instances",
      "description": "Today, AWS announces the general availability of the Amazon Elastic Block Storage (Amazon EBS) optimized Amazon Elastic Compute Cloud (Amazon EC2) C8gb, M8gb, and R8gb instances in 48xlarge sizes. We are also offering C8gb and R8gb in metal-48xl sizes. These instances are powered by AWS Graviton4 processors to deliver up to 30% better compute performance than AWS Graviton3 processors. At up to 300 Gbps of EBS bandwidth, these instances offer the highest EBS performance among non-accelerated compute EC2 instances. Take advantage of the higher block storage performance offered by these new EBS optimized EC2 instances to scale the performance and throughput of a wide variety of workloads.\n \nFor increased scalability, these instances offer sizes up to 48xlarge, including two metal sizes (C8gb and R8gb only), 3 varieties of memory to vCPUs ratios, up to 300 Gbps of EBS bandwidth, up to 400 Gbps of networking bandwidth. Offering up to 1440K IOPS, these instances have the highest Amazon EBS IOPS performance in Amazon EC2. These new instances support Elastic Fabric Adapter (EFA) networking, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n \nThe new instance sizes are available in US East (N. Virginia) and US West (Oregon) regions. Metal sizes are only available in US East (N. Virginia) region.\n \nTo learn more, see Amazon C8gb, M8gb, and R8gb Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/graviton4-ebs-optimized-larger-sizes",
      "pubDate": "2026-01-22T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-fe519ae0618f",
      "title": "Amazon MQ now supports Java Messaging Service (JMS) specification for RabbitMQ brokers",
      "description": "Amazon MQ now supports the ability for RabbitMQ 4 brokers to connect to JMS applications through the RabbitMQ JMS Topic Exchange plugin and JMS client. The JMS topic exchange plugin is enabled by default on all RabbitMQ 4 brokers, allowing you to use the JMS client to run your JMS 1.1, JMS 2.0, and JMS 3.1 applications on RabbitMQ. You can also use the RabbitMQ JMS client to send JMS messages to an AMQP exchange and consume messages from an AMQP queue to interoperate or migrate JMS workloads to AMQP workloads.\n  To start using your JMS applications on RabbitMQ, simply select RabbitMQ 4.2 when creating a new broker using the M7g instance type through the AWS Management console, AWS CLI, or AWS SDKs, and then use the RabbitMQ JMS client to connect your applications. To learn more about the plugin, see the Amazon MQ release notes and the Amazon MQ developer guide. This plugin is available in all regions where Amazon MQ RabbitMQ 4 instances are available today.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-mq-jms-spec-rabbitmq/",
      "pubDate": "2026-01-22T13:40:00.000Z",
      "source": "whatsNew",
      "services": [
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "q developer",
        "support"
      ]
    },
    {
      "id": "aws-news-d31c7e5cb27f",
      "title": "AWS Security Agent now supports GitHub Enterprise Cloud",
      "description": "AWS Security Agent now supports GitHub Enterprise Cloud, enabling customers to connect their GitHub Enterprise Organization and leverage AI-powered security capabilities across their private repositories. With this expansion, development teams can integrate security analysis directly into their GitHub workflows.\n  Customers can now connect their GitHub Enterprise Organization to AWS Security Agent by installing the AWS Security Agent GitHub app with the required permissions. Once connected, the agent provides three key capabilities for private repositories:\n \nAutomated Code Reviews: AWS Security Agent performs comprehensive security reviews on new pull requests, identifying vulnerabilities and compliance with internal security requirements before code is merged.\n \nPenetration Testing Integration: Leverage your GitHub Enterprise code repositories during penetration testing activities, allowing the agent to analyze your codebase for potential security weaknesses and attack vectors.\n \nAutomated Code Remediation: When security issues are identified during penetration testing, customers can choose to have AWS Security Agent automatically submit pull requests with recommended fixes, accelerating remediation workflows.\n \nThis capability is available in the US East (N. Virginia) region where AWS Security Agent operates. To get started, connect your GitHub Enterprise Organization to AWS Security Agent through the AWS Security Agent console. To learn more about AWS Security Agent, visit the product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-security-agent-ghe-support",
      "pubDate": "2026-01-22T09:01:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-7b4681d12507",
      "title": "How Thomson Reuters built an Agentic Platform Engineering Hub with Amazon Bedrock AgentCore",
      "description": "This blog post explains how TR's Platform Engineering team, a geographically distributed unit overseeing TR's service availability, boosted its operational productivity by transitioning from manual to an automated agentic system using Amazon Bedrock AgentCore.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-thomson-reuters-built-an-agentic-platform-engineering-hub-with-amazon-bedrock-agentcore/",
      "pubDate": "2026-01-21T21:39:42.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-e8a9b1280273",
      "title": "Build agents to learn from experiences using Amazon Bedrock AgentCore episodic memory",
      "description": "In this post, we walk you through the complete architecture to structure and store episodes, discuss the reflection module, and share compelling benchmarks that demonstrate significant improvements in agent task success rates.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-agents-to-learn-from-experiences-using-amazon-bedrock-agentcore-episodic-memory/",
      "pubDate": "2026-01-21T19:45:04.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "improvement"
      ]
    },
    {
      "id": "aws-news-327b561d384e",
      "title": "How bunq handles 97% of support with Amazon Bedrock",
      "description": "In this post, we show how bunq upgraded Finn, its in-house generative AI assistant, using Amazon Bedrock to transform user support and banking operations to be seamless, in multiple languages and time zones.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-bunq-handles-97-of-support-with-amazon-bedrock/",
      "pubDate": "2026-01-21T17:50:35.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "support"
      ]
    },
    {
      "id": "aws-news-1ace3e7d06ed",
      "title": "Using Strands Agents to create a multi-agent solution with Meta’s Llama 4 and Amazon Bedrock",
      "description": "In this post, we explore how to build a multi-agent video processing workflow using Strands Agents, Meta's Llama 4 models, and Amazon Bedrock to automatically analyze and understand video content through specialized AI agents working in coordination. To showcase the solution, we will use Amazon SageMaker AI to walk you through the code.",
      "link": "https://aws.amazon.com/blogs/machine-learning/using-strands-agents-to-create-a-multi-agent-solution-with-metas-llama-4-and-amazon-bedrock/",
      "pubDate": "2026-01-21T17:47:44.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-bb8eab4eebea",
      "title": "Streamline large binary object migrations: A Kafka-based solution for Oracle to Amazon Aurora PostgreSQL and Amazon S3",
      "description": "In this post, we present a scalable solution that addresses the challenge of migrating your large binary objects (LOBs) from Oracle to AWS by using a streaming architecture that separates LOB storage from structured data. This approach avoids size constraints, reduces Oracle licensing costs, and preserves data integrity throughout extended migration periods.",
      "link": "https://aws.amazon.com/blogs/big-data/streamline-large-binary-object-migrations-a-kafka-based-solution-for-oracle-to-amazon-aurora-postgresql-and-amazon-s3/",
      "pubDate": "2026-01-21T17:44:58.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "kafka"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "kafka"
      ]
    },
    {
      "id": "aws-news-c7fceed93fd6",
      "title": "Amazon ECR now supports cross-repository layer sharing to optimize storage and improve push performance",
      "description": "Amazon Elastic Container Registry (ECR) now enables you to share common image layers across repositories within a registry through a capability called blob mounting. This feature is especially valuable if you manage multiple microservices or applications built from common base images. With blob mounting, you can achieve faster image pushes by reusing existing layers instead of re-uploading identical content, and reduce storage costs by storing common layers once and referencing them across repositories.\n  Getting started is simple, enable the registry-level setting through the ECR console or AWS CLI. Once enabled, ECR automatically handles layer sharing when you push images.\n  Blob mounting is available in all AWS commercial and AWS GovCloud (US) Regions. To learn more about blob mounting, please visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ecr-cross-repository-layer-sharing/",
      "pubDate": "2026-01-20T21:31:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-c5eef2fe079f",
      "title": "Introducing multimodal retrieval for Amazon Bedrock Knowledge Bases",
      "description": "In this post, we'll guide you through building multimodal RAG applications. You'll learn how multimodal knowledge bases work, how to choose the right processing strategy based on your content type, and how to configure and implement multimodal retrieval using both the console and code examples.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-multimodal-retrieval-for-amazon-bedrock-knowledge-bases/",
      "pubDate": "2026-01-20T18:22:25.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-7fccf96cddb3",
      "title": "Amazon Quick Suite launches expanded size, faster ingestion, and richer data type support for SPICE datasets",
      "description": "Amazon Quick Suite SPICE engine is now supporting higher scale, faster ingestion, and broader data types to power advanced analytics and AI-driven workloads. With this launch, customers can load up to 2TB of data per dataset, doubling the previous 1TB limit, when using the new data preparation experience. Despite the increased dataset size, SPICE continues to deliver strong performance, with ingestion further optimized to enable even faster data loading and refresh to reduce time to insight. We’ve also expanded SPICE’s data type support by increasing string length limits from 2K to 64K Unicode characters and extending the supported timestamp range from year 1400 back to year 0001. As Quick Suite customers bring richer, more complex, and increasingly AI-driven workloads into SPICE, these enhancements enable broader data coverage, faster data onboarding, and more powerful analytics, without compromising performance. To learn more, visit our documentation.\n  The new SPICE dataset size limitation is now available in Amazon Quick Sight Enterprise Editions across all supported Amazon Quick Sight regions.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-quick-suite-launches-expanded-spice",
      "pubDate": "2026-01-20T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "lex",
        "launch",
        "now-available",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-793bfb71f7e4",
      "title": "Amazon EC2 G7e instances are now generally available",
      "description": "Today, Amazon announces the general availability of Amazon Elastic Compute Cloud (Amazon EC2) G7e instances, accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs. G7e instances offer up to 2.3x inference performance compared to G6e.\n \nCustomers can use G7e instances to deploy large language models (LLMs), agentic AI models, multimodal generative AI models, and physical AI models. G7e instances offer the highest performance for spatial computing workloads as well as workloads that require both graphics and AI processing capabilities. G7e instances feature up to 8 NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, with 96 GB of memory per GPU, and 5th Generation Intel Xeon processors. They support up to 192 virtual CPUs (vCPUs) and up to 1600 Gbps of Elastic Fabric Adapter networking bandwidth. G7e instances support NVIDIA GPUDirect Peer to Peer (P2P) that boosts performance for multi-GPU workloads. Multi-GPU G7e instances also support NVIDIA GPUDirect Remote Direct Memory Access (RDMA) with EFAv4 in EC2 UltraClusters, reducing latency for small-scale multi-node workloads.\n \nYou can use G7e instances for Amazon EC2 in the following AWS Regions: US East (N. Virginia) and US East (Ohio). You can purchase G7e instances as On-Demand Instances, Spot Instances, or as part of Savings Plans.\n \nTo get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit G7e instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-g7e-instances-generally-available",
      "pubDate": "2026-01-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-5c7af250881a",
      "title": "Amazon Quick Sight expands dashboard customization in tables and pivot tables",
      "description": "Building on our recent launch of customizable tables and pivot tables, Amazon Quick Sight now enables readers to add or remove fields, change aggregations, and modify formatting directly in dashboards—all without requiring updates from dashboard authors.\n  These enhanced capabilities empower readers with even greater flexibility to tailor their data views for specific analytical needs. For example, sales managers can add revenue breakdowns by product category to identify growth opportunities, while finance teams can change aggregations from sum to average to better understand spending patterns across departments.\n  These new customization features are now available in Amazon Quick Sight Enterprise Edition across all supported Amazon Quick Sight regions. To get started with these new customization features, see our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-quicksight-expands-dashboard-customization-tables-pivot-tables",
      "pubDate": "2026-01-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "lex",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "lex",
        "rds",
        "launch",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-0f988c99d843",
      "title": "Amazon CloudWatch Database Insights on-demand analysis now available in four additional Regions",
      "description": "Amazon CloudWatch Database Insights expands the availability of its on-demand analysis experience to four additional Regions - Asia Pacific (New Zealand), Asia Pacific (Taipei), Asia Pacific (Thailand), and Mexico (Central). CloudWatch Database Insights is a monitoring and diagnostics solution that helps database administrators and developers optimize database performance by providing comprehensive visibility into database metrics, query analysis, and resource utilization patterns. This feature leverages machine learning models to help identify performance bottlenecks during the selected time period, and gives advice on what to do next.\n  Previously, database administrators had to manually analyze performance data, correlate metrics, and investigate root cause. This process is time-consuming and requires deep database expertise. With this launch, you can now analyze database performance monitoring data for any time period with automated intelligence. The feature automatically compares your selected time period against normal baseline performance, identifies anomalies, and provides specific remediation advice. Through intuitive visualizations and clear explanations, you can quickly identify performance issues and receive step-by-step guidance for resolution. This automated analysis and recommendation system reduces mean-time-to-diagnosis from hours to minutes.\n  You can get started with this feature by enabling the Advanced mode of CloudWatch Database Insights on your Amazon Aurora and Amazon RDS databases using the RDS service console, AWS APIs, the AWS SDK, or AWS CloudFormation. Please refer to Aurora documentation or RDS documentation to get started.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-cloudwatch-database-insights-on-demand-analysis-available-additional-regions",
      "pubDate": "2026-01-20T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudformation",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "cloudformation",
        "cloudwatch",
        "launch",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-9b6e9d8a8bb6",
      "title": "Amazon EC2 High Memory U7i instances now available in additional regions",
      "description": "Amazon EC2 High Memory U7i instances are available in new regions. U7i-6tb.112xlarge instances are now available in AWS Asia Pacific (Thailand, Sydney, Singapore), Canada (Central), and AWS GovCloud (US-East), u7i-8tb.112xlarge instances are now available in AWS South America (Sao Paulo), and u7in-16tb.224xlarge instances are now available in AWS GovCloud (US-East). U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TiB of DDR5 memory, U7in-8tb instances offer 8TiB of DDR5 memory, and U7in-16tb instances offer 16TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n \nU7i-6tb and U7i-8tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7in-16tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 200Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server. \n \nTo learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ec-high-memory-ui-instances-additional-regions/",
      "pubDate": "2026-01-16T22:20:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "ga",
        "now-available",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-3bf74b37e9fd",
      "title": "Advanced fine-tuning techniques for multi-agent orchestration: Patterns from Amazon at scale",
      "description": "In this post, we show you how fine-tuning enabled a 33% reduction in dangerous medication errors (Amazon Pharmacy), engineering 80% human effort reduction (Amazon Global Engineering Services), and content quality assessments improving 77% to 96% accuracy (Amazon A+). This post details the techniques behind these outcomes: from foundational methods like Supervised Fine-Tuning (SFT) (instruction tuning), and Proximal Policy Optimization (PPO), to Direct Preference Optimization (DPO) for human alignment, to cutting-edge reasoning optimizations such as Grouped-based Reinforcement Learning from Policy Optimization (GRPO), Direct Advantage Policy Optimization (DAPO), and Group Sequence Policy Optimization (GSPO) purpose-built for agentic systems.",
      "link": "https://aws.amazon.com/blogs/machine-learning/advanced-fine-tuning-techniques-for-multi-agent-orchestration-patterns-from-amazon-at-scale/",
      "pubDate": "2026-01-16T15:51:21.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-dafc81891e3c",
      "title": "Deploy AI agents on Amazon Bedrock AgentCore using GitHub Actions",
      "description": "In this post, we demonstrate how to use a GitHub Actions workflow to automate the deployment of AI agents on AgentCore Runtime. This approach delivers a scalable solution with enterprise-level security controls, providing complete continuous integration and delivery (CI/CD) automation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/deploy-ai-agents-on-amazon-bedrock-agentcore-using-github-actions/",
      "pubDate": "2026-01-16T15:37:37.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "integration"
      ]
    },
    {
      "id": "aws-news-19244e48adfe",
      "title": "Amazon S3 on Outposts is now available on second-generation AWS Outposts racks",
      "description": "Amazon S3 on Outposts is now available on second-generation AWS Outposts racks for your data residency, low latency, and local data processing use cases on-premises. S3 on Outposts on second-generation Outposts racks offers three storage tiers: 196 TB, 490 TB, and 786 TB. Choose the storage tier that matches your workload, whether for production workloads, backups, or archival workloads.\n  With S3 on Outposts, you can store, secure, retrieve, and control access to your data using familiar S3 APIs and features. AWS Outposts is a fully managed service that extends AWS infrastructure, services, and tools to virtually any data center, co-location space, or on-premises facility for a consistent hybrid experience.\n  S3 on Outposts on second-generation Outposts racks is available in all AWS Regions and countries/territories where these racks are available. To learn more, visit the S3 on Outposts page or read our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-s3-second-generation-aws-outposts-racks",
      "pubDate": "2026-01-15T20:23:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "outposts"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "outposts",
        "now-available"
      ]
    },
    {
      "id": "aws-news-1d1cf97c35ee",
      "title": "Amazon Connect now provides agent scheduling metrics in data lake",
      "description": "Amazon Connect now provides agent scheduling metrics in data lake, making it easier for you to generate reports and insights from this data. For example, after publishing schedules for next month, you can access interval level (15 minutes or 30 minutes) metrics such as forecasted headcount, scheduled headcount, and projected service level in Connect analytics data lake. You can view aggregated metrics for an entire business unit (forecast group) or broken down by specific demand segments (demand groups). You can then visualize this data in Amazon Quick Sight or another BI tool of your choice for further analysis, such as identifying periods of over or under-staffing. This eliminates the need for manual reviews of agent schedules thus improving productivity for schedulers and supervisors.\n  This feature is available in all AWS Regions where Amazon Connect agent scheduling is available. To learn more about Amazon Connect agent scheduling, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-connect-scheduling-metrics/",
      "pubDate": "2026-01-15T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "forecast"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "forecast",
        "ga"
      ]
    },
    {
      "id": "aws-news-8a1ede3e0418",
      "title": "How the Amazon AMET Payments team accelerates test case generation with Strands Agents",
      "description": "In this post, we explain how we overcame the limitations of single-agent AI systems through a human-centric approach, implemented structured outputs to significantly reduce hallucinations and built a scalable solution now positioned for expansion across the AMET QA team and later across other QA teams in International Emerging Stores and Payments (IESP) Org.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-the-amazon-amet-payments-team-accelerates-test-case-generation-with-strands-agents/",
      "pubDate": "2026-01-15T15:55:35.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "expansion"
      ]
    },
    {
      "id": "aws-news-067620c2a122",
      "title": "Build a generative AI-powered business reporting solution with Amazon Bedrock",
      "description": "This post introduces generative AI guided business reporting—with a focus on writing achievements & challenges about your business—providing a smart, practical solution that helps simplify and accelerate internal communication and reporting.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-a-generative-ai-powered-business-reporting-solution-with-amazon-bedrock/",
      "pubDate": "2026-01-15T15:53:15.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-7f78364514e2",
      "title": "Amazon EBS now supports up to four Elastic Volumes modifications in 24 hours",
      "description": "Amazon Elastic Block Store (EBS) now supports up to four Elastic Volumes modifications per volume within a rolling 24-hour window. Elastic Volumes modifications allow you to increase the size, change the type, and adjust the performance of your EBS volumes. With this update, you can start a new modification immediately after the previous one completes, as long as you have initiated fewer than four modifications in the past 24 hours.\n \nThis enhancement improves your operational agility to immediately scale storage capacity or adjust performance in response to sudden data growth or unanticipated workload spikes. With Elastic Volumes modifications, you can modify your volumes without detaching them or restarting your instances, allowing your application to continue running with minimal performance impact.\n \nThis feature is available in all commercial AWS Regions, the AWS GovCloud (US) Regions, and the China Regions. This capability is automatically enabled without requiring changes to your existing workflows. To learn more, see Modify an Amazon EBS volume using Elastic Volumes operations in the Amazon EBS User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ebs-up-to-four-volume-modifications/",
      "pubDate": "2026-01-15T14:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-872d932bfe7a",
      "title": "How AutoScout24 built a Bot Factory to standardize AI agent development with Amazon Bedrock",
      "description": "In this post, we explore the architecture that AutoScout24 used to build their standardized AI development framework, enabling rapid deployment of secure and scalable AI agents.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-autoscout24-built-a-bot-factory-to-standardize-ai-agent-development-with-amazon-bedrock/",
      "pubDate": "2026-01-14T21:24:09.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-c6a7173ddda9",
      "title": "How Slack achieved operational excellence for Spark on Amazon EMR using generative AI",
      "description": "In this post, we show how Slack built a monitoring framework for Apache Spark on Amazon EMR that captures over 40 metrics, processes them through Kafka and Apache Iceberg, and uses Amazon Bedrock to deliver AI-powered tuning recommendations—achieving 30–50% cost reductions and 40–60% faster job completion times.",
      "link": "https://aws.amazon.com/blogs/big-data/how-slack-achieved-operational-excellence-for-spark-on-amazon-emr-using-generative-ai/",
      "pubDate": "2026-01-14T21:02:21.000Z",
      "source": "bigDataBlog",
      "services": [
        "bedrock",
        "emr",
        "kafka"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "emr",
        "kafka"
      ]
    },
    {
      "id": "aws-news-7925c18a56a8",
      "title": "Securing Amazon Bedrock cross-Region inference: Geographic and global",
      "description": "In this post, we explore the security considerations and best practices for implementing Amazon Bedrock cross-Region inference profiles. Whether you're building a generative AI application or need to meet specific regional compliance requirements, this guide will help you understand the secure architecture of Amazon Bedrock CRIS and how to properly configure your implementation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/securing-amazon-bedrock-cross-region-inference-geographic-and-global/",
      "pubDate": "2026-01-13T23:13:18.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-4cd689db778a",
      "title": "Amazon EC2 X8aedz instances are now available in Asia Pacific (Mumbai, Seoul) regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) X8aedz instances are available in Asia Pacific (Mumbai) and Asia Pacific (Seoul) regions. These instances are powered by 5th Gen AMD EPYC processors (formerly code named Turin). These instances offer the highest maximum CPU frequency, 5GHz in the cloud.\n  X8aedz instances are built using the latest sixth generation AWS Nitro Cards and are ideal for electronic design automation (EDA) workloads such as physical layout and physical verification jobs, and relational databases that benefit from high single-threaded processor performance and a large memory footprint. The combination of 5 GHz processors and local NVMe storage enables faster processing of memory-intensive backend EDA workloads such as floor planning, logic placement, clock tree synthesis (CTS), routing, and power/signal integrity analysis.\n  X8aedz instances feature a 32:1 ratio of memory to vCPU and are available in 8 sizes ranging from 2 to 96 vCPUs with 64 to 3,072 GiB of memory, including two bare metal variants, and up to 8 TB of local NVMe SSD storage.\n  Customers can purchase X8aedz instances via Savings Plans, On-Demand instances, and Spot instances. To get started, sign in to the AWS Management Console. For more information visit the Amazon EC2 X8aedz instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ec2-x8aedz-instances-asia-pacific-mumbai-seoul-regions",
      "pubDate": "2026-01-13T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "now-available"
      ]
    },
    {
      "id": "aws-news-45a82abb6922",
      "title": "Amazon RDS for PostgreSQL announces Extended Support minor  12.22-rds.20251114 and 11.22-rds.20251114",
      "description": "Amazon Relational Database Service (RDS) for PostgreSQL announces Amazon RDS Extended Support minor version  12.22-rds.20251114 and 11.22-rds.20251114. We recommend that you upgrade to this version to fix known security vulnerabilities and bugs in prior versions of PostgreSQL.\n  Amazon RDS Extended Support provides you more time, up to three years, to upgrade to a new major version to help you meet your business requirements. During Extended Support, Amazon RDS will provide critical security and bug fixes for your PostgreSQL databases after the community ends support for a major version. You can run your PostgreSQL databases on Amazon RDS with Extended Support for up to three years beyond a major version’s end of standard support date. Learn more about Extended Support in the Amazon RDS User Guide.\n  You can leverage automatic minor version upgrades to automatically upgrade your databases to more recent minor versions during scheduled maintenance windows. Learn more about upgrading your database instances, including automatic minor version upgrades, in the Amazon RDS User Guide.\n  Amazon RDS for PostgreSQL makes it easy to set up, operate, and scale PostgreSQL deployments in the cloud. Amazon RDS for PostgreSQL is available in all commercial and gov cloud region. See Amazon RDS for PostgreSQL for pricing details. Create or update a fully managed Amazon RDS database in the Amazon RDS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/1/amazon-rds-for-postgresql-announces-extended-support-minor-12-22-rds-20251114-and-11-22-rds-20251114",
      "pubDate": "2026-01-13T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-a5b575144ec4",
      "title": "Navigating architectural choices for a lakehouse using Amazon SageMaker",
      "description": "Over time, several distinct lakehouse approaches have emerged. In this post, we show you how to evaluate and choose the right lakehouse pattern for your needs. A lakehouse architecture isn’t about choosing between a data lake and a data warehouse. Instead, it’s an approach to interoperability where both frameworks coexist and serve different purposes within a unified data architecture. By understanding fundamental storage patterns, implementing effective catalog strategies, and using native storage capabilities, you can build scalable, high-performance data architectures that support both your current analytics needs and future innovation.",
      "link": "https://aws.amazon.com/blogs/big-data/navigating-architectural-choices-for-a-lakehouse-using-amazon-sagemaker/",
      "pubDate": "2026-01-12T20:46:27.000Z",
      "source": "bigDataBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-52d1b1a6c0c6",
      "title": "Announcing larger managed database bundles for Amazon Lightsail",
      "description": "Amazon Lightsail now offers two larger database bundles with up to 8 vCPUs, 32GB memory, and 960GB SSD storage. The new database bundles are available in both standard and high-availability plans. You can create MySQL and PostgreSQL databases using the new Lightsail managed database bundles.\n  The new larger database bundles enable you to scale your database workloads and run more data-intensive applications in Lightsail. These higher-performance database bundles are ideal for production workloads that require increased storage capacity and processing power to handle growing datasets and concurrent connections. Using these new bundles, you can run e-commerce platforms, content management systems, business intelligence applications, SaaS products, and more.\n  These new bundles are now available in all AWS Regions where Amazon Lightsail is available. For more information on pricing, or to get started with your free trial, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/larger-managed-database-bundles-lightsail/",
      "pubDate": "2026-01-09T22:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-f5848ed220cd",
      "title": "Amazon MQ now supports certificate based authentication with mutual TLS for RabbitMQ brokers",
      "description": "Amazon MQ now supports the ability for RabbitMQ brokers to perform authentication (determining who can log in) using X.509 client certificates with mutual TLS (mTLS). The RabbitMQ auth_mechanism_ssl plugin can be configured on brokers running RabbitMQ version 4.2 and above on Amazon MQ by making changes to the associated configuration file.\n  To start using certificate based authentication on Amazon MQ, simply select RabbitMQ 4.2 when creating a new broker using the M7g instance type through the AWS Management console, AWS CLI, or AWS SDKs, and then edit the associated configuration file with the required values. To learn more about the plugin, see the Amazon MQ release notes and the Amazon MQ developer guide. This plugin is available in all regions where Amazon MQ RabbitMQ 4 instances are available today.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-mq-certificate-based-authentication-mutual-tls-rabbitmq/",
      "pubDate": "2026-01-08T19:39:00.000Z",
      "source": "whatsNew",
      "services": [
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "q developer",
        "support"
      ]
    },
    {
      "id": "aws-news-5d0429585426",
      "title": "Amazon DocumentDB (with MongoDB compatibility) is Now Available in the Asia Pacific (Jakarta) Region",
      "description": "Amazon DocumentDB (with MongoDB compatibility) is now available in the Asia Pacific (Jakarta) region adding to the list of available regions where you can use Amazon DocumentDB.\n  Amazon DocumentDB is a fully managed, native JSON database that makes it simple and cost-effective to operate critical document workloads at virtually any scale without managing infrastructure. Amazon DocumentDB is designed to give you the scalability and durability you need when operating mission-critical MongoDB workloads. Storage scales automatically up to 128TiB without any impact to your application. In addition, Amazon DocumentDB natively integrates with AWS Database Migration Service(DMS), Amazon CloudWatch, AWS CloudTrail, AWS Lambda, AWS Backup and more. Amazon DocumentDB supports millions of requests per second and can be scaled out to 15 low latency read replicas in minutes with no application downtime.\n  To learn more about Amazon DocumentDB, please visit the Amazon DocumentDB product page and pricing page.\n  You can create a Amazon DocumentDB cluster from the AWS Management console, AWS Command Line Interface (CLI), or SDK.",
      "link": "https://aws.amazon.comabout-aws/whats-new/2026/01/amazon-documentdb-mongodb-compatibility-asia-pacific-jakarta-region",
      "pubDate": "2026-01-08T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "cloudwatch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-31581dc075c4",
      "title": "Announcing Apache Airflow 2.11 Support in Amazon Managed Workflows for Apache Airflow",
      "description": "You can now create Apache Airflow version 2.11 environments on Amazon Managed Workflows for Apache Airflow (MWAA). Apache Airflow 2.11 introduces several changes to help you prepare for upgrading to Apache Airflow 3. \n  Amazon MWAA is a managed orchestration service for Apache Airflow that makes it easier to set up and operate end-to-end data pipelines in the cloud. Apache Airflow 2.11 introduces several notable enhancements, such as new trigger-based scheduling for delta intervals, consistent reporting of metrics in milliseconds and other changes that will make it easy to migrate to Apache Airflow 3. In addition, MWAA now provides support for Python 3.12 that you can leverage in your workflows.\n  You can launch a new Apache Airflow 2.11 environment on Amazon MWAA with just a few clicks in the AWS Management Console in all currently supported Amazon MWAA regions. To learn more about Apache Airflow 2.11 visit the Amazon MWAA documentation, and the Apache Airflow 2.11 change log in the Apache Airflow documentation.\n  Apache, Apache Airflow, and Airflow are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/apache-airflow-2-11-support-amazon-managed-workflows/",
      "pubDate": "2026-01-07T17:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-d2b99bbcfdfb",
      "title": "Amazon EC2 I7ie instances now available in additional AWS regions",
      "description": "AWS is announcing starting today, Amazon EC2 I7ie instances are now available in AWS Asia Pacific (Mumbai), Canada West (Calgary) and Europe (Paris) regions. Designed for large storage I/O intensive workloads, I7ie instances are powered by 5th Gen Intel Xeon Processors with an all-core turbo frequency of 3.2 GHz, offering up to 40% better compute performance and 20% better price performance over existing I3en instances. I7ie instances offer up to 120TB local NVMe storage density for storage optimized instances and offer up to twice as many vCPUs and memory compared to prior generation instances. Powered by 3rd generation AWS Nitro SSDs, I7ie instances deliver up to 65% better real-time storage performance, up to 50% lower storage I/O latency, and 65% lower storage I/O latency variability compared to I3en instances.\n  I7ie are high density storage optimized instances, ideal for workloads requiring fast local storage with high random read/write performance at very low latency consistency to access large data sets. These instances are available in 9 different virtual sizes and deliver up to 100Gbps of network bandwidth and 60Gbps of bandwidth for Amazon Elastic Block Store (EBS).\n  To learn more, visit the I7ie instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ec2-i7ie-instances-additional-aws-regions/",
      "pubDate": "2026-01-07T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-304f0b522c8b",
      "title": "Amazon EMR Serverless eliminates local storage provisioning, reducing data processing costs by up to 20%",
      "description": "In this post, you'll learn how Amazon EMR Serverless eliminates the need to configure local disk storage for Apache Spark workloads through a new serverless storage capability. We explain how this feature automatically handles shuffle operations, reduces data processing costs by up to 20%, prevents job failures from disk capacity constraints, and enables elastic scaling by decoupling storage from compute.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-emr-serverless-eliminates-local-storage-provisioning-reducing-data-processing-costs-by-up-to-20/",
      "pubDate": "2026-01-06T22:45:40.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-6ef7d538452f",
      "title": "Amazon MQ now supports HTTP based authentication for RabbitMQ brokers",
      "description": "Amazon MQ now supports the ability for RabbitMQ brokers to perform authentication (determining who can log in) and authorization (determining what permissions they have) by making requests to an HTTP server. This plugin can be configured on brokers running RabbitMQ 4.2 and above on Amazon MQ by making changes to the associated configuration file.\n  To start using HTTP based authentication and authorization on Amazon MQ, simply select RabbitMQ 4.2 when creating a new broker using the m7g instance type through the AWS Management console, AWS CLI, or AWS SDKs, and then edit the associated configuration file. To learn more about the plugin, see the Amazon MQ release notes and the Amazon MQ developer guide. This plugin is available in all regions where Amazon MQ RabbitMQ 4 instances are available today.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-mq-http-based-rabbitmq-brokers/",
      "pubDate": "2026-01-06T17:35:00.000Z",
      "source": "whatsNew",
      "services": [
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "q developer",
        "support"
      ]
    },
    {
      "id": "aws-news-8961df6dac08",
      "title": "AWS Config now supports 21 new resource types",
      "description": "AWS Config now supports 21 additional AWS resource types across key services including Amazon EC2, Amazon SageMaker, and Amazon S3 Tables. This expansion provides greater coverage over your AWS environment, enabling you to more effectively discover, assess, audit, and remediate an even broader range of resources.\n  With this launch, if you have enabled recording for all resource types, then AWS Config will automatically track these new additions. The newly supported resource types are also available in Config rules and Config aggregators.\n  You can now use AWS Config to monitor the following newly supported resource types in all AWS Regions where the supported resources are available:\n  Resource Types:\n  \n \n \n  \nAWS::AppStream::AppBlockBuilder \n   AWS::IoT::ThingGroup \n  \nAWS::B2BI::Capability \n   AWS::IoTSiteWise::Asset \n  \nAWS::CleanRoomsML::TrainingDataset \n   AWS::Location::APIKey \n  \nAWS::CloudFront::KeyValueStore \n   AWS::MediaPackageV2::OriginEndpoint \n  \nAWS::Connect::SecurityProfile \n   AWS::PCAConnectorAD::Connector \n  \nAWS::Deadline::Monitor \n   AWS::Route53::DNSSEC \n  \nAWS::EC2::SubnetCidrBlock \n   AWS::S3Tables::TableBucketPolicy \n  \nAWS::ECR::ReplicationConfiguration \n   AWS::SageMaker::UserProfile \n  \nAWS::GameLift::Build \n   AWS::SecretsManager::ResourcePolicy \n  \nAWS::GuardDuty::MalwareProtectionPlan       \n   AWS::SSMContacts::Contact \n  \nAWS::ImageBuilder::LifecyclePolicy",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-config-new-resource-types",
      "pubDate": "2026-01-06T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "s3",
        "ec2",
        "cloudfront"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "ec2",
        "cloudfront",
        "launch",
        "ga",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-ad7d6516e129",
      "title": "Amazon EC2 G5 instances are now available in Asia Pacific (Hong Kong) Region",
      "description": "Starting today, the Amazon Elastic Compute Cloud (Amazon EC2) G5 instances powered by NVIDIA A10G Tensor Core GPUs are now available in the Asia Pacific (Hong Kong) region. G5 instances can be used for a wide range of graphics intensive and machine learning use cases.\n \nCustomers can use G5 instances for graphics-intensive applications such as remote workstations, video rendering, and cloud gaming to produce high fidelity graphics in real time. Machine learning customers can use G5 instances for high performance and cost-efficient training and inference for natural language processing, computer vision, and recommender engine use cases. G5 instances feature up to 8 NVIDIA A10G Tensor Core GPUs and 2nd generation AMD EPYC processors. They also support up to 192 vCPUs, up to 100 Gbps of network bandwidth, and up to 7.6 TB of local NVMe SSD storage. With eight G5 instance sizes that offer access to single or multiple GPUs, customers have the flexibility to pick the right instance size for their applications.\n \nCustomers can easily optimize G5 instances for their workloads with NVIDIA drivers specific to compute, gaming or workstation workloads. Customers can purchase G5 instances as On-Demand Instances or Reserved Instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ec2-g5-now-available-asia-pacific-hong-kong",
      "pubDate": "2026-01-05T18:55:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-23eaa0da3d41",
      "title": "AWS Transfer Family is now available in AWS Asia Pacific (New Zealand) region",
      "description": "Customers in AWS Asia Pacific (New Zealand) Region can now use AWS Transfer Family for file transfers over Secure File Transfer Protocol (SFTP), File Transfer Protocol (FTP), FTP over SSL (FTPS) and Applicability Statement 2 (AS2).\n  AWS Transfer Family provides fully managed file transfers for Amazon Simple Storage Service (Amazon S3) and Amazon Elastic File System (Amazon EFS) over SFTP, FTP, FTPS and AS2 protocols. In addition to file transfers, Transfer Family enables common file processing and event-driven automation for managed file transfer (MFT) workflows, helping customers to modernize and migrate their business-to-business file transfers to AWS.\n  To learn more about AWS Transfer Family, visit our product page and user guide. See the AWS Region Table for complete regional availability information.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-transfer-family-asia-pacific-new-zealand-region",
      "pubDate": "2026-01-05T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "now-available"
      ]
    },
    {
      "id": "aws-news-36722fddcb63",
      "title": "Building zero trust generative AI applications in healthcare with AWS Nitro Enclaves",
      "description": "In healthcare, generative AI is transforming how \nmedical professionals analyze data, \nsummarize clinical notes, and \ngenerate insights to improve patient outcomes. From \nautomating medical documentation to assisting in \ndiagnostic reasoning, large language models (LLMs) have the potential to augment clinical workflows and accelerate research. However, these innovations also introduce significant privacy, security, and intellectual property challenges.",
      "link": "https://aws.amazon.com/blogs/compute/building-zero-trust-generative-ai-applications-in-healthcare-with-aws-nitro-enclaves/",
      "pubDate": "2025-12-12T19:06:03.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-b56aaf668b93",
      "title": "Architecting conversational observability for cloud applications",
      "description": "In this post, we walk through building a generative AI–powered troubleshooting assistant for Kubernetes. The goal is to give engineers a faster, self-service way to diagnose and resolve cluster issues, cut down Mean Time to Recovery (MTTR), and reduce the cycles experts spend finding the root cause of issues in complex distributed systems.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-conversational-observability-for-cloud-applications/",
      "pubDate": "2025-12-11T15:59:39.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}