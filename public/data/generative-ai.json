{
  "lastUpdated": "2025-11-21T06:16:18.487Z",
  "category": "generative-ai",
  "totalItems": 36,
  "items": [
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-5d5e12cf24b1",
      "title": "AWS DMS Schema Conversion adds SAP (Sybase) ASE to PostgreSQL support with generative AI",
      "description": "AWS Database Migration Service (DMS) Schema Conversion is a fully managed feature of DMS that automatically assesses and converts database schemas to formats compatible with AWS target database services. Today, we're excited to announce that Schema Conversion now supports conversions from SAP Adaptive Server Enterprise (ASE) database (formerly known as Sybase) to Amazon RDS PostgreSQL and Amazon Aurora PostgreSQL, powered by Generative AI capability.\n  Using Schema Conversion, you can automatically convert database objects from your SAP (Sybase) ASE source to an to Amazon RDS PostgreSQL and Amazon Aurora PostgreSQL target. The integrated generative AI capability intelligently handles complex code conversions that typically require manual effort, such as stored procedures, functions, and triggers. Schema Conversion also provides detailed assessment reports to help you plan and execute your migration effectively.\n  To learn more about this feature, see the documentation for using SAP (Sybase) ASE as a source for AWS DMS Schema Conversion and using SAP (Sybase) ASE as a source for AWS DMS for data migration. For details about the generative AI capability, please refer to the User Guide. For AWS DMS Schema Conversion regional availability, please refer to the Supported AWS Regions page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-dms-schema-conversion-sap-sybase-ase-postgresql/",
      "pubDate": "2025-11-20T19:11:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-e746385d2aa7",
      "title": "MSD explores applying generative Al to improve the deviation management process using AWS services",
      "description": "This blog post has explores how MSD is harnessing the power of generative AI and databases to optimize and transform its manufacturing deviation management process. By creating an accurate and multifaceted knowledge base of past events, deviations, and findings, the company aims to significantly reduce the time and effort required for each new case while maintaining the highest standards of quality and compliance.",
      "link": "https://aws.amazon.com/blogs/machine-learning/msd-explores-applying-generative-al-to-improve-the-deviation-management-process-using-aws-services/",
      "pubDate": "2025-11-20T18:21:49.000Z",
      "source": "mlBlog",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds"
      ]
    },
    {
      "id": "aws-news-82390b5e23c0",
      "title": "Accelerating genomics variant interpretation with AWS HealthOmics and Amazon Bedrock AgentCore",
      "description": "In this blog post, we show you how agentic workflows can accelerate the processing and interpretation of genomics pipelines at scale with a natural language interface. We demonstrate a comprehensive genomic variant interpreter agent that combines automated data processing with intelligent analysis to address the entire workflow from raw VCF file ingestion to conversational query interfaces.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerating-genomics-variant-interpretation-with-aws-healthomics-and-amazon-bedrock-agentcore/",
      "pubDate": "2025-11-20T18:18:21.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-efa2bd21663c",
      "title": "How Rufus scales conversational shopping experiences to millions of Amazon customers with Amazon Bedrock",
      "description": "Our team at Amazon builds Rufus, an AI-powered shopping assistant which delivers intelligent, conversational experiences to delight our customers. More than 250 million customers have used Rufus this year. Monthly users are up 140% YoY and interactions are up 210% YoY. Additionally, customers that use Rufus during a shopping journey are 60% more likely to […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-rufus-scales-conversational-shopping-experiences-to-millions-of-amazon-customers-with-amazon-bedrock/",
      "pubDate": "2025-11-20T18:13:39.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-26ac62f98cf7",
      "title": "Amazon MSK Serverless expands availability to South America (São Paulo) region",
      "description": "You can now connect your Apache Kafka applications to Amazon MSK Serverless in the South America (São Paulo) AWS Regions.\n  Amazon MSK is a fully managed service for Apache Kafka and Kafka Connect that makes it easier for you to build and run applications that use Apache Kafka as a data store. Amazon MSK Serverless is a cluster type for Amazon MSK that allows you to run Apache Kafka without having to manage and scale cluster capacity. MSK Serverless automatically provisions and scales compute and storage resources, so you can use Apache Kafka on demand.\n  With these launches, Amazon MSK Serverless is now generally available in Asia Pacific (Sydney), Asia Pacific (Singapore), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Seoul), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (Stockholm), Europe (Paris), Europe (London), South America (São Paulo), US East (N. Virginia), US East (Ohio), and US West (Oregon) AWS regions. To learn more and get started, see our developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-msk-serverless-south-america-sao-paulo-region",
      "pubDate": "2025-11-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "kafka",
        "msk",
        "launch",
        "generally-available",
        "ga"
      ]
    },
    {
      "id": "aws-news-608d845b559d",
      "title": "AWS announces availability of Microsoft SQL Server 2025 images on Amazon EC2",
      "description": "Amazon EC2 now supports Microsoft SQL Server 2025 with License-Included (LI) Amazon Machine Images (AMIs), providing a quick way to launch the latest version of SQL Server. By running SQL Server 2025 on Amazon EC2, customers can take advantage of the security, performance, and reliability of AWS with the latest SQL Server features.\n  Amazon creates and manages Microsoft SQL Server 2025 AMIs to simplify the provisioning and management of SQL Server 2025 on EC2 Windows instances. These images support version 1.3 of the Transport Layer Security (TLS) protocol by default for enhanced performance and security. These images also come with pre-installed software such as AWS Tools for Windows PowerShell, AWS Systems Manager, AWS CloudFormation, and various network and storage drivers to make your management easier.\n  SQL Server 2025 AMIs are available in all commercial AWS Regions and the AWS GovCloud (US) Regions.\n  To learn more about the new AMIs, see SQL Server AMIs User Guide or read the blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-availability-microsoft-sql-server-2025-images-amazon-ec2",
      "pubDate": "2025-11-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudformation",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-c72f2536757e",
      "title": "Amazon MQ now supports RabbitMQ version 4.2",
      "description": "Amazon MQ now supports RabbitMQ version 4.2 which introduces native support for the AMQP 1.0 protocol, a new Raft based metadata store named Khepri, local shovels, and message priorities for quorum queues. RabbitMQ 4.2 also includes various bug fixes and performance improvements for throughput and memory management.\n  A key highlight of RabbitMQ 4.2 is the support of AMQP 1.0 as a core protocol offering enhanced features like modified outcome which allow consumers to modify message annotations before requeueing or dead lettering, and granular flow control, which offers benefits including letting a client application dynamically adjust how many messages it wants to receive from a specific queue. Amazon MQ has also introduced configurable resource limits for RabbitMQ 4.2 brokers which you can modify based on your application requirements. Starting from RabbitMQ 4.0, mirroring of classic queues is no longer supported. Non-replicated classic queues are still supported. Quorum queues are the only replicated and durable queue type supported on RabbitMQ 4.2 brokers, and now offer message priorities in addition to consumer priorities.\n  To start using RabbitMQ 4.2 on Amazon MQ, simply select RabbitMQ 4.2 when creating a new broker using the m7g instance type through the AWS Management console, AWS CLI, or AWS SDKs. Amazon MQ automatically manages patch version upgrades for your RabbitMQ 4.2 brokers, so you need to only specify the major.minor version. To learn more about the changes in RabbitMQ 4.2, see the Amazon MQ release notes and the Amazon MQ developer guide. This version is available in all regions where Amazon MQ m7g type instances are available today.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-mq-rabbitmq-42/",
      "pubDate": "2025-11-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "q developer",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-99d98790f34c",
      "title": "Amazon EC2 High Memory U7i instances now available in additional regions",
      "description": "Amazon EC2 High Memory U7i instances with 16TB of memory (u7in-16tb.224xlarge) are now available in the AWS Europe (Ireland) region, U7i instances with 12TB of memory (u7i-12tb.224xlarge) are now available in the AWS Asia Pacific (Hyderabad), and U7i instances with 8TB of memory (u7i-8tb.112xlarge) are now available in the Asia Pacific (Mumbai) and AWS GovCloud (US-West) region. U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7in-16tb instances offer 16TiB of DDR5 memory, U7i-12tb instances offer 12TiB of DDR5 memory, and U7i-8tb instances offer 8TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-8tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i-12tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7in-16tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 200Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-high-memory-u7i-additional-regions/",
      "pubDate": "2025-11-20T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-e6b9f765cd8c",
      "title": "Amazon Redshift Serverless now offers 4-RPU Minimum Capacity across more aws regions",
      "description": "Amazon Redshift now allows you to get started with Amazon Redshift Serverless with a lower data warehouse base capacity configuration of 4 Redshift Processing Units (RPUs) in the AWS Asia Pacific (Thailand), Asia Pacific (Jakarta), Africa (Cape Town), Asia Pacific (Hyderabad), Asia Pacific (Osaka), Asia Pacific (Malaysia), Asia Pacific (Taipei), Mexico (Central), Israel (Tel Aviv), Europe (Spain), Europe (Milan), Europe (Frankfurt) and Middle East (UAE) regions. Amazon Redshift Serverless measures data warehouse capacity in RPUs. 1 RPU provides you 16 GB of memory. You pay only for the duration of workloads you run in RPU-hours on a per-second basis. Previously, the minimum base capacity required to run Amazon Redshift Serverless was 8 RPUs. You can start using Amazon Redshift Serverless for as low as $1.50 per hour and pay only for the compute capacity your data warehouse consumes when it is active.\n  Amazon Redshift Serverless enables users to run and scale analytics without managing data warehouse clusters. The new lower capacity configuration makes Amazon Redshift Serverless suitable for both production and development environments, particularly when workloads require minimal compute and memory resources. This entry-level configuration supports data warehouses with up to 32 TB of Redshift managed storage, offering a maximum of 100 columns per table and 64 GB of memory.\n  To get started, see the Amazon Redshift Serverless feature page, user documentation, and API Reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-redshift-serverless-4-rpu-minimum-capacity/",
      "pubDate": "2025-11-20T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "redshift"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "redshift",
        "support"
      ]
    },
    {
      "id": "aws-news-e5f34da19404",
      "title": "Amazon CloudWatch application map now supports un-instrumented services discovery",
      "description": "Application map in Amazon CloudWatch now supports un-instrumented services discovery, cross-account views, and change history, helping SRE and DevOps teams monitor and troubleshoot their large-scale distributed applications. Application map now detects and visualizes services not instrumented with Application Signals, providing out-of-the-box observability coverage in your distributed environment. In addition, it provides a single, unified view for applications, services, and infrastructure distributed across AWS accounts, enabling end-to-end visibility. Furthermore, it provides a history of recent changes, helping teams quickly correlate when a modification occurred and how it aligns with shifts in application health or performance.\n  These enhancements help SRE and DevOps teams troubleshoot issues faster and operate with greater confidence in large-scale, distributed environments. For example, when latency or error rates spike, developers can now investigate recent configuration changes, and analyze dependencies across multiple AWS accounts, all from a single map. During post-incident reviews, teams can use historical change data to understand what shifted and when, improving long-term reliability. By unifying service discovery, dependency mapping, and change history, application map reduces mean-time-to-resolution (MTTR) and helps teams maintain application health across complex systems.\n  Starting today, the new capabilities in Application Map are available at no additional cost in all AWS commercial regions (except Taipei and New Zealand). To learn more about Application Map, please visit the Amazon CloudWatch Application Signals documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-application-map-un-instrumented-discovery/",
      "pubDate": "2025-11-20T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "cloudwatch",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-b681bec77a37",
      "title": "AWS Site-to-Site VPN is collaborating with eero to simplify remote connectivity",
      "description": "AWS Site-to-Site VPN is collaborating with eero to simplify how customers connect their remote sites to AWS. This collaboration will help customers to establish secure connectivity between their remote sites and AWS in just a few clicks.\n  Many AWS customers operate hundreds of remote sites - from restaurants and retail stores to gas stations and mobile offices. These sites rely on WiFi to connect employees, customers, and IoT applications like kiosks, ATMs, and vending machines, while also connecting with AWS for business operations. These customers also need a faster and efficient way to connect hundreds of sites to AWS. For example, quick service restaurants need to connect their point of sales systems at each site to their payment gateways in AWS. AWS Site-to-Site VPN and eero are collaborating to simplify remote site connectivity by combining eero's ease of use with AWS's networking services. This solution leverages eero’s WiFi access points and network gateways to provide local connectivity. Using eero’s gateway appliances and AWS Site-to-Site VPN, customers can automatically establish VPN connectivity to access their applications hosted in AWS such as payment gateways for point of sales systems in just a few clicks. This makes it simple and faster for customers to scale their remote site connectivity across hundreds of sites and eliminates the need for an onsite technician with networking expertise to set-up the connectivity.\n  Customers can use eero devices in the US geography to establish connectivity to AWS using Site-to-Site VPN. To learn more and get started, visit the AWS Site-to-Site VPN documentation and eero documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/site-to-site-vpn-eero-simplify-remote-connectivity/",
      "pubDate": "2025-11-20T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-c2cf5f1cc0c8",
      "title": "Claude Code deployment patterns and best practices with Amazon Bedrock",
      "description": "In this post, we explore deployment patterns and best practices for Claude Code with Amazon Bedrock, covering authentication methods, infrastructure decisions, and monitoring strategies to help enterprises deploy securely at scale. We recommend using Direct IdP integration for authentication, a dedicated AWS account for infrastructure, and OpenTelemetry with CloudWatch dashboards for comprehensive monitoring to ensure secure access, capacity management, and visibility into costs and developer productivity .",
      "link": "https://aws.amazon.com/blogs/machine-learning/claude-code-deployment-patterns-and-best-practices-with-amazon-bedrock/",
      "pubDate": "2025-11-19T23:17:38.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "rds",
        "cloudwatch",
        "integration"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-20066356eddb",
      "title": "How Amazon uses AI agents to support compliance screening of billions of transactions per day",
      "description": "Amazon's AI-powered Amazon Compliance Screening system tackles complex compliance challenges through autonomous agents that analyze, reason through, and resolve cases with precision. This blog post explores how Amazon’s Compliance team built its AI-powered investigation system through a series of AI agents built on AWS.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-uses-ai-agents-to-support-compliance-screening-of-billions-of-transactions-per-day/",
      "pubDate": "2025-11-19T19:39:18.000Z",
      "source": "mlBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-1668cb797b15",
      "title": "Amazon EKS introduces enhanced container network observability",
      "description": "Today, we’re announcing new network observability features in Amazon Elastic Kubernetes Service (EKS) that provide deeper insights into your container networking environment. These new capabilities help you better understand, monitor, and troubleshoot your Kubernetes network landscape in AWS.\n  Customers are increasingly deploying microservices to expand and incrementally innovate with software in the AWS cloud, while using Amazon EKS as the underlying platform to run their applications. With enhanced container network observability, customers can leverage granular, network-related metrics for better proactive anomaly detection across cluster traffic, cross-AZ flows, and AWS services. Using these metrics, customers can better measure system performance and visualize the underlying metrics using their preferred observability stack.\n  Additionally, EKS now provides network monitoring visualizations in the AWS console that accelerate and enhance precise troubleshooting for faster root cause analysis. Customers can also leverage these visual capabilities to pinpoint top-talkers and network flows causing retransmissions and retransmission timeouts, eliminating blind spots during incidents. These network monitoring features in EKS are powered by Amazon CloudWatch Network Flow Monitor.\n  Enhanced container network observability for EKS is available in all commercial AWS Regions where CloudWatch Network Flow Monitor is available. To learn more, visit the Amazon EKS documentation and AWS News Launch Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-enhanced-container-network-observability",
      "pubDate": "2025-11-19T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "eks",
        "cloudwatch",
        "launch"
      ]
    },
    {
      "id": "aws-news-2f588c5f0196",
      "title": "Using Spectrum fine-tuning to improve FM training efficiency on Amazon SageMaker AI",
      "description": "In this post you will learn how to use Spectrum to optimize resource use and shorten training times without sacrificing quality, as well as how to implement Spectrum fine-tuning with Amazon SageMaker AI training jobs. We will also discuss the tradeoff between QLoRA and Spectrum fine-tuning, showing that while QLoRA is more resource efficient, Spectrum results in higher performance overall.",
      "link": "https://aws.amazon.com/blogs/machine-learning/using-spectrum-fine-tuning-to-improve-fm-training-efficiency-on-amazon-sagemaker-ai/",
      "pubDate": "2025-11-19T15:51:40.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-fe7de9f6421d",
      "title": "Amazon ECR introduces archive storage class for rarely accessed container images",
      "description": "Amazon ECR now offers a new archive storage class to reduce storage costs for large volumes of rarely accessed container images. The new archive storage class helps you meet your compliance and retention requirements while optimizing storage cost. As part of this launch, ECR lifecycle policies now support archiving images based on last pull time, allowing you to use lifecycle rules to automatically archive images based on usage patterns.\n  To get started, you can archive images by configuring lifecycle rules to automatically archive images based on criteria such as image age, count, or last pull time, or using the ECR Console or API to archive images individually. You can archive an unlimited number of images. Archived images do not count against your image per repository limit. Once the images are archived, they are no longer accessible for pulls, but can be easily restored via ECR Console, CLI, or API within 20 minutes. Once restored, images can be pulled normally. All archival and restore operations are logged through CloudTrail for auditability.\n  The new ECR archive storage class is available in all AWS Commercial and AWS GovCloud (US) Regions. For pricing, visit the pricing page. To learn more, visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ecr-archive-storage-class-container-images/",
      "pubDate": "2025-11-19T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-a7a72fdcce0d",
      "title": "Amazon API Gateway now supports response streaming for REST APIs",
      "description": "Amazon API Gateway now progressively streams response payloads to clients as they become available. This improves REST API responsiveness by eliminating the need to buffer complete responses before transmission. This new capability works with backends that support streaming, including Lambda functions, HTTP proxy integrations, and private integrations.\n  Response streaming delivers three key benefits: improved time-to-first-byte (TTFB) performance, extended integration timeouts up to 15 minutes, and support for payloads larger than 10 MB. Generative AI applications particularly benefit from improved TTFB as users see responses appear incrementally in real-time, while complex deliberation-focused models that take longer to process can now run with extended timeouts. Additionally, large payload support enables direct streaming of media files and large datasets without requiring workarounds like pre-signed Amazon S3 URLs.\n  To learn about pricing for this feature, please see the Amazon API Gateway pricing page. Amazon API Gateway response streaming is available in all AWS Regions, including the AWS GovCloud (US) Regions, and works with regional, private, and edge-optimized endpoints. To get started, visit Amazon API Gateway documentation, AWS blog and customer success blog posts.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/api-gateway-response-streaming-rest-apis/",
      "pubDate": "2025-11-19T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "lambda",
        "s3",
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "lambda",
        "s3",
        "api gateway",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-b5adfd79cad0",
      "title": "AWS Announces Elemental MediaConnect Router",
      "description": "Today, AWS announces the general availability of AWS Elemental MediaConnect Router, a new capability that enables broadcasters and content providers to dynamically route live video between sources and destinations in the AWS network. This new capability transforms how you build and manage complex live video workflows in the cloud, eliminating the need to reconfigure infrastructure as routing needs change. The router enables complex scenarios like switching between primary and backup feeds, routing regional variants independently, and managing multiple feeds for comprehensive coverage.\n  MediaConnect Router optimizes content delivery across the AWS network, reducing transport latency while improving packet delivery reliability when compared to standard transport technologies. This fully managed capability supports routing between inputs and outputs in any supported region as well as between private and public endpoints, and it eliminates operational overhead and unused capacity costs.\n  You can start using MediaConnect Router through the MediaConnect console, via MediaConnect API, or AWS CDK. It works independently or alongside existing MediaConnect flows. It can also be part of a larger video workflow with AWS Elemental, a family of media services that help customers process, monetize, and deliver the highest quality video at global scale.\n  MediaConnect Router is available in all standard AWS Regions.\n  To learn more about MediaConnect, please visit here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/elemental-mediaconnect-router/",
      "pubDate": "2025-11-19T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-20e60c2dbbd1",
      "title": "AWS Marketplace adds A2A server support for Amazon Bedrock AgentCore Runtime",
      "description": "AWS Marketplace now offers Agent-to-Agent (A2A) server support and streamlined deployment for third-party AI agents and tools built for Amazon Bedrock AgentCore Runtime. The new capabilities accelerate deployment by pre-populating required environment variables in the AgentCore console and AWS CLI instructions in AWS Marketplace. Customers can now also procure and deploy A2A servers on AgentCore Runtime through AWS Marketplace, making it easier for them to leverage AI agents from AWS Partners. The improvements reduce deployment complexity by leveraging vendor-defined launch configurations while adding protocol flexibility to meet diverse customer needs.\n  AWS Partners can now offer A2A servers in addition to MCP servers and AI agents using AgentCore Runtime containers in the AWS Marketplace Management Portal. To accelerate customer onboarding, AWS Partners can define required environment variables for AgentCore Runtime supported products so that customers can quickly get started. AWS Partners can also enable free pricing for API-based SaaS products. These capabilities provide AWS Partners with the flexibility to bring new products to market and implement pricing strategies that align with their business models and customers’ needs.\n  Customers can learn more in the buyer guide and start exploring AI agent solutions in AWS Marketplace on the solutions page. For AWS Partners interested in implementing the capabilities, visit the seller guide and complete the AWS Marketplace listing workshop.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/marketplace-a2a-server-bedrock-agentcore-runtime/",
      "pubDate": "2025-11-19T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "launch",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-091c9e777a30",
      "title": "Amazon S3 adds new bucket-level setting to standardize encryption types used in your buckets",
      "description": "Amazon S3 now supports a new default encryption configuration setting to enforce Amazon S3 managed server-side encryption (SSE-S3) or server-side encryption with AWS KMS keys (SSE-KMS) for all write requests to your buckets. This new bucket-level setting helps you standardize the server-side encryption types that can be used with your buckets. Using the PutBucketEncryption API, you can disable server-side encryption with customer-provided keys (SSE-C) on specific buckets or in your AWS CloudFormation templates.\n  This enhancement to the PutBucketEncryption API is now available in all AWS Regions. You can use the AWS Management Console, SDK, API, or CLI to configure encryption controls for your buckets. To learn more, see the AWS Storage Blog post or default SSE-C setting for new S3 buckets FAQ in the S3 User Guide. For more information on the PutBucketEncryption API, visit the S3 documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-s3-bucket-level-standardize-encryption-types/",
      "pubDate": "2025-11-19T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "cloudformation",
        "now-available",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-19ca6df7eeca",
      "title": "Bringing tic-tac-toe to life with AWS AI services",
      "description": "RoboTic-Tac-Toe is an interactive game where two physical robots move around a tic-tac-toe board, with both the gameplay and robots’ movements orchestrated by LLMs. Players can control the robots using natural language commands, directing them to place their markers on the game board. In this post, we explore the architecture and prompt engineering techniques used to reason about a tic-tac-toe game and decide the next best game strategy and movement plan for the current player.",
      "link": "https://aws.amazon.com/blogs/machine-learning/bringing-tic-tac-toe-to-life-with-aws-ai-services/",
      "pubDate": "2025-11-18T22:08:57.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-8a70ac885513",
      "title": "HyperPod enhances ML infrastructure with security and storage",
      "description": "This blog post introduces two major enhancements to Amazon SageMaker HyperPod that strengthen security and storage capabilities for large-scale machine learning infrastructure. The new features include customer managed key (CMK) support for encrypting EBS volumes with organization-controlled encryption keys, and Amazon EBS CSI driver integration that enables dynamic storage management for Kubernetes volumes in AI workloads.",
      "link": "https://aws.amazon.com/blogs/machine-learning/hyperpod-enhances-ml-infrastructure-with-security-and-storage/",
      "pubDate": "2025-11-18T17:54:27.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "ga",
        "new-feature",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-39ca3e902331",
      "title": "Accelerating generative AI applications with a platform engineering approach",
      "description": "In this post, I will illustrate how applying platform engineering principles to generative AI unlocks faster time-to-value, cost control, and scalable innovation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerating-generative-ai-applications-with-a-platform-engineering-approach/",
      "pubDate": "2025-11-18T17:04:13.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-d693b35a0907",
      "title": "Amazon RDS Optimized Reads now supports R8gd and M8gd database instances",
      "description": "Amazon Relational Database Service (RDS) now supports R8gd and M8gd database instances for Optimized Reads on Amazon Aurora PostgreSQL and RDS for PostgreSQL, MySQL, and MariaDB. R8gd and M8gd database instances offer improved price-performance. For example, Optimized Reads on R8gd instances deliver up to 165% better throughput and up to 120% better price-performance over R6g instances for Aurora PostgreSQL.\n  Optimized Reads uses local NVMe-based SSD block storage available on these instances to store ephemeral data, such as temporary tables, reducing data access to/from network-based storage and improving read latency and throughput. The result is improved query performance for complex queries and faster index rebuild operations. Aurora PostgreSQL Optimized Reads instances using the I/O-Optimized configuration additionally use the local storage to extend their caching capacity. Database pages that are evicted from the in-memory buffer cache are cached in local storage to speed subsequent retrieval of that data.\n  Customers can get started with Optimized Reads through the AWS Management Console, CLI, and SDK by modifying their existing Aurora and RDS databases or creating a new database using R8gd or M8gd instances. These instances are available in the US East (N. Virginia, Ohio), US West (Oregon), Europe (Spain, Frankfurt), and Asia Pacific (Tokyo) Regions. For complete information on pricing and regional availability, please refer to the pricing page. For information on specific engine versions that support these DB instance types, please see the Aurora and RDS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-rds-optimized-reads-r8gd-m8gd-database-instances",
      "pubDate": "2025-11-18T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-9b1097f27203",
      "title": "AWS Transfer Family announces Terraform module to automate scanning of transferred files",
      "description": "AWS Transfer Family Terraform module now supports deployment of automated malware scanning workflows for files transferred using Transfer Family resources. This release streamlines centralized provisioning of threat detection workflows using Amazon GuardDuty S3 Protection, helping you meet data security requirements by identifying potential threats in transferred files.\n  AWS Transfer Family provides fully managed file transfers over SFTP, AS2, FTPS, FTP, and web browser-\n based interfaces for AWS storage services. Using the new module, you can programmatically provision workflows to scan incoming files, dynamically route files based on scan results, and generate threat notifications, in a single deployment. You can granularly implement threat detection for specific S3 prefixes while preserving folder structures post scanning, and ensure that only verified clean files reach your business applications and data lakes. This eliminates the overhead and risks associated with manual configurations, and provides a scalable deployment option for data security compliance.\n  Customers can get started by using the new module from the Terraform Registry. To learn more about Transfer Family, visit the product page and user guide. To see all the regions where Transfer Family is available, visit the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-transfer-family-terraform-module",
      "pubDate": "2025-11-18T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "support"
      ]
    },
    {
      "id": "aws-news-06b1a7b8cd3d",
      "title": "Your complete guide to Amazon Quick Suite at AWS re:Invent 2025",
      "description": "This year, re:Invent will be held in Las Vegas, Nevada, from December 1 to December 5, 2025, and this guide will help you navigate our comprehensive session catalog and plan your week. The sessions cater to business and technology leaders, product and engineering teams, and data and analytics teams interested in incorporating agentic AI capabilities across their teams and organization.",
      "link": "https://aws.amazon.com/blogs/machine-learning/your-complete-guide-to-amazon-quick-suite-at-aws-reinvent-2025/",
      "pubDate": "2025-11-17T19:26:56.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "ga"
      ]
    },
    {
      "id": "aws-news-10278621c4d1",
      "title": "Accelerate enterprise solutions with agentic AI-powered consulting: Introducing AWS Professional Service Agents",
      "description": "I'm excited to announce AWS Professional Services now offers specialized AI agents including the AWS Professional Services Delivery Agent. This represents a transformation to the consulting experience that embeds intelligent agents throughout the consulting life cycle to deliver better value for customers.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-enterprise-solutions-with-agentic-ai-powered-consulting-introducing-aws-professional-service-agents/",
      "pubDate": "2025-11-17T19:01:27.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-78f4b11efc59",
      "title": "Build a biomedical research agent with Biomni tools and Amazon Bedrock AgentCore Gateway",
      "description": "In this post, we demonstrate how to build a production-ready biomedical research agent by integrating Biomni's specialized tools with Amazon Bedrock AgentCore Gateway, enabling researchers to access over 30 biomedical databases through a secure, scalable infrastructure. The implementation showcases how to transform research prototypes into enterprise-grade systems with persistent memory, semantic tool discovery, and comprehensive observability for scientific reproducibility .",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-a-biomedical-research-agent-with-biomni-tools-and-amazon-bedrock-agentcore-gateway/",
      "pubDate": "2025-11-14T18:28:42.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "ga"
      ]
    },
    {
      "id": "aws-news-457bec95c2b9",
      "title": "Introducing agent-to-agent protocol support in Amazon Bedrock AgentCore Runtime",
      "description": "In this post, we demonstrate how you can use the A2A protocol for AI agents built with different frameworks to collaborate seamlessly. You'll learn how to deploy A2A servers on AgentCore Runtime, configure agent discovery and authentication, and build a real-world multi-agent system for incident response. We'll cover the complete A2A request lifecycle, from agent card discovery to task delegation, showing how standardized protocols eliminate the complexity of multi-agent coordination.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-agent-to-agent-protocol-support-in-amazon-bedrock-agentcore-runtime/",
      "pubDate": "2025-11-11T21:32:31.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}