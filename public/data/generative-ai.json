{
  "lastUpdated": "2026-02-09T06:53:03.416Z",
  "category": "generative-ai",
  "totalItems": 54,
  "items": [
    {
      "id": "aws-news-43e867f93eaa",
      "title": "Amazon Bedrock AgentCore Browser now supports browser profiles",
      "description": "Amazon Bedrock AgentCore Browser now supports browser profiles, enabling you to reuse authentication state across multiple browser sessions without repeated login flows. This feature reduces session setup time from minutes to tens of seconds for enterprise customers processing hundreds or thousands of automated browser sessions daily.\n \nBrowser profiles persist and reuse browser data including cookies and local storage across multiple sessions. You authenticate to a website once and save the session to a browser profile. When you start a new session using that saved profile, your authentication state is preserved, and you remain logged in. This enables agents to perform tasks on authenticated websites without manual login intervention. You can choose flexible session modes for both read-only and persistent operations, enabling parallel processing where multiple sessions use the same profile simultaneously.\n \nThis feature is available in all 14 AWS Regions where Amazon Bedrock AgentCore Browser is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), Asia Pacific (Seoul), and Canada (Central).\n \nTo learn more, visit the Browser Profiles documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-agentcore-browser-profiles",
      "pubDate": "2026-02-06T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-29ddb9057340",
      "title": "AWS Config now supports 30 new resource types",
      "description": "AWS Config now supports 30 additional AWS resource types across key services including Amazon EKS, Amazon Q, and AWS IoT. This expansion provides greater coverage over your AWS environment, enabling you to more effectively discover, assess, audit, and remediate an even broader range of resources.\n  With this launch, if you have enabled recording for all resource types, then AWS Config will automatically track these new additions. The newly supported resource types are also available in Config rules and Config aggregators.\n  You can now use AWS Config to monitor the following newly supported resource types in all AWS Regions where the supported resources are available:\n  Resource Types:\n  \n \n \n  \nAWS::ApplicationSignals::ServiceLevelObjective \n   AWS::IoT::SoftwarePackage \n  \nAWS::ARCZonalShift::AutoshiftObserverNotificationStatus      \n   AWS::IoT::TopicRule \n  \nAWS::B2BI::Transformer \n   AWS::IoTWireless::Destination \n  \nAWS::CE::CostCategory \n   AWS::IoTWireless::DeviceProfile \n  \nAWS::CleanRooms::ConfiguredTable \n   AWS::IoTWireless::NetworkAnalyzerConfiguration  \n  \nAWS::CleanRooms::Membership \n   AWS::IoTWireless::TaskDefinition \n  \nAWS::CodeArtifact::PackageGroup \n   AWS::IoTWireless::WirelessGateway \n  \nAWS::Connect::Prompt \n   AWS::Kinesis::ResourcePolicy \n  \nAWS::EKS::Nodegroup \n   AWS::PCAConnectorSCEP::Connector \n  \nAWS::GameLift::MatchmakingRuleSet \n   AWS::QBusiness::Application \n  \nAWS::GameLift::Script \n   AWS::QuickSight::DataSet \n  \nAWS::Glue::Crawler \n   AWS::QuickSight::Dashboard \n  \nAWS::InternetMonitor::Monitor \n   AWS::Route53::DNSSEC \n  \nAWS::IoT::BillingGroup \n   AWS::SSM::PatchBaseline \n  \nAWS::IoT::ResourceSpecificLogging \n   AWS::Transfer::User",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-config-new-resource-types",
      "pubDate": "2026-02-06T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "eks",
        "kinesis",
        "glue",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "eks",
        "kinesis",
        "glue",
        "quicksight",
        "launch",
        "ga",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-792a0c53071f",
      "title": "How Associa transforms document classification with the GenAI IDP Accelerator and Amazon Bedrock",
      "description": "Associa collaborated with the AWS Generative AI Innovation Center to build a generative AI-powered document classification system aligning with Associa’s long-term vision of using generative AI to achieve operational efficiencies in document management. The solution automatically categorizes incoming documents with high accuracy, processes documents efficiently, and provides substantial cost savings while maintaining operational excellence. The document classification system, developed using the Generative AI Intelligent Document Processing (GenAI IDP) Accelerator, is designed to integrate seamlessly into existing workflows. It revolutionizes how employees interact with document management systems by reducing the time spent on manual classification tasks.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-associa-transforms-document-classification-with-the-genai-idp-accelerator-and-amazon-bedrock/",
      "pubDate": "2026-02-05T20:41:52.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-eb570f9242d7",
      "title": "Reduce Mean Time to Resolution with an observability agent",
      "description": "In this post, we present an observability agent using OpenSearch Service and Amazon Bedrock AgentCore that can help surface root cause and get insights faster, handle multiple query-correlation cycles, and ultimately reduce MTTR even further.",
      "link": "https://aws.amazon.com/blogs/big-data/reduce-mean-time-to-resolution-with-an-observability-agent/",
      "pubDate": "2026-02-05T19:48:33.000Z",
      "source": "bigDataBlog",
      "services": [
        "bedrock",
        "agentcore",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-093fbdc9670f",
      "title": "Amazon EC2 G6e instances now available in the UAE region",
      "description": "Starting today, the Amazon EC2 G6e instances powered by NVIDIA L40S Tensor Core GPUs is now available in Middle East (UAE) Region. G6e instances can be used for a wide range of machine learning and spatial computing use cases.\n \nCustomers can use G6e instances to deploy large language models (LLMs) and diffusion models for generating images, video, and audio. Additionally, the G6e instances will unlock customers’ ability to create larger, more immersive 3D simulations and digital twins for spatial computing workloads. G6e instances feature up to 8 NVIDIA L40S Tensor Core GPUs with 48 GB of memory per GPU and third generation AMD EPYC processors. They also support up to 192 vCPUs, up to 400 Gbps of network bandwidth, up to 1.536 TB of system memory, and up to 7.6 TB of local NVMe SSD storage. \n  Amazon EC2 G6e instances are available today in the AWS US East (N. Virginia, Ohio), US West (Oregon), Asia Pacific (Tokyo, Seoul), Middle East (UAE) and Europe (Frankfurt, Spain, Stockholm) Regions. Customers can purchase G6e instances as On-Demand Instances, Reserved Instances, Spot Instances, or as part of Savings Plans.\n  To get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit the G6e instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-g6e-instances-uae-region/",
      "pubDate": "2026-02-05T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-639bbb72d5dd",
      "title": "Amazon EC2 I7ie instances now available in AWS Canada (Central)",
      "description": "AWS is announcing Amazon EC2 I7ie instances are now available in AWS Canada (Central) regions. Designed for large storage I/O intensive workloads, I7ie instances are powered by 5th Gen Intel Xeon Processors with an all-core turbo frequency of 3.2 GHz, offering up to 40% better compute performance and 20% better price performance over existing I3en instances. I7ie instances offer up to 120TB local NVMe storage density (highest in the cloud) for storage optimized instances and offer up to twice as many vCPUs and memory compared to prior generation instances. Powered by 3rd generation AWS Nitro SSDs, I7ie instances deliver up to 65% better real-time storage performance, up to 50% lower storage I/O latency, and 65% lower storage I/O latency variability compared to I3en instances.\n  I7ie are high density storage optimized instances, ideal for workloads requiring fast local storage with high random read/write performance at very low latency consistency to access large data sets. These instances are available in 9 different virtual sizes and deliver up to 100Gbps of network bandwidth and 60Gbps of bandwidth for Amazon Elastic Block Store (EBS).\n  To learn more, visit the I7ie instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-i7ie-instances-available-aws-canada/",
      "pubDate": "2026-02-05T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-22acca8edad5",
      "title": "Amazon EC2 High Memory U7i-6TB instances now available in AWS GovCloud (US-West)",
      "description": "Amazon EC2 High Memory U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in AWS GovCloud (US-West). U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-u7i-6tb-instances-available/",
      "pubDate": "2026-02-05T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-76536849a1c8",
      "title": "AWS Batch now supports unmanaged compute environments for Amazon EKS",
      "description": "AWS Batch now extends its job scheduling capabilities to unmanaged compute environments on Amazon EKS. With unmanaged EKS compute environments, you can leverage AWS Batch's job orchestration while maintaining full control over your Kubernetes infrastructure for security, compliance, or operational requirements.\n  With this capability, you can create unmanaged compute environments through CreateComputeEnvironment API and AWS Batch console by selecting your existing EKS cluster and specifying a Kubernetes namespace, then associate your EKS nodes with the compute environment using kubectl labeling.\n  AWS Batch supports developers, scientists, and engineers in running efficient batch processing for ML model training, simulations, and analysis at any scale. Unmanaged compute environments on Amazon EKS are available today in all AWS regions where AWS Batch is available. For more information, see the AWS Batch User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-batch-on-eks-unmanaged-compute-environments",
      "pubDate": "2026-02-04T20:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-d7fcc4742b73",
      "title": "Amazon EC2 G7e instances now available in US West (Oregon) region",
      "description": "Starting today, Amazon EC2 G7e instances accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs are now available in US West (Oregon) region. G7e instances offer up to 2.3x inference performance compared to G6e.\n \nCustomers can use G7e instances to deploy large language models (LLMs), agentic AI models, multimodal generative AI models, and physical AI models. G7e instances offer the highest performance for spatial computing workloads as well as workloads that require both graphics and AI processing capabilities. G7e instances feature up to 8 NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, with 96 GB of memory per GPU, and 5th Generation Intel Xeon processors. They support up to 192 virtual CPUs (vCPUs) and up to 1600 Gbps of networking bandwidth. G7e instances support NVIDIA GPUDirect Peer to Peer (P2P) that boosts performance for multi-GPU workloads. Multi-GPU G7e instances also support NVIDIA GPUDirect Remote Direct Memory Access (RDMA) with EFA in EC2 UltraClusters, reducing latency for small-scale multi-node workloads.\n \nYou can use G7e instances for Amazon EC2 in the following AWS Regions: US West (Oregon), US East (N. Virginia) and US East (Ohio). You can purchase G7e instances as On-Demand Instances, Spot Instances, or as part of Savings Plans.\n \nTo get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit G7e instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-g7e-instances-oregon-region/",
      "pubDate": "2026-02-04T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-fe5f77e82b59",
      "title": "Introducing Amazon EC2 C8id, M8id, and R8id instances",
      "description": "AWS is announcing the general availability of new Amazon EC2 C8id, M8id, and R8id instances powered by custom Intel Xeon 6 processors. These instances deliver up to 43% higher performance and 3.3x more memory bandwidth compared to previous generation C6id, M6id, and R6id instances.\n  C8id, M8id, and R8id instances offer up to 384 vCPUs, 3TiB of memory, and 22.8TB of NVMe SSD storage, 3x more than previous generation instances. These instances deliver up to 46% higher performance for I/O intensive database workloads, and up to 30% faster query results for I/O intensive real-time data analytics than previous sixth-generation instances. Additionally, these instances support Instance Bandwidth Configuration, allowing 25% flexible allocation between network and EBS bandwidth, allocating resources optimally for each workload.\n  C8id instances are ideal for compute-intensive workloads such as high-performance web servers, batch processing, distributed analytics, ad serving, video encoding, and gaming servers. M8id instances are well-suited for balanced workloads including application servers, microservices, enterprise applications, and small to medium databases. R8id instances are ideal for memory-intensive workloads such as in-memory databases, real-time big data analytics, large in-memory caches, and scientific computing applications.\n  C8id, M8id and R8id instances are available in US East (N. Virginia), US East (Ohio), and US West (Oregon). R8id instances are additionally available in Europe (Frankfurt). Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information visit the Amazon EC2 instance type page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8id-m8id-r8id-instances/",
      "pubDate": "2026-02-04T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-d70403809532",
      "title": "Democratizing business intelligence: BGL’s journey with Claude Agent SDK and Amazon Bedrock AgentCore",
      "description": "BGL is a leading provider of self-managed superannuation fund (SMSF) administration solutions that help individuals manage the complex compliance and reporting of their own or a client’s retirement savings, serving over 12,700 businesses across 15 countries. In this blog post, we explore how BGL built its production-ready AI agent using Claude Agent SDK and Amazon Bedrock AgentCore.",
      "link": "https://aws.amazon.com/blogs/machine-learning/democratizing-business-intelligence-bgls-journey-with-claude-agent-sdk-and-amazon-bedrock-agentcore/",
      "pubDate": "2026-02-03T20:28:29.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex"
      ]
    },
    {
      "id": "aws-news-febb53dcaed8",
      "title": "Use Amazon Quick Suite custom action connectors to upload text files to Google Drive using OpenAPI specification",
      "description": "In this post, we demonstrate how to build a secure file upload solution by integrating Google Drive with Amazon Quick Suite custom connectors using Amazon API Gateway and AWS Lambda.",
      "link": "https://aws.amazon.com/blogs/machine-learning/use-amazon-quick-suite-custom-action-connectors-to-upload-text-files-to-google-drive-using-openapi-specification/",
      "pubDate": "2026-02-03T19:14:30.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q",
        "lambda",
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "lambda",
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-137f18b50c6c",
      "title": "AI agents in enterprises: Best practices with Amazon Bedrock AgentCore",
      "description": "This post explores nine essential best practices for building enterprise AI agents using Amazon Bedrock AgentCore. Amazon Bedrock AgentCore is an agentic platform that provides the services you need to create, deploy, and manage AI agents at scale. In this post, we cover everything from initial scoping to organizational scaling, with practical guidance that you can apply immediately.",
      "link": "https://aws.amazon.com/blogs/machine-learning/ai-agents-in-enterprises-best-practices-with-amazon-bedrock-agentcore/",
      "pubDate": "2026-02-03T18:44:43.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "ga"
      ]
    },
    {
      "id": "aws-news-68e81d0b319e",
      "title": "Optimizing Flink’s join operations on Amazon EMR with Alluxio",
      "description": "In this post, we show you how to implement real-time data correlation using Apache Flink to join streaming order data with historical customer and product information, enabling you to make informed decisions based on comprehensive, up-to-date analytics. We also introduce an optimized solution to automatically load Hive dimension table data into Alluxio Universal Flash Storage (UFS) through the Alluxio cache layer. This enables Flink to perform temporal joins on changing data, accurately reflecting the content of a table at specific points in time.",
      "link": "https://aws.amazon.com/blogs/big-data/optimizing-flinks-join-operations-on-amazon-emr-with-alluxio/",
      "pubDate": "2026-02-03T18:41:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-d26c33084ae7",
      "title": "AWS Lake Formation is now available in Asia Pacific (New Zealand) Region",
      "description": "AWS Lake Formation is now available in the Asia Pacific (New Zealand) Region, enabling you to centrally manage and scale fine-grained data access permissions and share data securely within and outside your organization.\n  AWS Lake Formation is a service that allows you to define where your data resides and what data access and security policies you want to apply. Your users can then access the centralized AWS Glue Data Catalog which describes available data sets and their appropriate usage. Your users can then usethese data sets with their choice of analytics and machine learning services, like Amazon EMR for Apache Spark, Amazon Redshift, AWS Glue, Amazon QuickSight, and Amazon Athena.\n  To learn more about Lake Formation, visit the documentation. For AWS Lake Formation Region availability, please see the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/AWS-Lake-Formation-Asia-Pacific-New-Zealand-Region",
      "pubDate": "2026-02-03T18:14:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "emr",
        "redshift",
        "glue",
        "athena",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "emr",
        "redshift",
        "glue",
        "athena",
        "quicksight",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-ed5a3e662c9b",
      "title": "Agentic AI for healthcare data analysis with Amazon SageMaker Data Agent",
      "description": "On November 21, 2025, Amazon SageMaker introduced a built-in data agent within Amazon SageMaker Unified Studio that transforms large-scale data analysis. In this post, we demonstrate, through a detailed case study of an epidemiologist conducting clinical cohort analysis, how SageMaker Data Agent can help reduce weeks of data preparation into days, and days of analysis development into hours—ultimately accelerating the path from clinical questions to research conclusions.",
      "link": "https://aws.amazon.com/blogs/machine-learning/agentic-ai-for-healthcare-data-analysis-with-amazon-sagemaker-data-agent/",
      "pubDate": "2026-02-03T16:22:19.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "eks"
      ]
    },
    {
      "id": "aws-news-22cf1591c116",
      "title": "Amazon RDS for MySQL now supports new minor versions 8.0.45 and 8.4.8",
      "description": "Amazon Relational Database Service (Amazon RDS) for MySQL now supports MySQL minor versions 8.0.45 and 8.4.8, the latest minors released by the MySQL community. We recommend upgrading to the newer minor versions to fix known security vulnerabilities in prior versions of MySQL and to benefit from bug fixes, performance improvements, and new functionality added by the MySQL community. Learn more about the enhancements in RDS for MySQL 8.0.45 and 8.4.8 in the Amazon RDS user guide.\n  You can leverage automatic minor version upgrades to automatically upgrade your databases to more recent minor versions during scheduled maintenance windows. You can also use Amazon RDS Managed Blue/Green deployments for safer, simpler, and faster updates to your MySQL instances. Learn more about upgrading your database instances, including automatic minor version upgrades and Blue/Green Deployments, in the Amazon RDS User Guide.\n  Amazon RDS for MySQL makes it simple to set up, operate, and scale MySQL deployments in the cloud. Learn more about pricing details and regional availability at Amazon RDS for MySQL. Create or update a fully managed Amazon RDS for MySQL database in the Amazon RDS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-rds-mysql-minor-versions/",
      "pubDate": "2026-02-02T18:47:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "update",
        "improvement",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-d5f4b6b2d6d3",
      "title": "How Clarus Care uses Amazon Bedrock to deliver conversational contact center interactions",
      "description": "In this post, we illustrate how Clarus Care, a healthcare contact center solutions provider, worked with the AWS Generative AI Innovation Center (GenAIIC) team to develop a generative AI-powered contact center prototype. This solution enables conversational interaction and multi-intent resolution through an automated voicebot and chat interface. It also incorporates a scalable service model to support growth, human transfer capabilities--when requested or for urgent cases--and an analytics pipeline for performance insights.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-clarus-care-uses-amazon-bedrock-to-deliver-conversational-contact-center-interactions/",
      "pubDate": "2026-02-02T16:34:21.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova",
        "support"
      ]
    },
    {
      "id": "aws-news-c0c49cd38ca2",
      "title": "AWS HealthImaging adds JPEG XL support",
      "description": "AWS HealthImaging now supports storing and retrieving lossy compressed medical images in the JPEG XL transfer syntax (1.2.840.10008.1.2.4.112). It is now simpler than ever to integrate HealthImaging with applications that require JPEG XL encoded DICOM data, such as digital pathology whole slide imaging systems.\n \nWith this launch, HealthImaging stores your JPEG XL Lossy image data without transcoding, which maintains the fidelity of your data and reduces your storage costs. Further, you can retrieve stored image frames in the JPEG XL format without the latency of transcoding at retrieval time.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-healthimaging-adds-jpeg-xl",
      "pubDate": "2026-02-02T16:29:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-b3a6b988e927",
      "title": "Amazon CloudWatch Application Signals now supports integration with Kiro powers",
      "description": "Today, AWS announces Amazon CloudWatch Application Signals integration with Kiro powers, enabling developers and operators to investigate application health issues faster with AI agent-assisted workflows in Kiro. Kiro Powers is a repository of curated and pre-packaged Model Context Protocol (MCP) servers, steering files, and hooks validated by Kiro partners to accelerate specialized software development and deployment use cases.\n  Kiro power for Amazon CloudWatch Application Signals packages the Application Signals MCP server with targeted observability guidance, giving the Kiro agent instant context for service health monitoring, SLO compliance, and investigation workflows. With Kiro power for Application Signals, developers can now accelerate troubleshooting their distributed applications in minutes instead of spending hours, directly in their IDE. For example, developers triaging an SLO or isolating an impacted service or operation, the Kiro power will dynamically load the relevant guidance and operational signals, so AI agents receive only the context needed for the specific task at hand.\n \nAmazon CloudWatch Application Signals Kiro power Kiro power is available within Kiro IDE and Kiro powers webpage for one-click installation in all AWS Regions. To learn more about Application signals MCP server, visit our documentation. Amazon CloudWatch Application Signals helps you monitor and improve application performance on AWS by automatically collecting application telemetry and enabling you to track application health, performance, and service relationships. To get started, see the Amazon CloudWatch Application Signals documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/cloudwatch-application-signals-kiro-powers",
      "pubDate": "2026-01-30T20:16:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudwatch",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-57f8bfeb6fb5",
      "title": "Amazon RDS for Oracle now supports cross-Region replicas with additional storage volumes",
      "description": "Amazon RDS for Oracle now supports cross-Region replicas with additional storage volumes. With additional storage volumes, customers can add up to three storage volumes, each with up to 64 TiB, in addition to the primary storage volume for their database instance. As a result, customers get flexibility to add or remove storage with evolving workload demands, without incurring application downtime, and set up their database instance with up to 256 TiB storage. Now, with support for cross-Region replicas, customers that set up database instances with cross-Region replicas for business-critical applications also get the benefit of using additional storage volumes for storage flexibility.\n  When you create a cross-Region replica for a database instance that is set up with additional storage volumes, Amazon RDS for Oracle automatically configures the same storage layout on the replica. Subsequently, you can apply changes to additional storage volumes on the primary instance and the replica using the AWS Management Console, AWS CLI, or AWS SDK. In disaster recovery situations, you can promote a cross-Region replica to serve as the new standalone database, or execute a switchover to reverse roles between the primary database and the replica to meet low recovery point objective (RPO) and recovery time objective (RTO) for business critical applications.\n  You will need an Oracle Database Enterprise Edition (EE) license to use replicas in mounted mode, and an additional Oracle Active Data Guard license to use replicas in read-only mode. We recommend consulting your legal team or licensing expert to verify Oracle license requirements for your specific use case. Amazon RDS for Oracle cross-Region replicas with additional storage volumes is available in all AWS Regions including the AWS GovCloud (US) Regions. To learn more, see Amazon RDS for Oracle User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/rds-for-oracle-cross-region-replicas-additional-storage-volumes",
      "pubDate": "2026-01-30T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "rds",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-a1f9c6f03b3d",
      "title": "Scaling content review operations with multi-agent workflow",
      "description": "The agent-based approach we present is applicable to any type of enterprise content, from product documentation and knowledge bases to marketing materials and technical specifications. To demonstrate these concepts in action, we walk through a practical example of reviewing blog content for technical accuracy. These patterns and techniques can be directly adapted to various content review needs by adjusting the agent configurations, tools, and verification sources.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scaling-content-review-operations-with-multi-agent-workflow/",
      "pubDate": "2026-01-29T23:32:14.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-2bbf3449a6da",
      "title": "More room to build: serverless services now support payloads up to 1 MB",
      "description": "To support cloud applications that increasingly depend on rich contextual data, AWS is raising the maximum payload size from 256 KB to 1 MB for asynchronous AWS Lambda function invocations, Amazon Amazon SQS, and Amazon EventBridge. Developers can use this enhancement to build and maintain context-rich event-driven systems and reduce the need for complex workarounds such as data chunking or external large object storage.",
      "link": "https://aws.amazon.com/blogs/compute/more-room-to-build-serverless-services-now-support-payloads-up-to-1-mb/",
      "pubDate": "2026-01-29T22:16:14.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "lambda",
        "eventbridge",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "lambda",
        "eventbridge",
        "sqs",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-b60e47043c5f",
      "title": "Announcing increased 1 MB payload size support in Amazon EventBridge",
      "description": "Amazon EventBridge increases event payload size from 256 KB to 1 MB, enabling developers to ingest richer, complex payloads for their event-driven workloads without the need to split, compress, or externalize data.\n  Amazon EventBridge is a serverless event router that enables you to create scalable event-driven applications by routing events between your applications, third-party SaaS applications, and AWS services. These applications often need to process rich contextual data, including large-language model prompts, telemetry signals, and complex JSON structures for machine learning outputs. The new 1MB payload support in EventBridge Event Buses enables developers to streamline their architectures by including comprehensive data in a single event, reducing the need for complex data chunking or external storage solutions.\n  This feature is available in all commercial AWS Regions where Amazon EventBridge is offered, except Asia Pacific (New Zealand), Asia Pacific (Thailand), Asia Pacific (Malaysia), Asia Pacific (Taipei), and Mexico (Central). For a full list, see the AWS Regional Services List. To learn more, visit the EventBridge documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-eventbridge-increases-event-payload-size-256-kb-1-mb",
      "pubDate": "2026-01-29T18:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "eventbridge"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "eventbridge",
        "support"
      ]
    },
    {
      "id": "aws-news-0c96f506fa43",
      "title": "Amazon Bedrock now supports server-side custom tools using the Responses API",
      "description": "Amazon Bedrock now supports server-side tools in the Responses API using OpenAI API-compatible service endpoints. Bedrock already supports client-side tool use with the Converse, Chat Completions, and Responses APIs. Now, with the launch of server-side tool use for Responses API, Amazon Bedrock calls the tools directly without going through a client, enabling your AI applications to perform real-time, multi-step actions such as searching the web, executing code, and updating databases within the organizational, governance, compliance, and security boundaries of your AWS accounts. You can either submit your own custom Lambda function to run custom tools or use AWS-provided tools, such as notes and tasks.\n \nServer-side tools using the Responses API is available starting today with OpenAI's GPT OSS 20B/120B models in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Mumbai), South America (São Paulo), Europe (Ireland), Europe (London), and Europe (Milan) AWS Regions. Support for other regions and models is coming soon.\n \nTo get started, visit the service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-server-side-custom-tools-responses-api",
      "pubDate": "2026-01-29T18:09:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lambda",
        "launch",
        "ga",
        "support",
        "coming-soon"
      ]
    },
    {
      "id": "aws-news-a174e0b471b0",
      "title": "Amazon Cognito introduces inbound federation Lambda triggers",
      "description": "Amazon Cognito introduces inbound federation Lambda triggers that enable you to transform and customize federated user attributes during the authentication process. You can now modify responses from external SAML and OIDC providers before they are stored in your user pool, providing complete programmatic control over the federation flow without requiring changes to your identity provider configuration..\n \nInbound federation Lambda trigger addresses current limitations in federated authentication workflows, particularly issues caused by attribute size limits and the need for selective attribute storage from external identity providers. For example, large group attributes from external SAML or OIDC identity providers that exceed Cognito’s 2,048 character limit per attribute can block the authentication flow. This capability allows you to add, override, or suppress attribute values, such as modifying large group attributes, before creating new federated users or updating existing federated user profiles in Cognito.\n \nThe new inbound federation Lambda trigger is available through hosted UI (classic) and managed login in all AWS Regions where Amazon Cognito is available. To get started, configure the trigger using the AWS Management Console, AWS Command Line Interface (CLI), AWS Software Development Kits (SDKs), Cloud Development Kit (CDK), or AWS CloudFormation by adding the new parameter to your User Pool LambdaConfig. To learn more, see the Amazon Cognito Developer Guide for implementation examples and best practices.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-cognito-inbound-federation-lambda-trigger/",
      "pubDate": "2026-01-29T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "cloudformation"
      ]
    },
    {
      "id": "aws-news-07b0ac10943d",
      "title": "Amazon Keyspaces (for Apache Cassandra) introduces pre-warming with WarmThroughput for your tables",
      "description": "Amazon Keyspaces (for Apache Cassandra) now supports table pre-warming, allowing you to proactively prepare both new and existing tables to meet future traffic demands. This capability is available for tables in both provisioned and on-demand capacity modes, including multi-Region replicated tables.\n  Amazon Keyspaces (for Apache Cassandra) is a scalable, highly available, and managed Apache Cassandra–compatible database service. Amazon Keyspaces is serverless, so you pay for only the resources that you use and you can build applications that serve thousands of requests per second with virtually unlimited throughput and storage.\n  While Amazon Keyspaces automatically scales to accommodate growing workloads, certain scenarios like application launches, marketing campaigns, or seasonal events can create sudden traffic spikes that exceed normal scaling patterns. With pre-warming, you can now manually specify your expected peak throughput requirements during table creation or update operations, ensuring your tables are immediately ready to handle large traffic surges without scaling delays or increased error rates.\n  The pre-warming process is non-disruptive and runs asynchronously, allowing you to continue making other table modifications while pre-warming is in progress. Pre-warming incurs a one-time charge based on the difference between your specified values and the baseline capacity. The feature is now available in all AWS Commercial and AWS GovCloud (US) Regions where Amazon Keyspaces is offered. To learn more, visit the pre-warming launch blog or Amazon Keyspaces documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-keyspaces-apache-cassandra-pre-warming-warmthroughput-tables",
      "pubDate": "2026-01-29T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-4ced7eefbe8f",
      "title": "AWS announces Deployment Agent SOPs in AWS MCP Server (preview)",
      "description": "AWS announces the launch of deployment Standard Operating Procedures (SOPs) available in the AWS MCP Server. SOPs are structured, natural language instructions that guide AI agents through complex, multi-step tasks to ensure consistent, reliable, and efficient behavior. With these automated procedures, customers can deploy web applications to their AWS account using natural language prompts from any MCP-compatible IDE or CLI, including Kiro, Kiro CLI, Cursor, and Claude Code. Deployment works by generating AWS CDK infrastructure, deploying CloudFormation stacks, and creating CI/CD pipelines with recommended AWS security best practices.\n  Previously, developers struggled to take their vibe-coded applications to production with DevOps best practices in place. Now, developers can move quickly from prototype to production in as little as one prompt. When you ask your AI assistant configured with AWS MCP Server to deploy your web application, your AI agent will follow the multi-step plan defined in Agent SOPs to analyze the project structure, generate CDK infrastructure, and deploy a preview environment hosted on Amazon S3 and Amazon CloudFront. Once you are ready, it can configure AWS CodePipeline for automated production deployments from source repositories, setting up CI/CD automatically for your application. The Agent SOPs support web applications built with popular frameworks including React, Vue.js, Angular, and Next.js. Deployment documentation is automatically created in the repository, enabling agents to handle future deployments, query logs for troubleshooting and resume work across sessions.\n  The Agent SOPs are available in preview as part of the AWS MCP Server at no additional cost in the US East (N. Virginia) Region. You pay only for AWS resources you create and applicable data transfer costs. To get started, see the AWS MCP Server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/01/aws-announces-deployment-agent-sops-in-aws-mcp-server-preview",
      "pubDate": "2026-01-29T12:01:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "cloudformation",
        "cloudfront"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "cloudformation",
        "cloudfront",
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-defad7b9850a",
      "title": "Amazon EC2 R7gd instances are now available in Europe (Paris) Region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R7gd instances with up to 3.8 TB of local NVMe-based SSD block-level storage are available in Europe (Paris) Region.\n  R7gd are powered by AWS Graviton3 processors with DDR5 memory are built on the AWS Nitro System. They are ideal for memory-intensive workloads such as open-source databases, in-memory caches, and real-time big data analytics and are a great fit for applications that need access to high-speed, low latency local storage, including those that need temporary storage of data for scratch space, temporary files, and caches. \n  To learn more, see Amazon R7gd Instances. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/r7gd-instances-available-in-paris",
      "pubDate": "2026-01-28T18:18:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-fba5027dd519",
      "title": "Modernize game intelligence with generative AI on Amazon Redshift",
      "description": "In this post, we discuss how you can use Amazon Redshift as a knowledge base to provide additional context to your LLM. We share best practices and explain how you can improve the accuracy of responses from the knowledge base by following these best practices.",
      "link": "https://aws.amazon.com/blogs/big-data/modernize-game-intelligence-with-generative-ai-on-amazon-redshift/",
      "pubDate": "2026-01-28T17:54:53.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "redshift",
        "ga"
      ]
    },
    {
      "id": "aws-news-d62224513350",
      "title": "AWS Network Firewall now supports GenAI traffic visibility and enforcement with Web category-based filtering",
      "description": "AWS Network Firewall now provides visibility into generative AI (GenAI) application traffic and supports traffic filtering based on web categories. This new capability simplifies governance by enabling you to identify and control access to GenAI services, social media platforms, streaming sites, and other web categories directly within your firewall rules using pre-defined URL categories.\n  This approach of inspecting traffic based on URL categories helps security and compliance teams enforce consistent policies across their AWS environments while providing visibility into usage of emerging technologies like GenAI. You can now easily block access to inappropriate or high-risk domains, restrict GenAI tool usage to approved services, and meet regulatory requirements—all while reducing operational overhead. When combined with AWS Network Firewall's TLS inspection feature, you can inspect the full URL path using category-based rules for even more granular control.\n  This feature is available in all AWS commercial regions where AWS Network Firewall is supported.\n  To learn more about URL category filtering in AWS Network Firewall, visit AWS Network Firewall product page and service documentation. You can get started by updating your stateful rule groups in the AWS Management Console, AWS CLI, or AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-network-firewall-web-category-based-filtering",
      "pubDate": "2026-01-27T19:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-91aabbbbb459",
      "title": "Get started faster with one-click onboarding, serverless notebooks, and AI agents in Amazon SageMaker Unified Studio",
      "description": "Using Amazon SageMaker Unified Studio serverless notebooks, AI-assisted development, and unified governance, you can speed up your data and AI workflows across data team functions while maintaining security and compliance. In this post, we walk you through how these new capabilities in SageMaker Unified Studio can help you consolidate your fragmented data tools, reduce time to insight, and collaborate across your data teams.",
      "link": "https://aws.amazon.com/blogs/big-data/get-started-faster-with-one-click-onboarding-serverless-notebooks-and-ai-agents-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2026-01-27T18:54:19.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "unified studio"
      ]
    },
    {
      "id": "aws-news-e46f8829dff7",
      "title": "Build reliable Agentic AI solution with Amazon Bedrock: Learn from Pushpay’s journey on GenAI evaluation",
      "description": "In this post, we walk you through Pushpay's journey in building this solution and explore how Pushpay used Amazon Bedrock to create a custom generative AI evaluation framework for continuous quality assurance and establishing rapid iteration feedback loops on AWS.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-reliable-agentic-ai-solution-with-amazon-bedrock-learn-from-pushpays-journey-on-genai-evaluation/",
      "pubDate": "2026-01-27T17:39:57.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-470ab53245e2",
      "title": "Amazon RDS for PostgreSQL, MySQL and MariaDB now support r6id and r6gd database instances in additional AWS Regions",
      "description": "AWS memory optimized R6id database instances are now generally available for Amazon RDS for PostgreSQL, MySQL, and MariaDB in the Tel Aviv region. R6gd instances are now supported for Amazon RDS for PostgreSQL, MySQL, and MariaDB in Asia Pacific (Osaka), and EU (Spain, Zurich) regions.\n   AWS Graviton2-based instances provide up to 40% performance improvement over R5-based instances of equivalent sizes on Amazon Aurora and Amazon RDS databases, depending on database engine, version, and workload. R6gd instances also deliver local NVMe-based block level storage for low latency local storage. Memory-optimized R6id instances offer 58% higher TB storage per vCPU and 15% better price performance when compared with R5d instances.\n  You can easily launch R6gd or R6id database instances through the Amazon RDS Management Console or by using the AWS Command Line Interface (CLI). For detailed information about specific engine versions that support these database instance types, please refer to the Aurora and RDS documentation. For complete information on pricing and regional availability, please refer to the Amazon RDS pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-product-generally-available-rds-r6id-r6gd-expansion",
      "pubDate": "2026-01-27T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "graviton",
        "launch",
        "generally-available",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-3828f9f85f34",
      "title": "Build an intelligent contract management solution with Amazon Quick Suite and Bedrock AgentCore",
      "description": "This blog post demonstrates how to build an intelligent contract management solution using Amazon Quick Suite as your primary contract management solution, augmented with Amazon Bedrock AgentCore for advanced multi-agent capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-contract-management-solution-with-amazon-quick-suite-and-bedrock-agentcore/",
      "pubDate": "2026-01-27T16:28:16.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "amazon q"
      ]
    },
    {
      "id": "aws-news-b1fd3f7521e3",
      "title": "Amazon Lightsail expands blueprint selection with updated support for Node.js, LAMP, and Ruby on Rails blueprints",
      "description": "Amazon Lightsail now offers new Node.js, LAMP, and Ruby on Rails blueprints. These new blueprints have Instance Metadata Service Version 2 (IMDSv2) enforced by default. With just a few clicks, you can create a Lightsail virtual private server (VPS) of your preferred size with Node.js, LAMP, or Ruby on Rails preinstalled.\n  With Lightsail, you can easily get started on the cloud by choosing a blueprint and an instance bundle to build your web application. Lightsail instance bundles include instances preinstalled with your preferred operating system, storage, and monthly data transfer allowance, giving you everything you need to get up and running quickly.\n  These new blueprints are now available in all AWS Regions where Lightsail is available. For more information on blueprints supported on Lightsail, see Lightsail documentation. For more information on pricing, or to get started with your free trial, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-lightsail-nodejs-lamp-and-ruby-on-rails/",
      "pubDate": "2026-01-26T22:45:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-cd2c23a82364",
      "title": "Build a serverless AI Gateway architecture with AWS AppSync Events",
      "description": "In this post, we discuss how to use AppSync Events as the foundation of a capable, serverless, AI gateway architecture. We explore how it integrates with AWS services for comprehensive coverage of the capabilities offered in AI gateway architectures. Finally, we get you started on your journey with sample code you can launch in your account and begin building.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-a-serverless-ai-gateway-architecture-with-aws-appsync-events/",
      "pubDate": "2026-01-26T17:20:27.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-c5251005780f",
      "title": "How Totogi automated change request processing with Totogi BSS Magic and Amazon Bedrock",
      "description": "This blog post describes how Totogi automates change request processing by partnering with the AWS Generative AI Innovation Center and using the rapid innovation capabilities of Amazon Bedrock.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-totogi-automated-change-request-processing-with-totogi-bss-magic-and-amazon-bedrock/",
      "pubDate": "2026-01-26T16:16:25.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-424a910d5c85",
      "title": "Amazon Route 53 Domains adds support for .ai, and other top-level domains",
      "description": "Amazon Route 53 Domains now supports registration and management of ten new top-level domains (TLDs): .ai, .nz, .shop, .bot, .moi, .spot, .free, .deal, .now, and .hot. This expansion enhances Route 53's capabilities as a domain registration and DNS management service, offering customers more options to establish their online presence. With these additions, businesses and individuals can now leverage domain names tailored to specific industries, regions, or purposes directly through Amazon Web Services (AWS).\n  The new TLDs cater to various use cases. To name a few, the .ai domain, originally for Anguilla, has become popular among artificial intelligence companies. E-commerce sites can utilize .shop for their online storefronts. The .bot domain suits chatbot and AI-related services. The .now domain works well for time-sensitive services and instant delivery platforms. Users can register these domains through the Route 53 console, AWS CLI, or SDKs, enjoying integrated DNS management and automatic renewal features. This seamless integration allows for efficient domain administration alongside existing Route 53 hosted zones and DNS records.\n  To learn more about Amazon Route 53 Domains and start registering new domains, visit the Amazon Route 53 page. Domain registration pricing varies by TLD. Visit the pricing page for detailed pricing information.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/1/amazon-route-53-domains-adds-support-for-.ai-and-other-top-level-domains/",
      "pubDate": "2026-01-23T20:07:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-05211307b5cd",
      "title": "Build AI agents with Amazon Bedrock AgentCore using AWS CloudFormation",
      "description": "Amazon Bedrock AgentCore services are now being supported by various IaC frameworks such as AWS Cloud Development Kit (AWS CDK), Terraform and AWS CloudFormation Templates. This integration brings the power of IaC directly to AgentCore so developers can provision, configure, and manage their AI agent infrastructure. In this post, we use CloudFormation templates to build an end-to-end application for a weather activity planner.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-ai-agents-with-amazon-bedrock-agentcore-using-aws-cloudformation/",
      "pubDate": "2026-01-23T17:54:02.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "cloudformation",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-734b7da2685c",
      "title": "Announcing general availability of Amazon EC2 M4 Max Mac instances",
      "description": "Amazon Web Services announces general availability of Amazon EC2 M4 Max Mac instances, powered by the latest Mac Studio hardware. Amazon EC2 M4 Max Mac instances are the next-generation EC2 Mac instances, that enable Apple developers to migrate their most demanding build and test workloads onto AWS. These instances are ideal for building and testing applications for Apple platforms such as iOS, macOS, iPadOS, tvOS, watchOS, visionOS, and Safari.\n  Amazon EC2 M4 Max Mac instances offer up to 25% better application build performance compared to Amazon EC2 M1 Ultra Mac instances. M4 Max Mac instances are powered by the AWS Nitro System, providing up to 10 Gbps network bandwidth and 8 Gbps of Amazon Elastic Block Store (Amazon EBS) storage bandwidth. These instances are built on Apple M4 Max Mac Studio computers featuring a 16-core CPU, 40-core GPU, 16-core Neural Engine, and 128GB of unified memory. \n \nAmazon EC2 M4 Max Mac instances are available in US East (N. Virginia) and US West (Oregon).  To learn more about Amazon EC2 M4 Max Mac instances, visit the Amazon EC2 Mac page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ec2-m4-max-mac-instances-ga",
      "pubDate": "2026-01-23T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-2e90c0da2729",
      "title": "AWS Config launches 13 new managed rules",
      "description": "AWS Config announces launch of an additional 13 managed Config rules for various use cases such as security, durability, and operations. You can now search, discover, enable and manage these additional rules directly from AWS Config and govern more use cases for your AWS environment.\n  With this launch, you can now enable these controls across your account or across your organization. For example, you can assess your security posture across Amazon Cognito User pools, Amazon EBS Snapshots, AWS Cloudformation Stacks and more. Additionally, you can leverage Conformance Packs to group these new controls and deploy across an account or across organization, streamlining your multi-account governance.\n  For the full list of recently released rules, visit the AWS Config developer guide. For description of each rule and the AWS Regions in which it is available, please refer our Config managed rules documentation. To start using Config rules, please refer our documentation.\n  New Rules Launched:\n  \n \n \nAURORA_GLOBAL_DATABASE_ENCRYPTION_AT_REST\n \n \nCLOUDFORMATION_STACK_SERVICE_ROLE_CHECK\n \n \nCLOUDFORMATION_TERMINATION_PROTECTION_CHECK\n \n \nCLOUDFRONT_DISTRIBUTION_KEY_GROUP_ENABLED\n \n \nCOGNITO_USER_POOL_DELETE_PROTECTION_ENABLED\n \n \nCOGNITO_USER_POOL_MFA_ENABLED\n \n \nCOGNITO_USERPOOL_CUST_AUTH_THREAT_FULL_CHECK\n \n \nEBS_SNAPSHOT_BLOCK_PUBLIC_ACCESS\n \n \nECS_CAPACITY_PROVIDER_TERMINATION_CHECK\n \n \nECS_TASK_DEFINITION_EFS_ENCRYPTION_ENABLED\n \n \nECS_TASK_DEFINITION_LINUX_USER_NON_ROOT\n \n \nECS_TASK_DEFINITION_WINDOWS_USER_NON_ADMIN\n \n \nSES_SENDING_TLS_REQUIRED",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-config-launches-new-rules/",
      "pubDate": "2026-01-22T18:06:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "cloudformation",
        "cloudfront"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ecs",
        "cloudformation",
        "cloudfront",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-f4d657f0df55",
      "title": "Now available: 48xlarge and metal-48xl sizes for EBS optimized Amazon EC2 instances",
      "description": "Today, AWS announces the general availability of the Amazon Elastic Block Storage (Amazon EBS) optimized Amazon Elastic Compute Cloud (Amazon EC2) C8gb, M8gb, and R8gb instances in 48xlarge sizes. We are also offering C8gb and R8gb in metal-48xl sizes. These instances are powered by AWS Graviton4 processors to deliver up to 30% better compute performance than AWS Graviton3 processors. At up to 300 Gbps of EBS bandwidth, these instances offer the highest EBS performance among non-accelerated compute EC2 instances. Take advantage of the higher block storage performance offered by these new EBS optimized EC2 instances to scale the performance and throughput of a wide variety of workloads.\n \nFor increased scalability, these instances offer sizes up to 48xlarge, including two metal sizes (C8gb and R8gb only), 3 varieties of memory to vCPUs ratios, up to 300 Gbps of EBS bandwidth, up to 400 Gbps of networking bandwidth. Offering up to 1440K IOPS, these instances have the highest Amazon EBS IOPS performance in Amazon EC2. These new instances support Elastic Fabric Adapter (EFA) networking, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n \nThe new instance sizes are available in US East (N. Virginia) and US West (Oregon) regions. Metal sizes are only available in US East (N. Virginia) region.\n \nTo learn more, see Amazon C8gb, M8gb, and R8gb Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/graviton4-ebs-optimized-larger-sizes",
      "pubDate": "2026-01-22T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-fe519ae0618f",
      "title": "Amazon MQ now supports Java Messaging Service (JMS) specification for RabbitMQ brokers",
      "description": "Amazon MQ now supports the ability for RabbitMQ 4 brokers to connect to JMS applications through the RabbitMQ JMS Topic Exchange plugin and JMS client. The JMS topic exchange plugin is enabled by default on all RabbitMQ 4 brokers, allowing you to use the JMS client to run your JMS 1.1, JMS 2.0, and JMS 3.1 applications on RabbitMQ. You can also use the RabbitMQ JMS client to send JMS messages to an AMQP exchange and consume messages from an AMQP queue to interoperate or migrate JMS workloads to AMQP workloads.\n  To start using your JMS applications on RabbitMQ, simply select RabbitMQ 4.2 when creating a new broker using the M7g instance type through the AWS Management console, AWS CLI, or AWS SDKs, and then use the RabbitMQ JMS client to connect your applications. To learn more about the plugin, see the Amazon MQ release notes and the Amazon MQ developer guide. This plugin is available in all regions where Amazon MQ RabbitMQ 4 instances are available today.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-mq-jms-spec-rabbitmq/",
      "pubDate": "2026-01-22T13:40:00.000Z",
      "source": "whatsNew",
      "services": [
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "q developer",
        "support"
      ]
    },
    {
      "id": "aws-news-d31c7e5cb27f",
      "title": "AWS Security Agent now supports GitHub Enterprise Cloud",
      "description": "AWS Security Agent now supports GitHub Enterprise Cloud, enabling customers to connect their GitHub Enterprise Organization and leverage AI-powered security capabilities across their private repositories. With this expansion, development teams can integrate security analysis directly into their GitHub workflows.\n  Customers can now connect their GitHub Enterprise Organization to AWS Security Agent by installing the AWS Security Agent GitHub app with the required permissions. Once connected, the agent provides three key capabilities for private repositories:\n \nAutomated Code Reviews: AWS Security Agent performs comprehensive security reviews on new pull requests, identifying vulnerabilities and compliance with internal security requirements before code is merged.\n \nPenetration Testing Integration: Leverage your GitHub Enterprise code repositories during penetration testing activities, allowing the agent to analyze your codebase for potential security weaknesses and attack vectors.\n \nAutomated Code Remediation: When security issues are identified during penetration testing, customers can choose to have AWS Security Agent automatically submit pull requests with recommended fixes, accelerating remediation workflows.\n \nThis capability is available in the US East (N. Virginia) region where AWS Security Agent operates. To get started, connect your GitHub Enterprise Organization to AWS Security Agent through the AWS Security Agent console. To learn more about AWS Security Agent, visit the product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-security-agent-ghe-support",
      "pubDate": "2026-01-22T09:01:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-36722fddcb63",
      "title": "Building zero trust generative AI applications in healthcare with AWS Nitro Enclaves",
      "description": "In healthcare, generative AI is transforming how \nmedical professionals analyze data, \nsummarize clinical notes, and \ngenerate insights to improve patient outcomes. From \nautomating medical documentation to assisting in \ndiagnostic reasoning, large language models (LLMs) have the potential to augment clinical workflows and accelerate research. However, these innovations also introduce significant privacy, security, and intellectual property challenges.",
      "link": "https://aws.amazon.com/blogs/compute/building-zero-trust-generative-ai-applications-in-healthcare-with-aws-nitro-enclaves/",
      "pubDate": "2025-12-12T19:06:03.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-b56aaf668b93",
      "title": "Architecting conversational observability for cloud applications",
      "description": "In this post, we walk through building a generative AI–powered troubleshooting assistant for Kubernetes. The goal is to give engineers a faster, self-service way to diagnose and resolve cluster issues, cut down Mean Time to Recovery (MTTR), and reduce the cycles experts spend finding the root cause of issues in complex distributed systems.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-conversational-observability-for-cloud-applications/",
      "pubDate": "2025-12-11T15:59:39.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}