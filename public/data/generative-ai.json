{
  "lastUpdated": "2025-11-10T06:16:56.037Z",
  "category": "generative-ai",
  "totalItems": 46,
  "items": [
    {
      "id": "aws-news-ee9cf44040dd",
      "title": "Democratizing AI: How Thomson Reuters Open Arena supports no-code AI for every professional with Amazon Bedrock",
      "description": "In this blog post, we explore how TR addressed key business use cases with Open Arena, a highly scalable and flexible no-code AI solution powered by Amazon Bedrock and other AWS services such as Amazon OpenSearch Service, Amazon Simple Storage Service (Amazon S3), Amazon DynamoDB, and AWS Lambda. We'll explain how TR used AWS services to build this solution, including how the architecture was designed, the use cases it solves, and the business profiles that use it.",
      "link": "https://aws.amazon.com/blogs/machine-learning/democratizing-ai-how-thomson-reuters-open-arena-supports-no-code-ai-for-every-professional-with-amazon-bedrock/",
      "pubDate": "2025-11-07T21:51:22.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "lex",
        "lambda",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex",
        "lambda",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "support"
      ]
    },
    {
      "id": "aws-news-0e92324b3b39",
      "title": "Introducing structured output for Custom Model Import in Amazon Bedrock",
      "description": "Today, we are excited to announce the addition of structured output to Custom Model Import. Structured output constrains a model's generation process in real time so that every token it produces conforms to a schema you define. Rather than relying on prompt-engineering tricks or brittle post-processing scripts, you can now generate structured outputs directly at inference time.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-structured-output-for-custom-model-import-in-amazon-bedrock/",
      "pubDate": "2025-11-07T18:53:55.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-bde0cc69d3f1",
      "title": "Transform your MCP architecture: Unite MCP servers through AgentCore Gateway",
      "description": "Earlier this year, we introduced Amazon Bedrock AgentCore Gateway, a fully managed service that serves as a centralized MCP tool server, providing a unified interface where agents can discover, access, and invoke tools. Today, we're extending support for existing MCP servers as a new target type in AgentCore Gateway. With this capability, you can group multiple task-specific MCP servers aligned to agent goals behind a single, manageable MCP gateway interface. This reduces the operational complexity of maintaining separate gateways, while providing the same centralized tool and authentication management that existed for REST APIs and AWS Lambda functions.",
      "link": "https://aws.amazon.com/blogs/machine-learning/transform-your-mcp-architecture-unite-mcp-servers-through-agentcore-gateway/",
      "pubDate": "2025-11-06T17:43:23.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "lambda",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f2e6a41b8c65",
      "title": "AWS B2B Data Interchange is now available in AWS Europe (Ireland) Region",
      "description": "Customers in AWS Europe (Ireland) Region can now use AWS B2B Data Interchange to build highly customizable, scalable and cost-efficient EDI workloads.\n  AWS B2B Data Interchange automates validation, transformation, and generation of EDI files such as ANSI X12 documents to and from JSON and XML data formats. With this launch, you can use AWS B2B Data Interchange to process your EDI documents in AWS Europe (Ireland) Region, which enables you to meet your compliance and data sovereignty obligations while modernizing your B2B integration workloads. As part of this launch, the AWS B2B Data Interchange generative AI mapping capability will also become available in AWS Europe (Ireland) Region, simplifying mapping code development and ultimately expediting trading partners onboarding.\n  To learn more about AWS B2B Data Interchange visit our product page, user-guide or take our self-paced workshop. See the AWS Region Table for complete regional availability.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-b2b-data-interchange-europe-ireland-region",
      "pubDate": "2025-11-06T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "ga",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-c2cb92ded76a",
      "title": "AWS IoT Greengrass v2.16 introduces system log forwarder and TPM2.0 capabilities",
      "description": "AWS announces the release of AWS IoT Greengrass v2.16, introducing new core components for nucleus and nucleus lite. AWS IoT Greengrass is an Internet of Things (IoT) edge runtime and cloud service that helps customers build, deploy, and manage device software at the edge. The latest version 2.16 release includes enhanced debugging capabilities through the system log forwarder component. This component uploads system log files to AWS Cloud Watch, making it easier for developers to troubleshoot IoT edge applications.\n  The AWS IoT Greengrass v2.16 release also features a new nucleus lite version (v2.3) with TPM2.0 specification support, enabling developers to manage edge device security for their resource constrained devices using hardware-based root of trust modules. The implementation helps developers to scale their IoT deployments with confidence while providing secure storage for secrets and streamlined device authentication.\n  AWS IoT Greengrass v2.16 is available in all AWS Regions where AWS IoT Greengrass is offered. To learn more about AWS IoT Greengrass v2.16 and its new features, visit the AWS IoT Greengrass documentation. Follow the Getting Started guide for a quick introduction to AWS IoT Greengrass.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-greengrass-v2-16-system-log-forwarder-tpm-2-0-capabilities",
      "pubDate": "2025-11-06T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4cdb33674ab0",
      "title": "Amazon Elastic VMware Service (Amazon EVS) is now available in additional Regions",
      "description": "Today, we're announcing that Amazon Elastic VMware Service (Amazon EVS) is now available in all availability zones in the Asia Pacific (Mumbai), Asia Pacific (Sydney), Canada (Central) and Europe (Paris) Regions. This expansion provides more options to leverage the scale and flexibility of AWS for running your VMware workloads in the cloud.\n  Amazon EVS lets you run VMware Cloud Foundation (VCF) directly within your Amazon Virtual Private Cloud (VPC) on EC2 bare-metal instances, powered by AWS Nitro. Using either our step-by-step configuration workflow or the AWS Command Line Interface (CLI) with automated deployment capabilities, you can set up a complete VCF environment in just a few hours. This rapid deployment enables faster workload migration to AWS, helping you eliminate aging infrastructure, reduce operational risks, and meet critical timelines for exiting your data center.\n  The added availability in the Asia Pacific (Mumbai), Asia Pacific (Sydney), Canada (Central) and Europe (Paris) Regions gives your VMware workloads lower latency through closer proximity to your end users, compliance with data residency or sovereignty requirements, and additional high availability and resiliency options for your enhanced redundancy strategy.\n  To get started, visit the Amazon EVS product detail page and user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-evs-additional-regions",
      "pubDate": "2025-11-06T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "now-available",
        "expansion"
      ]
    },
    {
      "id": "aws-news-e85ab9e07aac",
      "title": "How Amazon Search increased ML training twofold using AWS Batch for Amazon SageMaker Training jobs",
      "description": "In this post, we show you how Amazon Search optimized GPU instance utilization by leveraging AWS Batch for SageMaker Training jobs. This managed solution enabled us to orchestrate machine learning (ML) training workloads on GPU-accelerated instance families like P5, P4, and others. We will also provide a step-by-step walkthrough of the use case implementation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-search-increased-ml-training-twofold-using-aws-batch-for-amazon-sagemaker-training-jobs/",
      "pubDate": "2025-11-05T17:15:35.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-610aae9a57eb",
      "title": "Amazon CloudWatch Application Signals adds AI-powered Synthetics debugging",
      "description": "Amazon CloudWatch Application Signals Model Context Protocol or MCP Server for Application Performance Monitoring (APM) now integrates CloudWatch Synthetics canary monitoring directly into its audit framework, enabling automated, AI-powered debugging of synthetic monitoring failures. DevOps teams and developers can now use natural language questions like 'Why is my checkout canary failing?' in compatible AI assistants such as Amazon Q, Claude, or other supported assistants to utilize the new AI-powered debugged capabilities and quickly distinguish between canary infrastructure issues and actual service problems, addressing the significant challenge of extensive manual analysis in maintaining reliable synthetic monitoring.\n  The integration extends Application Signals' existing multi-signal (services, operations, SLOs, golden signals) analysis capabilities to include comprehensive canary diagnostics. The new feature automatically correlates canary failures with service health metrics, traces, and dependencies through an intelligent audit pipeline. Starting from natural language prompts from users, the system performs multi-layered diagnostic analysis across six major areas: Network Issues, Authentication Failures, Performance Problems, Script Errors, Infrastructure Issues, and Service Dependencies. This analysis includes automated comparison of HTTP Archive or HAR files, CloudWatch logs analysis, S3 artifact examination, and configuration validation, significantly reducing the time needed to identify and resolve synthetic monitoring issues.\n Customers can then access these insights through natural language interactions with supported AI assistants.\n  This feature is available in all commercial AWS regions where Amazon CloudWatch Synthetics is offered. Customers will need access to a compatible AI agent such as Amazon Q, Claude, or other supported AI assistants to utilize the AI-powered debugging capabilities.\n  To learn more about implementing AI-based debugging for your synthetic monitoring, visit the CloudWatch Application Signals MCP Server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/application-signals-ai-powered-synthetics/",
      "pubDate": "2025-11-05T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "s3",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "s3",
        "cloudwatch",
        "new-feature",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-4c55d57ac45a",
      "title": "Iterate faster with Amazon Bedrock AgentCore Runtime direct code deployment",
      "description": "Amazon Bedrock AgentCore is an agentic platform for building, deploying, and operating effective agents securely at scale. Amazon Bedrock AgentCore Runtime is a fully managed service of Bedrock AgentCore, which provides low latency serverless environments to deploy agents and tools. It provides session isolation, supports multiple agent frameworks including popular open-source frameworks, and handles multimodal […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/iterate-faster-with-amazon-bedrock-agentcore-runtime-direct-code-deployment/",
      "pubDate": "2025-11-04T18:30:44.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "support"
      ]
    },
    {
      "id": "aws-news-dd03fcd2c480",
      "title": "AWS Config launches 42 new managed rules",
      "description": "AWS Config announces launch of an additional 42 managed Config rules for various use cases such as security, cost, durability, and operations. You can now search, discover, enable and manage these additional rules directly from AWS Config and govern more use cases for your AWS environment.\n \nWith this launch, you can now enable these controls across your account or across your organization. For example, you can evaluate your tagging strategies across Amazon EKS Fargate profiles, Amazon EC2 Network Insight Analyses, AWS Glue Machine learning transforms. Or you can assess your security posture across Amazon Cognito Identity pools, Amazon Lightsail buckets, AWS Amplify apps and more. Additionally, you can leverage Conformance Packs to group these new controls and deploy across an account or across organization, streamlining your multi-account governance.\n \nFor the full list of recently released rules, visit the AWS Config developer guide. For description of each rule and the AWS Regions in which it is available, please refer our Config managed rules documentation. To start using Config rules, please refer our documentation.\n  New Rules Launched:\n  \n \n \nAMPLIFY_APP_NO_ENVIRONMENT_VARIABLES\n \n \nAMPLIFY_BRANCH_DESCRIPTION\n \n \nAPIGATEWAY_STAGE_DESCRIPTION\n \n \nAPIGATEWAYV2_STAGE_DESCRIPTION\n \n \nAPI_GWV2_STAGE_DEFAULT_ROUTE_DETAILED_METRICS_ENABLED\n \n \nAPIGATEWAY_STAGE_ACCESS_LOGS_ENABLED\n \n \nAPPCONFIG_DEPLOYMENT_STRATEGY_MINIMUM_FINAL_BAKE_TIME\n \n \nAPPCONFIG_DEPLOYMENT_STRATEGY_TAGGED\n \n \nAPPFLOW_FLOW_TRIGGER_TYPE_CHECK\n \n \nAPPMESH_VIRTUAL_NODE_CLOUD_MAP_IP_PREF_CHECK\n \n \nAPPMESH_VIRTUAL_NODE_DNS_IP_PREF_CHECK\n \n \nAPPRUNNER_SERVICE_IP_ADDRESS_TYPE_CHECK\n \n \nAPPRUNNER_SERVICE_MAX_UNHEALTHY_THRESHOLD\n \n \nAPS_RULE_GROUPS_NAMESPACE_TAGGED\n \n \nAUDITMANAGER_ASSESSMENT_TAGGED\n \n \nBATCH_MANAGED_COMPUTE_ENV_ALLOCATION_STRATEGY_CHECK\n \n \nBATCH_MANAGED_SPOT_COMPUTE_ENVIRONMENT_MAX_BID\n \n \nCOGNITO_IDENTITY_POOL_UNAUTHENTICATED_LOGINS\n \n \nCOGNITO_USER_POOL_PASSWORD_POLICY_CHECK\n \n \nCUSTOMERPROFILES_DOMAIN_TAGGED\n \n \nDEVICEFARM_PROJECT_TAGGED\n \n \nDEVICEFARM_TEST_GRID_PROJECT_TAGGED\n \n \nDMS_REPLICATION_INSTANCE_MULTI_AZ_ENABLED\n \n \nEC2_LAUNCH_TEMPLATES_EBS_VOLUME_ENCRYPTED\n \n \nEC2_NETWORK_INSIGHTS_ANALYSIS_TAGGED\n \n \nEKS_FARGATE_PROFILE_TAGGED\n \n \nGLUE_ML_TRANSFORM_TAGGED\n \n \nIOT_SCHEDULED_AUDIT_TAGGED\n \n \nIOT_PROVISIONING_TEMPLATE_DESCRIPTION\n \n \nIOT_PROVISIONING_TEMPLATE_JITP\n \n \nIOT_PROVISIONING_TEMPLATE_TAGGED\n \n \nKINESIS_VIDEO_STREAM_MINIMUM_DATA_RETENTION\n \n \nLAMBDA_FUNCTION_DESCRIPTION\n \n \nLIGHTSAIL_BUCKET_ALLOW_PUBLIC_OVERRIDES_DISABLED\n \n \nRDS_MYSQL_CLUSTER_COPY_TAGS_TO_SNAPSHOT_CHECK\n \n \nRDS_PGSQL_CLUSTER_COPY_TAGS_TO_SNAPSHOT_CHECK\n \n \nROUTE53_RESOLVER_FIREWALL_DOMAIN_LIST_TAGGED\n \n \nROUTE53_RESOLVER_FIREWALL_RULE_GROUP_ASSOCIATION_TAGGED\n \n \nROUTE53_RESOLVER_FIREWALL_RULE_GROUP_TAGGED\n \n \nROUTE53_RESOLVER_RESOLVER_RULE_TAGGED\n \n \nRUM_APP_MONITOR_TAGGED\n \n \nRUM_APP_MONITOR_CLOUDWATCH_LOGS_ENABLED",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-config-launches-42-new-managed-rules/",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "ec2",
        "rds",
        "eks",
        "fargate",
        "kinesis",
        "glue",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "ec2",
        "rds",
        "eks",
        "fargate",
        "kinesis",
        "glue",
        "cloudwatch",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-bcdec442f542",
      "title": "Amazon Bedrock AgentCore Runtime now supports direct code deployment",
      "description": "Amazon Bedrock AgentCore Runtime now supports two deployment methods for AI agents: container-based deployment and direct code upload. Developers can now choose between direct code-zip file upload for rapid prototyping and iteration, or leverage advanced container-based options for complex use cases requiring custom configurations.\n  AgentCore Runtime provides a serverless, framework and model agnostic runtime for running agents and tools at scale. This deployment option streamlines the prototyping workflow while maintaining enterprise security and scaling capabilities for production deployments. Developers can now deploy agents using direct code-zip upload with easy drag-and-drop functionality. This enables faster iteration cycles, empowering developers to prototype quickly and focus on building innovative agent capabilities.\n  This feature is available in all nine AWS Regions where Amazon Bedrock AgentCore Runtime is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), and Europe (Ireland).\n  To learn more about AgentCore Runtime deployment options, see the AgentCore documentation and get started with the AgentCore Starter Toolkit. AgentCore offers consumption-based pricing with no upfront costs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-bedrock-agentcore-runtime-code-deployment/",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "nova",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-31cd99dbf479",
      "title": "Amazon RDS for Oracle is now available with R7i memory-optimized instances offering up to 64:1 memory-to-vCPU ratio",
      "description": "Amazon Relational Database Service (RDS) for Oracle is now available with R7i memory-optimized preconfigured instances that offer additional memory and storage I/O per vCPU. Powered by custom 4th Gen Intel Xeon Scalable processors with AWS Nitro System and DDR5 memory for high performance, these instances provide up to 64:1 memory-to-vCPU ratio. Many Oracle database workloads require high memory, but can safely reduce the number of vCPUs without impacting application performance. By running such Oracle database workloads on R7i pre-configured instances, customers can lower their Oracle database licensing and support costs while meeting high performance application requirements.\n  Memory optimized R7i pre-configured instances are available for Amazon RDS for Oracle with Bring Your Own License (BYOL) license model supporting both Oracle Database Enterprise Edition and Oracle Database Standard Edition 2. To learn more about Amazon RDS for Oracle R7i memory-optimized preconfigured instances, read RDS for Oracle User Guide and visit Amazon RDS for Oracle Pricing for available instance configurations, pricing details, and region availability.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-rds-oracle-r7i-memory-optimized-instances/",
      "pubDate": "2025-11-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b6563e5ae405",
      "title": "Amazon CloudWatch Agent adds support for NVMe Local Volume Performance Statistics",
      "description": "Amazon CloudWatch agent now supports the collection of detailed performance metrics for NVMe local volumes on Amazon EC2 instances. These metrics give you insights into behavior and performance characteristics of your NVMe local storage.\n  The CloudWatch agent can now be configured to collect and send detailed NVMe metrics to CloudWatch, providing deeper visibility into storage performance. The new metrics include comprehensive performance indicators such as queue depths, I/O sizes, and device utilization. These metrics are similar to the detailed performance statistics available for EBS volumes, providing a consistent monitoring experience across both storage types. You can create CloudWatch dashboards, set alarms, and analyze trends for your NVMe-based instance store volumes.\n  Detailed performance statistics for Amazon EC2 instance store volumes via Amazon CloudWatch agent are available for all local NVMe volumes attached to Nitro-based EC2 instances in all AWS Commercial and AWS GovCloud (US) Regions. See the Amazon CloudWatch pricing page for CloudWatch pricing details.\n  To get started with detailed performance statistics for Amazon EC2 instance store volumes in CloudWatch, see Collect Amazon EC2 instance store volume NVMe driver metrics in the Amazon CloudWatch User Guide. To learn more about detailed performance statistics for Amazon EC2 instance store volumes, see Amazon EC2 instance store volumes in the Amazon EC2 User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-agent-nvme-local-volume-performance-statistics",
      "pubDate": "2025-11-03T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "cloudwatch",
        "support"
      ]
    },
    {
      "id": "aws-news-2537f16f1b31",
      "title": "Clario streamlines clinical trial software configurations using Amazon Bedrock",
      "description": "This post builds upon our previous post discussing how Clario developed an AI solution powered by Amazon Bedrock to accelerate clinical trials. Since then, Clario has further enhanced their AI capabilities, focusing on innovative solutions that streamline the generation of software configurations and artifacts for clinical trials while delivering high-quality clinical evidence.",
      "link": "https://aws.amazon.com/blogs/machine-learning/clario-streamlines-clinical-trial-software-configurations-using-amazon-bedrock/",
      "pubDate": "2025-10-31T15:49:09.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-3dc939af4c74",
      "title": "AWS Marketplace now offers pricing model flexibility and simplified deployment for AI agents and tools",
      "description": "AWS Marketplace now offers flexible pricing models, simplified authentication, and streamlined deployment for AI agents and tools. The new capabilities include contract-based and usage-based pricing for Amazon Bedrock AgentCore Runtime containers, and simplified OAuth credential management through Quick Launch for API-based AI agents and tools. Customers can also use supported remote MCP servers procured through AWS Marketplace as MCP targets on AgentCore Gateway, making it easier for them to connect to AI agents and tools from AWS Partners at scale. The improvements reduce deployment complexity while offering pricing models that better align with diverse customer needs.\n  For Partners, the new capabilities for AI agents and tools streamline management and provide additional pricing options through AWS Marketplace. Partners can now manage all their AI agents and tools listings from one page in the AWS Marketplace Management Portal, reducing the complexity of managing multiple listings across different interfaces. With usage-based and contract-based pricing options for AgentCore Runtime compatible products, Partners have more flexibility to implement pricing strategies that align with their business models and customers’ needs.\n  Customers can learn more in the buyer guide and start exploring AI agent solutions in AWS Marketplace on the solutions page. For partners interested in implementing the capabilities, visit the seller guide and complete the workshop.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-marketplace-pricing-ai-agents-tools/",
      "pubDate": "2025-10-31T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "launch",
        "ga",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-dc918b27e947",
      "title": "The Model Context Protocol (MCP) Proxy for AWS is now generally available",
      "description": "Today, AWS announces the general availability of the Model Context Protocol (MCP) Proxy for AWS, a client-side proxy that enables MCP clients to connect to remote, AWS-hosted MCP servers using AWS SigV4 authentication. The Proxy supports popular agentic AI development tools like Amazon Q Developer CLI, Kiro, Cursor, and popular agent frameworks like Strands Agents. Customers can connect to remote MCP servers with AWS credentials using the Proxy to automatically handle MCP protocol communications via SigV4. The Proxy also helps customers to connect to MCP servers built on Amazon Bedrock AgentCore Gateway or Runtime using SigV4 authentication.\n  This release allows developers and agents to extend development workflows to include AWS service interactions from AWS MCP server tools. For example, you can use AWS MCP servers to work with resources like AWS S3 buckets or Amazon RDS tables through existing MCP servers with SigV4. The MCP Proxy for AWS includes safety controls such as read-only mode to prevent unintended changes, configurable retry logic for reliability, and logging for troubleshooting. Customers can install the Proxy from source, through Python package managers, or by using a container making it simple to configure with their preferred MCP-supported development tool.\n  The MCP Proxy for AWS is open-source and available now. Visit the AWS GitHub repository to view the installation and configuration options and start connecting with remote AWS MCP Servers today.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/model-context-protocol-proxy-available/",
      "pubDate": "2025-10-31T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "amazon q",
        "q developer",
        "s3",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "amazon q",
        "q developer",
        "s3",
        "rds",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-164c0c0d28a9",
      "title": "Reduce CAPTCHAs for AI agents browsing the web with Web Bot Auth (Preview) in Amazon Bedrock AgentCore Browser",
      "description": "AI agents need to browse the web on your behalf. When your agent visits a website to gather information, complete a form, or verify data, it encounters the same defenses designed to stop unwanted bots: CAPTCHAs, rate limits, and outright blocks. Today, we are excited to share that AWS has a solution. Amazon Bedrock AgentCore […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/reduce-captchas-for-ai-agents-browsing-the-web-with-web-bot-auth-preview-in-amazon-bedrock-agentcore-browser/",
      "pubDate": "2025-10-30T21:55:03.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-9bbbb9cddf3a",
      "title": "Split Cost Allocation Data for Amazon EKS supports Kubernetes labels",
      "description": "Starting today, Split Cost Allocation Data for Amazon EKS now allows you to import up to 50 Kubernetes custom labels per pod as cost allocation tags. You can attribute costs of your Amazon EKS cluster at the pod level using custom attributes, such as cost center, application, business unit, and environment in AWS Cost and Usage Report (CUR).\n  With this new capability, you can better align your cost allocation with specific business requirements and organizational structure driven by your cloud financial management needs. This enables granular cost visibility of your EKS clusters running multiple application containers using shared EC2 instances, allowing you to allocate the shared costs of your EKS cluster. For new split cost allocation data customers, you can enable this feature in the AWS Billing and Cost Management console. For existing customers, EKS will automatically import the labels, but you must activate them as cost allocation tags. After activation, Kubernetes custom labels are available in your CUR within 24 hours. You can use the Containers Cost Allocation dashboard to visualize the costs in Amazon QuickSight and the CUR query library to query the costs using Amazon Athena.\n  This feature is available in all AWS Regions where Split Cost Allocation Data for Amazon EKS is available. To get started, visit Understanding Split Cost Allocation Data.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/split-cost-allocation-data-amazon-eks-kubernetes-labels/",
      "pubDate": "2025-10-30T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "ec2",
        "eks",
        "athena",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "ec2",
        "eks",
        "athena",
        "quicksight",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-0e14a6765269",
      "title": "AWS Elastic Beanstalk adds support for Amazon Corretto 25",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Java applications using Amazon Corretto 25 on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest Java 25 features while benefiting from AL2023's enhanced security and performance capabilities.\n  AWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Corretto 25 on AL2023 allows developers to take advantage of the latest Java language features including compact object headers, ahead-of-time (AOT) caching, and structured concurrency. Developers can create Elastic Beanstalk environments running Corretto 25 through the Elastic Beanstalk Console, CLI, or API.\n  This platform is generally available in commercial regions where Elastic Beanstalk is available including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n  For more information about Corretto 25 and Linux Platforms, see the Elastic Beanstalk developer guide. To learn more about Elastic Beanstalk, visit the Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-elastic-beanstalk-support-amazon-corretto-25",
      "pubDate": "2025-10-30T14:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-83d88081c292",
      "title": "Amazon GameLift Servers adds telemetry metrics to all server SDKs and game engine plugins",
      "description": "Today, Amazon GameLift Servers launched the addition of built-in telemetry metrics across all server SDKs and game engine plugins. Built on OpenTelemetry, an open source framework, Amazon GameLift Servers telemetry metrics enable game developers to generate, collect, and export critical client-side metrics for game-specific insights.\n  With this release, Amazon GameLift Servers can now be configured to collect and publish telemetry metrics for game servers running on managed Amazon EC2 and container fleets. Customers can leverage both pre-defined metrics and custom metrics, publishing them to Amazon Managed Service for Prometheus or Amazon CloudWatch. This data can be visualized through ready-to-use dashboards (via Amazon Managed Grafana or Amazon CloudWatch) to help game developers optimize resource utilization, improve player experience, and identify and resolve potential operational issues.\n  Telemetry metrics are now available in all Amazon GameLift Servers supported regions, except AWS China. For more information on monitoring resources using telemetry metrics on Amazon GameLift Servers, please visit the Amazon GameLift Servers documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-gamelift-servers-telemetry-metrics",
      "pubDate": "2025-10-30T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "cloudwatch",
        "grafana"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "cloudwatch",
        "grafana",
        "launch",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-d7fcb69efc2a",
      "title": "AWS Serverless MCP Server now supports tools for AWS Lambda event source mappings (ESM)",
      "description": "The AWS Serverless Model Context Protocol (MCP) Server now supports specialized tools for AWS Lambda event source mappings (ESM), helping developers configure and manage ESMs more efficiently. These new tools combine the power of AI assistance with Lambda ESM expertise to streamline how developers set up, optimize, and troubleshoot event-driven serverless applications built on Lambda.\n  We previously launched the open-source Serverless MCP Server to enhance how developers build modern applications with AI-powered contextual guidance for architecture decisions, infrastructure provisioning, deployment automation, and troubleshooting of serverless applications. Starting today, we’re expanding the MCP server’s capabilities with new ESM tools that empower AI assistants, like Amazon Q Developer and Kiro, with proven knowledge of ESM patterns and best practices. The new ESM tools translate high-level throughput, latency, and reliability requirements into specific ESM configurations, generate complete AWS Serverless Application Model (AWS SAM) templates with optimized settings, validate network topology for Amazon Virtual Private Cloud (VPC)-based event sources, and diagnose common ESM issues. Thus, these tools enhance the event-driven application development experience, guiding developers through the entire ESM lifecycle, from initial setup to optimization and troubleshooting.\n  The key new ESM tools being added to the Serverless MCP Server are: the ESM guidance tool for contextual guidance across all supported event sources, the ESM optimization tool for analyzing configuration tradeoffs, and the ESM Kafka troubleshooting tool for specialized diagnostics with Amazon Managed Streaming for Apache Kafka (Amazon MSK) and self-managed Apache Kafka clusters.\n  To learn more about the Serverless MCP Server and how it can transform your AI-assisted application development, visit the launch blog post and documentation. To download and try out the open-source MCP server with your AI-enabled IDE of choice, visit the GitHub repository.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-serverless-mcp-server-tools-lambda-esm",
      "pubDate": "2025-10-30T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "translate",
        "lambda",
        "kafka",
        "msk"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "translate",
        "lambda",
        "kafka",
        "msk",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-afcb32dc6a87",
      "title": "Amazon Bedrock AgentCore Browser now reduces CAPTCHAs with Web Bot Auth (Preview)",
      "description": "Amazon Bedrock AgentCore Browser provides a fast, secure, cloud-based browser for AI agents to interact with websites at scale. It now enables agents to establish trusted, accountable access quickly and reduce CAPTCHA interruptions in automated workflows through Web Bot Auth, a draft IETF protocol that cryptographically identifies AI agents to websites. Traditional security measures like CAPTCHAs, rate limits, and blocks often halt automated workflows because Web Application Firewalls (WAFs) treat all automated traffic as suspicious - meaning AI agents frequently need human intervention to complete their tasks.\n  By enabling Web Bot Auth, AgentCore Browser streamlines bot verification across major security providers including Akamai Technologies, Cloudflare, and HUMAN Security. It automatically generates security credentials, signs HTTP requests with private keys, and registers verified identities - getting you started immediately without the need to register with multiple WAF providers or manage verification infrastructure.\n  Web Bot Auth support for AgentCore Browser is available in preview in all nine AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), and Europe (Ireland).\n  Learn more about this feature through the blog, see the Reduce CAPTCHAs with Web Bot Auth documentation to get started with Web Bot Auth in Browser. AgentCore offers consumption-based pricing with no upfront costs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-bedrock-agentcore-browser-web-bot-auth-preview/",
      "pubDate": "2025-10-30T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "waf"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "waf",
        "preview",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-b346e7e645cb",
      "title": "Announcing an AI agent context pack for AWS IoT Greengrass developers",
      "description": "AWS announces the release of a new AI agent context package for accelerating edge device application development using AWS IoT Greengrass. AWS IoT Greengrass is an IoT edge runtime and cloud service that helps developers build, deploy, and manage device software at the edge. The context package includes ready-to-use instructions, examples, and templates - enabling developers to leverage generative AI tools and agents for faster software creation, testing and deployment.\n  Available as an open-source GitHub repository under the Creative Commons Attribution Share Alike 4.0 license, the AWS IoT Greengrass AI agent context package helps streamline development workflows. Developers can boost productivity by cloning the repository and integrating it with modern generative AI tools like Amazon Q to help accelerate cloud-connected edge application development while simplifying fleet-wide deployment and management.\n  This new capability is available in all AWS Regions where AWS IoT Greengrass is supported. To learn more about AWS IoT Greengrass and its new AI agent context pack, visit the AWS IoT Greengrass documentation. Follow the getting started guide for a quick introduction to AWS IoT Greengrass.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/ai-agent-context-pack-iot-greengrass-developers/",
      "pubDate": "2025-10-30T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-27671df15317",
      "title": "Amazon EBS introduces additional performance monitoring metrics for EBS volumes",
      "description": "Amazon EBS now provides additional visibility to monitor the average IOPS and average throughput of your Amazon EBS volumes with two new CloudWatch metrics - VolumeAvgIOPS and VolumeAvgThroughput. You can use the metrics to monitor the I/O being driven on your EBS volumes to track performance trends.\n  With these new volume level metrics, you can troubleshoot performance bottlenecks and optimize your volume’s provisioned performance to meet your application needs. The metrics will provide per-minute visibility into the driven average IOPS and average throughput on your EBS volume. With Amazon CloudWatch, you can use the new metrics to create customized dashboards and set alarms that notify you or automatically perform actions based on the metrics.\n  The VolumeAvgIOPS and VolumeAvgThroughput metrics are available by default at a 1-minute frequency at no additional charge and are supported for all EBS volumes attached to an EC2 Nitro instance in all Commercial AWS Regions, including the AWS GovCloud (US) Regions and AWS China Regions. To learn more about these new metrics, please visit the EBS CloudWatch Metrics documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ebs-performance-monitoring-metrics-ebs-volumes",
      "pubDate": "2025-10-29T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "cloudwatch",
        "support"
      ]
    },
    {
      "id": "aws-news-a236b6dfe8a4",
      "title": "Amazon EC2 High Memory U7i instances are now available in AWS Europe (London) Region",
      "description": "Amazon EC2 U7i-8tb (u7i-8tb.112xlarge) instances are now available in the AWS Europe (London) region. U7i-8tb instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids), delivering up to 135% more compute performance over existing U-1 instances. U7i-8tb instances offer 8TiB of DDR5 memory enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-8tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-high-memory-u7i-instances-aws-europe-london-region",
      "pubDate": "2025-10-29T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-caa5409ed3fd",
      "title": "AWS Elastic Beanstalk adds support for Amazon Corretto 25 and Tomcat 11",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Tomcat 11 applications using Amazon Corretto 25 on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest Java 25 and Jakarta EE 11 features while benefiting from AL2023's enhanced security and performance capabilities.\n \nAWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Tomcat 11 with Corretto 25 on AL2023 allows developers to take advantage of the latest Java language features including compact object headers, ahead-of-time (AOT) caching, and structured concurrency. Developers can create Elastic Beanstalk environments running Corretto 25 with Tomcat 11 on AL2023 through the Elastic Beanstalk Console, CLI, or API.\n \nThis platform is generally available in commercial regions where Elastic Beanstalk is available including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n \nFor more information about Corretto 25 with Tomcat 11 and Linux Platforms, see the Elastic Beanstalk developer guide. To learn more about Elastic Beanstalk, visit the Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-elastic-beanstalk-amazon-corretto-25-tomcat-11",
      "pubDate": "2025-10-29T14:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-178988bb1907",
      "title": "Amazon EC2 Im4gn instances now available in AWS Europe (Milan) Region",
      "description": "Starting today, Amazon EC2 Im4gn Instances are available in Europe (Milan) region. Im4gn instances are built on the AWS Nitro System and are powered by AWS Graviton2 processors. They feature up to 30TB of instance storage with the 2nd Generation AWS Nitro SSDs that are custom-designed by AWS for the storage performance of I/O intensive workloads such as SQL/NoSQL databases, search engines, distributed file systems and data analytics. These instances help with transactions processed per second (TPS) for I/O intensive workloads such as relational databases (e.g. MySQL, MariaDB, PostgreSQL), and NoSQL databases (KeyDB, ScyllaDB, Cassandra) which have medium-large size data sets and can benefit from high compute performance and high network throughput. They are also an ideal fit for search engines, and data analytics workloads requiring fast access to data sets on local storage.\n  The Im4gn instances also feature up to 100 Gbps networking and support for Elastic Fabric Adapter (EFA) for applications requiring high levels of inter-node communication.\n  Get started with Im4gn instances by visiting the AWS Management Console, AWS Command Line Interface (CLI), or AWS SDKs. To learn more, visit the Im4gn instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-im4gn-instances-europe-milan-region",
      "pubDate": "2025-10-28T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-7c3764552c84",
      "title": "Amazon Kinesis Data Streams now supports 10x larger record sizes",
      "description": "Amazon Kinesis Data Streams now supports record sizes up to 10MiB, a tenfold increase from the previous 1MiB limit. This launch enables customers to publish intermittent larger data payloads in their data streams while continuing to use existing Kinesis Data Streams APIs in their applications. This launch is accompanied by a 2x increase in the maximum PutRecords request size from 5MiB to 10MiB.\n  Amazon Kinesis Data Streams is a serverless data streaming service that enables customers to capture, process, and store real-time data streams at any scale. With this launch, customers no longer need to maintain separate processing pipelines for handling intermittent large records, and can thus simplify their data pipelines. This reduces operational overhead for IoT analytics, change data capture, and generative AI workloads. You can update your stream's maximum record size up to 10 MiB using either the AWS Management Console or the UpdateMaxRecordSize API via the AWS SDK or CLI. Once your stream is configured, you can publish and consume larger records using existing Kinesis Data Streams APIs. You do not incur additional costs to use this capability beyond your regular Kinesis data streams charges.\n  In conjunction with this launch, AWS Lambda now supports larger payloads up to 6MiB from Kinesis Data Streams.\n  Amazon Kinesis Data Streams supports large records in the AWS Regions documented here. To learn more about using large records and how common downstream applications handle large records, please see our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-kinesis-data-streams-10x-larger-record-sizes",
      "pubDate": "2025-10-28T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "rds",
        "kinesis"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "rds",
        "kinesis",
        "launch",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-250729ecad99",
      "title": "Amazon EC2 I7i instances now available in additional AWS GovCloud (US) Regions",
      "description": "Amazon Web Services (AWS) announces the availability of high performance Storage Optimized Amazon EC2 I7i instances in the AWS GovCloud (US-East, US-West) Regions. Powered by 5th generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.2 GHz, these new instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances. Powered by 3rd generation AWS Nitro SSDs, I7i instances offer up to 45TB of NVMe storage with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances.\n  I7i instances offer the best compute and storage performance for x86-based storage optimized instances in Amazon EC2, ideal for I/O intensive and latency-sensitive workloads that demand very high random IOPS performance with real-time latency to access the small to medium size datasets (multi-TBs). Additionally, torn write prevention feature support up to 16KB block sizes, enabling customers to eliminate database performance bottlenecks.\n  I7i instances are available in eleven sizes - nine virtual sizes up to 48xlarge and two bare metal sizes - delivering up to 100Gbps of network bandwidth and 60Gbps of Amazon Elastic Block Store (EBS) bandwidth.\n To learn more, visit the I7i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-i7i-instances-aws-govcloud-us-regions",
      "pubDate": "2025-10-28T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-61355b26b823",
      "title": "AWS Resource Explorer supports 47 additional resource types",
      "description": "AWS Resource Explorer now supports 47 more resource types services including Amazon Bedrock, AWS Shield, and AWS Glue.\n  With this release, customers can now search for the following resource types in AWS Resource Explorer:\n  \n \n \n  \n1. amplify:apps \n   26. profile:domains/object-types \n  \n2. aoss:collection \n   27. resiliencehub:app \n  \n3. app-integrations:application \n   28. route53-recovery-control:controlpanel/routingcontrol \n  \n4. appconfig:application/environment \n   29. route53-recovery-readiness:cell \n  \n5. appconfig:extensionassociation \n   30. s3:storage-lens-group \n  \n6. bedrock:agent-alias \n   31. s3express:bucket \n  \n7. cloudtrail:dashboard \n   32. sagemaker:monitoring-schedule \n  \n8. comprehend:flywheel \n   33. shield:protection \n  \n9. devicefarm:instanceprofile \n   34. shield:protection-group \n  \n10. directconnect:dx-gateway \n   35. ssm-incidents:response-plan \n  \n11. elasticloadbalancing:listener/gwy \n   36. verifiedpermissions:policy-store \n  \n12. elasticloadbalancing:loadbalancer/gwy \n   37. vpc-lattice:service \n  \n13. fsx:backup \n   38. vpc-lattice:service/listener \n  \n14. glue:dataQualityRuleset \n   39. vpc-lattice:servicenetwork \n  \n15. glue:registry \n   40. vpc-lattice:servicenetworkserviceassociation \n  \n16. iottwinmaker:workspace/sync-job \n   41. vpc-lattice:targetgroup \n  \n17. ivs:encoder-configuration \n   42. wafv2:ipset \n  \n18. ivs:ingest-configuration \n   43. wafv2:regexpatternset \n  \n19. ivs:playback-restriction-policy \n   44. wafv2:rulegroup \n  \n20. ivs:storage-configuration \n   45. wafv2:webacl \n  \n21. lex:bot \n   46. wisdom:content \n  \n22. mediatailor:vodSource \n   47. workspaces-web:portal \n  \n23. network-firewall:stateful-rulegroup \n     \n  \n24. network-firewall:stateless-rulegroup \n     \n  \n25. profile:domains/integrations \n     \n  \n \nTo view a complete list of all supported types, see the supported resource types page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-resource-explorer-47-resource-types/",
      "pubDate": "2025-10-28T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "sagemaker",
        "comprehend",
        "lex",
        "s3",
        "glue",
        "waf"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "comprehend",
        "lex",
        "s3",
        "glue",
        "waf",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-1aa16589c5f7",
      "title": "Amazon EC2 I7ie instances now available in AWS GovCloud (US) Region",
      "description": "AWS is announcing starting today, Amazon EC2 I7ie instances are now available in AWS GovCloud (US-West) region. Designed for large storage I/O intensive workloads, I7ie instances are powered by 5th Gen Intel Xeon Processors with an all-core turbo frequency of 3.2 GHz, offering up to 40% better compute performance and 20% better price performance over existing I3en instances. I7ie instances offer up to 120TB local NVMe storage density (highest in the cloud) for storage optimized instances and offer up to twice as many vCPUs and memory compared to prior generation instances. Powered by 3rd generation AWS Nitro SSDs, I7ie instances deliver up to 65% better real-time storage performance, up to 50% lower storage I/O latency, and 65% lower storage I/O latency variability compared to I3en instances.\n  I7ie are high density storage optimized instances, ideal for workloads requiring fast local storage with high random read/write performance at very low latency consistency to access large data sets. These instances are available in 9 different virtual sizes and deliver up to 100Gbps of network bandwidth and 60Gbps of bandwidth for Amazon Elastic Block Store (EBS).\n  To learn more, visit the I7ie instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-i7ie-instances-govcloud-us-region/",
      "pubDate": "2025-10-28T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-b3eab0dbf681",
      "title": "Beyond pilots: A proven framework for scaling AI to production",
      "description": "In this post, we explore the Five V's Framework—a field-tested methodology that has helped 65% of AWS Generative AI Innovation Center customer projects successfully transition from concept to production, with some launching in just 45 days. The framework provides a structured approach through Value, Visualize, Validate, Verify, and Venture phases, shifting focus from \"What can AI do?\" to \"What do we need AI to do?\" while ensuring solutions deliver measurable business outcomes and sustainable operational excellence.",
      "link": "https://aws.amazon.com/blogs/machine-learning/beyond-pilots-a-proven-framework-for-scaling-ai-to-production/",
      "pubDate": "2025-10-24T14:42:41.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "launch"
      ]
    },
    {
      "id": "aws-news-e0919cbce33a",
      "title": "AWS Lambda increases maximum payload size from 256 KB to 1 MB for asynchronous invocations",
      "description": "AWS Lambda increases asynchronous invocations maximum payload size from 256 KB to 1 MB, allowing customers to ingest richer, complex payloads for their event-driven workloads without the need to split, compress, or externalize data. Customers invoke their Lambda functions asynchronously using either Lambda API directly, or by receiving push-based events from various AWS services like Amazon S3, Amazon CloudWatch, Amazon SNS, Amazon EventBridge, AWS Step Functions.\n  Modern cloud applications increasingly rely on AWS Lambda’s asynchronous invocations and its integration with various AWS serverless services to build scalable, event-driven architectures. These applications often need to process rich contextual data, including large-language model prompts, telemetry signals, and complex JSON structures for machine learning outputs. With increase in maximum payload size to 1MB for asynchronous invocations, developers can streamline their architectures by including comprehensive data, from detailed user profiles to complete transaction histories, in a single event, eliminating the need for complex data chunking or external storage solutions.\n  This feature is generally available in all AWS Commercial and AWS GovCloud (US) Regions. Customers can start sending asynchronous invocation payloads up to 1 MB using Lambda’s invoke API. Customers are charged for 1 request per each asynchronous invocation for first 256 KB. Individual payload size beyond 256 KB is charged 1 additional request for each 64 KB of chunk up to 1 MB. To learn more, read Lambda asynchronous invocation documentation and AWS Lambda pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-lambda-payload-size-256-kb-1-mb-invocations/",
      "pubDate": "2025-10-24T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "lambda",
        "s3",
        "eventbridge",
        "step functions",
        "sns",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "lambda",
        "s3",
        "eventbridge",
        "step functions",
        "sns",
        "cloudwatch",
        "generally-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-a68cc34788e6",
      "title": "Build scalable creative solutions for product teams with Amazon Bedrock",
      "description": "In this post, we explore how product teams can leverage Amazon Bedrock and AWS services to transform their creative workflows through generative AI, enabling rapid content iteration across multiple formats while maintaining brand consistency and compliance. The solution demonstrates how teams can deploy a scalable generative AI application that accelerates everything from product descriptions and marketing copy to visual concepts and video content, significantly reducing time to market while enhancing creative quality.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-scalable-creative-solutions-for-product-teams-with-amazon-bedrock/",
      "pubDate": "2025-10-22T23:02:04.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-c0b42ee33a26",
      "title": "Build a proactive AI cost management system for Amazon Bedrock – Part 2",
      "description": "In this post, we explore advanced cost monitoring strategies for Amazon Bedrock deployments, introducing granular custom tagging approaches for precise cost allocation and comprehensive reporting mechanisms that build upon the proactive cost management foundation established in Part 1. The solution demonstrates how to implement invocation-level tagging, application inference profiles, and integration with AWS Cost Explorer to create a complete 360-degree view of generative AI usage and expenses.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-a-proactive-ai-cost-management-system-for-amazon-bedrock-part-2/",
      "pubDate": "2025-10-22T18:58:16.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "integration"
      ]
    },
    {
      "id": "aws-news-4ff92cfccd7d",
      "title": "How Twilio built a multi-engine query platform using Amazon Athena and open-source Presto",
      "description": "At Twilio, we manage a 20 petabyte-scale Amazon S3 data lake that serves the analytics needs of over 1,500 users, processing 2.5 million queries monthly and scanning an average of 85 PB of data. To meet our growing demands for scalability, emerging technology support, and data mesh architecture adoption, we built Odin, a multi-engine query platform that provides an abstraction layer built on top of Presto Gateway. In this post, we discuss how we designed and built Odin, combining Amazon Athena with open-source Presto to create a flexible, scalable data querying solution.",
      "link": "https://aws.amazon.com/blogs/big-data/how-twilio-built-a-multi-engine-query-platform-using-amazon-athena-and-open-source-presto/",
      "pubDate": "2025-10-21T20:57:32.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex",
        "s3",
        "athena"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "athena",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-4b870ae0925a",
      "title": "Best practices for upgrading from Amazon Redshift DC2 to RA3 and Amazon Redshift Serverless",
      "description": "As analytical demands grow, many customers are upgrading from DC2 to RA3 or Amazon Redshift Serverless, which offer independent compute and storage scaling, along with advanced capabilities such as data sharing, zero-ETL integration, and built-in artificial intelligence and machine learning (AI/ML) support with Amazon Redshift ML. This post provides a practical guide to plan your target architecture and migration strategy, covering upgrade options, key considerations, and best practices to facilitate a successful and seamless transition.",
      "link": "https://aws.amazon.com/blogs/big-data/best-practices-for-upgrading-from-amazon-redshift-dc2-to-ra3-and-amazon-redshift-serverless/",
      "pubDate": "2025-10-15T21:46:41.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "redshift",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-447e7b731c69",
      "title": "Building a real-time ICU patient analytics pipeline with AWS Lambda event source mapping",
      "description": "In this post, we demonstrate how to build a serverless architecture that processes real-time ICU patient monitoring data using Lambda event source mapping for immediate alert generation and data aggregation, followed by persistent storage in Amazon S3 with an Iceberg catalog for comprehensive healthcare analytics.",
      "link": "https://aws.amazon.com/blogs/big-data/building-a-real-time-icu-patient-analytics-pipeline-with-aws-lambda-event-source-mapping/",
      "pubDate": "2025-10-10T21:55:53.000Z",
      "source": "bigDataBlog",
      "services": [
        "lambda",
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "s3",
        "ga"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-8acfb46eaaa9",
      "title": "Serverless generative AI architectural patterns – Part 2",
      "description": "This post explores two complementary approaches for non-real-time scenarios: buffered asynchronous processing for time-intensive individual requests, and batch processing for scheduled or event-driven workflows.",
      "link": "https://aws.amazon.com/blogs/compute/part-2-serverless-generative-ai-architectural-patterns/",
      "pubDate": "2025-09-04T21:46:26.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-a04bdd57b5ee",
      "title": "Serverless generative AI architectural patterns – Part 1",
      "description": "This two-part series explores the different architectural patterns, best practices, code implementations, and design considerations essential for successfully integrating generative AI solutions into both new and existing applications. In this post, we focus on patterns applicable for architecting real-time generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-generative-ai-architectural-patterns/",
      "pubDate": "2025-09-04T21:45:47.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-7a855eaafa04",
      "title": "Simplifying sustainability reporting using AWS and generative AI in banking",
      "description": "In this post, you learn how you can use generative AI services on Amazon Web Services (AWS) to automate your sustainability reporting requirements, reduce manual effort, and improve accuracy. You do this by implementing an automated solution for extracting, processing, and validating data from corporate reports.",
      "link": "https://aws.amazon.com/blogs/architecture/simplifying-sustainability-reporting-using-aws-and-generative-ai-in-banking/",
      "pubDate": "2025-06-26T17:54:46.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-2355834bf9d4",
      "title": "Amazon Bedrock baseline architecture in an AWS landing zone",
      "description": "In this post, we explore the Amazon Bedrock baseline architecture and how you can secure and control network access to your various Amazon Bedrock capabilities within AWS network services and tools. We discuss key design considerations, such as using Amazon VPC Lattice auth policies, Amazon Virtual Private Cloud (Amazon VPC) endpoints, and AWS Identity and Access Management (IAM) to restrict and monitor access to your Amazon Bedrock capabilities.",
      "link": "https://aws.amazon.com/blogs/architecture/amazon-bedrock-baseline-architecture-in-an-aws-landing-zone/",
      "pubDate": "2025-06-23T18:36:51.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "iam"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}