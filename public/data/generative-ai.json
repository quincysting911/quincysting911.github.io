{
  "lastUpdated": "2025-12-28T06:16:24.488Z",
  "category": "generative-ai",
  "totalItems": 45,
  "items": [
    {
      "id": "aws-news-703f728efd33",
      "title": "Amazon Connect expands automated agent performance evaluations to 5 additional languages",
      "description": "Amazon Connect now automates agent performance evaluations in Portuguese, French, Italian, German, and Spanish using generative AI. Managers define custom evaluation criteria in natural language and receive AI-generated evaluations with justifications in their preferred language. Performance evaluations also supports cross-language evaluation and can complete assessments in English, even when the conversation is in another language. This enables multilingual contact centers to use a standardized evaluation framework across languages.\n  This feature is supported in 8 AWS regions including US East (N. Virginia), US West (Oregon), Europe (Frankfurt), Europe (London), Canada (Central), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Asia Pacific (Singapore). For information about Amazon Connect pricing, please visit our pricing page. To learn more, please visit our documentation and our webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-connect-automated-performance-evaluations-additional-languages/",
      "pubDate": "2025-12-26T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-98b72560b9ff",
      "title": "Programmatically creating an IDP solution with Amazon Bedrock Data Automation",
      "description": "In this post, we explore how to programmatically create an IDP solution that uses Strands SDK, Amazon Bedrock AgentCore, Amazon Bedrock Knowledge Base, and Bedrock Data Automation (BDA). This solution is provided through a Jupyter notebook that enables users to upload multi-modal business documents and extract insights using BDA as a parser to retrieve relevant chunks and augment a prompt to a foundational model (FM).",
      "link": "https://aws.amazon.com/blogs/machine-learning/programmatically-creating-an-idp-solution-with-amazon-bedrock-data-automation/",
      "pubDate": "2025-12-24T17:26:00.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-1aa1ece04af9",
      "title": "Exploring the zero operator access design of Mantle",
      "description": "In this post, we explore how Mantle, Amazon's next-generation inference engine for Amazon Bedrock, implements a zero operator access (ZOA) design that eliminates any technical means for AWS operators to access customer data.",
      "link": "https://aws.amazon.com/blogs/machine-learning/exploring-the-zero-operator-access-design-of-mantle/",
      "pubDate": "2025-12-23T22:18:12.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-6ca65b24753d",
      "title": "NVIDIA Nemotron 3 Nano now available on Amazon Bedrock",
      "description": "Amazon Bedrock now supports NVIDIA Nemotron 3 Nano 30B A3B model, NVIDIA's latest breakthrough in efficient language modeling that delivers high reasoning performance, native tool calling support, and extended context processing with 256k token context window. This model employs an efficient hybrid Mixture-of-Experts (MoE) architecture to ensure higher throughput than its predecessors for agentic and coding workloads, while maintaining the reasoning depth of a larger model. With explicit reasoning controls and higher accuracy enabled by advanced reinforcement learning techniques and multi-environment post-training at scale, this model is ideal for enterprises, startups, and individual developers building multi-agent workflows, developer productivity tools, processes automation, and for scientific and mathematical reasoning analysis, amongst others.\n  NVIDIA Nemotron 3 Nano on Amazon Bedrock is powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock, provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and provides out-of-the-box compatibility with OpenAI API specifications.\n \nNVIDIA Nemotron 3 Nano is available today on Amazon Bedrock in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Mumbai), South America (Sao Paulo), Europe (London), and Europe (Milan) AWS Regions, and supports both unified and OpenAI API-compatible service endpoints on Amazon Bedrock. To learn more and get started, visit Amazon Bedrock console or the service documentation here. To get started with Amazon Bedrock OpenAI API-compatible service endpoints, visit documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/nvidia-nemotron-3-nano-amazon-bedrock",
      "pubDate": "2025-12-23T18:11:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "now-available",
        "support",
        "new-model"
      ]
    },
    {
      "id": "aws-news-4b2bdb387b66",
      "title": "Amazon MSK expands Standard Brokers and Express Brokers to Asia Pacific (New Zealand) Region",
      "description": "Amazon Managed Streaming for Apache Kafka (Amazon MSK) is now available in Asia Pacific (New Zealand) region. Customers can create Amazon MSK Provisioned clusters in this region starting today.\n  Amazon MSK is a fully managed service for Apache Kafka and Kafka Connect that makes it easier for you to build and run applications that use Apache Kafka as a data store. Amazon MSK is fully compatible with Apache Kafka, which enables you to more quickly migrate your existing Apache Kafka workloads to Amazon MSK with confidence or build new ones from scratch. With Amazon MSK, you spend more time building innovative streaming applications and less time managing Kafka clusters.\n  Amazon MSK offers two types of Apache Kafka provisioned broker - Standard brokers and Express brokers. Standard brokers offer the most flexibility to configure your cluster’s performance. You can configure availability, durability, throughput, and latency. You also control the storage configurations on your cluster and are responsible for managing storage provisioning and utilization. Express brokers are a new broker type for Amazon MSK Provisioned designed to deliver up to 3x more throughput per broker, scale up to 20x faster, up to 5x more partitions per broker, and reduce recovery time by 90% as compared to Standard brokers. Express brokers come pre-configured with Kafka best practices by default, support all Kafka APIs, and provide the same low-latency performance that Amazon MSK customers expect, so they can continue using existing client applications without any changes.\n  You can now create an MSK provisioned cluster with Standard or Express brokers in Asia Pacific (New Zealand) Region through the Amazon MSK console or the Amazon CLI. To get started, see the Amazon MSK Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-msk-additional-aws-region/",
      "pubDate": "2025-12-23T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex",
        "kafka",
        "msk"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "lex",
        "kafka",
        "msk",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-cc5bb60ce34a",
      "title": "How dLocal automated compliance reviews using Amazon Quick Automate",
      "description": "In this post, we share how dLocal worked closely with the AWS team to help shape the product roadmap, reinforce its role as an industry innovator, and set new benchmarks for operational excellence in the global fintech landscape.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-dlocal-automated-compliance-reviews-using-amazon-quick-automate/",
      "pubDate": "2025-12-23T17:24:20.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "amazon q",
        "roadmap"
      ]
    },
    {
      "id": "aws-news-18026f1debde",
      "title": "Introducing Visa Intelligent Commerce on AWS: Enabling agentic commerce with Amazon Bedrock AgentCore",
      "description": "In this post, we explore how AWS and Visa are partnering to enable agentic commerce through Visa Intelligent Commerce using Amazon Bedrock AgentCore. We demonstrate how autonomous AI agents can transform fragmented shopping and travel experiences into seamless, end-to-end workflows—from discovery and comparison to secure payment authorization—all driven by natural language.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-visa-intelligent-commerce-on-aws-enabling-agentic-commerce-with-amazon-bedrock-agentcore/",
      "pubDate": "2025-12-23T16:45:47.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-876bfc20c2ec",
      "title": "AWS Transform enables network conversion for hybrid data center migrations",
      "description": "AWS Transform now supports automatic network conversion from hybrid data centers, eliminating manual network mapping for environments running both VMware and non-VMware workloads. The service now analyzes VLANs and IP ranges across all exported source networks and maps these to AWS constructs like Virtual Private Clouds (VPCs), subnets, and security groups.\n  AWS Transform for VMware is an agentic AI-powered service that automates the discovery, planning, and migration of VMware workloads, accelerating infrastructure modernization with increased confidence. The service extends support to hybrid data centers by analyzing exported data from application mapping tools such as modelizeIT to automatically generate Infrastructure as Code and provision AWS networking resources.\n  This feature is available in all AWS Transform target Regions.\n  To learn more, visit the AWS Transform product page, read the user guide, or get started in the AWS Transform web experience.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-transform-hybrid-network-migration/",
      "pubDate": "2025-12-23T12:47:00.000Z",
      "source": "whatsNew",
      "services": [
        "transform for vmware"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "transform for vmware",
        "support"
      ]
    },
    {
      "id": "aws-news-da30ce7f7705",
      "title": "AWS End User Messaging SMS launches a Generative AI Registration Reviewer (Preview)",
      "description": "Starting today, AWS End User Messaging customers can use AWS generative AI to review their phone number registrations, so you can submit to mobile carriers correctly the first time. With the registration reviewer (preview), AWS will provide you feedback on your registration form checking the message sample, opt-in description, use-case, help and stop messages, etc., helping you submit an accurate and complete registration.\n  AWS End User Messaging provides developers with a scalable and cost-effective messaging infrastructure without compromising the safety, security, or results of their communications. Developers can integrate messaging to support uses cases such as one-time passcodes (OTP) at sign-ups, account updates, appointment reminders, delivery notifications, promotions and more.\n  Support for generative AI registration reviewer is available in all AWS Regions where End User Messaging is available, see the AWS Region table.\n  To learn more, see AWS End User Messaging.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/end-user-messaging-sms-ai-registration-reviewer/",
      "pubDate": "2025-12-23T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "preview",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-76f14102cb0e",
      "title": "Move Beyond Chain-of-Thought with Chain-of-Draft on Amazon Bedrock",
      "description": "This post explores Chain-of-Draft (CoD), an innovative prompting technique introduced in a Zoom AI Research paper Chain of Draft: Thinking Faster by Writing Less, that revolutionizes how models approach reasoning tasks. While Chain-of-Thought (CoT) prompting has been the go-to method for enhancing model reasoning, CoD offers a more efficient alternative that mirrors human problem-solving patterns—using concise, high-signal thinking steps rather than verbose explanations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/move-beyond-chain-of-thought-with-chain-of-draft-on-amazon-bedrock/",
      "pubDate": "2025-12-22T18:37:13.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-ad80f84900d5",
      "title": "Enhance document analytics with Strands AI Agents for the GenAI IDP Accelerator",
      "description": "To address the need for businesses to quickly analyze information and unlock actionable insights, we are announcing Analytics Agent, a new feature that is seamlessly integrated into the GenAI IDP Accelerator. With this feature, users can perform advanced searches and complex analyses using natural language queries without SQL or data analysis expertise. In this post, we discuss how non-technical users can use this tool to analyze and understand the documents they have processed at scale with natural language.",
      "link": "https://aws.amazon.com/blogs/machine-learning/enhance-document-analytics-with-strands-ai-agents-for-the-genai-idp-accelerator/",
      "pubDate": "2025-12-22T18:26:17.000Z",
      "source": "mlBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "new-feature"
      ]
    },
    {
      "id": "aws-news-8086b8793273",
      "title": "AWS Storage Gateway now supports Nutanix AHV hypervisor",
      "description": "The AWS Storage Gateway service now supports the Nutanix AHV hypervisor as a deployment option for S3 File, Tape and Volume gateways. If you use Nutanix AHV hypervisor-based on-premises infrastructure, you can now deploy Storage Gateway in your environment to access virtually unlimited cloud storage. \n \nNutanix AHV (Acropolis Hypervisor) is a KVM-based virtualization platform that is integrated into the Nutanix hyper-converged infrastructure (HCI) solution. With this launch, you have the option to deploy Storage Gateway on a Nutanix AHV hypervisor. \n \nStorage Gateway is a hybrid cloud storage service that provides on-premises applications access to virtually unlimited cloud storage using NFS, SMB, iSCSI, and iSCSI-VTL interfaces. You can use the service to backup and archive data to AWS, shift on-premises storage to cloud-backed file shares, and provide on-premises applications low-latency access to data in AWS. You can deploy Storage Gateway as a virtual appliance (VMware ESXi, Microsoft Hyper-V, Linux KVM, and now Nutanix) on premises or as an Amazon EC2 instance in AWS.\n \nThis capability is available in all AWS Regions. Visit the Storage Gateway User guide to learn more, or log into the Storage Gateway management console to get started.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-storage-gateway-nutanix-avh-hypervisor",
      "pubDate": "2025-12-22T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "ec2",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-2a8609aa014d",
      "title": "AWS Wickr launches admin APIs for programmatic network management at scale",
      "description": "AWS Wickr now provides a suite of admin APIs that empower administrators to programmatically manage secure communication networks at scale. These APIs enable you to automate critical administrative workflows including user lifecycle management, network configuration, and security group administration. With user lifecycle management APIs, you can automatically create users and assign security groups when employees join, or deactivate accounts when they leave. Network configuration APIs allow you to quickly create or delete networks on demand as your organization scales or restructures, and push standardized retention and federation policies across departments. Security group administration APIs enable automatic user placement based on directory attributes such as job function or clearance level. By connecting Wickr administration directly into your identity management systems, policy management frameworks, and automation pipelines, you can now manage secure communications infrastructure across thousands of users alongside your other cloud service integrations.\n \n\n AWS Wickr is a security-first messaging and collaboration service designed to help keep your communications secure, private, and compliant. AWS Wickr protects messaging, voice and video calling, file sharing, screen sharing, and location sharing with end-to-end encryption. Customers have full administrative control over data and users, including single sign-on (SSO) integration. Administrators can enforce policies that set password complexity and retention rules, configure ephemeral messaging options, or remotely delete credentials. You can log conversations to a private data store so you can retain messages and files sent to and from the organization to meet compliance requirements.\n  The AWS Wickr Admin APIs are available today in all AWS regions where AWS Wickr is currently supported, including AWS GovCloud (US-West). You can leverage these APIs through AWS SDKs, the AWS Command Line Interface (AWS CLI), or direct REST API calls. To learn more, see:\n \n \n \nAWS Wickr API Reference\n \n \nAWS Wickr Product Page\n \n \nAWS Wickr Administrator Guide",
      "link": "https://aws.amazon.comabout-aws/whats-new/2025/12/aws-wickr-admin-apis-generally-available/",
      "pubDate": "2025-12-22T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "launch",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-28e135e2892d",
      "title": "Amazon Bedrock Data Automation launches instruction optimization for your document blueprints",
      "description": "Amazon Bedrock Data Automation (BDA) now supports blueprint instruction optimization, enabling you to improve the accuracy of your custom field extraction using just a few example document assets with ground truth labels. BDA automates the generation of insights from unstructured multimodal content such as documents, images, audio, and videos for your GenAI-powered applications. Blueprint instruction optimization automatically refines the natural language instructions in your blueprints, helping you achieve production-ready accuracy in minutes without model training or fine-tuning.\n  With blueprint instruction optimization, you can now bring up to 10 representative document assets from your production workload and provide the correct, expected values for each field. Blueprint instruction optimization analyzes the differences between your expected results and the Data Automation inference results, and then refines the natural language instructions to improve extraction accuracy across your examples. For your intelligent document processing applications, you can now improve the accuracy of extracting insights such as invoice line items, contract terms, tax form fields, or medical billing codes. After optimization completes, you receive detailed evaluation metrics including exact match rates and F1 scores measured against your ground truth, giving you confidence that your blueprint is ready for production deployment. \n  Data Automation blueprint instruction optimization for documents is available in all AWS Regions where Amazon Bedrock Data Automation is supported. \n  To learn more, see the Bedrock Data Automation User Guide and the Amazon Bedrock Pricing page. To get started with blueprint instruction optimization, navigate to your blueprint in the Amazon Bedrock console, go to Data Automation, select your custom outputs for documents, and select Start Optimization.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/bedrock-data-automation-optimization-document-blueprints/",
      "pubDate": "2025-12-19T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-8e1c4cd655a7",
      "title": "Build and deploy scalable AI agents with NVIDIA NeMo, Amazon Bedrock AgentCore, and Strands Agents",
      "description": "This post demonstrates how to use the powerful combination of Strands Agents, Amazon Bedrock AgentCore, and NVIDIA NeMo Agent Toolkit to build, evaluate, optimize, and deploy AI agents on Amazon Web Services (AWS) from initial development through production deployment.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-and-deploy-scalable-ai-agents-with-nvidia-nemo-amazon-bedrock-agentcore-and-strands-agents/",
      "pubDate": "2025-12-18T17:26:39.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-80dfb7cea192",
      "title": "Amazon ECS Managed Instances now supports Amazon EC2 Spot Instances",
      "description": "Amazon ECS Managed Instances now supports Amazon EC2 Spot Instances, extending the range of capabilities available with AWS-managed infrastructure. With this launch, you can leverage spare EC2 capacity at up to 90% discount compared to On-Demand prices for fault-tolerant workloads, while AWS handles infrastructure management.\n  ECS Managed Instances is a fully managed compute option designed to eliminate infrastructure management overhead, dynamically scale EC2 instances to match your workload requirements and continuously optimize task placement to reduce infrastructure costs. You can simply define your task requirements such as the number of vCPUs, memory size, and CPU architecture, and Amazon ECS automatically provisions, configures and operates most optimal EC2 instances within your AWS account using AWS-controlled access. You can also specify desired instance types in Managed Instances capacity provider configuration, including GPU-accelerated, network-optimized, and burstable performance, to run your workloads on the instance families you prefer. With today's launch, you can additionally configure a new parameter, capacityOptionType, as spot or on-demand in your capacity provider configuration.\n  Support for EC2 Spot Instances is available in all AWS Regions that Amazon ECS Managed Instances is available. You will be charged for the management of compute provisioned, in addition to your spot Amazon EC2 costs. To learn more about ECS Managed Instances, visit the feature page, documentation, and AWS News launch blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ecs-managed-instances-ec2-spot-instances",
      "pubDate": "2025-12-18T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "ecs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "ecs",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-5d22d44eeb20",
      "title": "Now generally available: Amazon EC2 M8gn and M8gb instances",
      "description": "Today, AWS announces the general availability of the new Amazon Elastic Compute Cloud (Amazon EC2) M8gn and M8gb instances. These instances are powered by AWS Graviton4 processors to deliver up to 30% better compute performance than AWS Graviton3 processors. M8gn instances feature the latest 6th generation AWS Nitro Cards, and offer up to 600 Gbps network bandwidth, the highest network bandwidth among network optimized EC2 instances. M8gb offer up to 150 Gbps of EBS bandwidth to provide higher EBS performance compared to same-sized equivalent Graviton4-based instances.\n  M8gn are ideal for network-intensive workloads such as high-performance file systems, distributed web scale in-memory caches, caching fleets, real-time big data analytics, and Telco applications such as 5G User Plane Function (UPF). M8gb are ideal for workloads requiring high block storage performance such as high performance databases and NoSQL databases.\n \nM8gn instances offer instance sizes up to 48xlarge, up to 768 GiB of memory, up to 600 Gbps of networking bandwidth, and up to 60 Gbps of bandwidth to Amazon Elastic Block Store (EBS). They also support EFA networking on the 16xlarge, 24xlarge, and 48xlarge sizes.\n  M8gb instances offer sizes up to 24xlarge, up to 768 GiB of memory, up to 150 Gbps of EBS bandwidth, and up to 200 Gbps of networking bandwidth. They support Elastic Fabric Adapter (EFA) networking on the 16xlarge and 24xlarge sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n \nThe new instances are available in the following AWS Regions: US East (N. Virginia), and US West (Oregon).\n  To learn more, see Amazon EC2 M8gn and M8gb Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/generally-available-amazon-ec2-m8gn-m8gb-instances",
      "pubDate": "2025-12-17T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "graviton",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-c8e1d411e6b8",
      "title": "Amazon EC2 C8g, M8g, R8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8g and M8g instances are available in AWS GovCloud (US-West) and R8g and M8g instances are available in AWS GovCloud (US-East) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. They are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon C8g, M8g and R8g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. C8g and R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 C8g Instances, Amazon EC2 M8g Instances, and Amazon EC2 R8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS GovCloud (US) Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-c8g-m8g-r8g-instances-additional-regions",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-e1072d090a34",
      "title": "Amazon EC2 C8g instances now available in Europe (Zurich)",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8g instances are available in AWS Europe (Zurich) region. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 C8g instances are built for compute-intensive workloads, such as high performance computing (HPC), batch processing, gaming, video encoding, scientific modeling, distributed analytics, CPU-based machine learning (ML) inference, and ad serving. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon C7g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. C8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 C8g Instances. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-c8g-instances-europe-zurich",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-41d288f2de9f",
      "title": "Amazon OpenSearch Service announces new OI2 instances",
      "description": "Amazon OpenSearch Service introduces OI2 instances, expanding the OpenSearch Optimized Instance family. The new OI2 instances delivers up to 9% higher indexing throughput compared to OR2 instances and up to 33% over I8g instances in our internal benchmarks.\n \nThe new OI2 OpenSearch Optimized instances use the same architecture as the OR2 instances, leveraging best-in-class cloud technologies like Amazon S3, to provide high durability, and improved price-performance for higher indexing throughput better for indexing heavy workload. Each OpenSearch Optimized instance is provisioned with compute, 3rd generation AWS Nitro SSDs for caching, and remote Amazon S3-based managed storage. OI2 offers pay-as-you-go pricing and reserved instances, with a simple hourly rate for the instance including the NVMe storage, as well as managed storage provisioned. OI2 instances come in sizes ‘large’ through ‘24xlarge’, and offer compute, memory, and up to 22.5 TB storage. Please refer to the Amazon OpenSearch Service pricing page for pricing details.\n  OI2 instance family is now available on Amazon OpenSearch Service across 12 regions globally: US East (N. Virginia, Ohio), US West (Oregon), Canada (Central), Asia Pacific (Mumbai, Singapore, Sydney, Tokyo), Europe (Frankfurt, Ireland, London, Spain).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-opensearch-service-oi2-instances/",
      "pubDate": "2025-12-17T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a4d885726005",
      "title": "Amazon EC2 M8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) M8g instances are available in Asia Pacific (Thailand, Jakarta, Melbourne), and AWS Middle East (UAE) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 M8g instances are built for general-purpose workloads, such as application servers, microservices, gaming servers, midsize data stores, and caching fleets. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon M7g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. M8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 M8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-m8g-additional-regions/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-3d31af0ecae0",
      "title": "Amazon EC2 R8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8g instances are available in AWS Europe (Paris), and Asia Pacific (Hyderabad) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 R8g instances are ideal for memory-intensive workloads such as databases, in-memory caches, and real-time big data analytics. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. AWS Graviton4-based R8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 1.5TB) than Graviton3-based R7g instances. These instances are up to 30% faster for web applications, 40% faster for databases, and 45% faster for large Java applications compared to AWS Graviton3-based R7g instances. R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 R8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-r8g-instances-additional-regions/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a159bd5150c4",
      "title": "Amazon OpenSearch Service now offers a new multi-tier storage",
      "description": "Amazon OpenSearch Service now offers a new multi-tier storage option powered by OpenSearch Optimized Instances. This new architecture combines Amazon S3 cloud technology with local instance storage to deliver improved durability and performance. The new multi-tier architecture features two tiers: hot and warm. The hot tier handles frequently accessed data, while the warm tier leverages Amazon S3 for cost-effective storage of less frequently accessed data. \n  Until now, Amazon OpenSearch Service supported a warm tier through UltraWarm, which provided cost-effective storage for read-only data. The new warm tier powered by OpenSearch Optimized instances supports write operations, providing greater flexibility for data management. You can automate rotating data from hot to warm as it ages using Index State Management feature.\n \nFor warm tier deployments, customers can use OpenSearch Optimized (OI2) instances (size ‘large’ to ‘8xlarge’), with addressable warm of up to five times the local cache size. tandard Managed Storage charges apply for warm data. The new Multi-tier experience is available on OpenSearch 3.3 and above. For more information please refer to the documentation.\n  New Multi-Tier experience on OI2 instance family is now available on Amazon OpenSearch Service across 12 regions globally: US East (N. Virginia, Ohio), US West (Oregon), Canada (Central), Asia Pacific (Mumbai, Singapore, Sydney, Tokyo), Europe (Frankfurt, Ireland, London, Spain).  Please refer to the Amazon OpenSearch Service pricing page for pricing details",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/writeable-warm-tier-opensearch-optimized-instances/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f8f0c1cb093c",
      "title": "AWS IAM Identity Center is now available in the Asia Pacific (Taipei) AWS Region",
      "description": "You can now deploy AWS IAM Identity Center in 37 AWS Regions, including Asia Pacific (Taipei).\n  IAM Identity Center is the recommended service for managing workforce access to AWS applications. It enables you to connect your existing source of workforce identities to AWS once and offer your users single sign on experience across AWS. It powers the personalized experiences offered by AWS applications, such as Amazon Q, and the ability to define and audit user-aware access to data in AWS services, such as Amazon Redshift. It can also help you manage access to multiple AWS accounts from a central place. IAM Identity Center is available at no additional cost in these AWS Regions.\n  To learn more about IAM Identity Center, visit the product detail page. To get started, see the IAM Identity Center user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-iam-identity-center-asia-pacific-taipei-region/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center",
        "now-available"
      ]
    },
    {
      "id": "aws-news-06b34c0d447a",
      "title": "AWS Artifact enables access to previous versions of compliance reports",
      "description": "AWS Artifact now enables direct access to previous versions of AWS compliance reports, eliminating the need to contact AWS Support or account representatives. This self-service capability helps customers efficiently manage their compliance documentation requirements, particularly during audits and vendor assessments that require historical compliance evidence.\n  To access previous report versions, you need the \"artifact:ListReportVersions\" IAM permission, which is included in the AWS managed policy \"AWSArtifactReportsReadOnlyAccess\". If you're unable to view previous versions of reports in the AWS Artifact console, please contact your AWS account administrator to request this permission.\n  Once authorized, you can access previous versions of compliance reports (such as SOC, ISO, and C5) directly through the AWS Artifact console. Simply navigate to the reports page and select any report to view its available versions. The availability of previous report versions varies by compliance program, with some reports offering versions from multiple prior years while others may have more limited historical coverage.\n  This feature is now generally available in US East (N. Virginia) and AWS GovCloud (US-West) Regions.\n  To learn more about accessing previous versions of compliance reports, visit the AWS Artifact documentation. For general information about AWS Artifact, see the AWS Artifact product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-artifact-access-previous-versions-compliance-reports",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "iam",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f12f19beadac",
      "title": "AWS Security Incident Response introduces integration with Slack",
      "description": "AWS Security Incident Response now offers integration with the cloud-based team collaboration platform Slack, enabling you to prepare for, respond to, and recover from security events faster and more effectively while maintaining your existing notification and communication workflows. With the bidirectional integration, you can create and update cases in both the Security Incident Response console and Slack with automatic data replication. Each Security Incident Response case is represented as a dedicated Slack channel, while comments and attachments sync instantly. This gives responders immediate access to critical case information and enables more efficient collaboration regardless of tool preference.\n  The integration helps security teams engage faster and accelerate response times by automatically adding Security Incident Response watchers to the corresponding Slack channel. This integration is available as an open-source solution on GitHub, providing customers and partners the opportunity to customize and extend the functionality. The integration leverages EventBridge which allows customers to continue using their existing security incident management and notification tooling, while leveraging AWS Security Incident Response capabilities. The solution features a modular architecture, and includes guidance on how to use Amazon Q Developer, Kiro, or similar AI assistants that help make it easy to add new integration targets beyond Slack.\n  To get started with the AWS Security Incident Response Slack integration, visit our GitHub repository. Visit our technical documentation for Slack for implementation details. Learn more about AWS Security Incident Response in the service’s User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-security-incident-response-integration-slack",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "eventbridge"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "eventbridge",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-5ba02da780e9",
      "title": "Amazon Quick Suite now supports memory for chat agents",
      "description": "We are announcing memory for chat agents in Amazon Quick Suite – a feature that allows users to get personalized responses based on their previous conversations. With this feature, Quick Suite remembers the preferences users specify in chat and generate responses that are tailored to them. Users can also view their inferred preferences and remove any memory they don’t want Quick chat agents to use.\n  Previously, chat users needed to repeat their preferences around response format, acronyms, dashboards, and integrations in every conversation. They also had to clarify ambiguous topics and entities in chat, increasing the tedious back and forth needed to get accurate and insightful responses. Memory addresses this pain point by remembering facts and details about users in a way that ensures responses provided to users continuously learn and improve. Users also control what Quick Suite remembers about them – all the memories are viewable and removable by users, and users have the choice to start chat in Private Mode in which conversations are not used to infer memories.\n  Memory in Quick Suite chat agents is available in US East (N. Virginia) and US West (Oregon). To learn more, visit the Amazon Quick Suite User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-quick-suite-memory-chat-agents/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "rds",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-143d7e18abbc",
      "title": "Amazon Quick Suite browser extension now supports Quick Flows",
      "description": "Amazon Quick Suite browser extension now supports Amazon Quick Flows, enabling you to run workflows directly within your web browser, eliminating the need to manually extract information from each web page. You can invoke workflows that you've created or that have been shared with you, and pass web page content as input—all without leaving your browser.\n  This capability is great for completing routine tasks such as analyzing contract documents to extract key terms, or generating weekly reports from project dashboards that automatically notify stakeholders.\n  Quick Flows in browser extension is available now in US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland). There are no additional charges for using the browser extension beyond standard Quick Flows usage.\n  To get started, visit your Chrome, Firefox or Edge store page to install browser extension and sign in with your Quick Suite account. Once you sign in, look for the Flows icon below the chat box to invoke your flows. To learn more about invoking Quick Flows in browser extension, please visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/quick-suite-browser-extension-quick-flows/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-d57b77f74852",
      "title": "Amazon Elastic VMware Service (Amazon EVS) is now available in additional Regions",
      "description": "Today, we're announcing that Amazon Elastic VMware Service (Amazon EVS) is now available in all availability zones in the US West (N. California), Asia Pacific (Hyderabad), Asia Pacific (Malaysia), Canada West (Calgary), Europe (Milan), Mexico (Central), and South America (São Paulo) Regions. This expansion provides more options to leverage the scale and flexibility of AWS for running your VMware workloads in the cloud.\n  Amazon EVS lets you run VMware Cloud Foundation (VCF) directly within your Amazon Virtual Private Cloud (VPC) on EC2 bare-metal instances, powered by AWS Nitro. Using either our step-by-step configuration workflow or the AWS Command Line Interface (CLI) with automated deployment capabilities, you can set up a complete VCF environment in just a few hours. This rapid deployment enables faster workload migration to AWS, helping you eliminate aging infrastructure, reduce operational risks, and meet critical timelines for exiting your data center.\n  The added availability in these Regions gives your VMware workloads lower latency through closer proximity to your end users, compliance with data residency or sovereignty requirements, and additional high availability and resiliency options for your enhanced redundancy strategy.\n  To get started, visit the Amazon EVS product detail page and user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-evs-available-in-additional-regions/",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available",
        "expansion"
      ]
    },
    {
      "id": "aws-news-563e37119679",
      "title": "Amazon Managed Service for Apache Flink is now available in AWS Asia Pacific (Auckland) Region",
      "description": "Starting today, customers can use Amazon Managed Service for Apache Flink in Asia Pacific (Auckland) Region to build real-time stream processing applications.\n  Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon Simple Storage Service (Amazon S3), custom integrations, and more using built-in connectors.\n  You can learn more about Amazon Managed Service for Apache Flink here. For Amazon Managed Service for Apache Flink region availability, refer to the AWS Region Table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-managed-service-apache-flink-aws-asia-pacific-auckland-region/",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-29dfac7f5a0b",
      "title": "Announcing cost allocation using users’ attributes",
      "description": "AWS announces a new cost allocation feature that uses existing workforce user attributes like cost center, division, organization, and department to track and analyze AWS application usage and cost. This new capability enables customers to allocate per-user monthly subscription and on-demand fees of AWS applications, such as Amazon Q Business, Amazon Q Developer, and Amazon QuickSight, to respective internal business units.\n  Customers should import their workforce users’ attributes to IAM Identity Center, the recommended service for managing workforce access to AWS applications. After importing the attributes, customers can enable one or more of these attributes as cost allocation tags from the AWS Billing and Cost Management console. When users access AWS applications, their usage and cost are automatically recorded with selected attributes. Cloud Financial Operations (FinOps) professionals can view and analyze costs in AWS Cost Explorer and AWS CUR 2.0, gaining visibility into how different teams drive AWS usage and costs.\n  Support for cost allocation using user attributes is generally available in all AWS Regions, excluding GovCloud (US) Regions and China (Beijing) and China (Ningxia) Regions.\n  To learn more, see organizing and tracking cost using AWS cost allocation tags.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/cost-allocation-using-users-attributes",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "q business",
        "iam",
        "iam identity center",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "q business",
        "iam",
        "iam identity center",
        "quicksight",
        "generally-available",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-7790bd8307b4",
      "title": "Amazon EKS introduces enhanced network security policies",
      "description": "Today, we’re announcing enhanced network policy capabilities in Amazon Elastic Kubernetes Service (EKS), allowing customers to improve the network security posture for their Kubernetes workloads and their integrations with cluster-external destinations. This enhancement builds on network segmentation features previously supported in EKS. Now you can centrally enforce network access filters across the entire cluster, as well as leverage Domain Name System (DNS) based policies to secure egress traffic from your cluster’s environment.\n  As customers continue to scale their application environments using EKS, network traffic isolation is increasingly fundamental for preventing unauthorized access to resources inside and outside the cluster. To address this, EKS introduced support for Kubernetes NetworkPolicies in the Amazon VPC Container Network Interface (VPC CNI) plugin, allowing you to segment pod-to-pod communication at a namespace level. Now you can further strengthen the defensive posture for your Kubernetes network environment by centrally managing network filters for the whole cluster. Also, cluster admins now have a more stable and predictable approach for preventing unauthorized access to cluster-external resources in the cloud or on-prem using egress rules that filter traffic to external endpoints based on their Fully Qualified Domain Name (FQDN).\n  These new network security features are available in all commercial AWS Regions for new EKS clusters running Kubernetes version 1.29 or later, with support for existing clusters to follow in the coming weeks. ClusterNetworkPolicy is available in all EKS cluster launch modes using VPC CNI v1.21.1 or later. DNS-based policies are only supported in EKS Auto Mode-launched EC2 instances. To learn more, visit the Amazon EKS documentation or read the launch blog post here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-eks-enhanced-network-security-policies",
      "pubDate": "2025-12-15T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "eks",
        "launch",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-145bc0082f15",
      "title": "How Bayer transforms Pharma R&D with a cloud-based data science ecosystem using Amazon SageMaker",
      "description": "In this post, we discuss how Bayer AG used the next generation of Amazon SageMaker to build a cloud-based Pharma R&D Data Science Ecosystem (DSE) that unified data ingestion, storage, analytics, and AI/ML workflows.",
      "link": "https://aws.amazon.com/blogs/big-data/how-bayer-transforms-pharma-rd-with-a-cloud-based-data-science-ecosystem-using-amazon-sagemaker/",
      "pubDate": "2025-12-12T23:06:25.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-36722fddcb63",
      "title": "Building zero trust generative AI applications in healthcare with AWS Nitro Enclaves",
      "description": "In healthcare, generative AI is transforming how \nmedical professionals analyze data, \nsummarize clinical notes, and \ngenerate insights to improve patient outcomes. From \nautomating medical documentation to assisting in \ndiagnostic reasoning, large language models (LLMs) have the potential to augment clinical workflows and accelerate research. However, these innovations also introduce significant privacy, security, and intellectual property challenges.",
      "link": "https://aws.amazon.com/blogs/compute/building-zero-trust-generative-ai-applications-in-healthcare-with-aws-nitro-enclaves/",
      "pubDate": "2025-12-12T19:06:03.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-bf9d1270943d",
      "title": "AWS DataSync increases scalability and performance for on-premises file transfers",
      "description": "AWS DataSync Enhanced mode now supports data transfers between on-premises file servers and Amazon S3, enabling customers to transfer datasets that scale to virtually unlimited numbers of files at higher levels of performance than DataSync Basic mode.\n  AWS DataSync is a secure, high-speed file transfer service that optimizes data movement over a network. Enhanced mode uses parallel processing to deliver higher performance and scalability for datasets of any size, while removing file count limitations and providing detailed transfer metrics for better monitoring and management. Previously, Enhanced mode was available for data transfers between Amazon S3 locations and for multicloud transfers. This launch extends the capabilities of Enhanced mode to support transfers between on-premises NFS or SMB file servers, and Amazon S3. Using Enhanced mode, customers can accelerate generative AI workloads by rapidly moving training datasets to AWS, power data lake analytics by synchronizing on-premises data with cloud-based pipelines, and drive large-scale migrations for archival and cloud modernization.\n  This new capability is available in all AWS Regions where AWS DataSync is offered. To get started, visit the AWS DataSync console. For more information, see the AWS DataSync documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-datasync-scalability-performance-on-premises-file-transfers",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "launch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-e86106073841",
      "title": "AWS Shield network security director now supports multi-account analysis",
      "description": "Today, AWS Shield announces multi-account network security management and automated network analysis for network security director, which is currently in preview. AWS Shield network security director provides visibility into the AWS resources in your AWS organization, identifies missing or misconfigured network security services, and recommends remediation steps.\n  With network security director, you can specify a delegated administrator account from which you can start continuous network analysis for multiple accounts or organizational units in your AWS Organization. You can then centrally view each account’s network topology, network security findings, and recommended remediations for missing or misconfigured network security services. You can also easily summarize and report on the network security misconfigurations identified by AWS Shield network security director from within Amazon Q Developer in the AWS Management Console and chat applications.\n  AWS Shield network security director is also now available in five additional AWS regions: Europe (Ireland), Europe (Frankfurt), Asia Pacific (Hong Kong), Asia Pacific (Singapore), and Australia (Sydney).\n  To learn more, visit the overview page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-shield-network-security-director-multi-account-analysis",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "preview",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b56aaf668b93",
      "title": "Architecting conversational observability for cloud applications",
      "description": "In this post, we walk through building a generative AI–powered troubleshooting assistant for Kubernetes. The goal is to give engineers a faster, self-service way to diagnose and resolve cluster issues, cut down Mean Time to Recovery (MTTR), and reduce the cycles experts spend finding the root cause of issues in complex distributed systems.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-conversational-observability-for-cloud-applications/",
      "pubDate": "2025-12-11T15:59:39.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    }
  ]
}