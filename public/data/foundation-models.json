{
  "lastUpdated": "2025-09-28T12:35:39.876Z",
  "category": "foundation-models",
  "totalItems": 19,
  "items": [
    {
      "id": "aws-news-4240934578e0",
      "title": "Amazon CloudWatch now supports resource tags when monitoring vended metrics",
      "description": "Today, Amazon CloudWatch announces support for a new tag-based telemetry experience to help customers monitor their metrics and set up their alarms using AWS resources tags. This new capability simplifies monitoring cloud infrastructure at scale by automatically adapting alarms and metrics analysis as resources change. DevOps engineers and cloud administrators can now create dynamic monitoring views that align with their organizational structure using their existing AWS resource tags.\n  Tag-based querying filtering eliminates the manual overhead of updating alarms and dashboards after deployments, freeing teams to focus on innovation rather than maintenance. This provides faster, targeted insights that match how teams organize their systems. Teams can query AWS default metrics using their existing resource tags, making it easier to troubleshoot issues and maintain operational visibility while focusing on core business initiatives.\n  CloudWatch tag-based filtering is available in the following regions: US East (N. Virginia); US East (Ohio); US West (N. California); US West (Oregon); Asia Pacific (Tokyo); Asia Pacific (Seoul); Asia Pacific (Singapore); Asia Pacific (Sydney); Asia Pacific (Mumbai); Asia Pacific (Osaka); Canada (Central); Europe (Frankfurt); Europe (Ireland); Europe (London); Europe (Paris); Europe (Stockholm) and South America (São Paulo).\n  To get started, simply enable tag enriched telemetry with one click in the Amazon CloudWatch Settings, or through the AWS Command Line Interface (AWS CLI), and AWS SDKs to use your existing AWS resource tags to monitor your infrastructure. Learn more on the Amazon CloudWatch documentation page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-cloudwatch-tags-observability",
      "pubDate": "2025-09-25T09:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-b8a7a01ed381",
      "title": "Accelerate AI agent development with the Nova Act IDE extension",
      "description": "The Nova Act extension is a new IDE-integrated tool that enables developers to create browser automation agents using natural language through the Nova Act model, offering features like Builder Mode, chat capabilities, and predefined templates while streamlining the development process without leaving their preferred development environment.",
      "link": "https://aws.amazon.com/blogs/aws/accelerate-ai-agent-development-with-the-nova-act-ide-extension/",
      "pubDate": "2025-09-23T16:01:04.000Z",
      "source": "news-blog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models",
        "industry-cases"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-2d74e91ea4b5",
      "title": "Amazon Nova Act extension: Build and test AI agents within your IDE",
      "description": "We’re excited today to announce the Amazon Nova Act extension - a tool that transforms how you build with Nova Act by bringing the entire agent development experience directly into IDEs like Visual Studio Code, Kiro, and Cursor. The Nova Act extension consolidates natural language based script creation, granular scripting precision, and robust browser testing into a single, unified user interface, eliminating the need to switch between multiple tools across development, validation, and iteration.\n  The Nova Act extension is built on top of the Nova Act SDK, available in research preview since March 2025. The Nova Act extension addresses feedback we have received from developers and consolidates the agent development lifecycle, from ideation to production, into one unified user interface within your IDE.\n  The Nova Act extension is available today from your IDE’s extension marketplace. The Nova Act GitHub repository includes documentation and examples to get started.\n  Learn more about the Nova Act extension and see the Nova Act extension in action at our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-nova-act-extension-build-test-ai-agents-ide/",
      "pubDate": "2025-09-23T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "preview"
      ]
    },
    {
      "id": "aws-news-9c6439e1f1c9",
      "title": "Amazon RDS for MySQL announces Innovation Release 9.4 in Amazon RDS Database Preview Environment",
      "description": "Amazon RDS for MySQL now supports community MySQL Innovation Release 9.4 in the Amazon RDS Database Preview Environment, allowing you to evaluate the latest Innovation Release on Amazon RDS for MySQL. You can deploy MySQL 9.4 in the Amazon RDS Database Preview Environment which provides the benefits of a fully managed database, making it simpler to set up, operate, and monitor databases.\n  MySQL 9.4 is the latest Innovation Release from the MySQL community. MySQL Innovation releases include bug fixes, security patches, as well as new features. MySQL Innovation releases are supported by the community until the next innovation minor, whereas MySQL Long Term Support (LTS) Releases, such as MySQL 8.0 and MySQL 8.4, are supported by the community for up to eight years. Please refer to the MySQL 9.4 release notes and Amazon RDS MySQL release notes for more details.\n  Amazon RDS Database Preview Environment supports both Single-AZ and Multi-AZ deployments on the latest generation of instance classes. Amazon RDS Database Preview Environment database instances are retained for a maximum of 60 days and are automatically deleted after the retention period. Amazon RDS database snapshots created in the Preview Environment can only be used to create or restore database instances within the Preview Environment.\n  Amazon RDS Database Preview Environment database instances are priced the same as production RDS instances created in the US East (Ohio) Region. For further information, see Working with the Database Preview Environment. To get started with the Preview Environment from the RDS console, navigate here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-rds-mysql-innovation-release-94-database-preview-environment/",
      "pubDate": "2025-09-19T15:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "preview",
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-d073fb3f6dab",
      "title": "Announcing AWS Neuron SDK 2.26.0",
      "description": "Today, AWS announces the general availability of Neuron SDK 2.26.0, delivering improvements for deep learning workloads on AWS Inferentia and Trainium-based instances. This release introduces support for PyTorch 2.8 and JAX 0.6.2, along with enhanced inference capabilities on Trainium2 (Trn2) instances. These updates enable developers to leverage the latest frameworks while benefiting from improved model deployment flexibility and performance optimizations.\n  With Neuron SDK 2.26.0, customers can now deploy FLUX.1-dev image generation model, along with Llama 4 Scout and Maverick variants (beta) on Trn2 instances. The release introduces expert parallelism support (beta) for efficient distribution of Mixture-of-Experts (MoE) models across multiple NeuronCores, and adds new capabilities through new Neuron Kernel Interface (NKI) APIs. The updated Neuron Profiler provides improved capabilities, including system profile grouping for distributed workloads.\n  The new SDK version is available in all AWS Regions supporting Inferentia and Trainium instances, offering enhanced performance and monitoring capabilities for machine learning workloads.\n  To learn more and for a full list of new features and enhancements, see:\n  \n \n \nAWS Neuron 2.26.0 release notes\n \n \nTrn2 Instances\n \n \nTrn1 Instances\n \n \nInf2 Instances",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-neuron-2-26-announce/",
      "pubDate": "2025-09-19T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "lex",
        "trainium",
        "inferentia",
        "neuron"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "machine-learning",
        "natural-language"
      ],
      "tags": [
        "lex",
        "trainium",
        "inferentia",
        "neuron",
        "beta",
        "new-feature",
        "update",
        "improvement",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-3105df2f3e57",
      "title": "Qwen models are now available in Amazon Bedrock",
      "description": "Amazon Bedrock has expanded its model offerings with the addition of Qwen 3 foundation models enabling users to access and deploy them in a fully managed, serverless environment. These models feature both mixture-of-experts (MoE) and dense architectures to support diverse use cases including advanced code generation, multi-tool business automation, and cost-optimized AI reasoning.",
      "link": "https://aws.amazon.com/blogs/aws/qwen-models-are-now-available-in-amazon-bedrock/",
      "pubDate": "2025-09-18T22:02:11.000Z",
      "source": "news-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-151bf1dc2ea9",
      "title": "DeepSeek-V3.1 model now available in Amazon Bedrock",
      "description": "AWS launches DeepSeek-V3.1 as a fully managed models in Amazon Bedrock. DeepSeek-V3.1 is a hybrid open weight model that switches between thinking mode for detailed step-by-step analysis and non-thinking mode for faster responses.",
      "link": "https://aws.amazon.com/blogs/aws/deepseek-v3-1-now-available-in-amazon-bedrock/",
      "pubDate": "2025-09-18T21:49:48.000Z",
      "source": "news-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-c753ba529f3a",
      "title": "Scale visual production using Stability AI Image Services in Amazon Bedrock",
      "description": "This post was written with Alex Gnibus of Stability AI. Stability AI Image Services are now available in Amazon Bedrock, offering ready-to-use media editing capabilities delivered through the Amazon Bedrock API. These image editing tools expand on the capabilities of Stability AI’s Stable Diffusion 3.5 models (SD3.5) and Stable Image Core and Ultra models, which […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/scale-visual-production-using-stability-ai-image-services-in-amazon-bedrock/",
      "pubDate": "2025-09-18T21:25:49.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "natural-language"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a073e4c7ece2",
      "title": "Prompting for precision with Stability AI Image Services in Amazon Bedrock",
      "description": "Amazon Bedrock now offers Stability AI Image Services: 9 tools that improve how businesses create and modify images. The technology extends Stable Diffusion and Stable Image models to give you precise control over image creation and editing. Clear prompts are critical—they provide art direction to the AI system. Strong prompts control specific elements like tone, […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/prompting-for-precision-with-stability-ai-image-services-in-amazon-bedrock/",
      "pubDate": "2025-09-18T21:25:34.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "foundation-models"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-3150c633eaf5",
      "title": "Stability AI Image Services now available in Amazon Bedrock",
      "description": "Amazon Bedrock announces the availability of Stability AI Image Services, a comprehensive suite of 9 specialized image editing tools designed to accelerate professional creative workflows. Stability AI Image Services enable granular control over image editing with a range of tools designed to work with your creative process, allowing you to take a single concept from ideation to finished product with precision and flexibility.\n  Stability AI Image Services offers two categories of image editing capabilities: Edit tools: Remove Background, Erase Object, Search and Replace, Search and Recolor, and Inpaint let you make targeted modifications to specific parts of your images. Control tools: Structure, Sketch, Style Guide, and Style Transfer give you powerful ways to generate variations based on existing images or sketches.\n  Stability AI Image Services is now available in Amazon Bedrock through the API and is supported in US West (Oregon), US East (N. Virginia), and US East (Ohio). For more information on supported regions, visit the Amazon Bedrock Model Support by Regions guide. For more details about Stability AI Image Services and its capabilities, visit the Stability AI product page and Stability AI documentation page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/stability-ai-image-services-generally-available-amazon-bedrock",
      "pubDate": "2025-09-18T16:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "natural-language",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-0f3ee5cb5f1f",
      "title": "Qwen3 models are now available fully managed in Amazon Bedrock",
      "description": "Amazon Bedrock continues to expand model choice by adding four Qwen3 open weight foundation models, now available as fully managed, serverless offerings. The lineup includes: Qwen3-Coder-480B-A35B-Instruct, Qwen3-Coder-30B-A3B-Instruct, Qwen3-235B-A22B-Instruct-2507, and Qwen3-32B for efficient dense computation. These models feature both dense and Mixture-of-Experts (MoE) architectures, providing flexible options for various development needs.\n  These open weight models enable you to build powerful AI applications with advanced agentic capabilities, without managing any infrastructure. The two Qwen3-Coder models excel at agentic coding and complex software engineering tasks, offering state-of-the-art performance for function calling and tool use. The 235B model delivers efficient general reasoning and instruction following across diverse tasks, while the 32B dense model provides a more traditional architecture suitable for a wide range of computational tasks.\n  Qwen3 models (32B, Coder-30B) are available today in the US East (N. Virginia), US West (Oregon), Asia Paciﬁc (Mumbai, Tokyo), Europe (Ireland, London, Milan, Stockholm), and South America (São Paulo) AWS Regions. Qwen 235B is available today in theUS West (Oregon), Asia Paciﬁc (Mumbai, Tokyo), and Europe (London, Milan, Stockholm) AWS Regions. Qwen Coder-480B is available today in the US West (Oregon), Asia Paciﬁc (Mumbai, Tokyo), and Europe (London, Stockholm) AWS Regions. Check the full Region list for future updates. To learn more, read the blog, product page, Amazon Bedrock pricing, and documentation. To get started with Qwen in Amazon Bedrock, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/qwen3-models-fully-managed-amazon-bedrock",
      "pubDate": "2025-09-18T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "natural-language"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "update"
      ]
    },
    {
      "id": "aws-news-b2e219fc1dd9",
      "title": "DeepSeek-V3.1 model now available fully managed in Amazon Bedrock",
      "description": "DeepSeek-V3.1 is now available as a fully managed foundation model in Amazon Bedrock. This advanced open weight model allows you to switch between thinking mode for detailed step-by-step analysis and non-thinking mode for quicker responses. With comprehensive multilingual support, it delivers enhanced accuracy and reduced hallucinations compared to previous DeepSeek models, while maintaining visibility into its decision-making process.\n  You can use DeepSeek-V3.1's enterprise-grade capabilities across critical business functions, from state-of-the-art software development to complex mathematical reasoning and data analysis. The model excels at sophisticated problem-solving tasks, demonstrating strong performance in coding benchmarks and technical challenges. Its enhanced tool-calling capabilities and seamless workflow integration make it ideal for building AI agents and automating enterprise processes, while its transparent reasoning approach helps teams understand and trust its outputs.\n  \n DeepSeek-V3.1 is now available in the US West (Oregon), Asia Paciﬁc (Tokyo), Asia Paciﬁc (Mumbai), Europe (London), and Europe (Stockholm) AWS Regions. To learn more, read the blog, product page, Amazon Bedrock pricing, and documentation. To get started with DeepSeek in Amazon Bedrock, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/deepseek-v3-1-model-fully-managed-amazon-bedrock",
      "pubDate": "2025-09-18T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "natural-language"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-949eb2c3ce5a",
      "title": "AWS Parallel Computing Service (PCS) now supports Amazon EC2 Capacity Blocks for ML",
      "description": "AWS Parallel Computing Service (PCS) now supports Amazon EC2 Capacity Blocks for ML. You can now use Amazon EC2 instances reserved using EC2 Capacity Blocks natively in PCS clusters.\n  Native support for EC2 Capacity Blocks in PCS simplifies capacity planning for cutting-edge GPU-based workloads in Slurm clusters, helping to ensure that GPU capacity is available when and where it’s needed. EC2 Capacity Blocks can be associated with PCS compute node groups via an EC2 Launch Template.\n  PCS is a managed service that makes it easier for you to run and scale your high performance computing (HPC) workloads and build scientific and engineering models on AWS using Slurm. You can use PCS to build complete, elastic environments that integrate compute, storage, networking, and visualization tools. PCS simplifies cluster operations with managed updates and built-in observability features, helping to remove the burden of maintenance. You can work in a familiar environment, focusing on your research and innovation instead of worrying about infrastructure.\n  PCS now supports EC2 Capacity Blocks in all AWS Regions where both services are available. Read more about PCS support for EC2 Capacity Blocks in the PCS User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/aws-parallel-computing-service-ec2-capacity-blocks-ml/",
      "pubDate": "2025-09-17T07:00:00.000Z",
      "source": "whats-new",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "foundation-models"
      ],
      "tags": [
        "nova",
        "launch",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-431447666038",
      "title": "Unified multimodal access layer for Quora’s Poe using Amazon Bedrock",
      "description": "In this post, we explore how the AWS Generative AI Innovation Center and Quora collaborated to build a unified wrapper API framework that dramatically accelerates the deployment of Amazon Bedrock FMs on Quora’s Poe system. We detail the technical architecture that bridges Poe’s event-driven ServerSentEvents protocol with Amazon Bedrock REST-based APIs, demonstrate how a template-based configuration system reduced deployment time from days to 15 minutes, and share implementation patterns for protocol translation, error handling, and multi-modal capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/unified-multimodal-access-layer-for-quoras-poe-using-amazon-bedrock/",
      "pubDate": "2025-09-16T16:40:11.000Z",
      "source": "ml-blog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "industry-cases"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-bd724f32f406",
      "title": "Amazon SageMaker HyperPod announces health monitoring agent support for Slurm clusters",
      "description": "Today, Amazon SageMaker HyperPod announces the general availability of the health monitoring agent for Slurm clusters. SageMaker HyperPod helps you provision resilient clusters for running machine learning (ML) workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs). The health monitoring agent performs passive, background health checks of instances to identify problems in key areas without impact on application behavior or performance, flags failures instantly, and replaces any unhealthy instances to keep your training jobs running smoothly. \n \nThe agent runs continuously on all GPU- or Trainium-based nodes in your HyperPod cluster, watching for hardware issues such as unresponsive GPUs or NVLink error counters. When a fault is detected, it marks the node as unhealthy and automatically reboots or replaces it with a healthy node, keeping your jobs running without requiring manual intervention. The agent also follows a co-ordinated approach to handling failures with the job auto-resume functionality available with Slurm clusters. For example, jobs with auto-resume enabled will continue from the last saved checkpoint once nodes are replaced by the agent. This hands-free recovery—already available on HyperPod clusters orchestrated with Amazon EKS—now gives Slurm clusters the same resilient environment, helping teams train large models for weeks without disruption and reclaim time and costs that would otherwise be lost to mid-run failures. In addition, customers can now also reboot their nodes using a simple command in case of intermittent issues such as GPU driver issues requiring reset. \n \nHealth monitoring agent for Slurm is available in all regions where HyperPod is generally available. The agent is auto-enabled on all newly created Slurm clusters; to enable it on an existing cluster, simply upgrade to the latest HyperPod AMI by calling the UpdateClusterSoftware API. To learn more, visit the Amazon SageMaker HyperPod documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-sagemaker-hyperpod-health-monitoring-agent-slurm/",
      "pubDate": "2025-09-15T18:00:00.000Z",
      "source": "whats-new",
      "services": [
        "sagemaker",
        "hyperpod",
        "trainium"
      ],
      "categories": [
        "foundation-models",
        "machine-learning",
        "industry-cases"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "trainium",
        "generally-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-217d740871a7",
      "title": "Announcing on-demand deployment for custom Meta Llama models in Amazon Bedrock",
      "description": "Starting today, customers can use the on-demand deployment option in Amazon Bedrock for their Meta Llama 3.3 models that have been fine-tuned or distilled in Bedrock. Models customized on or after September 15, 2025 will be eligible.\n  This enables Bedrock customers to reduce costs by processing requests in real time without requiring pre-provisioned compute resources. Customers only pay for what they use, eliminating the need for an always-on infrastructure.\n  Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models from leading AI companies via a single API. Amazon Bedrock also provides a broad set of capabilities customers need to build generative AI applications with security, privacy, and responsible AI built in.\n  To get started, visit documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/on-demand-deployment-custom-meta-llama-models-amazon-bedrock",
      "pubDate": "2025-09-15T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "ai-safety"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-c1f00f103971",
      "title": "Amazon SageMaker notebooks now support P6-B200 instance type",
      "description": "We are pleased to announce general availability of Amazon EC2 P6-B200 instances on SageMaker notebooks.\n  Amazon EC2 P6-B200 instances are powered by 8 NVIDIA Blackwell GPUs with 1440 GB of high-bandwidth GPU memory and 5th Generation Intel Xeon processors (Emerald Rapids). These instances deliver up to 2x better performance compared to P5en instances for AI training. Customers can use P6-B200 instances to interactively develop and fine-tune large foundation models, including LLMs, mixture of experts models, and multi-modal reasoning models. These instances enable efficient experimentation with larger models directly in JupyterLab or CodeEditor environments for generative AI applications such as enterprise copilots and content generation across text, images, and video.\n  Amazon EC2 P6-B200 instances are available for SageMaker notebooks in the AWS US East (Ohio) and US West (Oregon) regions.\n  Visit developer guides for instructions on setting up and using JupyterLab and CodeEditor applications on SageMaker Studio and SageMaker notebook instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/09/amazon-sagemaker-notebooks-p6-b200-instance-type",
      "pubDate": "2025-09-12T14:00:00.000Z",
      "source": "whats-new",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai",
        "foundation-models",
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-0b47e55e58e4",
      "title": "AWS named as a Leader in 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for 15 years in a row",
      "description": "AWS is recognized as a Leader in the 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services for the fifteenth consecutive year. In the report, Gartner once again placed AWS highest on the “Ability to Execute” axis. We believe this reflects our ongoing commitment to giving customers the broadest and deepest set of capabilities to accelerate innovation as well as unparalleled security, reliability, and performance they can trust for their most critical applications.",
      "link": "https://aws.amazon.com/blogs/aws/aws-named-as-a-leader-in-2025-gartner-magic-quadrant-for-strategic-cloud-platform-services-for-15-years-in-a-row/",
      "pubDate": "2025-08-15T16:59:11.000Z",
      "source": "news-blog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models",
        "industry-cases"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-d2be49d3bcd1",
      "title": "Celebrating 10 years of Amazon Aurora innovation",
      "description": "Amazon Aurora is celebrating its 10th anniversary with a livestream event on August 21, 2025, highlighting a decade of database innovation since its groundbreaking architecture that decoupled storage from compute.",
      "link": "https://aws.amazon.com/blogs/aws/celebrating-10-years-of-amazon-aurora-innovation/",
      "pubDate": "2025-08-15T16:01:02.000Z",
      "source": "news-blog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai",
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    }
  ]
}