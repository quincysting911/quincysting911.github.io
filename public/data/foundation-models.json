{
  "lastUpdated": "2026-01-23T06:18:28.209Z",
  "category": "foundation-models",
  "totalItems": 12,
  "items": [
    {
      "id": "aws-news-3489e5c40783",
      "title": "Amazon SageMaker HyperPod introduces enhanced lifecycle scripts debugging",
      "description": "Amazon SageMaker HyperPod now provides enhanced troubleshooting capabilities for lifecycle scripts, making it easier to identify and resolve issues during cluster node provisioning. SageMaker HyperPod helps you provision resilient clusters for running AI/ML workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs).\n  When lifecycle scripts encounter issues during cluster creation or node operations, you now receive detailed error messages that include the specific CloudWatch log group and log stream names where you can find execution logs for lifecycle scripts. You can view these error messages by running the DescribeCluster API or by viewing the cluster details page in the SageMaker console. The console also provides a \"View lifecycle script logs\" button that navigates directly to the relevant CloudWatch log stream, making it easier to locate logs. Additionally, CloudWatch logs for lifecycle scripts now include specific markers to help you track lifecycle script execution progress, including indicators for when the lifecycle script log begins, when scripts are being downloaded, when downloads complete, and when scripts succeed or fail. These markers help you quickly identify where issues occurred during the provisioning process. These enhancements reduce the time required to diagnose and fix lifecycle script failures, helping you get your HyperPod clusters up and running faster.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is supported. To learn more, see SageMaker HyperPod cluster management in the Amazon SageMaker Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-sagemaker-hyperpod-lcs-enhanced-debug/",
      "pubDate": "2026-01-21T19:15:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "cloudwatch"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "cloudwatch",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-456e02260dac",
      "title": "Amazon Bedrock Reserved Tier available now for Claude Sonnet 4.5 in AWS GovCloud (US-West)",
      "description": "Today, Amazon Bedrock introduces the expansion of the Reserved service tier designed for workloads requiring predictable performance and guaranteed tokens-per-minute capacity. The Reserved tier provides the ability to reserve prioritized compute capacity, keeping service levels predictable for your mission critical applications. It also includes the flexibility to allocate different input and output tokens-per-minute capacities to match the exact requirements of your workload and control cost. This is particularly valuable because many workloads have asymmetric token usage patterns. For instance, summarization tasks consume many input tokens but generate fewer output tokens, while content generation applications require less input and more output capacity. When your application needs more tokens-per-minute capacity than what you reserved , the service automatically overflows to the pay-as-you-go Standard tier, ensuring uninterrupted operations. The Reserved tier is available today for Anthropic Claude Sonnet 4.5 in AWS GovCloud (US-West). Customers can reserve capacity for 1 month or 3 month duration. Customers pay a fixed price per 1K tokens-per-minute and are billed monthly. Amazon Bedrock Reserved Tier is available for customers in AWS GovCloud (US-West) via GOV-CRIS cross-region profile.\n  With the expansion of the Reserved service tier, Amazon Bedrock continues to provide more choice to customers, helping them develop, scale, and deploy applications and agents that improve productivity and customer experiences while balancing performance and cost requirements.\n  For more information about the AWS Regions where Amazon Bedrock Reserved tier is available, refer to the Documentation. To get access to the Reserved tier, please contact your AWS account team.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-reserved-tier-for-claude-sonnet-in-govcloud/",
      "pubDate": "2026-01-21T17:02:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "expansion"
      ]
    },
    {
      "id": "aws-news-1d5285365111",
      "title": "Amazon Bedrock Reserved Tier available now for Claude Opus 4.5 and Haiku 4.5",
      "description": "Today, Amazon Bedrock announces the expansion of the Reserved service tier designed for workloads requiring predictable performance and guaranteed tokens-per-minute capacity. The Reserved tier provides the ability to reserve prioritized compute capacity, keeping service levels predictable for your mission critical applications. It also includes the flexibility to allocate different input and output tokens-per-minute capacities to match the exact requirements of your workload and control cost. This is particularly valuable because many workloads have asymmetric token usage patterns. For instance, summarization tasks consume many input tokens but generate fewer output tokens, while content generation applications require less input and more output capacity. When your application needs more tokens-per-minute capacity than what you reserved , the service automatically overflows to the pay-as-you-go Standard tier, ensuring uninterrupted operations. The Reserved tier and is available today for Anthropic Claude Opus 4.5 and Claude Haiku 4.5. Customers can reserve capacity for 1 month or 3 month duration. Customers pay a fixed price per 1K tokens-per-minute and are billed monthly.\n  With the expansion of the Reserved service tier, Amazon Bedrock continues to provide more choice to customers, helping them develop, scale, and deploy applications and agents that improve productivity and customer experiences while balancing performance and cost requirements.\n  For more information about the AWS Regions where Amazon Bedrock Reserved tier is available, refer to the Documentation. To get access to the Reserved tier, please contact your AWS account team.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-reserved-tier-claude-opus-haiku/",
      "pubDate": "2026-01-16T18:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "expansion"
      ]
    },
    {
      "id": "aws-news-4d20717331d3",
      "title": "How Palo Alto Networks enhanced device security infra log analysis with Amazon Bedrock",
      "description": "Palo Alto Networks’ Device Security team wanted to detect early warning signs of potential production issues to provide more time to SMEs to react to these emerging problems. They partnered with the AWS Generative AI Innovation Center (GenAIIC) to develop an automated log classification pipeline powered by Amazon Bedrock. In this post, we discuss how Amazon Bedrock, through Anthropic’ s Claude Haiku model, and Amazon Titan Text Embeddings work together to automatically classify and analyze log data. We explore how this automated pipeline detects critical issues, examine the solution architecture, and share implementation insights that have delivered measurable operational improvements.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-palo-alto-networks-enhanced-device-security-infra-log-analysis-with-amazon-bedrock/",
      "pubDate": "2026-01-16T15:46:36.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "improvement"
      ]
    },
    {
      "id": "aws-news-ada5748d03cb",
      "title": "Scale creative asset discovery with Amazon Nova Multimodal Embeddings unified vector search",
      "description": "In this post, we describe how you can use Amazon Nova Multimodal Embeddings to retrieve specific video segments. We also review a real-world use case in which Nova Multimodal Embeddings achieved a recall success rate of 96.7% and a high-precision recall of 73.3% (returning the target content in the top two results) when tested against a library of 170 gaming creative assets. The model also demonstrates strong cross-language capabilities with minimal performance degradation across multiple languages.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scale-creative-asset-discovery-with-amazon-nova-multimodal-embeddings-unified-vector-search/",
      "pubDate": "2026-01-15T15:45:02.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-5b09b020ff29",
      "title": "AWS Data Exports  adds granular operation visibility for Amazon Bedrock model usage",
      "description": "AWS Data Exports now enables customers to distinguish between Amazon Bedrock operation types in their cost reports for enhanced cost analysis and optimization. This granular operation information is available in Cost and Usage Reports (CUR), CUR 2.0, and Data Exports for FOCUS, and is particularly valuable for FinOps teams, cost optimization professionals, and organizations using Amazon Bedrock that require detailed billing analysis.\n  Customers will now see specific operation types such as \"InvokeModelInference\" and \"InvokeModelStreamingInference\" in their cost reports, replacing generic \"Usage\" labels. These granular operation types appear in the \"line_item_operation\" column in Legacy CUR and CUR 2.0 reports, the \"x_Operation\" column in FOCUS reports, and AWS Cost Explorer API Operation dimension values. This visibility now extends to all foundation models on Amazon Bedrock, enabling precise tracking of usage patterns and cost optimization opportunities across all model providers.\n  To learn more about AWS Billing and Cost Management, visit the AWS Billing and Cost Management documentation, and for AWS Data Exports, visit the AWS Data Exports documentation. To get started with Amazon Bedrock, visit the Amazon Bedrock page and see the Amazon Bedrock documentation for more details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-granular-usage-visibility",
      "pubDate": "2026-01-15T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-2ee469a433b5",
      "title": "Transform AI development with new Amazon SageMaker AI model customization and large-scale training capabilities",
      "description": "This post explores how new serverless model customization capabilities, elastic training, checkpointless training, and serverless MLflow work together to accelerate your AI development from months to days.",
      "link": "https://aws.amazon.com/blogs/machine-learning/transform-ai-development-with-new-amazon-sagemaker-ai-model-customization-and-large-scale-training-capabilities/",
      "pubDate": "2026-01-14T21:13:42.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-4124e81eda7a",
      "title": "Amazon Bedrock introduces API keys to streamline development in GovCloud regions",
      "description": "API keys for Amazon Bedrock are now available in AWS GovCloud (US) regions, expanding a feature that simplifies authentication and accelerates generative AI development. Originally launched in commercial AWS regions in July 2025, API keys for Amazon Bedrock enable developers to quickly generate access credentials directly within the Amazon Bedrock console or AWS SDK without needing to manually configure IAM principals and policies.\n  With the introduction of API keys for Amazon Bedrock, developers can generate short-term and long-term API keys directly from the Amazon Bedrock console or API to authenticate API calls to Amazon Bedrock models. Short-term API keys are valid for the duration of your console session, or up to 12 hours, whichever is shorter. Long-term API keys give you the flexibility to define key validity duration and manage the keys from the AWS IAM console.\n  Bedrock API key authentication is now available in the AWS GovCloud (US) and commercial AWS Regions where Amazon Bedrock is available.\n  To learn more about API keys in Amazon Bedrock, visit the API Keys documentation in the Amazon Bedrock user guide, or check out our blog for code snippets and implementation examples.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-bedrock-api-keys-streamline-development-govcloud/",
      "pubDate": "2026-01-14T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "iam"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "iam",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-7a070b83b1b0",
      "title": "Amazon SageMaker HyperPod now validates service quotas before creating clusters on console",
      "description": "Amazon SageMaker HyperPod console now validates service quotas for your AWS account before initiating cluster creation, enabling you to confirm sufficient quota availability before provisioning begins. SageMaker HyperPod helps you provision resilient clusters for running AI/ML workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs).\n  When creating large-scale AI/ML clusters, you need to ensure your account has sufficient quotas for instances, storage, and networking resources, but quota validation previously required manual checks across multiple AWS services, often resulting in failed cluster creation attempts and wasted time if you miss requesting quota limit increases. The new quota validation capability in the SageMaker HyperPod console automatically checks your account-level quotas against your cluster configuration, including instance type limits, EBS volume sizes, and VPC-related quotas when creating new resources. The validation displays a clear table showing expected utilization, applied quota values, and compliance status for each quota. When quotas may be exceeded, you receive a warning alert with direct links to the Service Quotas console to request increases.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is supported. For a complete list of service quota validation checks performed, refer to the Amazon SageMaker HyperPod User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-sagemaker-hyperpod-validates-service-quotas/",
      "pubDate": "2026-01-12T18:10:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-12eadb812c54",
      "title": "How Omada Health scaled patient care by fine-tuning Llama models on Amazon SageMaker AI",
      "description": "This post is co-written with Sunaina Kavi, AI/ML Product Manager at Omada Health. Omada Health, a longtime innovator in virtual healthcare delivery, launched a new nutrition experience in 2025, featuring OmadaSpark, an AI agent trained with robust clinical input that delivers real-time motivational interviewing and nutrition education. It was built on AWS. OmadaSpark was designed […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-omada-health-scaled-patient-care-by-fine-tuning-llama-models-on-amazon-sagemaker-ai/",
      "pubDate": "2026-01-12T16:56:12.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "launch"
      ]
    },
    {
      "id": "aws-news-9aa4ee62ff93",
      "title": "Crossmodal search with Amazon Nova Multimodal Embeddings",
      "description": "In this post, we explore how Amazon Nova Multimodal Embeddings addresses the challenges of crossmodal search through a practical ecommerce use case. We examine the technical limitations of traditional approaches and demonstrate how Amazon Nova Multimodal Embeddings enables retrieval across text, images, and other modalities. You learn how to implement a crossmodal search system by generating embeddings, handling queries, and measuring performance. We provide working code examples and share how to add these capabilities to your applications.",
      "link": "https://aws.amazon.com/blogs/machine-learning/crossmodal-search-with-amazon-nova-multimodal-embeddings/",
      "pubDate": "2026-01-10T00:06:16.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    }
  ]
}