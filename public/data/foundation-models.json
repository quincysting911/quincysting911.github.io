{
  "lastUpdated": "2026-01-20T06:19:57.491Z",
  "category": "foundation-models",
  "totalItems": 10,
  "items": [
    {
      "id": "aws-news-4d20717331d3",
      "title": "How Palo Alto Networks enhanced device security infra log analysis with Amazon Bedrock",
      "description": "Palo Alto Networks’ Device Security team wanted to detect early warning signs of potential production issues to provide more time to SMEs to react to these emerging problems. They partnered with the AWS Generative AI Innovation Center (GenAIIC) to develop an automated log classification pipeline powered by Amazon Bedrock. In this post, we discuss how Amazon Bedrock, through Anthropic’ s Claude Haiku model, and Amazon Titan Text Embeddings work together to automatically classify and analyze log data. We explore how this automated pipeline detects critical issues, examine the solution architecture, and share implementation insights that have delivered measurable operational improvements.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-palo-alto-networks-enhanced-device-security-infra-log-analysis-with-amazon-bedrock/",
      "pubDate": "2026-01-16T15:46:36.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "improvement"
      ]
    },
    {
      "id": "aws-news-ada5748d03cb",
      "title": "Scale creative asset discovery with Amazon Nova Multimodal Embeddings unified vector search",
      "description": "In this post, we describe how you can use Amazon Nova Multimodal Embeddings to retrieve specific video segments. We also review a real-world use case in which Nova Multimodal Embeddings achieved a recall success rate of 96.7% and a high-precision recall of 73.3% (returning the target content in the top two results) when tested against a library of 170 gaming creative assets. The model also demonstrates strong cross-language capabilities with minimal performance degradation across multiple languages.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scale-creative-asset-discovery-with-amazon-nova-multimodal-embeddings-unified-vector-search/",
      "pubDate": "2026-01-15T15:45:02.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-36d8b357cc69",
      "title": "AWS Data Exports  adds granular operation visibility for Amazon Bedrock model usage",
      "description": "AWS Data Exports now enables customers to distinguish between Amazon Bedrock operation types in their cost reports for enhanced cost analysis and optimization. This granular operation information is available in Cost and Usage Reports (CUR), CUR 2.0, and Data Exports for FOCUS, and is particularly valuable for FinOps teams, cost optimization professionals, and organizations using Amazon Bedrock that require detailed billing analysis.\n  Customers will now see specific operation types such as \"InvokeModelInference\" and \"InvokeModelStreamingInference\" in their cost reports, replacing generic \"Usage\" labels. These granular operation types appear in the \"line_item_operation\" column in Legacy CUR and CUR 2.0 reports, the \"x_Operation\" column in FOCUS reports, and AWS Cost Explorer API Operation dimension values. This visibility now extends to all foundation models on Amazon Bedrock, enabling precise tracking of usage patterns and cost optimization opportunities across all model providers.\n  To learn more about AWS Billing and Cost Management, visit the AWS Billing and Cost Management documentation, and for AWS Data Exports, visit the AWS Data Exports documentation. To get started with Amazon Bedrock, visit the Amazon Bedrock page and see the Amazon Bedrock documentation for more details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/granular-amazon-bedrock/",
      "pubDate": "2026-01-15T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-2ee469a433b5",
      "title": "Transform AI development with new Amazon SageMaker AI model customization and large-scale training capabilities",
      "description": "This post explores how new serverless model customization capabilities, elastic training, checkpointless training, and serverless MLflow work together to accelerate your AI development from months to days.",
      "link": "https://aws.amazon.com/blogs/machine-learning/transform-ai-development-with-new-amazon-sagemaker-ai-model-customization-and-large-scale-training-capabilities/",
      "pubDate": "2026-01-14T21:13:42.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-4124e81eda7a",
      "title": "Amazon Bedrock introduces API keys to streamline development in GovCloud regions",
      "description": "API keys for Amazon Bedrock are now available in AWS GovCloud (US) regions, expanding a feature that simplifies authentication and accelerates generative AI development. Originally launched in commercial AWS regions in July 2025, API keys for Amazon Bedrock enable developers to quickly generate access credentials directly within the Amazon Bedrock console or AWS SDK without needing to manually configure IAM principals and policies.\n  With the introduction of API keys for Amazon Bedrock, developers can generate short-term and long-term API keys directly from the Amazon Bedrock console or API to authenticate API calls to Amazon Bedrock models. Short-term API keys are valid for the duration of your console session, or up to 12 hours, whichever is shorter. Long-term API keys give you the flexibility to define key validity duration and manage the keys from the AWS IAM console.\n  Bedrock API key authentication is now available in the AWS GovCloud (US) and commercial AWS Regions where Amazon Bedrock is available.\n  To learn more about API keys in Amazon Bedrock, visit the API Keys documentation in the Amazon Bedrock user guide, or check out our blog for code snippets and implementation examples.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-bedrock-api-keys-streamline-development-govcloud/",
      "pubDate": "2026-01-14T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "iam"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "iam",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-7a070b83b1b0",
      "title": "Amazon SageMaker HyperPod now validates service quotas before creating clusters on console",
      "description": "Amazon SageMaker HyperPod console now validates service quotas for your AWS account before initiating cluster creation, enabling you to confirm sufficient quota availability before provisioning begins. SageMaker HyperPod helps you provision resilient clusters for running AI/ML workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs).\n  When creating large-scale AI/ML clusters, you need to ensure your account has sufficient quotas for instances, storage, and networking resources, but quota validation previously required manual checks across multiple AWS services, often resulting in failed cluster creation attempts and wasted time if you miss requesting quota limit increases. The new quota validation capability in the SageMaker HyperPod console automatically checks your account-level quotas against your cluster configuration, including instance type limits, EBS volume sizes, and VPC-related quotas when creating new resources. The validation displays a clear table showing expected utilization, applied quota values, and compliance status for each quota. When quotas may be exceeded, you receive a warning alert with direct links to the Service Quotas console to request increases.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is supported. For a complete list of service quota validation checks performed, refer to the Amazon SageMaker HyperPod User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-sagemaker-hyperpod-validates-service-quotas/",
      "pubDate": "2026-01-12T18:10:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-12eadb812c54",
      "title": "How Omada Health scaled patient care by fine-tuning Llama models on Amazon SageMaker AI",
      "description": "This post is co-written with Sunaina Kavi, AI/ML Product Manager at Omada Health. Omada Health, a longtime innovator in virtual healthcare delivery, launched a new nutrition experience in 2025, featuring OmadaSpark, an AI agent trained with robust clinical input that delivers real-time motivational interviewing and nutrition education. It was built on AWS. OmadaSpark was designed […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-omada-health-scaled-patient-care-by-fine-tuning-llama-models-on-amazon-sagemaker-ai/",
      "pubDate": "2026-01-12T16:56:12.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "launch"
      ]
    },
    {
      "id": "aws-news-9aa4ee62ff93",
      "title": "Crossmodal search with Amazon Nova Multimodal Embeddings",
      "description": "In this post, we explore how Amazon Nova Multimodal Embeddings addresses the challenges of crossmodal search through a practical ecommerce use case. We examine the technical limitations of traditional approaches and demonstrate how Amazon Nova Multimodal Embeddings enables retrieval across text, images, and other modalities. You learn how to implement a crossmodal search system by generating embeddings, handling queries, and measuring performance. We provide working code examples and share how to add these capabilities to your applications.",
      "link": "https://aws.amazon.com/blogs/machine-learning/crossmodal-search-with-amazon-nova-multimodal-embeddings/",
      "pubDate": "2026-01-10T00:06:16.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-d9db993d9387",
      "title": "MiniMax-M2 is now available on Amazon SageMaker JumpStart",
      "description": "MiniMax-M2 is now available on Amazon SageMaker JumpStart, providing customers with immediate access to deploy this efficient open-source model in minutes. With SageMaker JumpStart, you can quickly discover, evaluate, and deploy MiniMax-M2 using either SageMaker Studio's intuitive interface or the SageMaker Python SDK for programmatic deployment.\n \nMiniMax-M2 redefines efficiency for agents. It's a compact, fast, and cost-effective MoE model (230 billion total parameters with 10 billion active parameters) built for elite performance in coding and agentic tasks, all while maintaining powerful general intelligence.\n \nTo learn more about deploying foundation models with SageMaker JumpStart, deployment options with the SDK, and best practices for implementation, refer to our documentation.\n \nMiniMax-M2 is available in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Mumbai), Asia Pacific (Sydney), Asia Pacific (Jakarta), Canada (Central), Europe (Frankfurt), Europe (Stockholm), Europe (Ireland), Europe (London), Europe (Paris), South America (São Paulo).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/minimax-m2-on-sagemaker-jumpstart",
      "pubDate": "2025-12-23T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    }
  ]
}