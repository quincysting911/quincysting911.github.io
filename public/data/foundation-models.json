{
  "lastUpdated": "2025-10-15T06:15:42.218Z",
  "category": "foundation-models",
  "totalItems": 7,
  "items": [
    {
      "id": "aws-news-bf153180c688",
      "title": "Customizing text content moderation with Amazon Nova",
      "description": "In this post, we introduce Amazon Nova customization for text content moderation through Amazon SageMaker AI, enabling organizations to fine-tune models for their specific moderation needs. The evaluation across three benchmarks shows that customized Nova models achieve an average improvement of 7.3% in F1 scores compared to the baseline Nova Lite, with individual improvements ranging from 4.2% to 9.2% across different content moderation tasks.",
      "link": "https://aws.amazon.com/blogs/machine-learning/customizing-text-content-moderation-with-amazon-nova/",
      "pubDate": "2025-10-09T21:47:08.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "organizations",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-a455e3668042",
      "title": "Automate Amazon QuickSight data stories creation with agentic AI using Amazon Nova Act",
      "description": "In this post, we demonstrate how Amazon Nova Act automates QuickSight data story creation, saving time so you can focus on making critical, data-driven business decisions.",
      "link": "https://aws.amazon.com/blogs/machine-learning/automate-amazon-quicksight-data-stories-creation-with-agentic-ai-using-amazon-nova-act/",
      "pubDate": "2025-10-07T17:43:26.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "amazon q",
        "quicksight"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "amazon q",
        "quicksight"
      ]
    },
    {
      "id": "aws-news-08b1de84b163",
      "title": "Responsible AI: How PowerSchool safeguards millions of students with AI-powered content filtering using Amazon SageMaker AI",
      "description": "In this post, we demonstrate how PowerSchool built and deployed a custom content filtering solution using Amazon SageMaker AI that achieved better accuracy while maintaining low false positive rates. We walk through our technical approach to fine tuning Llama 3.1 8B, our deployment architecture, and the performance results from internal validations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/responsible-ai-how-powerschool-safeguards-millions-of-students-with-ai-powered-content-filtering-using-amazon-sagemaker-ai/",
      "pubDate": "2025-10-06T19:14:40.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "rds"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "rds"
      ]
    },
    {
      "id": "aws-news-64984ffcbecb",
      "title": "Unlock global AI inference scalability using new global cross-Region inference on Amazon Bedrock  with Anthropic’s Claude Sonnet 4.5",
      "description": "Organizations are increasingly integrating generative AI capabilities into their applications to enhance customer experiences, streamline operations, and drive innovation. As generative AI workloads continue to grow in scale and importance, organizations face new challenges in maintaining consistent performance, reliability, and availability of their AI-powered applications. Customers are looking to scale their AI inference workloads across […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/unlock-global-ai-inference-scalability-using-new-global-cross-region-inference-on-amazon-bedrock-with-anthropics-claude-sonnet-4-5/",
      "pubDate": "2025-10-03T21:37:26.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-cebc03ef3cac",
      "title": "Cohere’s Embed v4 multimodal embeddings model now available on Amazon Bedrock",
      "description": "Amazon Bedrock now offers Cohere Embed v4, the latest state-of-the-art multimodal embedding model from Cohere that produces high-quality embeddings for text, images, and complex business documents. This powerful addition to Amazon Bedrock enables enterprises to build AI applications with frontier search and retrieval capabilities.\n  Traditional embedding models often struggle to understand complex multimodal business materials, such as business presentations and sales and financial reports, requiring extensive data pre-processing pipelines. Embed v4 addresses this challenge by natively processing documents with tables, graphs, diagrams, code snippets, and even handwritten notes. The model handles real-world imperfections such as spelling errors and formatting issues, eliminating the need for time-consuming data cleanup and helping you surface insights from previously difficult-to-search information.\n  With support for over 100 languages, including Arabic, English, French, Japanese, and Korean, Embed v4 enables global organizations to seamlessly search for information, breaking language barriers. The model is also fine-tuned for industries such as finance, healthcare, and manufacturing, delivering superior performance on specialized documents including financial reports, medical records, and product specifications.\n  Cohere Embed v4 is available for on-demand inference in US East (N. Virginia), Europe (Ireland), and Asia Pacific (Tokyo), and can be accessed from select public AWS Regions through cross-region inference. Review the Amazon Bedrock Model Support by Regions guide for complete regional availability. To get started, visit the Amazon Bedrock console to request model access. For more information, refer to the Cohere product page and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/coheres-embed-v4-multimodal-embeddings-bedrock/",
      "pubDate": "2025-10-02T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "rds",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "rds",
        "organizations",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-6f92469f3352",
      "title": "AWS API MCP Server v1.0.0 release",
      "description": "Today, AWS announces the v1.0.0 release of the AWS API model context protocol (MCP) server enabling foundation models (FMs) to interact with any AWS API through natural language by creating and executing syntactically correct CLI commands.\n  The v1.0.0 release of the AWS API MCP Server contains many enhancements that make the server easier to configure, use, and integrate with MCP clients and agentic frameworks. This release reduces startup time and removes several dependencies by converting the suggest_aws_command tool to a remote service rather than relying on local installation. Security enhancements offer improved secure file system controls, and better input validation. Customers using AWS CloudWatch agent can now collect logs from the API MCP Server for improved observability. In order to support more hosting and configuration options, the AWS API MCP Server now offers streamable HTTP transport in addition to the existing stdio. To make human-in-the-loop workflows requiring iterative inputs more reliable, the AWS API MCP Server now includes elicitation in supported MCP clients. To provide additional safeguards the API MCP Server can be configured to deny certain types of actions or require human oversight and consent for mutating actions. This release also includes a new experimental tool called get_execution_plan to provide prescriptive workflows for common AWS tasks. The tool can be enabled by setting the EXPERIMENTAL_AGENT_SCRIPTS flag to true.\n  Customers can configure the AWS API MCP Server for use with their MCP-compatible clients from several popular MCP registries. The AWS API MCP Server is also available packaged as a container in the Amazon ECR Public Gallery.\n  The AWS API MCP Server is open-source and available now. Visit the AWS Labs GitHub repository to view the source, download, and start experimenting with natural language interaction with AWS APIs today.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-api-mcp-server-v1-0-0-release",
      "pubDate": "2025-10-01T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "rds",
        "cloudwatch",
        "experimental",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    }
  ]
}