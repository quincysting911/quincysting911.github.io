{
  "lastUpdated": "2025-10-30T06:15:13.288Z",
  "category": "foundation-models",
  "totalItems": 15,
  "items": [
    {
      "id": "aws-news-a3a16bb3b64d",
      "title": "TwelveLabs’ Marengo Embed 3.0 for advanced video understanding now in Amazon Bedrock",
      "description": "TwelveLabs' Marengo Embed 3.0 is now available on Amazon Bedrock, bringing advanced video-native multimodal embedding capabilities to developers and organizations working with video content. Marengo embedding models unify videos, images, audio, and text into a single representation space, enabling you to build sophisticated video search and content analysis applications for any-to-any search, recommendation systems, and other multimodal tasks with industry-leading performance.\n  Marengo 3.0 delivers several key enhancements. Extended video processing capacity: process up to 4 hours of video and audio content and files up to 6GB—double the capacity of previous versions—making it ideal for analyzing full sporting events, extended training videos, and complete film productions. Enhanced sports analysis: the model delivers significant improvements with better understanding of gameplay dynamics, player movements, and event detection. Global multilingual support: expanded language capabilities from 12 to 36 languages, enabling global organizations to build unified search and retrieval systems that work seamlessly across diverse regions and markets. Multimodal search precision: combine images and descriptive text in a single embedding request, merging visual similarity with semantic understanding to deliver more accurate and contextually relevant search results.\n  AWS is the first cloud provider to offer TwelveLab’s Marengo 3.0 model, now available in US East (N. Virginia), Europe (Ireland), and Asia Pacific (Seoul). The model supports synchronous inference for low-latency text and image embeddings, and asynchronous inference for processing for video, audio, and large-scale image files. To get started, visit the Amazon Bedrock console. To learn more, read product page, and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/twelvelabs-marengo3-embed-amazon-bedrock",
      "pubDate": "2025-10-29T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "organizations",
        "ga",
        "now-available",
        "improvement",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-6eba81ffcdb0",
      "title": "4 new image editing tools added to Stability AI Image Services in Amazon Bedrock",
      "description": "Amazon Bedrock announces the availability of 4 new image editing tools to Stability AI Image Services: outpaint, fast upscale, conservative upscale, and creative upscale. These tools give creators precise control over their workflows, enabling them to transform concepts into finished products efficiently. The expanded suite now offers enhanced flexibility for professional creative projects.\n  Stability AI Image Services offers three categories of image editing capabilities: Edit tools: Remove Background, Erase Object, Search and Replace, Search and Recolor, Inpaint, and Outpaint (NEW) let you make targeted modifications to specific parts of your images; Upscale tools: Fast Upscale (NEW), Conservative Upscale (NEW), and Creative Upscale (NEW) enable you to enhance resolution while preserving quality; Control tools: Structure, Sketch, Style Guide, and Style Transfer give you powerful ways to generate variations based on existing images or sketches.\n  Stability AI Image Services is available in Amazon Bedrock through the API and is supported in US West (Oregon), US East (N. Virginia), and US East (Ohio). For more information on supported regions, visit the Amazon Bedrock Model Support by Regions guide. For more details about Stability AI Image Services and its capabilities, visit the launch blog, Stability AI product page, and Stability AI documentation page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/stability-ai-image-updates-amazon-bedrock/",
      "pubDate": "2025-10-29T20:51:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-f9c6e157cfd4",
      "title": "Web Grounding: Build accurate AI applications with Amazon Nova models",
      "description": "We are excited to announce the general availability of Web Grounding, a new built-in tool for Nova models. Customers can use Web Grounding today with Nova Premier using the Amazon Bedrock tool use API. Support for additional Nova models is coming soon.\n  Web Grounding is a built-in tool that can be used to retrieve and incorporate publicly available information with citations as context for responses. Developers can use the Web Grounding tool to implement a turnkey Retrieval Augmented Generation (RAG) solution using current, real-time information, reducing hallucinations and leading to more accurate outputs.\n  Web Grounding is available today in AWS US East (N. Virginia) Region.\n  Learn more about using the Web Grounding tool on Nova models and steps to get started at our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/web-grounding-ai-applications-amazon-nova-models",
      "pubDate": "2025-10-29T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "support",
        "coming-soon"
      ]
    },
    {
      "id": "aws-news-db1d5d1ad3f7",
      "title": "Announcing Amazon Nova Multimodal Embeddings",
      "description": "We are excited to announce the general availability of Amazon Nova Multimodal Embeddings, a state-of-the-art embedding model for agentic RAG and semantic search. It is the first unified embedding model that supports text, documents, images, video, and audio through a single model, to enable cross-modal retrieval with leading accuracy.\n  Managing and searching across different content types traditionally required multiple specialized embedding models, leading to complexity, higher costs, and data silos. Amazon Nova Multimodal Embeddings maps diverse content types into a unified space with leading accuracy, helping break down these silos. Developers can build cross-modal applications that search video archives using complex queries, find relevant product images based on customer questions, or search financial documentation that contain both infographics and text explanations, all using a single embedding model.\n  The model supports inputs of up to 8K tokens in length and video/audio segments up to 30 seconds, with the capability to segment larger files. Multiple output embedding dimensions allow organizations to balance accuracy and performance with storage and computation costs. Organizations can choose between synchronous API for near real-time applications and asynchronous API for efficient processing of larger files, enabling them to optimize for both latency-sensitive and high-volume workloads.\n  Amazon Nova Multimodal Embeddings is available in US East (N. Virginia) in Amazon Bedrock.\n  To learn more, read the AWS News blog and user guide. To get started with Nova Multimodal Embeddings in Amazon Bedrock, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-nova-multimodal-embeddings/",
      "pubDate": "2025-10-28T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "lex",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-86a35a734483",
      "title": "Generate Gremlin queries using Amazon Bedrock models",
      "description": "In this post, we explore an innovative approach that converts natural language to Gremlin queries using Amazon Bedrock models such as Amazon Nova Pro, helping business analysts and data scientists access graph databases without requiring deep technical expertise. The methodology involves three key steps: extracting graph knowledge, structuring the graph similar to text-to-SQL processing, and generating executable Gremlin queries through an iterative refinement process that achieved 74.17% overall accuracy in testing.",
      "link": "https://aws.amazon.com/blogs/machine-learning/generate-gremlin-queries-using-amazon-bedrock-models/",
      "pubDate": "2025-10-23T20:57:29.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-1892be311751",
      "title": "Now generally available: AWS RTB Fabric for real-time bidding workloads",
      "description": "Today, AWS announces RTB Fabric, a fully managed service that helps you connect with your AdTech partners such as Amazon Ads, GumGum, Kargo, MobileFuse, Sovrn, TripleLift, Viant, Yieldmo, and more in three steps while delivering single-digit millisecond latency through a private, high-performance network environment. RTB Fabric reduces standard cloud networking costs by up to 80% and does not require upfront commitments.\n \nThe service includes modules, a capability that helps you bring your own and partner applications securely into the compute environment for real-time bidding. Modules support containerized applications and foundation models (FMs) that can enhance transaction efficiency and bidding effectiveness. Today, AWS RTB Fabric launches with three built-in modules to help you optimize traffic, improve bid efficiency, and increase bid response rates—all running inline for consistent low-latency execution. AWS RTB Fabric helps you to optimize auction execution, maximize supply monetization, and increase publisher revenue. You can connect with AdTech companies faster to reach target audiences, increase campaign scale, and improve performance for higher return on ad spend.\n \nAWS RTB Fabric is generally available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Tokyo), Europe (Frankfurt), and Europe (Ireland).. To learn more, read the Blog, Documentation, or visit the AWS RTB Fabric product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-rtb-fabric-generally-available/",
      "pubDate": "2025-10-23T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "launch",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-84c8038a250f",
      "title": "Streamline code migration using Amazon Nova Premier with an agentic workflow",
      "description": "In this post, we demonstrate how Amazon Nova Premier with Amazon Bedrock can systematically migrate legacy C code to modern Java/Spring applications using an intelligent agentic workflow that breaks down complex conversions into specialized agent roles. The solution reduces migration time and costs while improving code quality through automated validation, security assessment, and iterative refinement processes that handle even large codebases exceeding token limitations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/streamline-code-migration-using-amazon-nova-premier-with-an-agentic-workflow/",
      "pubDate": "2025-10-22T18:48:48.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-4cf5d24f3814",
      "title": "Building a multi-agent voice assistant with Amazon Nova Sonic and Amazon Bedrock AgentCore",
      "description": "In this post, we explore how Amazon Nova Sonic's speech-to-speech capabilities can be combined with Amazon Bedrock AgentCore to create sophisticated multi-agent voice assistants that break complex tasks into specialized, manageable components. The approach demonstrates how to build modular, scalable voice applications using a banking assistant example with dedicated sub-agents for authentication, banking inquiries, and mortgage services, offering a more maintainable alternative to monolithic voice assistant designs.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-a-multi-agent-voice-assistant-with-amazon-nova-sonic-and-amazon-bedrock-agentcore/",
      "pubDate": "2025-10-21T17:31:05.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-8e47ff068b33",
      "title": "Amazon Nova now supports the customization of content moderation settings",
      "description": "Amazon Nova models now support the customization of content moderation settings for approved business use cases that require processing or generating sensitive content.\n  Organizations with approved business use cases can adjust content moderation settings across four domains: safety, sensitive content, fairness, and security. These settings allow customers to adjust specific settings relevant to their business requirements. Amazon Nova enforces essential, non-configurable controls to ensure responsible use of AI, such as controls to prevent harm to children and preserve privacy.\n  Customization of content moderation settings is available for Amazon Nova Lite and Amazon Nova Pro in the US East (N. Virginia) region.\n  To learn more about Amazon Nova, visit the Amazon Nova product page and to learn about Amazon Nova responsible use of AI, visit the AWS AI Service Cards, or see the User Guide. To see if your business model is appropriate to customize content moderation settings, contact your AWS Account Manager.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-nova-customization-content-moderation-settings/",
      "pubDate": "2025-10-21T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "rds",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "rds",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-7a86c4c249c4",
      "title": "Voice AI-powered drive-thru ordering with Amazon Nova Sonic and dynamic menu displays",
      "description": "In this post, we'll demonstrate how to implement a Quick Service Restaurants (QSRs) drive-thru solution using Amazon Nova Sonic and AWS services. We'll walk through building an intelligent system that combines voice AI with interactive menu displays, providing technical insights and implementation guidance to help restaurants modernize their drive-thru operations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/voice-ai-powered-drive-thru-ordering-with-amazon-nova-sonic-and-dynamic-menu-displays/",
      "pubDate": "2025-10-16T18:36:28.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-c7d82641b37e",
      "title": "Optimizing document AI and structured outputs by fine-tuning Amazon Nova Models and on-demand inference",
      "description": "This post provides a comprehensive hands-on guide to fine-tune Amazon Nova Lite for document processing tasks, with a focus on tax form data extraction. Using our open-source GitHub repository code sample, we demonstrate the complete workflow from data preparation to model deployment.",
      "link": "https://aws.amazon.com/blogs/machine-learning/optimizing-document-ai-and-structured-outputs-by-fine-tuning-amazon-nova-models-and-on-demand-inference/",
      "pubDate": "2025-10-16T18:32:55.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-5bc447bea6ce",
      "title": "Amazon Bedrock simplifies access with automatic enablement of serverless foundation models",
      "description": "Amazon Bedrock now provides immediate access to all serverless foundation models by default for users in all commercial AWS regions. This update eliminates the need for manually activating model access, allowing you to instantly start using these models through the Amazon Bedrock console playground, AWS SDK, and Amazon Bedrock features including Agents, Flows, Guardrails, Knowledge Bases, Prompt Management, and Evaluations.\n  While you can quickly begin using serverless foundation models from most providers, Anthropic models, although enabled by default, still require you to submit a one-time usage form before first use. You can complete this form either through the API or through the Amazon Bedrock console by selecting an Anthropic model from the playground. When completed through the AWS organization management account, the form submission automatically enables Anthropic models across all member accounts in the organization.\n  This simplified access is available across all commercial AWS regions where Amazon Bedrock is supported. Account administrators retain full control over model access through IAM policies and Service Control Policies (SCPs) to restrict access as needed. For implementation guidance and examples on access controls, please refer to our blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-bedrock-automatic-enablement-serverless-foundation-models",
      "pubDate": "2025-10-15T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "iam"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "iam",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-8b165ea93ef7",
      "title": "DeepSeek, OpenAI, and Qwen models available in Amazon Bedrock in additional Regions",
      "description": "Amazon Bedrock is bringing DeepSeek-V3.1, OpenAI open-weight models, and Qwen3 models to more AWS Regions worldwide, expanding access to cutting-edge AI for customers across the globe. This regional expansion enables organizations in more countries and territories to deploy these powerful foundation models locally, ensuring compliance with data residency requirements, reducing network latency, and delivering faster AI-powered experiences to their users.\n  DeepSeek-V3.1 and Qwen3 Coder-480B are now available in the US East (Ohio) and Asia Pacific (Jakarta) AWS Regions. OpenAI open-weight models (20B, 120B) and Qwen3 models (32B, 235B, Coder-30B) are now available in the US East (Ohio), Europe (Frankfurt), and Asia Pacific (Jakarta) AWS Regions.\n  Check out the full Region list for future updates. To learn more about these models visit the Amazon Bedrock product page. To get started, access the Amazon Bedrock console and view the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/deepseek-openai-qwen-models-amazon-bedrock-additional-regions",
      "pubDate": "2025-10-15T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "organizations",
        "ga",
        "now-available",
        "update",
        "expansion"
      ]
    },
    {
      "id": "aws-news-cd9bdeebe4b4",
      "title": "Claude 4.5 Haiku by Anthropic now in Amazon Bedrock",
      "description": "Claude Haiku 4.5 is now available in Amazon Bedrock. Claude Haiku 4.5 delivers near-frontier performance matching Claude Sonnet 4's capabilities in coding, computer use, and agent tasks at substantially lower cost and faster speeds, making state-of-the-art AI accessible for scaled deployments and budget-conscious applications.\n  The model's enhanced speed makes it ideal for latency-sensitive applications like real-time customer service agents and chatbots where response time is critical. For computer use tasks, Haiku 4.5 delivers significant performance improvements over previous models, enabling faster and more responsive applications. This model supports vision and unlocks new use cases where customers previously had to choose between performance and cost. It enables economically viable agent experiences, supports multi-agent systems for complex coding projects, and powers large-scale financial analysis and research applications. Haiku 4.5 maintains Claude's unique character while delivering the performance and efficiency needed for production deployments.\n  Claude Haiku 4.5 is now available in Amazon Bedrock via global cross region inference in multiple locations. To view the full list of available regions, refer to the documentation. To get started with Haiku 4.5 in Amazon Bedrock visit the Amazon Bedrock console, Anthropic's Claude in Amazon Bedrock product page, and the Amazon Bedrock pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "pubDate": "2025-10-15T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    }
  ]
}