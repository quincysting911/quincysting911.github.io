{
  "lastUpdated": "2026-02-01T06:35:55.549Z",
  "category": "foundation-models",
  "totalItems": 10,
  "items": [
    {
      "id": "aws-news-99b1a7d7c5d6",
      "title": "Evaluating generative AI models with Amazon Nova LLM-as-a-Judge on Amazon SageMaker AI",
      "description": "Evaluating the performance of large language models (LLMs) goes beyond statistical metrics like perplexity or bilingual evaluation understudy (BLEU) scores. For most real-world generative AI scenarios, it’s crucial to understand whether a model is producing better outputs than a baseline or an earlier iteration. This is especially important for applications such as summarization, content generation, […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/evaluating-generative-ai-models-with-amazon-nova-llm-as-a-judge-on-amazon-sagemaker-ai/",
      "pubDate": "2026-01-30T21:07:34.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "lex"
      ]
    },
    {
      "id": "aws-news-050a26e65371",
      "title": "Scale AI in South Africa using Amazon Bedrock global cross-Region inference with Anthropic Claude 4.5 models",
      "description": "In this post, we walk through how global cross-Region inference routes requests and where your data resides, then show you how to configure the required AWS Identity and Access Management (IAM) permissions and invoke Claude 4.5 models using the global inference profile Amazon Resource Name (ARN). We also cover how to request quota increases for your workload. By the end, you'll have a working implementation of global cross-Region inference in af-south-1.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scale-ai-in-south-africa-using-amazon-bedrock-global-cross-region-inference-with-anthropic-claude-4-5-models/",
      "pubDate": "2026-01-30T17:12:02.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "iam"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "iam"
      ]
    },
    {
      "id": "aws-news-a76018245791",
      "title": "Create a customizable cross-company log lake, Part II: Build and add Amazon Bedrock",
      "description": "In this post, you learn how to build Log Lake, a customizable cross-company data lake for compliance-related use cases that combines AWS CloudTrail and Amazon CloudWatch logs. You'll discover how to set up separate tables for writing and reading, implement event-driven partition management using AWS Lambda, and transform raw JSON files into read-optimized Apache ORC format using AWS Glue jobs. Additionally, you'll see how to extend Log Lake by adding Amazon Bedrock model invocation logs to enable human review of agent actions with elevated permissions, and how to use an AI agent to query your log data without writing SQL.",
      "link": "https://aws.amazon.com/blogs/big-data/create-a-customizable-cross-company-log-lake-part-ii-build-and-add-amazon-bedrock/",
      "pubDate": "2026-01-27T17:46:45.000Z",
      "source": "bigDataBlog",
      "services": [
        "bedrock",
        "lambda",
        "glue",
        "cloudwatch"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lambda",
        "glue",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-b2b47008b4a3",
      "title": "Amazon Bedrock now supports 1-hour duration for prompt caching",
      "description": "Amazon Bedrock now supports a 1-hour time-to-live (TTL) option for prompt caching for select Anthropic Claude models. With this update, you can extend the persistence of cached prompt prefixes from the default 5 minutes to 1 hour, improving cost efficiency and performance for long-running agentic workflows and multi-turn conversations.\n  Previously, cached content remained active for a fixed 5-minute window and refreshed when reused. With the new 1-hour TTL option, you can maintain context for users who interact less frequently, or for complex agents that require more time between steps—such as tool use, retrieval, and orchestration. The 1-hour TTL is also useful for longer sessions and batch processing where you want cached content to persist across extended periods.\n  1-hour TTL prompt caching is generally available for Anthropic’s Claude Sonnet 4.5, Claude Haiku 4.5, and Claude Opus 4.5 in all commercial AWS Regions and AWS GovCloud (US) Regions where these models are available. The 1-hour cache is billed at a different rate than the standard 5-minute cache. To learn more, refer to the Amazon Bedrock documentation and Amazon Bedrock Pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-one-hour-duration-prompt-caching/",
      "pubDate": "2026-01-26T22:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "generally-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-3489e5c40783",
      "title": "Amazon SageMaker HyperPod introduces enhanced lifecycle scripts debugging",
      "description": "Amazon SageMaker HyperPod now provides enhanced troubleshooting capabilities for lifecycle scripts, making it easier to identify and resolve issues during cluster node provisioning. SageMaker HyperPod helps you provision resilient clusters for running AI/ML workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs).\n  When lifecycle scripts encounter issues during cluster creation or node operations, you now receive detailed error messages that include the specific CloudWatch log group and log stream names where you can find execution logs for lifecycle scripts. You can view these error messages by running the DescribeCluster API or by viewing the cluster details page in the SageMaker console. The console also provides a \"View lifecycle script logs\" button that navigates directly to the relevant CloudWatch log stream, making it easier to locate logs. Additionally, CloudWatch logs for lifecycle scripts now include specific markers to help you track lifecycle script execution progress, including indicators for when the lifecycle script log begins, when scripts are being downloaded, when downloads complete, and when scripts succeed or fail. These markers help you quickly identify where issues occurred during the provisioning process. These enhancements reduce the time required to diagnose and fix lifecycle script failures, helping you get your HyperPod clusters up and running faster.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is supported. To learn more, see SageMaker HyperPod cluster management in the Amazon SageMaker Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-sagemaker-hyperpod-lcs-enhanced-debug/",
      "pubDate": "2026-01-21T19:15:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "cloudwatch"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "cloudwatch",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-456e02260dac",
      "title": "Amazon Bedrock Reserved Tier available now for Claude Sonnet 4.5 in AWS GovCloud (US-West)",
      "description": "Today, Amazon Bedrock introduces the expansion of the Reserved service tier designed for workloads requiring predictable performance and guaranteed tokens-per-minute capacity. The Reserved tier provides the ability to reserve prioritized compute capacity, keeping service levels predictable for your mission critical applications. It also includes the flexibility to allocate different input and output tokens-per-minute capacities to match the exact requirements of your workload and control cost. This is particularly valuable because many workloads have asymmetric token usage patterns. For instance, summarization tasks consume many input tokens but generate fewer output tokens, while content generation applications require less input and more output capacity. When your application needs more tokens-per-minute capacity than what you reserved , the service automatically overflows to the pay-as-you-go Standard tier, ensuring uninterrupted operations. The Reserved tier is available today for Anthropic Claude Sonnet 4.5 in AWS GovCloud (US-West). Customers can reserve capacity for 1 month or 3 month duration. Customers pay a fixed price per 1K tokens-per-minute and are billed monthly. Amazon Bedrock Reserved Tier is available for customers in AWS GovCloud (US-West) via GOV-CRIS cross-region profile.\n  With the expansion of the Reserved service tier, Amazon Bedrock continues to provide more choice to customers, helping them develop, scale, and deploy applications and agents that improve productivity and customer experiences while balancing performance and cost requirements.\n  For more information about the AWS Regions where Amazon Bedrock Reserved tier is available, refer to the Documentation. To get access to the Reserved tier, please contact your AWS account team.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-reserved-tier-for-claude-sonnet-in-govcloud/",
      "pubDate": "2026-01-21T17:02:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "expansion"
      ]
    },
    {
      "id": "aws-news-1d5285365111",
      "title": "Amazon Bedrock Reserved Tier available now for Claude Opus 4.5 and Haiku 4.5",
      "description": "Today, Amazon Bedrock announces the expansion of the Reserved service tier designed for workloads requiring predictable performance and guaranteed tokens-per-minute capacity. The Reserved tier provides the ability to reserve prioritized compute capacity, keeping service levels predictable for your mission critical applications. It also includes the flexibility to allocate different input and output tokens-per-minute capacities to match the exact requirements of your workload and control cost. This is particularly valuable because many workloads have asymmetric token usage patterns. For instance, summarization tasks consume many input tokens but generate fewer output tokens, while content generation applications require less input and more output capacity. When your application needs more tokens-per-minute capacity than what you reserved , the service automatically overflows to the pay-as-you-go Standard tier, ensuring uninterrupted operations. The Reserved tier and is available today for Anthropic Claude Opus 4.5 and Claude Haiku 4.5. Customers can reserve capacity for 1 month or 3 month duration. Customers pay a fixed price per 1K tokens-per-minute and are billed monthly.\n  With the expansion of the Reserved service tier, Amazon Bedrock continues to provide more choice to customers, helping them develop, scale, and deploy applications and agents that improve productivity and customer experiences while balancing performance and cost requirements.\n  For more information about the AWS Regions where Amazon Bedrock Reserved tier is available, refer to the Documentation. To get access to the Reserved tier, please contact your AWS account team.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-reserved-tier-claude-opus-haiku/",
      "pubDate": "2026-01-16T18:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "expansion"
      ]
    },
    {
      "id": "aws-news-4d20717331d3",
      "title": "How Palo Alto Networks enhanced device security infra log analysis with Amazon Bedrock",
      "description": "Palo Alto Networks’ Device Security team wanted to detect early warning signs of potential production issues to provide more time to SMEs to react to these emerging problems. They partnered with the AWS Generative AI Innovation Center (GenAIIC) to develop an automated log classification pipeline powered by Amazon Bedrock. In this post, we discuss how Amazon Bedrock, through Anthropic’ s Claude Haiku model, and Amazon Titan Text Embeddings work together to automatically classify and analyze log data. We explore how this automated pipeline detects critical issues, examine the solution architecture, and share implementation insights that have delivered measurable operational improvements.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-palo-alto-networks-enhanced-device-security-infra-log-analysis-with-amazon-bedrock/",
      "pubDate": "2026-01-16T15:46:36.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "improvement"
      ]
    },
    {
      "id": "aws-news-5b09b020ff29",
      "title": "AWS Data Exports  adds granular operation visibility for Amazon Bedrock model usage",
      "description": "AWS Data Exports now enables customers to distinguish between Amazon Bedrock operation types in their cost reports for enhanced cost analysis and optimization. This granular operation information is available in Cost and Usage Reports (CUR), CUR 2.0, and Data Exports for FOCUS, and is particularly valuable for FinOps teams, cost optimization professionals, and organizations using Amazon Bedrock that require detailed billing analysis.\n  Customers will now see specific operation types such as \"InvokeModelInference\" and \"InvokeModelStreamingInference\" in their cost reports, replacing generic \"Usage\" labels. These granular operation types appear in the \"line_item_operation\" column in Legacy CUR and CUR 2.0 reports, the \"x_Operation\" column in FOCUS reports, and AWS Cost Explorer API Operation dimension values. This visibility now extends to all foundation models on Amazon Bedrock, enabling precise tracking of usage patterns and cost optimization opportunities across all model providers.\n  To learn more about AWS Billing and Cost Management, visit the AWS Billing and Cost Management documentation, and for AWS Data Exports, visit the AWS Data Exports documentation. To get started with Amazon Bedrock, visit the Amazon Bedrock page and see the Amazon Bedrock documentation for more details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-bedrock-granular-usage-visibility",
      "pubDate": "2026-01-15T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-4124e81eda7a",
      "title": "Amazon Bedrock introduces API keys to streamline development in GovCloud regions",
      "description": "API keys for Amazon Bedrock are now available in AWS GovCloud (US) regions, expanding a feature that simplifies authentication and accelerates generative AI development. Originally launched in commercial AWS regions in July 2025, API keys for Amazon Bedrock enable developers to quickly generate access credentials directly within the Amazon Bedrock console or AWS SDK without needing to manually configure IAM principals and policies.\n  With the introduction of API keys for Amazon Bedrock, developers can generate short-term and long-term API keys directly from the Amazon Bedrock console or API to authenticate API calls to Amazon Bedrock models. Short-term API keys are valid for the duration of your console session, or up to 12 hours, whichever is shorter. Long-term API keys give you the flexibility to define key validity duration and manage the keys from the AWS IAM console.\n  Bedrock API key authentication is now available in the AWS GovCloud (US) and commercial AWS Regions where Amazon Bedrock is available.\n  To learn more about API keys in Amazon Bedrock, visit the API Keys documentation in the Amazon Bedrock user guide, or check out our blog for code snippets and implementation examples.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-bedrock-api-keys-streamline-development-govcloud/",
      "pubDate": "2026-01-14T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "iam"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "iam",
        "launch",
        "now-available"
      ]
    }
  ]
}