{
  "lastUpdated": "2025-10-16T06:15:32.240Z",
  "category": "foundation-models",
  "totalItems": 10,
  "items": [
    {
      "id": "aws-news-becb82a21696",
      "title": "Transforming enterprise operations: Four high-impact use cases with Amazon Nova",
      "description": "In this post, we share four high-impact, widely adopted use cases built with Nova in Amazon Bedrock, supported by real-world customers deployments, offerings available from AWS partners, and experiences. These examples are ideal for organizations researching their own AI adoption strategies and use cases across industries.",
      "link": "https://aws.amazon.com/blogs/machine-learning/transforming-enterprise-operations-four-high-impact-use-cases-with-amazon-nova/",
      "pubDate": "2025-10-15T18:26:10.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-cd9bdeebe4b4",
      "title": "Claude 4.5 Haiku by Anthropic now in Amazon Bedrock",
      "description": "Claude Haiku 4.5 is now available in Amazon Bedrock. Claude Haiku 4.5 delivers near-frontier performance matching Claude Sonnet 4's capabilities in coding, computer use, and agent tasks at substantially lower cost and faster speeds, making state-of-the-art AI accessible for scaled deployments and budget-conscious applications.\n  The model's enhanced speed makes it ideal for latency-sensitive applications like real-time customer service agents and chatbots where response time is critical. For computer use tasks, Haiku 4.5 delivers significant performance improvements over previous models, enabling faster and more responsive applications. This model supports vision and unlocks new use cases where customers previously had to choose between performance and cost. It enables economically viable agent experiences, supports multi-agent systems for complex coding projects, and powers large-scale financial analysis and research applications. Haiku 4.5 maintains Claude's unique character while delivering the performance and efficiency needed for production deployments.\n  Claude Haiku 4.5 is now available in Amazon Bedrock via global cross region inference in multiple locations. To view the full list of available regions, refer to the documentation. To get started with Haiku 4.5 in Amazon Bedrock visit the Amazon Bedrock console, Anthropic's Claude in Amazon Bedrock product page, and the Amazon Bedrock pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "pubDate": "2025-10-15T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "now-available",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-5bc447bea6ce",
      "title": "Amazon Bedrock simplifies access with automatic enablement of serverless foundation models",
      "description": "Amazon Bedrock now provides immediate access to all serverless foundation models by default for users in all commercial AWS regions. This update eliminates the need for manually activating model access, allowing you to instantly start using these models through the Amazon Bedrock console playground, AWS SDK, and Amazon Bedrock features including Agents, Flows, Guardrails, Knowledge Bases, Prompt Management, and Evaluations.\n  While you can quickly begin using serverless foundation models from most providers, Anthropic models, although enabled by default, still require you to submit a one-time usage form before first use. You can complete this form either through the API or through the Amazon Bedrock console by selecting an Anthropic model from the playground. When completed through the AWS organization management account, the form submission automatically enables Anthropic models across all member accounts in the organization.\n  This simplified access is available across all commercial AWS regions where Amazon Bedrock is supported. Account administrators retain full control over model access through IAM policies and Service Control Policies (SCPs) to restrict access as needed. For implementation guidance and examples on access controls, please refer to our blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-bedrock-automatic-enablement-serverless-foundation-models",
      "pubDate": "2025-10-15T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "iam"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "iam",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-8b165ea93ef7",
      "title": "DeepSeek, OpenAI, and Qwen models available in Amazon Bedrock in additional Regions",
      "description": "Amazon Bedrock is bringing DeepSeek-V3.1, OpenAI open-weight models, and Qwen3 models to more AWS Regions worldwide, expanding access to cutting-edge AI for customers across the globe. This regional expansion enables organizations in more countries and territories to deploy these powerful foundation models locally, ensuring compliance with data residency requirements, reducing network latency, and delivering faster AI-powered experiences to their users.\n  DeepSeek-V3.1 and Qwen3 Coder-480B are now available in the US East (Ohio) and Asia Pacific (Jakarta) AWS Regions. OpenAI open-weight models (20B, 120B) and Qwen3 models (32B, 235B, Coder-30B) are now available in the US East (Ohio), Europe (Frankfurt), and Asia Pacific (Jakarta) AWS Regions.\n  Check out the full Region list for future updates. To learn more about these models visit the Amazon Bedrock product page. To get started, access the Amazon Bedrock console and view the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/deepseek-openai-qwen-models-amazon-bedrock-additional-regions",
      "pubDate": "2025-10-15T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "organizations",
        "ga",
        "now-available",
        "update",
        "expansion"
      ]
    },
    {
      "id": "aws-news-bf153180c688",
      "title": "Customizing text content moderation with Amazon Nova",
      "description": "In this post, we introduce Amazon Nova customization for text content moderation through Amazon SageMaker AI, enabling organizations to fine-tune models for their specific moderation needs. The evaluation across three benchmarks shows that customized Nova models achieve an average improvement of 7.3% in F1 scores compared to the baseline Nova Lite, with individual improvements ranging from 4.2% to 9.2% across different content moderation tasks.",
      "link": "https://aws.amazon.com/blogs/machine-learning/customizing-text-content-moderation-with-amazon-nova/",
      "pubDate": "2025-10-09T21:47:08.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "organizations",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-a455e3668042",
      "title": "Automate Amazon QuickSight data stories creation with agentic AI using Amazon Nova Act",
      "description": "In this post, we demonstrate how Amazon Nova Act automates QuickSight data story creation, saving time so you can focus on making critical, data-driven business decisions.",
      "link": "https://aws.amazon.com/blogs/machine-learning/automate-amazon-quicksight-data-stories-creation-with-agentic-ai-using-amazon-nova-act/",
      "pubDate": "2025-10-07T17:43:26.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "amazon q",
        "quicksight"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "amazon q",
        "quicksight"
      ]
    },
    {
      "id": "aws-news-08b1de84b163",
      "title": "Responsible AI: How PowerSchool safeguards millions of students with AI-powered content filtering using Amazon SageMaker AI",
      "description": "In this post, we demonstrate how PowerSchool built and deployed a custom content filtering solution using Amazon SageMaker AI that achieved better accuracy while maintaining low false positive rates. We walk through our technical approach to fine tuning Llama 3.1 8B, our deployment architecture, and the performance results from internal validations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/responsible-ai-how-powerschool-safeguards-millions-of-students-with-ai-powered-content-filtering-using-amazon-sagemaker-ai/",
      "pubDate": "2025-10-06T19:14:40.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "rds"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "rds"
      ]
    },
    {
      "id": "aws-news-64984ffcbecb",
      "title": "Unlock global AI inference scalability using new global cross-Region inference on Amazon Bedrock  with Anthropic’s Claude Sonnet 4.5",
      "description": "Organizations are increasingly integrating generative AI capabilities into their applications to enhance customer experiences, streamline operations, and drive innovation. As generative AI workloads continue to grow in scale and importance, organizations face new challenges in maintaining consistent performance, reliability, and availability of their AI-powered applications. Customers are looking to scale their AI inference workloads across […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/unlock-global-ai-inference-scalability-using-new-global-cross-region-inference-on-amazon-bedrock-with-anthropics-claude-sonnet-4-5/",
      "pubDate": "2025-10-03T21:37:26.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-cebc03ef3cac",
      "title": "Cohere’s Embed v4 multimodal embeddings model now available on Amazon Bedrock",
      "description": "Amazon Bedrock now offers Cohere Embed v4, the latest state-of-the-art multimodal embedding model from Cohere that produces high-quality embeddings for text, images, and complex business documents. This powerful addition to Amazon Bedrock enables enterprises to build AI applications with frontier search and retrieval capabilities.\n  Traditional embedding models often struggle to understand complex multimodal business materials, such as business presentations and sales and financial reports, requiring extensive data pre-processing pipelines. Embed v4 addresses this challenge by natively processing documents with tables, graphs, diagrams, code snippets, and even handwritten notes. The model handles real-world imperfections such as spelling errors and formatting issues, eliminating the need for time-consuming data cleanup and helping you surface insights from previously difficult-to-search information.\n  With support for over 100 languages, including Arabic, English, French, Japanese, and Korean, Embed v4 enables global organizations to seamlessly search for information, breaking language barriers. The model is also fine-tuned for industries such as finance, healthcare, and manufacturing, delivering superior performance on specialized documents including financial reports, medical records, and product specifications.\n  Cohere Embed v4 is available for on-demand inference in US East (N. Virginia), Europe (Ireland), and Asia Pacific (Tokyo), and can be accessed from select public AWS Regions through cross-region inference. Review the Amazon Bedrock Model Support by Regions guide for complete regional availability. To get started, visit the Amazon Bedrock console to request model access. For more information, refer to the Cohere product page and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/coheres-embed-v4-multimodal-embeddings-bedrock/",
      "pubDate": "2025-10-02T07:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "rds",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "rds",
        "organizations",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    }
  ]
}