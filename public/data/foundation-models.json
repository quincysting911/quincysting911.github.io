{
  "lastUpdated": "2025-12-02T06:17:11.704Z",
  "category": "foundation-models",
  "totalItems": 13,
  "items": [
    {
      "id": "aws-news-2650c3263efd",
      "title": "Amazon Connect introduces agentic self-service with more natural, expressive, and adaptive voice interactions",
      "description": "Amazon Connect is introducing agentic self-service capabilities that enable AI agents to understand, reason, and take action across voice and messaging channels to automate routine and complex customer service tasks. Connect enables you to blend deterministic and agentic experiences, allowing you to deploy these AI agents at scale, reliably and safely. With integration with advanced speech models from Amazon Nova Sonic, voice self-service experiences now deliver more natural and adaptive interactions. Connect's self-service voice AI agents understand not only what customers say but how they say it, adapting voice responses to match customer tone and sentiment while maintaining natural conversational pace across multiple languages and accents. For example, when a customer calls about an order issue, your AI agent can greet them by name, ask clarifying questions, look up their order status, and process a refund, with voice interactions that adapt to the customer's tone and respond expressively throughout the conversation. This enables your contact center to automate complex troubleshooting, account management, and consultative interactions while maintaining the ability to escalate to a live representative at any point.\n  Nova Sonic support with Amazon Connect is available in two commercial AWS Regions: US East (N. Virginia) and US West (Oregon) and fully available in English and Spanish and in preview for French, Italian, and German. To learn more about this feature see the Amazon Connect Administrator Guide and Amazon Connect pricing page. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-agentic-self-service",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "lex",
        "preview",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-75e400c9e536",
      "title": "Multimodal retrieval for Bedrock Knowledge Bases now generally available",
      "description": "Today, AWS announces the general availability of multimodal retrieval in Bedrock Knowledge Bases. Amazon Bedrock Knowledge Bases offers managed, end-to-end Retrieval Augmented Generation (RAG) workflows to create accurate, low latency, and custom Generative AI applications by incorporating contextual information from your company's data sources. Supporting multimodal retrieval in Knowlesdge Bases enables developers to build AI-powered search and question-answering applications that work across text, images, audio, and video files. For example, a user could ask their assistant \"show me Q1 projections for Amazon Bedrock\" and Bedrock Knowledge Bases will retrieve relevant text from documents, graphs, video snippets, and audio related to revenue projections for Bedrock, allowing the assistant to generate richer and more complete answers for the end user. Previously, customers could only search through text documents and images. Now they can unlock insights from all their enterprise data formats through one unified, fully managed workflow.\n \nOrganizations struggle to extract insights from their growing multimedia data—videos, audio recordings, images, and documents— because building AI applications that can search across these different modalities is complex. As a result, valuable information trapped in terabytes of meeting recordings, training videos, and visual documentation remains inaccessible, preventing organizations from making data-driven decisions quickly and accurately. With multimodal retrieval for Knowledge Bases, developers can ingest multimodal content with full control of the parsing, chunking, embedding (e.g. Amazon Nova multimodal), and vector storage options. From there, they can then send a text query or an image as input and get relevant text, image, audio, and video segments back in order to generate a response in their generative AI applications using their choice of LLM.\n \nFor more information about creating multimodal Knowledge Bases in Bedrock, please refer to the documentation. Region availability is dependent on the features selected for multimodal support, please refer to the documentation for details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/multimodal-retrieval-bedrock-knowledge-bases/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "lex",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "lex",
        "organizations",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-2d932c791873",
      "title": "Announcing AWS AI League 2026 Championship",
      "description": "Today, AWS announces the AWS AI League 2026 Championship, expanding its flagship AI tournament with new challenges and doubling the prize pool to $50,000 for builders to compete and innovate. AI League transforms how builders use AWS AI services through gamified competition centered on solving real world business challenges.\n  The program provides participants with a quick orientation, then focuses on tournaments with two challenge tracks: the Model Customization challenge using Amazon SageMaker AI to fine-tune foundation models for specific domains, and the Agentic AI challenge using Amazon Bedrock AgentCore to build intelligent agents that can reason, plan, and execute complex tasks. Enterprises can apply to host internal tournaments and receive AWS credits, creating environments where teams collaborate and compete while building AI solutions relevant to their specific business needs. Individual developers can participate at AWS Summits, testing their abilities against peers while working directly with AWS AI services. \n  For more information about the AWS AI League and how to participate, please visit the AWS AI League page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/ai-league-2026-championship/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "nova",
        "sagemaker",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "sagemaker",
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-f3f2eea0b334",
      "title": "How Myriad Genetics achieved fast, accurate, and cost-efficient document processing using the AWS open-source Generative AI Intelligent Document Processing Accelerator",
      "description": "In this post, we explore how Myriad Genetics partnered with the AWS Generative AI Innovation Center to transform their healthcare document processing pipeline using Amazon Bedrock and Amazon Nova foundation models, achieving 98% classification accuracy while reducing costs by 77% and processing time by 80%. We detail the technical implementation using AWS's open-source GenAI Intelligent Document Processing Accelerator, the optimization strategies for document classification and key information extraction, and the measurable business impact on Myriad's prior authorization workflows.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-myriad-genetics-achieved-fast-accurate-and-cost-efficient-document-processing-using-the-aws-open-source-generative-ai-intelligent-document-processing-accelerator/",
      "pubDate": "2025-11-27T00:58:14.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-587d9a94208c",
      "title": "How CBRE powers unified property management search and digital assistant using Amazon Bedrock",
      "description": "In this post, CBRE and AWS demonstrate how they transformed property management by building a unified search and digital assistant using Amazon Bedrock, enabling professionals to access millions of documents and multiple databases through natural language queries. The solution combines Amazon Nova Pro for SQL generation and Claude Haiku for document interactions, achieving a 67% reduction in processing time while maintaining enterprise-grade security across more than eight million documents.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-cbre-powers-unified-property-management-search-and-digital-assistant-using-amazon-bedrock/",
      "pubDate": "2025-11-27T00:56:27.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-f2f20ca0e88d",
      "title": "Building AI-Powered Voice Applications: Amazon Nova Sonic Telephony Integration Guide",
      "description": "Available through the Amazon Bedrock bidirectional streaming API, Amazon Nova Sonic can connect to your business data and external tools and can be integrated directly with telephony systems. This post will introduce sample implementations for the most common telephony scenarios.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-ai-powered-voice-applications-amazon-nova-sonic-telephony-integration-guide/",
      "pubDate": "2025-11-26T21:21:54.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "integration"
      ]
    },
    {
      "id": "aws-news-b38de7bae141",
      "title": "Evaluate models with the Amazon Nova evaluation container using Amazon SageMaker AI",
      "description": "This blog post introduces the new Amazon Nova model evaluation features in Amazon SageMaker AI. This release adds custom metrics support, LLM-based preference testing, log probability capture, metadata analysis, and multi-node scaling for large evaluations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/evaluate-models-with-the-amazon-nova-evaluation-container-using-amazon-sagemaker-ai/",
      "pubDate": "2025-11-26T19:39:01.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-5de16f9b057e",
      "title": "Enhanced performance for Amazon Bedrock Custom Model Import",
      "description": "You can now achieve significant performance improvements when using Amazon Bedrock Custom Model Import, with reduced end-to-end latency, faster time-to-first-token, and improved throughput through advanced PyTorch compilation and CUDA graph optimizations. With Amazon Bedrock Custom Model Import you can to bring your own foundation models to Amazon Bedrock for deployment and inference at scale. In this post, we introduce how to use the improvements in Amazon Bedrock Custom Model Import.",
      "link": "https://aws.amazon.com/blogs/machine-learning/enhanced-performance-for-amazon-bedrock-custom-model-import/",
      "pubDate": "2025-11-26T16:46:01.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "improvement"
      ]
    },
    {
      "id": "aws-news-838cda64c2a9",
      "title": "Amazon SageMaker HyperPod now supports programmatic node reboot and replacement",
      "description": "Today, Amazon SageMaker HyperPod announces the general availability of new APIs that enable programmatic rebooting and replacement of SageMaker HyperPod cluster nodes. SageMaker HyperPod helps you provision resilient clusters for running machine learning (ML) workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs). The new BatchRebootClusterNodes and BatchReplaceClusterNodes APIs enable customers to programmatically reboot or replace unresponsive or degraded cluster nodes, providing a consistent, orchestrator agnostic approach to node recovery operations.\n  The new APIs enhance node management capabilities for both Slurm and EKS orchestrated clusters complementing existing node reboot and replacement workflows. Existing orchestrator-specific methods, such as Kubernetes labels for EKS clusters and Slurm commands for Slurm clusters, remain available alongside the newly introduced programmatic capabilities for reboot and replace operations through these purpose-built APIs. When cluster nodes become unresponsive due to issues such as memory overruns or hardware degradation, recovery operations such as node reboots and replacements maybe be necessary and can be initiated through these new APIs. These capabilities are particularly valuable when running time-sensitive workloads. For instance, when a Slurm controller, login or compute node becomes unresponsive, administrators can trigger a reboot operation using the API and monitor its progress to get nodes back to operational status. Similarly, EKS cluster administrators can replace degraded worker nodes programmatically. Each API supports batch operations of up to 25 instances, enabling efficient management of large-scale recovery scenarios.\n  The reboot and replace APIs are currently supported in three AWS regions where SageMaker HyperPod is available: US East (Ohio), Asia Pacific (Mumbai), and Asia Pacific (Tokyo).The APIs can be accessed through the AWS CLI, SDK, or API calls. For more information, see the Amazon SageMaker HyperPod documentation for BatchRebootClusterNodes and BatchReplaceClusterNodes.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-hyperpod-programmatic-node-reboot-replacement",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-352e788815d3",
      "title": "Amazon Bedrock introduces Reserved Service tier",
      "description": "Today, Amazon Bedrock introduces a new Reserved service tier designed for workloads requiring predictable performance and guaranteed tokens-per-minute capacity. The Reserved tier provides the ability to reserve prioritized compute capacity, keeping service levels predictable for your mission critical applications. It also includes the flexibility to allocate different input and output tokens-per-minute capacities to match the exact requirements of your workload and control cost. This is particularly valuable because many workloads have asymmetric token usage patterns. For instance, summarization tasks consume many input tokens but generate fewer output tokens, while content generation applications require less input and more output capacity. When your application needs more tokens-per-minute capacity than what you reserved , the service automatically overflows to the pay-as-you-go Standard tier, ensuring uninterrupted operations. The Reserved tier targets 99.5% uptime for model response and is available today for Anthropic Claude Sonnet 4.5. Customers can reserve capacity for 1 month or 3 month duration. Customers pay a fixed price per 1K tokens-per-minute and are billed monthly.\n  With the Reserved service tier, Amazon Bedrock continues to provide more choice to customers, helping them develop, scale, and deploy applications and agents that improve productivity and customer experiences while balancing performance and cost requirements.\n  For more information about the AWS Regions where Amazon Bedrock Reserved is available, refer to the Documentation. To get access to the Reserved tier, please contact your AWS account team.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-bedrock-reserved-service-tier/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex"
      ]
    },
    {
      "id": "aws-news-60262ac8a35f",
      "title": "Accelerate generative AI innovation in Canada with Amazon Bedrock cross-Region inference",
      "description": "We are excited to announce that customers in Canada can now access advanced foundation models including Anthropic's Claude Sonnet 4.5 and Claude Haiku 4.5 on Amazon Bedrock through cross-Region inference (CRIS). This post explores how Canadian organizations can use cross-Region inference profiles from the Canada (Central) Region to access the latest foundation models to accelerate AI initiatives. We will demonstrate how to get started with these new capabilities, provide guidance for migrating from older models, and share recommended practices for quota management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-generative-ai-innovation-in-canada-with-amazon-bedrock-cross-region-inference/",
      "pubDate": "2025-11-24T23:56:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-5d462e79f71b",
      "title": "Claude Opus 4.5 now available in Amazon Bedrock",
      "description": "Customers can now use Claude Opus 4.5 in Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models from leading AI companies. Opus 4.5 is Anthropic's newest model, setting new standards across coding, agentic workflows, computer use, and office tasks while making Opus-level intelligence accessible at one-third the cost.\n  Opus 4.5 excels at professional software engineering tasks, achieving state-of-the-art performance on SWE-bench. The model handles ambiguity, reasons about tradeoffs and can figure out fixes for bugs that require reasoning across multiple systems. It can help transform multi-day team development projects into hours-long tasks with improved multilingual coding capabilities. This generation of Claude spans the full development lifecycle: Opus 4.5 for production code and lead agents, Sonnet 4.5 for rapid iteration and scaled user experiences, Haiku 4.5 for sub-agents and free-tier products.\n  Beyond coding, the model powers agents that produce documents, spreadsheets, and presentations with consistency, professional polish, and domain awareness, making it ideal for finance and other precision-critical verticals. As Anthropic's best vision model yet, it unlocks workflows that depend on complex visual interpretation and multi-step navigation. Through the Amazon Bedrock API, Opus 4.5 introduces two new capabilities: tool search and tool use examples. Together, these updates enable Claude to navigate large tool libraries and accurately execute complex tasks. A new effort parameter, available in beta, lets you control how much effort Claude allocates across thinking, tool calls, and responses to balance performance with latency, and cost.\n  Claude Opus 4.5 is now available in Amazon Bedrock via global cross region inference in multiple locations. For the full list of available regions, refer to the documentation. To get started with the model in Amazon Bedrock, read the launch blog or visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/claude-opus-4-5-amazon-bedrock",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "rds"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "rds",
        "launch",
        "beta",
        "ga",
        "now-available",
        "update"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    }
  ]
}