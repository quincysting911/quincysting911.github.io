{
  "lastUpdated": "2025-12-16T06:17:51.909Z",
  "category": "ai-services",
  "totalItems": 9,
  "items": [
    {
      "id": "aws-news-b77817f9e138",
      "title": "Introducing the Apache Spark troubleshooting agent for Amazon EMR and AWS Glue",
      "description": "In this post, we show you how the Apache Spark troubleshooting agent helps analyze Apache Spark issues by providing detailed root causes and actionable recommendations. You’ll learn how to streamline your troubleshooting workflow by integrating this agent with your existing monitoring solutions across Amazon EMR and AWS Glue.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-the-apache-spark-troubleshooting-agent-for-amazon-emr-and-aws-glue/",
      "pubDate": "2025-12-16T02:02:46.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr",
        "glue"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "emr",
        "glue"
      ]
    },
    {
      "id": "aws-news-1ddf08efc0c4",
      "title": "Applying data loading best practices for ML training with Amazon S3 clients",
      "description": "In this post, we present practical techniques and recommendations for optimizing throughput in ML training workloads that read data directly from Amazon S3 general purpose buckets.",
      "link": "https://aws.amazon.com/blogs/machine-learning/applying-data-loading-best-practices-for-ml-training-with-amazon-s3-clients/",
      "pubDate": "2025-12-15T17:29:31.000Z",
      "source": "mlBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "s3"
      ]
    },
    {
      "id": "aws-news-cd68753eba87",
      "title": "AWS Partner Central now includes opportunity deal sizing",
      "description": "Today, AWS announces deal sizing capability in AWS Partner Central. This new feature, available within the APN Customer Engagements (ACE) Opportunities, uses AI to provide deal size estimates and AWS service recommendations. Deal Sizing capability allows Partners to save time on deal management by simplifying the process of estimating AWS monthly recurring revenue (MMR) when creating or updating opportunities.\n  Partners can optionally import AWS Pricing Calculator URLs to automatically populate AWS service selections and corresponding spend estimates into their opportunities, reducing the need for manual re-entry. When a Pricing Calculator URL is provided, deal sizing delivers enhanced insights including pricing strategy optimization recommendations, potential cost savings analysis, Migration Acceleration Program (MAP) eligibility indicators, and modernization pathway analysis. These enhanced insights help Partners refine their technical approach and strengthen funding applications, accelerating the funding approval process.\n  Deal sizing is now available in AWS Partner Central worldwide. The feature is accessible through both AWS Partner Central and the AWS Partner Central API for Selling, which is available in the US East (N. Virginia) Region.\n  To get started, log in to AWS Partner Central in the console to create or update opportunities and view deal sizing insights. For API integration with your CRM system, see the AWS Partner Central API Documentation. To learn more about deal sizing, visit the Partner Central Sales Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-partner-central-opportunity-deal-sizing",
      "pubDate": "2025-12-09T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ga",
        "now-available",
        "new-feature",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-f4552e03b140",
      "title": "Auto-optimize your Amazon OpenSearch Service vector database",
      "description": "AWS recently announced the general availability of auto-optimize for the Amazon OpenSearch Service vector engine. This feature streamlines vector index optimization by automatically evaluating configuration trade-offs across search quality, speed, and cost savings. You can then run a vector ingestion pipeline to build an optimized index on your desired collection or domain. Previously, optimizing index […]",
      "link": "https://aws.amazon.com/blogs/big-data/auto-optimize-your-amazon-opensearch-service-vector-database/",
      "pubDate": "2025-12-08T23:58:24.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-262fa5942e1b",
      "title": "Build billion-scale vector databases in under an hour with GPU acceleration on Amazon OpenSearch Service",
      "description": "AWS recently announced the general availability of GPU-accelerated vector (k-NN) indexing on Amazon OpenSearch Service. You can now build billion-scale vector databases in under an hour and index vectors up to 10 times faster at a quarter of the cost. This feature dynamically attaches serverless GPUs to boost domains and collections running CPU-based instances. With […]",
      "link": "https://aws.amazon.com/blogs/big-data/build-billion-scale-vector-databases-in-under-an-hour-with-gpu-acceleration-on-amazon-opensearch-service/",
      "pubDate": "2025-12-08T23:57:19.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-56b08362877c",
      "title": "Introducing AWS DevOps Agent (preview), frontier agent for operational excellence",
      "description": "We're excited to launch AWS DevOps Agent in preview, a frontier agent that resolves and proactively prevents incidents, continuously improving reliability and performance of applications in AWS, multicloud, and hybrid environments. AWS DevOps Agent investigates incidents and identifies operational improvements as an experienced DevOps engineer would: by learning your resources and their relationships, working with your observability tools, runbooks, code repositories, and CI/CD pipelines, and correlating telemetry, code, and deployment data across all of them to understand the relationships between your application resources.\n \nAWS DevOps Agent autonomously triages incidents and guides teams to rapid resolution to reduce Mean Time to Resolution (MTTR). AWS DevOps Agent begins investigating the moment an alert comes in, whether at 2 AM or during peak hours, to quickly restore your application to optimal performance. It analyzes patterns across historical incidents to provide actionable recommendations that strengthen key areas including observability, infrastructure optimization, and deployment pipeline enhancement. AWS DevOps Agent helps access the untapped insights in your operational data and tools without changing your workflows.\n \nAWS DevOps Agent is available at no additional cost during preview in the US East (N. Virginia) Region. To learn more, read the AWS News Blog and see getting started.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/devops-agent-preview-frontier-agent-operational-excellence/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "launch",
        "preview",
        "ga",
        "improvement",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-a003c3534e1a",
      "title": "Amazon OpenSearch Service adds GPU-accelerated and auto-optimized vector indexes",
      "description": "You can now build billion-scale vector databases in under an hour on Amazon OpenSearch Service with GPU-acceleration, and auto-optimize vector indexes for optimal trade-offs between search quality, speed and cost.\n  Previously, large-scale vector indexes took days to build, and optimizing them required experts to spend weeks of manual tuning. The time, cost and effort weighed down innovation velocity, and customers forwent cost and performance optimizations. You can now run serverless, auto-optimize jobs to generate optimization recommendations. You simply specify search latency and recall requirements, and these jobs will evaluate index configurations (k-NN algorithms, quantization, and engine settings) automatically. Then, you can use vector GPU-acceleration to build an optimized index up to 10X faster at a quarter of the indexing cost. Serverless GPUs dynamically activate and accelerate your domain or collection, so you’re only billed when you benefit from speed boosts—all done without you managing GPU instances.\n  These capabilities help you scale AI applications including semantic search, recommendation engines, and agentic systems more efficiently. By simplifying and accelerating the time to build large-scale, optimized vector databases, your team will be empowered to innovate faster.\n  Vector GPU-acceleration is available for vector collections and OpenSearch 3.1+ domains in US East (N. Virginia), US West (Oregon), Asia Paciﬁc (Sydney), Europe (Ireland), and Asia Pacific (Tokyo) Regions. Vector auto-optimize is available for vector collections and OpenSearch 2.17+ domains in US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Paciﬁc (Mumbai), Asia Paciﬁc (Singapore), Asia Paciﬁc (Sydney), Asia Paciﬁc (Tokyo), Europe (Frankfurt) and Europe (Ireland) Regions. Learn more.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-opensearch-service-gpu-accelerated-auto-optimized-vector-indexes",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "opensearch",
        "opensearch service",
        "eks"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "nova",
        "opensearch",
        "opensearch service",
        "eks",
        "ga"
      ]
    },
    {
      "id": "aws-news-60f93eef06f8",
      "title": "Announcing Database Savings Plans with up to 35% savings",
      "description": "Today, AWS announces Database Savings Plans, a new flexible pricing model that helps you save up to 35% in exchange for a commitment to a consistent amount of usage (measured in $/hour) over a one-year term with no upfront payment.\n  Database Savings Plans automatically apply to eligible serverless and provisioned instance usage regardless of supported engine, instance family, size, deployment option, or AWS Region. For example, with Database Savings Plans, you can change between Aurora db.r7g and db.r8g instances, shift a workload from EU (Ireland) to US (Ohio), modernize from Amazon RDS for Oracle to Amazon Aurora PostgreSQL or from RDS to Amazon DynamoDB and still benefit from discounted pricing offered by Database Savings Plans.\n  Database Savings Plans will be available starting today in all AWS Regions, except China Regions, with support for Amazon Aurora, Amazon RDS, Amazon DynamoDB, Amazon ElastiCache, Amazon DocumentDB (with MongoDB compatibility), Amazon Neptune, Amazon Keyspaces (for Apache Cassandra), Amazon Timestream, and AWS Database Migration Service (DMS).\n  You can get started with Database Savings Plans from the AWS Billing and Cost Management Console or by using the AWS CLI. To realize the largest savings, you can make a commitment to Savings Plans by using purchase recommendations provided in the console. For a more customized analysis, you can use the Savings Plans Purchase Analyzer to estimate potential cost savings for custom purchase scenarios. For more information, visit the Database Savings Plans pricing page and the AWS Savings Plans FAQs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/database-savings-plans-savings",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "dynamodb",
        "rds"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lex",
        "dynamodb",
        "rds",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    }
  ]
}