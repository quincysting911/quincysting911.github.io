{
  "lastUpdated": "2026-02-20T06:40:44.081Z",
  "category": "ai-services",
  "totalItems": 6,
  "items": [
    {
      "id": "aws-news-fa285336edf8",
      "title": "Best practices for right-sizing Amazon OpenSearch Service domains",
      "description": "In this post, we guide you through the steps to determine if your OpenSearch Service domain is right-sized, using AWS tools and best practices to optimize your configuration for workloads like log analytics, search, vector search, or synthetic data testing.",
      "link": "https://aws.amazon.com/blogs/big-data/best-practices-for-right-sizing-amazon-opensearch-service-domains/",
      "pubDate": "2026-02-18T20:16:21.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-c4a04b172090",
      "title": "Announcing new high performance computing Amazon EC2 Hpc8a instances",
      "description": "AWS announces Amazon EC2 Hpc8a instances, the next generation of high performance computing optimized instance, powered by 5th Gen AMD EPYC processors (formerly code named Turin). With a maximum frequency of 4.5GHz, Hpc8a instances deliver up to 40% higher performance and up to 25% better price performance compared to Hpc7a instances, helping customers accelerate compute-intensive workloads while optimizing costs.\n  \n Built on the latest sixth-generation AWS Nitro Cards, Hpc8a instances are designed for compute-intensive, latency-sensitive HPC workloads. They are ideal for tightly coupled applications such as computational fluid dynamics (CFD), weather forecasting, explicit finite element analysis (FEA), and multiphysics simulations that require fast inter-node communication and consistent high performance.\n  Hpc8a instances feature 192 cores, 768 GiB memory and 300 Gbps of Elastic Fabric Adapter (EFA) network bandwidth, enabling fast, low-latency cluster scaling for large-scale HPC workloads. Compared to Hpc7a instances, Hpc8a instances also provide up to 42% higher memory bandwidth, further improving performance for memory-intensive simulations and scientific computing workloads.\n  Hpc8a instances are available today in US East (Ohio) and Europe (Stockholm). Customers can purchase Hpc8a instances via Savings Plans or On-Demand instances. To get started, sign in to the AWS Management Console. For more information visit the Amazon EC2 Hpc8a instance page or AWS news blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/announcing-amazon-ec2-hpc8a-instances/",
      "pubDate": "2026-02-16T21:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "forecast",
        "ec2",
        "rds"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "forecast",
        "ec2",
        "rds"
      ]
    },
    {
      "id": "aws-news-7e0632d6192f",
      "title": "AI Troubleshooting in the AWS Support Center Console now supports 7 additional languages",
      "description": "AI troubleshooting in the AWS Support Center Console is now available in seven languages in addition to English: Japanese, Korean, Mandarin (Simplified), Mandarin (Traditional), Spanish, Portuguese, French. AWS Support Center Console is the primary interface where customers manage their AWS support experience, including creating and tracking support cases. Previously, AI troubleshooting capabilities were only available in English, creating a barrier for customers who prefer to work in their native language. With this launch, customers can now interact with AI-powered troubleshooting assistance in their preferred language.\n  AWS Support's AI troubleshooting helps customers resolve issues faster by providing immediate, contextual recommendations while they create a support case. For example, a Japanese developer troubleshooting an EC2 connectivity issue can now receive AI-generated insights and potential solutions in Japanese, reducing the time needed to understand and implement fixes. This capability is seamlessly integrated into the support experience and is available to all customers regardless of support plan, ensuring that language is no longer a barrier to self-service support.\n  All customers regardless of support plan can access the experience by selecting a supported language in their console settings and clicking the “Try it now” link in the banner at the top of the AWS Support Center Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/ai-troubleshooting-in-aws-support-center/",
      "pubDate": "2026-02-12T18:39:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ec2",
        "launch",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f4c0e3221bd7",
      "title": "AWS HealthOmics introduces a Kiro Power and Kiro IDE extension for bioinformatics workflow development",
      "description": "AWS HealthOmics announces a Kiro Power and Kiro IDE extension to create, run, debug, and optimize HealthOmics workflows faster with AI agent-assisted development. With the HealthOmics extension for Kiro IDE, customers can create, modify, and analyze workflows in domain-specific languages including Nextflow and WDL directly in the Kiro interface. AWS HealthOmics is a HIPAA-eligible service that helps accelerate scientific breakthroughs at scale with fully managed bioinformatics workflows.\n  Kiro Powers is a repository of curated and pre-packaged Model Context Protocol (MCP) servers, steering files, and agent hooks to accelerate specialized software development and deployment use cases. The Kiro Power for HealthOmics packages the HealthOmics MCP server with guidance, giving the Kiro agent expertise in HealthOmics workflow creation and optimization. The HealthOmics Kiro IDE extension provides syntax highlighting, code completion, and troubleshooting guidance, along with HealthOmics engine compatibility checking, performance optimization recommendations, automated run analysis with failure diagnostics, and workflow import/export capabilities.\n  To get started, download and install the HealthOmics Kiro Power from https://kiro.dev/powers/ and HealthOmics Kiro IDE extension from Open VSX Registry.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-healthomics-introduces-kiro-plugin-for-bioinformatics-workflow-development/",
      "pubDate": "2026-02-09T21:03:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": []
    },
    {
      "id": "aws-news-578522f933b9",
      "title": "How Artera enhances prostate cancer diagnostics using AWS",
      "description": "In this post, we explore how Artera used Amazon Web Services (AWS) to develop and scale their AI-powered prostate cancer test, accelerating time to results and enabling personalized treatment recommendations for patients.",
      "link": "https://aws.amazon.com/blogs/architecture/how-artera-enhances-prostate-cancer-diagnostics-using-aws/",
      "pubDate": "2026-01-29T17:06:57.000Z",
      "source": "architectureBlog",
      "services": [
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    }
  ]
}