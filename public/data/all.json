{
  "lastUpdated": "2026-02-14T06:30:23.081Z",
  "totalItems": 203,
  "sources": {
    "whatsNew": 94,
    "mlBlog": 20,
    "newsBlog": 19,
    "bigDataBlog": 17,
    "architectureBlog": 17,
    "computeBlog": 19,
    "developersAndDevOps": 17
  },
  "items": [
    {
      "id": "aws-news-354bc14bf132",
      "title": "Customize AI agent browsing with proxies, profiles, and extensions in Amazon Bedrock AgentCore Browser",
      "description": "Today, we are announcing three new capabilities that address these requirements: proxy configuration, browser profiles, and browser extensions. Together, these features give you fine-grained control over how your AI agents interact with the web. This post will walk through each capability with configuration examples and practical use cases to help you get started.",
      "link": "https://aws.amazon.com/blogs/machine-learning/customize-ai-agent-browsing-with-proxies-profiles-and-extensions-in-amazon-bedrock-agentcore-browser/",
      "pubDate": "2026-02-13T22:57:34.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-f5e7f3b23733",
      "title": "Common streaming data enrichment patterns in Amazon Kinesis Data Analytics for Apache Flink",
      "description": "Common streaming data enrichment patterns in Amazon Managed Service for Apache FlinkStream data processing allows you to act on data in real time. Real-time data analytics can help you have on-time and optimized responses while improving overall customer experience. Apache Flink is a distributed computation framework that allows for stateful real-time data processing. It provides a […]",
      "link": "https://aws.amazon.com/blogs/big-data/common-streaming-data-enrichment-patterns-in-amazon-kinesis-data-analytics-for-apache-flink/",
      "pubDate": "2026-02-13T19:46:16.000Z",
      "source": "bigDataBlog",
      "services": [
        "kinesis"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "kinesis"
      ]
    },
    {
      "id": "aws-news-6f3849266f26",
      "title": "AWS Batch now provides Job Queue and Share Utilization Visibility",
      "description": "AWS Batch now provides Queue and Share Utilization Visibility, giving you insights into how your workloads are distributed across compute resources. This feature introduces queue utilization data in job queue snapshots, revealing compute capacity used by your first-in-first-out (FIFO) and fair share job queues, along with capacity consumption by individual fair share allocations. Additionally, the ListServiceJobs API now includes a scheduledAt timestamp for AWS Batch service jobs, allowing you to track when jobs are scheduled for execution.\n  Queue and Share Utilization Visibility helps you understand which fair-share allocations consume the most capacity and pinpoint the specific jobs driving resource consumption. You can monitor overall queue utilization and drill down into active shares to optimize resource distribution, or filter jobs by share identifier to analyze consumption patterns and scheduling behavior across your workloads.\n  You can access this feature using the GetJobQueueSnapshot, ListJobs, and ListServiceJobs APIs, or through the AWS Batch Management Console by navigating to your job queue details page and selecting the new Share Utilization tab. This feature is available today in all AWS Regions where AWS Batch is available. To learn more, visit the Job Queue Snapshot, List Jobs, and List Service Jobs pages of the AWS Batch API Reference Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-batch-provides-job-queue-share-utilization",
      "pubDate": "2026-02-13T17:30:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-426c2cf99ac0",
      "title": "Amazon Connect launches in-app notifications to surface critical operational alerts to business users",
      "description": "Amazon Connect now supports in-app notifications in the workspace header, visible from any page, so your team can stay informed without interrupting their workflow— whether configuring, analyzing data, or servicing customers. A notification icon appears in the header of every workspace page, with a badge indicating unread messages. Click the icon to view messages, access relevant resources through embedded links, and manage read/unread status—all without navigating away from your current task. For example, if all supervisors need to complete a certain training by end of week, a notification can be published to non-compliant users to remind them.\n  The new notification APIs enable you to programmatically send targeted messages to specific audiences within your organization, ensuring teams stay aware of urgent updates, policy changes, and action items requiring immediate attention. Amazon Connect will also leverage this capability to deliver system updates and important announcements.\n  In-app notifications are available in all AWS regions where Amazon Connect is available and offer public API and AWS CloudFormation support. To learn more about in-app notifications, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-in-app-notifications",
      "pubDate": "2026-02-13T17:20:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudformation",
        "launch",
        "ga",
        "update",
        "support",
        "announcement"
      ]
    },
    {
      "id": "aws-news-86a52dfe7164",
      "title": "Amazon Connect now provides real time AI-powered overviews and recommended next actions for Tasks",
      "description": "Amazon Connect now provides AI-powered Task overviews with suggested next actions so agents can understand work items faster and resolve them more quickly. For example, when an agent receives a Task to process a refund request submitted through an online form, Amazon Connect summarizes earlier activities such as verifying order details, checking return eligibility, and confirming the payment method, and then presents recommended next steps to complete the refund.\n  To enable this feature, add the Connect assistant flow block to your flows before a Task contact is assigned to your agent. You can guide the recommendations of your generative AI-powered Tasks assistant by adding knowledge bases.\n  This new feature is available in all AWS regions where Amazon Connect real time agent assistance is available. To learn more and get started, refer to the help documentation, pricing page, or visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/connect-tasks-ai-assistance",
      "pubDate": "2026-02-13T17:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-32455357f2c9",
      "title": "Amazon RDS now supports backup configuration when restoring snapshots",
      "description": "Amazon Relational Database Service (RDS) and Amazon Aurora now offer greater flexibility for restore operations to view and modify backup retention period and preferred backup window prior to and upon restoring database snapshots. The backup retention period lets you specify how many days backups are retained, while the preferred backup window allows you to set your desired backup schedule.\n  Previously, restored database instances and clusters inherited backup parameter values from snapshot metadata and could only be modified after restore was complete. This launch introduces two enhancements - you can now view the backup retention period and preferred backup window settings as part of automated backups and snapshots, providing visibility into backup configurations before initiating restore operation. Additionally, you can now specify or modify the backup retention period and preferred backup window when restoring database instances and clusters, eliminating the need to modify the instance or cluster after restoration.\n  These enhancements are available for all Amazon RDS database engines (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, and DB2) and Amazon Aurora (MySQL-Compatible and PostgreSQL-Compatible editions) in all AWS commercial regions and AWS GovCloud (US) regions where RDS and Aurora are supported and respective database engines are available. You can use these features through the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs at no additional cost. For more information, see Amazon RDS and Amazon Aurora User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-aurora-backup-configuration-restoring-snapshots/",
      "pubDate": "2026-02-13T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "launch",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-c19f2f91df70",
      "title": "Announcing Amazon EC2 C8i, M8i, and R8i instances on second-generation AWS Outposts racks",
      "description": "AWS is announcing local support for the latest generation of x86-powered Amazon EC2 instances on second-generation AWS Outposts racks, including C8i compute-optimized instances, M8i general-purpose instances, and R8i memory-optimized instances. These new instances deliver 20% better performance and 2.5x more memory bandwidth compared to the C7i, M7i, and R7i instances on second-generation Outposts racks. In addition, C8i, M8i, and R8i instances on second-generation Outposts racks deliver 20% more compute capacity than C7i, M7i, and R7i instances within the same rack space and power draw, enabling better space and energy efficiency for your on-premises workloads.\n  C8i, M8i, and R8i instances on second-generation Outposts racks are powered by custom Intel Xeon 6 processors available only on AWS and are ideal for a broad range of on-premises workloads requiring enhanced performance, such as larger databases, more memory-intensive applications, advanced real-time big data analytics, high-performance video encoding and streaming, and CPU-based edge inference with more sophisticated machine learning (ML) models.\n  To learn more about second-generation Outposts racks, refer to the Outposts racks product page and the user guide. For the most updated list of countries and territories and the AWS Regions where second-generation Outposts racks are supported, check out the Outposts rack FAQs page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8i-m8i-and-r8i-instances-on-aws-outposts/",
      "pubDate": "2026-02-12T22:34:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "outposts"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "outposts",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-86e8f3e987b4",
      "title": "Amazon Bedrock adds support for the latest open-weight models in Asia Pacific (Sydney)",
      "description": "Amazon Bedrock is a fully managed service that provides secure, enterprise-grade access to high-performing foundation models from leading AI companies, enabling you to build and scale generative AI applications. Today, Amazon Bedrock announced support for the latest open-weight models in Asia Pacific (Sydney) using the bedrock-mantle endpoint. These include models from industry-leading providers, including DeepSeek, Google, MiniMax, Mistral, Moonshot AI, MiniMax, Nvidia, and OpenAI. The bedrock-mantle endpoint is powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock. It provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and delivers out-of-the-box compatibility with OpenAI API specifications.\n \n\n To learn more and get started, visit the Amazon Bedrock console or the Amazon Bedrock service documentation. To get started with Amazon Bedrock OpenAI API-compatible service endpoints, visit the OpenAI API compatibility documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-support-latest-open-weight-models-asia-pacific-sydney/",
      "pubDate": "2026-02-12T22:14:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "support",
        "new-model"
      ]
    },
    {
      "id": "aws-news-e68e4d57a409",
      "title": "Amazon S3 Access Grants are now available in the AWS Asia Pacific (Taipei) Region",
      "description": "You can now create Amazon S3 Access Grants in the AWS Asia Pacific (Taipei) Region.\n \nAmazon S3 Access Grants map identities in directories such as Microsoft Entra ID, or AWS Identity and Access Management (IAM) principals, to datasets in S3. This helps you manage data permissions at scale by automatically granting S3 access to end users based on their corporate identity.\n \nVisit the AWS Region Table for complete regional availability information. To learn more about Amazon S3 Access Grants, visit our product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-s3-access-grants-are-available-in-taipei",
      "pubDate": "2026-02-12T21:47:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "iam",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a0fbcc6e4099",
      "title": "Amazon Bedrock expands support for AWS PrivateLink",
      "description": "Amazon Bedrock is a fully managed service that provides secure, enterprise-grade access to high-performing foundation models from leading AI companies. It enables you to build and scale generative AI applications. Amazon Bedrock already supported AWS PrivateLink for the bedrock-runtime endpoint. Now, with this launch, you can also use AWS PrivateLink to privately access your applications using the bedrock-mantle endpoint. The bedrock-mantle endpoint is powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock. It provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and delivers out-of-the-box compatibility with OpenAI API specifications.\n \nAWS PrivateLink support for OpenAI API-compatible endpoints is available in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Jakarta), Asia Pacific (Tokyo), Asia Pacific (Mumbai), Asia Pacific (Sydney), South America (São Paulo), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Milan), Europe (Stockholm), and South America (Sao Paulo) AWS Regions. To learn more and get started, visit the Amazon Bedrock console or the Amazon Bedrock service documentation. To get started with Amazon Bedrock OpenAI API-compatible service endpoints, visit the OpenAI API compatibility documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-expands-aws-privatelink-support-openai-api-endpoints/",
      "pubDate": "2026-02-12T21:40:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "launch",
        "support",
        "new-model"
      ]
    },
    {
      "id": "aws-news-4ac2d5c3fee1",
      "title": "AI meets HR: Transforming talent acquisition with Amazon Bedrock",
      "description": "In this post, we show how to create an AI-powered recruitment system using Amazon Bedrock, Amazon Bedrock Knowledge Bases, AWS Lambda, and other AWS services to enhance job description creation, candidate communication, and interview preparation while maintaining human oversight.",
      "link": "https://aws.amazon.com/blogs/machine-learning/ai-meets-hr-transforming-talent-acquisition-with-amazon-bedrock/",
      "pubDate": "2026-02-12T20:18:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lambda"
      ]
    },
    {
      "id": "aws-news-5dc8f40dd93f",
      "title": "Build long-running MCP servers on Amazon Bedrock AgentCore with Strands Agents integration",
      "description": "In this post, we provide you with a comprehensive approach to achieve this. First, we introduce a context message strategy that maintains continuous communication between servers and clients during extended operations. Next, we develop an asynchronous task management framework that allows your AI agents to initiate long-running processes without blocking other operations. Finally, we demonstrate how to bring these strategies together with Amazon Bedrock AgentCore and Strands Agents to build production-ready AI agents that can handle complex, time-intensive operations reliably.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-long-running-mcp-servers-on-amazon-bedrock-agentcore-with-strands-agents-integration/",
      "pubDate": "2026-02-12T20:16:20.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "integration"
      ]
    },
    {
      "id": "aws-news-48e777b8ef81",
      "title": "AWS expands Resource Control Policies support to Amazon DynamoDB",
      "description": "AWS Resource Control Policies (RCPs) now support Amazon DynamoDB. RCPs are a type of organization policy that you can use to manage permissions in your organization. RCPs offer central control over the maximum available permissions for resources in your organization.\n \nWith this expansion, you can now use RCPs to manage permissions for Amazon DynamoDB. For example, you can create policies that prevent identities outside your organization from accessing DynamoDB, helping you build a data perimeter and enforce baseline security standards across your AWS environment.  \n \nRCPs are available in all AWS commercial Regions and AWS GovCloud (US) Regions. To learn more about RCPs and view the full list of supported AWS services, visit the Resource control policies (RCPs) documentation in the AWS Organizations User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-expands-resource-control-policies-amazon",
      "pubDate": "2026-02-12T20:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "dynamodb",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "dynamodb",
        "rds",
        "organizations",
        "ga",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-dc4b03f3c7f7",
      "title": "Amazon Bedrock increases default quotas for Anthropic’s Claude Sonnet 4.5 model in AWS GovCloud (US)",
      "description": "Amazon Bedrock has increased the default quotas for Anthropic’s Claude Sonnet 4.5 in AWS GovCloud (US-West) and AWS GovCloud (US-East) to 5,000,000 tokens per minute and 1,000 requests per minute, aligning with commercial AWS regions. This 25x increase enables customers to scale their AI workloads more effectively in regulated environments.\n Claude Sonnet 4.5 is Anthropic's latest Sonnet model, excelling at building complex agents, coding, and long-horizon tasks while maintaining optimal speed and cost-efficiency for high-volume use-cases.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-s4.5-quota-aws-govcloud-us",
      "pubDate": "2026-02-12T19:52:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex"
      ]
    },
    {
      "id": "aws-news-7e0632d6192f",
      "title": "AI Troubleshooting in the AWS Support Center Console now supports 7 additional languages",
      "description": "AI troubleshooting in the AWS Support Center Console is now available in seven languages in addition to English: Japanese, Korean, Mandarin (Simplified), Mandarin (Traditional), Spanish, Portuguese, French. AWS Support Center Console is the primary interface where customers manage their AWS support experience, including creating and tracking support cases. Previously, AI troubleshooting capabilities were only available in English, creating a barrier for customers who prefer to work in their native language. With this launch, customers can now interact with AI-powered troubleshooting assistance in their preferred language.\n  AWS Support's AI troubleshooting helps customers resolve issues faster by providing immediate, contextual recommendations while they create a support case. For example, a Japanese developer troubleshooting an EC2 connectivity issue can now receive AI-generated insights and potential solutions in Japanese, reducing the time needed to understand and implement fixes. This capability is seamlessly integrated into the support experience and is available to all customers regardless of support plan, ensuring that language is no longer a barrier to self-service support.\n  All customers regardless of support plan can access the experience by selecting a supported language in their console settings and clicking the “Try it now” link in the banner at the top of the AWS Support Center Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/ai-troubleshooting-in-aws-support-center/",
      "pubDate": "2026-02-12T18:39:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ec2",
        "launch",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-fc86dccc391a",
      "title": "Amazon RDS for PostgreSQL supports minor versions  18.2, 17.8, 16.12, 15.16 and 14.21",
      "description": "Amazon Relational Database Service (RDS) for PostgreSQL now supports the latest minor versions 18.2, 17.8, 16.12, 15.16, and 14.21. We recommend that you upgrade to the latest minor versions to fix known security vulnerabilities in prior versions of PostgreSQL, and to benefit from the bug fixes added by the PostgreSQL community. This release also includes new extension pg_stat_monitor that enables you to collect performance metrics and evaluate query performance insights in a unified view.\n  You can upgrade your databases during scheduled maintenance windows using automatic minor version upgrades. To simplify operations at scale, enable automatic minor version upgrades and use the AWS Organizations Upgrade Rollout Policy to orchestrate thousands of upgrades in phases, first to development environments before upgrading production systems. You can also use Amazon RDS Blue/Green deployments with physical replication to minimize downtime for minor version upgrades.\n  Amazon RDS for PostgreSQL makes it simple to set up, operate, and scale PostgreSQL deployments in the cloud. See Amazon RDS for PostgreSQL Pricing for pricing details and regional availability. Create or update a fully managed Amazon RDS database in the Amazon RDS Management Console or by using the AWS Command Line Interface (CLI).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-minor-version-18-2-17-8-16-12-15-16-14-21",
      "pubDate": "2026-02-12T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-52a5cdfbb2f8",
      "title": "Announcing new Amazon EC2 general purpose M8azn instances",
      "description": "AWS is announcing the general availability of new Amazon EC2 M8azn instances, general purpose high-frequency high-network instances powered by fifth generation AMD EPYC (formerly code named Turin) processors, offering the highest maximum CPU frequency, 5GHz in the cloud. M8azn instances offer up to 2x compute performance compared to previous generation M5zn instances, and up to 24% higher performance than M8a instances.\n  M8azn instances deliver up to 4.3x higher memory bandwidth and 10x larger L3 cache compared to M5zn instances allowing latency-sensitive and compute-intensive workloads to achieve results faster. These instances also offer up to 2x networking throughput and up to 3x EBS throughput versus M5zn instances. Built on the AWS Nitro System using sixth generation Nitro Cards, these instances are ideal for applications such as real-time financial analytics, high-performance computing, high-frequency trading (HFT), CI/CD, intensive gaming, and simulation modeling for the automotive, aerospace, energy, and telecommunication industries. M8azn instances feature a 4:1 ratio of memory to vCPU and are available in 9 sizes ranging from 2 to 96 vCPUs with up to 384 GiB of memory, including two bare metal variants.\n  M8azn instances are available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Tokyo), and Europe (Frankfurt) Regions. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. To get started, sign in to the AWS Management Console. For more information visit the Amazon EC2 M8azn instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-m8azn-instances-generally-available",
      "pubDate": "2026-02-12T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ec2",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-5602fd73e43a",
      "title": "Amazon S3 Tables add partition and sort order definition in the CreateTable API",
      "description": "Amazon S3 Tables announce partition and sort order definition support for the CreateTable API. This enhancement simplifies setting these properties programmatically, making it easier to manage and optimize data in tables when they are created.\n  To use this feature, you can specify fields for partition transforms and sort order in the CreateTable API call. You can also define these properties when you create tables using the AWS CLI or the AWS SDK.\n  To create tables with partition and sort order, upgrade to the latest version of the AWS CLI and AWS SDKs. This support is available in all AWS Regions where S3 Tables are available. To learn more, visit the Amazon S3 Tables overview page and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/s3-tables-partition-and-sort-order-createtable-api/",
      "pubDate": "2026-02-12T11:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-231b224caaba",
      "title": "AWS Backup adds cross-Region database snapshot copy to logically air-gapped vaults",
      "description": "AWS Backup now supports single-action database snapshot copies to logically air-gapped vaults across AWS Regions. This capability is available for Amazon Aurora, Amazon Neptune, and Amazon DocumentDB snapshots, eliminating the need for an intermediate copying step in target Regions.\n \nYou can perform cross-Region and cross-account snapshot copies to protect against incidents like ransomware events and Region outages that might affect your production accounts or primary Regions. Previously, this required a two-step process—first copying snapshots to the target Region in a backup vault, then copying them to the logically air-gapped vault in the same Region. Now, you can complete this in one step, achieving faster recovery point objectives (RPOs) while eliminating costs associated with intermediate copies. This streamlined process also removes the need for custom scripts or AWS Lambda functions to monitor intermediate copy status.\n \nThis feature is available for Amazon Aurora, Amazon Neptune and Amazon DocumentDB, in all Regions where AWS Backup supports these databases and logically air-gapped vaults. You can start using this feature today through the AWS Management Console, AWS Command Line Interface (CLI), or AWS SDKs. To get started, refer to the AWS Backup documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-adds-cross-region-database-snapshot-logically-air-gapped-vaults/",
      "pubDate": "2026-02-12T11:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-6a19d601fcb1",
      "title": "Amazon Connect  launches granular access controls for analytics dashboards",
      "description": "Amazon Connect dashboards now provides granular access controls for analytics dashboards. This enables you to apply resource tags that control who is able to see metrics for specific resources such as agents, queues, and routing profiles. You can now filter metrics using tags to view aggregate metrics for agents or queues that share the same tags. For example, you can tag agents with Department:Customer Service to restrict dashboard metrics visibility to Customer Service team managers.\n \n\n Amazon Connect dashboards are available in all AWS commercial and AWS GovCloud (US-West) regions where Amazon Connect is offered. To learn more about dashboards, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-launches-granular-access",
      "pubDate": "2026-02-12T07:26:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-22def9800bc5",
      "title": "Amazon Athena adds 1-minute reservations and new capacity control features",
      "description": "Amazon Athena is a serverless interactive query service that makes it easy to analyze data using SQL. With Athena, there’s no infrastructure to manage, you simply submit queries and get results. Capacity Reservations is a feature of Athena that addresses the need to run critical workloads by providing dedicated serverless capacity for workloads you specify. In this post, we highlight three new capabilities that make Capacity Reservations more flexible and easier to manage: reduced minimums for fine-grained capacity adjustments, an autoscaling solution for dynamic workloads, and capacity cost and performance controls.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-athena-adds-1-minute-reservations-and-new-capacity-control-features/",
      "pubDate": "2026-02-11T22:16:01.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex",
        "athena"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "athena"
      ]
    },
    {
      "id": "aws-news-f20129c0b05f",
      "title": "AWS Payment Cryptography Achieves Cartes Bancaires Approval",
      "description": "Today, AWS Payment Cryptography has become one of the first cloud-based payment cryptography services to obtain approval from Groupement des Cartes Bancaires (CB), France's national card payment network. This CB approval, combined with existing compliance credentials, enables customers to run payment workloads in AWS while helping customers maintain CB compliance.\n  Organizations such as acquirers, payment facilitators, networks, switches, processors, and issuing banks that are moving workloads to the cloud can rely on AWS Payment Cryptography’s CB approval as part of their compliance frameworks. Organizations processing card payments typically require Hardware Security Modules (HSM) to perform cryptography in a compliant manner. AWS Payment Cryptography provides equivalent functionality in an elastic, scalable service, eliminating the operational burden of procuring and manage standalone payment HSMs. Customers can leverage the service’s shared responsibility model with PCI PIN, PCI P2PE, PCI 3DS, PCI DSS, SOC-2, CSA STAR and ISO27001 certifications as well as the additional CB approval.\n  AWS Payment Cryptography is available in the following AWS Regions: Canada (Montreal), US East (Ohio, N. Virginia), US West (Oregon), Europe (Ireland, Frankfurt, London, Paris), Africa (Cape Town) and Asia Pacific (Singapore, Tokyo, Osaka, Mumbai, Hyderabad, Sydney).\n  To start using the service, please download the latest AWS CLI/SDK and see the AWS Payment Cryptography user guide for more information including further compliance details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/payment-cryptography-cartes-bancaires",
      "pubDate": "2026-02-11T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-d53fbf6dc1eb",
      "title": "Amazon Connect launches after contact work timeout configuration for tasks, chats, and emails",
      "description": "Amazon Connect now supports the ability to configure agents with after contact work timeout settings for chat, tasks, emails, and callbacks. After contact work timeouts improve agent efficiency by time-boxing the amount of time each agent can spend doing after contact work for a contact, before being automatically set back to a ready state so they can be offered another contact. You can now enable these settings at the channel level for each agent to further optimize how agents spend their time. For example, you could choose to enable a shorter ACW timeout for emails while maintaining a longer ACW timeout for voice contacts to give agents a cool-down period between phone calls to prepare for the next customer interaction.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-omnichannel-acw-timeouts",
      "pubDate": "2026-02-11T20:14:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-e106de24be50",
      "title": "Amazon Connect launches auto-accept for tasks, chats, and emails",
      "description": "Amazon Connect now supports the ability to configure agents with auto-accept settings for chat, tasks, emails, and callbacks. When auto-accept is enabled, incoming contacts are automatically connected to available agents instead of waiting on the agent to manually accept or reject each contact, ensuring that customers receive timely assistance. Previously, these settings were available only for inbound voice contacts. You can now enable these settings at the channel level for each agent to further optimize how agents spend their time. For example, you could choose to enable auto-accept for tasks while keeping auto-accept disabled for voice calls to ensure that the agent is connected to a voice call only once they indicate they are ready.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-omnichannel-auto-accept",
      "pubDate": "2026-02-11T20:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-95cd2d9f146e",
      "title": "NVIDIA Nemotron 3 Nano 30B MoE model is now available in Amazon SageMaker JumpStart",
      "description": "Today we’re excited to announce that the NVIDIA Nemotron 3 Nano 30B model with  3B active parameters is now generally available in the Amazon SageMaker JumpStart model catalog. You can accelerate innovation and deliver tangible business value with Nemotron 3 Nano on Amazon Web Services (AWS) without having to manage model deployment complexities. You can power your generative AI applications with Nemotron capabilities using the managed deployment capabilities offered by SageMaker JumpStart.",
      "link": "https://aws.amazon.com/blogs/machine-learning/nvidia-nemotron-3-nano-30b-is-now-available-in-amazon-sagemaker-jumpstart/",
      "pubDate": "2026-02-11T19:38:47.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker",
        "jumpstart",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "jumpstart",
        "lex",
        "generally-available",
        "now-available"
      ]
    },
    {
      "id": "aws-news-35989e7c7eae",
      "title": "Amazon Aurora DSQL is now available in additional AWS Regions",
      "description": "Amazon Aurora DSQL is now available with single-Region clusters in Asia Pacific (Melbourne), Asia Pacific (Sydney), Canada (Central), and Canada West (Calgary). Aurora DSQL is the fastest serverless, distributed SQL database that enables you to build always available applications with virtually unlimited scalability, the highest availability, and zero infrastructure management. It is designed to make scaling and resilience effortless for your applications and offers the fastest distributed SQL reads and writes.\n  With this launch, Aurora DSQL is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Canada (Central), Canada West (Calgary), Asia Pacific (Melbourne), Asia Pacific (Sydney), Asia Pacific (Osaka), Asia Pacific (Tokyo), Asia Pacific (Seoul), Europe (Ireland), Europe (London), Europe (Frankfurt), and Europe (Paris).\n  Get started with Aurora DSQL for free with the AWS Free Tier. To learn more, visit the Aurora DSQL webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-aurora-dsql-additional-aws-regions",
      "pubDate": "2026-02-11T19:30:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-681847d4f879",
      "title": "Amazon MSK now supports broker logs on Express Brokers",
      "description": "Amazon Managed Streaming for Apache Kafka (MSK) now supports broker logs for Express brokers at no additional cost. With access to broker logs, you can troubleshoot client connectivity and availability issues and get insights into broker behavior during rebalances or fail-overs. You can also easily integrate Kafka operational telemetry into existing observability pipelines using pre-built integrations with Amazon CloudWatch Logs and Amazon S3. Broker Logs are available for both new and existing Express brokers . You can enable them from the Amazon MSK Console or AWS CLI. To learn how to setup broker log delivery, see the Amazon MSK broker logs documentation.\n  MSK Express brokers are designed to deliver up to three times more throughput per broker, scale up to 20 times faster, and reduce recovery time by 90 percent compared to Standard brokers running Apache Kafka. Express broker logs are supported in all AWS regions where express brokers are available. With Amazon MSK, you spend more time innovating on applications and less time managing clusters. Visit the Amazon MSK developer guide to get started.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-msk-express-brokers-support-broker-logs",
      "pubDate": "2026-02-11T19:23:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "s3",
        "kafka",
        "msk",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova",
        "s3",
        "kafka",
        "msk",
        "cloudwatch",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-e198bdd73bc5",
      "title": "AWS announces 6 new locations for AWS Data Transfer Terminal",
      "description": "AWS Data Transfer Terminal is now available in six additional locations in Seattle and Phoenix (US), London (UK), Paris (France), Sydney (Australia), and Tokyo (Japan), expanding availability alongside existing locations in San Francisco, Los Angeles, and New York City (US), and Munich (Germany). AWS Data Transfer Terminal is a secure, physical location where you can bring your storage devices and upload data to AWS including Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), and others using a high throughput network connection.\n  Data Transfer Terminals are ideal for customers who need to transfer large amounts of data to the AWS quickly and securely. Common use cases span various industries and applications, including video production data for processing in the media and entertainment industry, training data for Advanced Driver Assistance Systems (ADAS) in the automotive industry, migrating legacy data in the financial services industry, and uploading equipment sensor data in the industrial and agricultural sectors. Once uploaded, you can immediately leverage AWS services like Amazon Athena for analysis, Amazon SageMaker for machine learning, or Amazon Elastic Compute Cloud (Amazon EC2) for application development, reducing data processing time from weeks to minutes.\n  To learn more, visit the Data Transfer Terminal product page and documentation. To get started, make a reservation at your nearby Data Transfer Terminal in the AWS Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-data-transfer-terminal-6-new-locations/",
      "pubDate": "2026-02-11T19:02:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "s3",
        "ec2",
        "eks",
        "athena"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "ec2",
        "eks",
        "athena",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-8ffc4d07b41b",
      "title": "AWS Elastic Beanstalk now supports GitHub Actions for automated application deployment",
      "description": "AWS Elastic Beanstalk now enables you to use GitHub Actions to automatically deploy web applications when you push code or configuration changes to your GitHub repository, streamlining your continuous integration and continuous deployment (CI/CD) pipeline for scalable web applications.\n \nGitHub Actions allow development teams to automate their software delivery process, enabling CI/CD workflows that automatically build, test, and deploy code changes whenever developers push updates to their repositories. Teams deploying to Elastic Beanstalk can now benefit from enhanced automation that handles deployment package creation, S3 uploads, version management, and environment monitoring. The new GitHub Action provides a simplified way to deploy applications to Elastic Beanstalk using declarative configuration in GitHub Actions workflows, offering comprehensive automation for the entire deployment lifecycle. This action automatically creates applications and environments when needed, manages deployment packages with configurable exclusions, and integrates seamlessly with IAM using OpenID Connect (OIDC) authentication.\n \nTo get started, add the \"aws-elasticbeanstalk-deploy\" action to your GitHub Actions workflow file with configuration parameters for your application deployment. The action supports configuring environment settings and platform versions, optional health monitoring and deployment validation, intelligent retry logic for reliable deployments, and S3 bucket management for deployment artifacts. To learn more, visit the README for the AWS Elastic Beanstalk Deploy GitHub action.\n \nYou can use this GitHub Action for your Elastic Beanstalk applications in all commercial AWS Regions where Elastic Beanstalk is available.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-elastic-beanstalk-github-action",
      "pubDate": "2026-02-11T19:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "iam",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-b81c3d11b6ea",
      "title": "AWS Lake Formation enhances cross-account sharing",
      "description": "AWS Lake Formation now enhances cross-account sharing, allowing you to share hundreds of thousands of tables across accounts. You can centralize permissions in Lake Formation for resources such as catalogs, databases, and tables for multi-account analytics environments that require fine-grained access controls at scale.\n  You can share Data Catalog resources (databases, tables, and columns) with external IAM principals, AWS accounts, AWS Organizations, and organizational units (OUs). Lake Formation sets up a single AWS Resource Access Manager resource share for an unlimited number of tables to another account, eliminating previous resource association limits per resource type. To get started, upgrade to cross-account version 5 through the Lake Formation console or API. Any new cross-account permission grants will automatically use wildcard patterns in the AWS Resource Access Manager resource shares instead of individual resource associations. All existing cross-account shares continue to function, and all existing Lake Formation APIs remain compatible.\n \nTo learn more, visit the AWS Lake Formation product page and documentation. For AWS Lake Formation Region availability, please see the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-lake-formation-cross-account-sharing",
      "pubDate": "2026-02-11T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "iam",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-6cf8e8c43707",
      "title": "MSK simplifies Kafka topic management with new APIs and console integration",
      "description": "Amazon Managed Streaming for Apache Kafka (Amazon MSK) now offers three new APIs (CreateTopic, UpdateTopic, and DeleteTopic), making it easier to manage your Kafka topics for your MSK provisioned clusters without the need to set up and maintain Kafka admin clients. You can programmatically create, update, and delete Kafka topics using your familiar interfaces including AWS CLI, AWS SDKs, and AWS CloudFormation. With these APIs, you can define topic properties such as replication factor and partition count, along with configuration settings like retention and cleanup policies. The new APIs together with the ListTopics and DescribeTopic APIs are integrated into the Amazon MSK console, bringing all topic operstions to one place. You can now create or update topics with just a few clicks using guided defaults while gaining comprehensive visibility into topic configurations, partition-level information, and metrics.\n  These MSK topic management capabilities are available at no additional cost for all Amazon MSK provisioned clusters using Kafka version 3.6 and above across AWS regions where Amazon MSK is offered. To start using these features, you'll need to set up the appropriate IAM permissions. To learn more on how to get started, see the Amazon MSK Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-msk-kafka-topics-public-apis/",
      "pubDate": "2026-02-11T17:46:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "iam",
        "kafka",
        "msk"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudformation",
        "iam",
        "kafka",
        "msk",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-9bbc90812487",
      "title": "Amazon EC2 R8i and R8i-flex instances are now available in additional AWS regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8i and R8i-flex instances are available in the Asia Pacific (New Zealand) and Middle East (UAE) regions. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. The R8i and R8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver 20% higher performance than R7i instances, with even higher gains for specific workloads. They are up to 30% faster for PostgreSQL databases, up to 60% faster for NGINX web applications, and up to 40% faster for AI deep learning recommendation models compared to R7i.\n  R8i-flex, our first memory-optimized Flex instances, are the easiest way to get price performance benefits for a majority of memory-intensive workloads. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  R8i instances are a great choice for all memory-intensive workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. R8i instances offer 13 sizes including 2 bare metal sizes and the new 96xlarge size for the largest applications. R8i instances are SAP-certified and deliver 142,100 aSAPS, delivering exceptional performance for mission-critical SAP workloads.\n  To get started, sign in to the AWS Management Console. For more information about the R8i and R8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-r8i-r8i-flex-instances-AKL-DXB-region/",
      "pubDate": "2026-02-11T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a0980a66101f",
      "title": "Amazon EC2 C8i and C8i-flex instances are now available in Europe (Paris), Canada (Central), and US West (N. California) regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8i and C8i-flex instances are available in the Europe (Paris), Canada (Central), and US West (N. California) regions. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. These C8i and C8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver up to 20% higher performance than C7i and C7i-flex instances, with even higher gains for specific workloads. The C8i and C8i-flex are up to 60% faster for NGINX web applications, up to 40% faster for AI deep learning recommendation models, and 35% faster for Memcached stores compared to C7i and C7i-flex.\n  C8i-flex are the easiest way to get price performance benefits for a majority of compute intensive workloads like web and application servers, databases, caches, Apache Kafka, Elasticsearch, and enterprise applications. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  C8i instances are a great choice for all memory-intensive workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. C8i instances offer 13 sizes including 2 bare metal sizes and the new 96xlarge size for the largest applications.\n  To get started, sign in to the AWS Management Console. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information about the new C8i and C8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8i-c8i-flex-instances-europe-paris-canada-central-uswest-ncalifornia-regions",
      "pubDate": "2026-02-11T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "kafka"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "kafka",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-ddcbfc655623",
      "title": "Amazon RDS for MariaDB now supports community MariaDB minor versions 10.6.25, 10.11.16, 11.4.10, and 11.8.6",
      "description": "Amazon Relational Database Service (Amazon RDS) for MariaDB now supports community MariaDB minor versions 10.6.25, 10.11.16, 11.4.10, and 11.8.6. We recommend that you upgrade to the latest minor versions to fix known security vulnerabilities in prior versions of MariaDB, and to benefit from the bug fixes, performance improvements, and new functionality added by the MariaDB community.\n  You can leverage automatic minor version upgrades to automatically upgrade your databases to more recent minor versions during scheduled maintenance windows. You can also leverage Amazon RDS Managed Blue/Green deployments for safer, simpler, and faster updates to your MariaDB instances. Learn more about upgrading your database instances, including automatic minor version upgrades and Blue/Green Deployments, in the Amazon RDS User Guide.\n  Amazon RDS for MariaDB makes it straightforward to set up, operate, and scale MariaDB deployments in the cloud. Learn more about pricing details and regional availability at Amazon RDS for MariaDB. Create or update a fully managed Amazon RDS database in the Amazon RDS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-rds-mariadb-community-versions/",
      "pubDate": "2026-02-11T16:23:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-3537a41f10b9",
      "title": "Amazon DocumentDB (with MongoDB compatibility) is Now Available in the Europe (Zurich) Region",
      "description": "Amazon DocumentDB (with MongoDB compatibility) is now available in the Europe (Zurich) region adding to the list of available regions where you can use Amazon DocumentDB.\n \nAmazon DocumentDB is a fully managed, native JSON database that makes it simple and cost-effective to operate critical document workloads at virtually any scale without managing infrastructure. Amazon DocumentDB is designed to give you the scalability and durability you need when operating mission-critical MongoDB workloads. Storage scales automatically up to 128TiB without any impact to your application. In addition, Amazon DocumentDB natively integrates with AWS Database Migration Service (DMS), Amazon CloudWatch, AWS CloudTrail, AWS Lambda, AWS Backup and more. Amazon DocumentDB supports millions of requests per second and can be scaled out to 15 low latency read replicas in minutes with no application downtime.\n \nTo learn more about Amazon DocumentDB, please visit the Amazon DocumentDB product page and pricing page.\n \nYou can create a Amazon DocumentDB cluster from the AWS Management console, AWS Command Line Interface (CLI), or SDK.",
      "link": "https://aws.amazon.comabout-aws/whats-new/2026/02/amazon-documentdb-mongodb-compatibility-europe-zurich-region",
      "pubDate": "2026-02-11T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "cloudwatch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-123e63417c8b",
      "title": "Amazon DocumentDB (with MongoDB compatibility) is Now Available in the Asia Pacific (Melbourne) Region",
      "description": "Amazon DocumentDB (with MongoDB compatibility) is now available in the Asia Pacific (Melbourne) region adding to the list of available regions where you can use Amazon DocumentDB.\n \nAmazon DocumentDB is a fully managed, native JSON database that makes it simple and cost-effective to operate critical document workloads at virtually any scale without managing infrastructure. Amazon DocumentDB is designed to give you the scalability and durability you need when operating mission-critical MongoDB workloads. Storage scales automatically up to 128TiB without any impact to your application. In addition, Amazon DocumentDB natively integrates with AWS Database Migration Service (DMS), Amazon CloudWatch, AWS CloudTrail, AWS Lambda, AWS Backup and more. Amazon DocumentDB supports millions of requests per second and can be scaled out to 15 low latency read replicas in minutes with no application downtime.\n \nTo learn more about Amazon DocumentDB, please visit the Amazon DocumentDB product page and pricing page.\n \nYou can create a Amazon DocumentDB cluster from the AWS Management console, AWS Command Line Interface (CLI), or SDK.",
      "link": "https://aws.amazon.comabout-aws/whats-new/2026/02/amazon-documentdb-mongodb-compatibility-asia-pacific-melbourne-region",
      "pubDate": "2026-02-11T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "cloudwatch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-20dd478d2bcb",
      "title": "Mastering Amazon Bedrock throttling and service availability: A comprehensive guide",
      "description": "This post shows you how to implement robust error handling strategies that can help improve application reliability and user experience when using Amazon Bedrock. We'll dive deep into strategies for optimizing performances for the application with these errors. Whether this is for a fairly new application or matured AI application, in this post you will be able to find the practical guidelines to operate with on these errors.",
      "link": "https://aws.amazon.com/blogs/machine-learning/mastering-amazon-bedrock-throttling-and-service-availability-a-comprehensive-guide/",
      "pubDate": "2026-02-11T15:52:54.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-f28ad49fa3a4",
      "title": "Swann provides Generative AI to millions of IoT Devices using Amazon Bedrock",
      "description": "This post shows you how to implement intelligent notification filtering using Amazon Bedrock and its gen-AI capabilities. You'll learn model selection strategies, cost optimization techniques, and architectural patterns for deploying gen-AI at IoT scale, based on Swann Communications deployment across millions of devices.",
      "link": "https://aws.amazon.com/blogs/machine-learning/swann-provides-generative-ai-to-millions-of-iot-devices-using-amazon-bedrock/",
      "pubDate": "2026-02-11T15:48:15.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-0b76fca6e392",
      "title": "How LinqAlpha assesses investment theses using Devil’s Advocate on Amazon Bedrock",
      "description": "LinqAlpha is a Boston-based multi-agent AI system built specifically for institutional investors. The system supports and streamlines agentic workflows across company screening, primer generation, stock price catalyst mapping, and now, pressure-testing investment ideas through a new AI agent called Devil’s Advocate. In this post, we share how LinqAlpha uses Amazon Bedrock to build and scale Devil’s Advocate.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-linqalpha-assesses-investment-theses-using-devils-advocate-on-amazon-bedrock/",
      "pubDate": "2026-02-11T15:45:30.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "support"
      ]
    },
    {
      "id": "aws-news-4e118507f390",
      "title": "Amazon Connect introduces audio enhancements for noisy environments",
      "description": "Today, AWS announces the release of Audio Enhancement for Amazon Connect, helping improve audio quality and reliability for voice calls in noisy contact center environments. With this launch, you can enable Audio Enhancement for your agents so that end customers can hear them more clearly, even in the presence of background noise within the contact center environment.\n  The Audio Enhancement capability suppresses agent-side background noises and isolates agent voices, removing the effect of background noise and chatter in busy contact center environments. Audio Enhancement offers two specialized modes to match different agent setups. The \"Voice Isolation\" mode suppresses noises as well as background speech within the contact center, while the \"Noise Suppression\" mode only suppresses background noises. Contact center administrators can enable these capabilities for agents through the User Management page and select the appropriate mode based on their equipment and setup. Agents with proper permissions can also adjust their settings directly from the Contact Control Panel to optimize for their current environment.\n  The Audio Enhancement capability is available in all commercial AWS Regions where Amazon Connect is offered.\n  To learn more about Amazon Connect Audio Enhancement, please see the Amazon Connect website and the Amazon Connect Administrator Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-audio-enhancements",
      "pubDate": "2026-02-11T13:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-39b93afa34c1",
      "title": "Amazon Bedrock AgentCore Browser now supports proxy configuration",
      "description": "Amazon Bedrock AgentCore Browser now supports customer-provided proxy configuration, enabling customers to route browser sessions through their own proxy infrastructure for geo-targeting, regional content access, and compliance requirements. Organizations can access geo-restricted content, verify region-specific pricing, and validate localized application behavior across markets. Customers in regulated industries such as healthcare and financial services can route traffic through corporate proxy infrastructure to meet security policies while automating critical business processes.\n  Browser proxies help eliminate re-authentication cycles due to rotating IPs, while providing stable, controllable egress addresses for IP allowlisting requirements. The feature currently supports both HTTP and HTTPS protocols with secure credential management through AWS Secrets Manager. This enhancement is particularly valuable for healthcare organizations accessing portals with strict IP allowlisting, financial services companies with rigorous egress policies, and enterprises routing traffic through corporate proxy infrastructure that provides auditing and security policy enforcement.\n  This feature is available in all fourteen AWS Regions where Amazon Bedrock AgentCore Browser is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), and Europe (Stockholm).\n  To learn more, visit the Browser Proxies documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/bedrock-agentcore-browser-proxy",
      "pubDate": "2026-02-11T06:16:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "secrets manager",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "secrets manager",
        "organizations",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-4cbce46f295e",
      "title": "How Zalando innovates their Fast-Serving layer by migrating to Amazon Redshift",
      "description": "In this post, we show how Zalando migrated their fast-serving layer data warehouse to Amazon Redshift to achieve better price-performance and scalability.",
      "link": "https://aws.amazon.com/blogs/big-data/how-zalando-innovates-their-fast-serving-layer-by-migrating-to-amazon-redshift/",
      "pubDate": "2026-02-10T23:37:35.000Z",
      "source": "bigDataBlog",
      "services": [
        "nova",
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova",
        "redshift"
      ]
    },
    {
      "id": "aws-news-79a047a8ae20",
      "title": "Amazon SageMaker HyperPod now supports node actions from the console",
      "description": "Amazon SageMaker HyperPod now enables you to manage individual cluster nodes directly from the AWS Console. HyperPod cluster operators managing large-scale AI/ML workloads often need to connect to nodes for troubleshooting, reboot unresponsive instances, or replace degraded nodes. Connecting to a node previously required manually constructing SSM connection strings, while node recovery actions such as reboot and replace required CLI commands — the console now provides a single interface for all node actions.\n  With node actions in the console, you can now connect to any node via AWS Systems Manager (SSM). The console provides pre-populated SSM CLI commands with copy-to-clipboard support, and direct SSM session launch in the console. While SageMaker HyperPod clusters already support automatic replacement and reboot of unhealthy instances, there are scenarios such as memory overruns or undetectable hardware degradation that may require manual intervention. Now, node actions in the console provide a consistent approach to manually reboot nodes to recover from transient issues, delete unhealthy nodes, and replace nodes, with batch operations supporting multiple node actions simultaneously, enabling you to resolve node issues in minutes. This capability is especially valuable when running time-sensitive AI training and inference workloads where minimizing downtime is essential.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is supported. You can perform all these node actions in the HyperPod Cluster management page on console. Click on the respective links to learn more about replace/reboot and connecting to a node.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-sagemaker-hyperpod-node-actions/",
      "pubDate": "2026-02-10T19:15:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-0d02aec495a3",
      "title": "How Amazon uses Amazon Nova models to automate operational readiness testing for new fulfillment centers",
      "description": "In this post, we discuss how Amazon Nova in Amazon Bedrock can be used to implement an AI-powered image recognition solution that automates the detection and validation of module components, significantly reducing manual verification efforts and improving accuracy.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-uses-amazon-nova-models-to-automate-operational-readiness-testing-for-new-fulfillment-centers/",
      "pubDate": "2026-02-10T18:34:09.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-2c6246a1ff48",
      "title": "Iberdrola enhances IT operations using Amazon Bedrock AgentCore",
      "description": "Iberdrola, one of the world’s largest utility companies, has embraced cutting-edge AI technology to revolutionize its IT operations in ServiceNow. Through its partnership with AWS, Iberdrola implemented different agentic architectures using Amazon Bedrock AgentCore, targeting three key areas: optimizing change request validation in the draft phase, enriching incident management with contextual intelligence, and simplifying change model selection using conversational AI. These innovations reduce bottlenecks, help teams accelerate ticket resolution, and deliver consistent and high-quality data handling throughout the organization.",
      "link": "https://aws.amazon.com/blogs/machine-learning/iberdrola-enhances-it-operations-using-amazon-bedrock-agentcore/",
      "pubDate": "2026-02-10T18:31:57.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-8115f2327170",
      "title": "Building real-time voice assistants with Amazon Nova Sonic compared to cascading architectures",
      "description": "Amazon Nova Sonic delivers real-time, human-like voice conversations through the bidirectional streaming interface. In this post, you learn how Amazon Nova Sonic can solve some of the challenges faced by cascaded approaches, simplify building voice AI agents, and provide natural conversational capabilities. We also provide guidance on when to choose each approach to help you make informed decisions for your voice AI projects.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-real-time-voice-assistants-with-amazon-nova-sonic-compared-to-cascading-architectures/",
      "pubDate": "2026-02-10T18:29:05.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-814a29034488",
      "title": "Amazon EC2 C8id, M8id, and R8id instances are available in additional regions",
      "description": "Amazon Elastic Compute Cloud (EC2) C8id, M8id, and R8id instances powered by custom Intel Xeon 6 processors feature up to 384 vCPUs, 3TiB of memory, and 22.8TB of NVMe SSD storage and deliver up to 43% higher performance and 3.3x more memory bandwidth compared to previous generation C6id, M6id, and R6id instances. Starting today, C8id and M8id instances are available in Europe (Frankfurt) and Asia Pacific (Tokyo) regions, with M8id also available in Europe (Spain) region. Additionally, R8id instances are now available in Europe (Spain) and Asia Pacific (Tokyo) regions.\n  These instances deliver up to 46% higher performance for I/O intensive database workloads, and up to 30% faster query results for I/O intensive real-time data analytics than previous sixth-generation instances. Additionally, these instances support Instance Bandwidth Configuration, allowing 25% flexible allocation between network and EBS bandwidth, allocating resources optimally for each workload.\n  C8id instances are ideal for compute-intensive workloads such as high-performance web servers, batch processing, distributed analytics, ad serving, video encoding, and gaming servers. M8id instances are well-suited for balanced workloads including application servers, microservices, enterprise applications, and small to medium databases. R8id instances are ideal for memory-intensive workloads such as in-memory databases, real-time big data analytics, large in-memory caches, and scientific computing applications.\n  C8id, M8id and R8id instances are available in US East (N. Virginia, Ohio), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Tokyo) regions. M8id and R8id instances are additionally available in Europe (Spain) region. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information visit the Amazon EC2 instance type page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/c8id-m8id-and-r8id-in-additional-regions/",
      "pubDate": "2026-02-10T18:21:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-df2c20ddea76",
      "title": "Amazon Athena now supports 1-minute reservations and 4 DPU minimum capacity",
      "description": "Amazon Athena now supports 1-minute Capacity Reservations and a lower minimum capacity of 4 Data Processing Units (DPUs) for all reservations. Now, you can get started with less capacity and make more frequent, fine-grained adjustments to match your workload patterns—with no long-term commitments and cost savings up to 95% for short-duration query workloads.\n  Capacity Reservations provides dedicated serverless compute and is ideal for workloads requiring query prioritization and concurrency controls. You pay only for capacity that you reserve and there are no data scanned charges. Reserved capacity works seamlessly with existing Athena queries and workgroups—simply attach workgroups to a reservation and submit queries with no changes in your SQL queries or application code required.\n  To learn more, see the Athena User Guide and Athena pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-athena-one-minute-capacity-reservations/",
      "pubDate": "2026-02-10T16:52:00.000Z",
      "source": "whatsNew",
      "services": [
        "athena"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "athena",
        "support"
      ]
    },
    {
      "id": "aws-news-47906801ca88",
      "title": "Amazon Bedrock adds support for six fully-managed open weights models",
      "description": "Amazon Bedrock now supports six new models spanning frontier reasoning and agentic coding: DeepSeek V3.2, MiniMax M2.1, GLM 4.7, GLM 4.7 Flash, Kimi K2.5, and Qwen3 Coder Next. These six models bring customers access to the most capable open weights models available today, delivering frontier-class performance at significantly lower inference costs. They collectively cover the full spectrum of enterprise AI workloads: DeepSeek V3.2 and Kimi K2.5 push the frontier on reasoning and agentic intelligence, GLM 4.7 and Minimax 2.1 set new standards for autonomous coding with massive output windows, and Qwen3 Coder Next and GLM 4.7 Flash offer lightweight, cost-efficient alternatives purpose-built for production deployment.\n \nThese models on Amazon Bedrock are powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock, provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and provides out-of-the-box compatibility with OpenAI API specifications.\n \nTo learn more and get started, visit Amazon Bedrock console or the service documentation here. To get started with Amazon Bedrock OpenAI API-compatible service endpoints, visit documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-adds-support-six-open-weights-models",
      "pubDate": "2026-02-10T16:02:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "rds",
        "support",
        "new-model"
      ]
    },
    {
      "id": "aws-news-2baacc65d7a9",
      "title": "Amazon OpenSearch Serverless now supports Collection Groups",
      "description": "Amazon OpenSearch Serverless now supports Collection Groups, a new capability that enables you to share OpenSearch Compute Units (OCUs) across collections with different AWS KMS keys. This new capability delivers enhanced cost optimization through a shared compute model that reduces overall OCU expenses while maintaining collection-level security and access controls. Additionally, Collection Groups introduce the ability to specify minimum OCU allocations alongside maximum OCU limits, allowing you to provision compute capacity upfront at startup for more predictable performance.\n  Collection Groups are particularly valuable for multi-tenant workloads where different tenants require data encryption with separate KMS keys while still benefiting from shared compute resources. By grouping collections together, you can optimize OCU utilization across workloads, reduce costs through resource sharing, and maintain the security isolation required by different encryption keys. The minimum OCU setting ensures your collections have guaranteed baseline capacity from the moment they start, eliminating cold start delays and providing consistent performance for latency-sensitive applications.\n  Collection groups are available in all regions where Amazon OpenSearch Serverless is currently available. To learn more about configuring and managing collection groups, visit the Amazon OpenSearch Serverless documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-opensearch-serverless-supports-collection-groups/",
      "pubDate": "2026-02-10T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "opensearch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-cf2d10da92a8",
      "title": "Amazon EKS Auto Mode Announces Enhanced Logging for its Managed Kubernetes Capabilities",
      "description": "Amazon Elastic Kubernetes Service (Amazon EKS) Auto Mode’s managed capabilities can now be configured as log delivery sources using Amazon CloudWatch Vended Logs. This integration enables customers to monitor and troubleshoot their EKS Auto Mode clusters more effectively by automatically collecting logs from Auto Mode’s managed Kubernetes capabilities for compute autoscaling, block storage, load balancing, and pod networking.\n  Customers can configure log delivery for Auto Mode capabilities using CloudWatch APIs or the AWS Console. Each Auto Mode capability can be configured as a CloudWatch Vended Logs delivery source, enabling reliable, secure log delivery with built-in AWS authentication and authorization at a reduced price compared to standard CloudWatch Logs. Customers can deliver these logs to CloudWatch Logs, Amazon S3, or Amazon Kinesis Data Firehose destinations.\n  This feature is available today in all regions where EKS Auto Mode is available. Standard CloudWatch Logs, S3, or Kinesis charges apply depending on the chosen destination.\n  To learn more about EKS Auto Mode logging capabilities, visit the Amazon EKS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-eks-auto-mode-enhanced-logging",
      "pubDate": "2026-02-10T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "eks",
        "kinesis",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "eks",
        "kinesis",
        "cloudwatch",
        "integration"
      ]
    },
    {
      "id": "aws-news-dd23c1677fba",
      "title": "AWS CloudWatch Alarm Mute Rules eliminate alert fatigue",
      "description": "Amazon CloudWatch now supports Alarm Mute Rules, enabling customers to temporarily mute alarm notifications during planned deployments, maintenance windows, and off-hours without compromising monitoring visibility. This new capability helps eliminate alert fatigue while maintaining complete situational awareness across their infrastructure.\n  Alarm Mute Rules transform operational workflows by allowing teams to create one-time or recurring rules that silence notifications for up to 100 individual alarms around deployment calendars, scheduled maintenance activities, or predictable off-hours periods when non-critical alerts become disruptive. Customers can configure actions for OK, ALARM, and INSUFFICIENT_DATA states, and when mute rules expire, any previously muted actions are automatically triggered as long as the alarm remains in the same state it was in when the actions were muted, ensuring critical issues are never overlooked while preventing unnecessary alert fatigue.\n  This eliminates the operational risk of forgotten script-based workarounds and reduces alert noise during planned activities, enabling engineering teams to focus on core business initiatives rather than managing notification fatigue.\n \n\n CloudWatch Alarm Mute Rules is available today in all AWS Regions supporting alarm-level muting.\n \nTo get started, see CloudWatch User Guide for Alarm Mute Rules. You can create mute rules through the Amazon CloudWatch Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-cloudwatch-alarm-muting-rules",
      "pubDate": "2026-02-10T09:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudwatch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-9d4e4d6f3cb9",
      "title": "Amazon EC2 C8gn instances are now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8gn instances, powered by the latest-generation AWS Graviton4 processors, are available in the AWS Region Asia Pacific (Seoul, Melbourne), Canada (Central), Europe (Spain), and AWS GovCloud (US-East, US-West). The new instances provide up to 30% better compute performance than Graviton3-based Amazon EC2 C7gn instances. Amazon EC2 C8gn instances feature the latest 6th generation AWS Nitro Cards, and offer up to 600 Gbps network bandwidth, the highest network bandwidth among network optimized EC2 instances. \n  \n Take advantage of the enhanced networking capabilities of C8gn to scale performance and throughput, while optimizing the cost of running network-intensive workloads such as network virtual appliances, data analytics, CPU-based artificial intelligence and machine learning (AI/ML) inference. \n  \n For increased scalability, C8gn instances offer instance sizes up to 48xlarge, up to 384 GiB of memory, and up to 60 Gbps of bandwidth to Amazon Elastic Block Store (EBS). C8gn instances support Elastic Fabric Adapter (EFA) networking on the 16xlarge, 24xlarge, 48xlarge, metal-24xl, and metal-48xl sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters. \n  \n C8gn instances are available in the following AWS Regions: US East (N. Virginia, Ohio), US West (Oregon, N.California), Europe (Frankfurt, Stockholm, Ireland, London, Spain), Asia Pacific (Singapore, Malaysia, Sydney, Thailand, Mumbai, Seoul, Melbourne), Middle East (UAE), Africa (Cape Town), Canada West (Calgary, Central), AWS GovCloud (US-East, US-West).\n  \n To learn more, see Amazon C8gn Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8gn-instances-additional-regions",
      "pubDate": "2026-02-09T23:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "rds",
        "graviton",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-326540a6a823",
      "title": "Using Amazon SageMaker Unified Studio Identity center (IDC) and IAM-based domains together",
      "description": "In this post, we demonstrate how to access an Amazon SageMaker Unified Studio IDC-based domain with a new IAM-based domain using role reuse and attribute-based access control.",
      "link": "https://aws.amazon.com/blogs/big-data/using-amazon-sagemaker-unified-studio-identity-center-idc-and-iam-based-domains-together/",
      "pubDate": "2026-02-09T22:27:10.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam"
      ]
    },
    {
      "id": "aws-news-4fccc11c5096",
      "title": "Orchestrate end-to-end scalable ETL pipeline with Amazon SageMaker workflows",
      "description": "This post explores how to build and manage a comprehensive extract, transform, and load (ETL) pipeline using SageMaker Unified Studio workflows through a code-based approach. We demonstrate how to use a single, integrated interface to handle all aspects of data processing, from preparation to orchestration, by using AWS services including Amazon EMR, AWS Glue, Amazon Redshift, and Amazon MWAA. This solution streamlines the data pipeline through a single UI.",
      "link": "https://aws.amazon.com/blogs/big-data/orchestrate-end-to-end-scalable-etl-pipeline-with-amazon-sagemaker-workflows/",
      "pubDate": "2026-02-09T22:14:13.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "emr",
        "redshift",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "emr",
        "redshift",
        "glue"
      ]
    },
    {
      "id": "aws-news-9164d1ec8b97",
      "title": "Amazon Neptune Analytics is now available in 7 additional regions",
      "description": "Amazon Neptune Analytics is now available in Middle East (Bahrain), Middle East (UAE), Israel (Tel Aviv), Africa (Cape Town), Canada (Calgary), Asia Pacific (Malaysia), and Europe (Zurich) regions. You can now create and manage Neptune Analytics graphs in these new regions and run advanced graph analytics.\n  Amazon Neptune is a serverless graph database for connected data, improves the accuracy of AI applications, and lowers operational burden and costs. Neptune instantly scales graph workloads removing the need to manage capacity. By modeling data as a graph, Neptune captures context that improves accuracy and explainability of generative AI applications. To make AI application development easier, Neptune offers fully managed GraphRAG with Amazon Bedrock Knowledge Bases, and integrations with Strands AI Agents SDK and popular agentic memory tools. It also easily analyzes tens of billions of relationships across structured and unstructured data within seconds delivering strategic insights. Neptune is the only database and analytics engine that gives you the power of connected data with the enterprise capabilities and value of AWS.\n  To get started, you can create a new Neptune Analytics graphs using the AWS Management Console, or AWS CLI. For more information on pricing and region availability, refer to the Neptune pricing page and AWS Region Table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-neptune-analytics-in-seven-additional-regions",
      "pubDate": "2026-02-09T21:45:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "ga",
        "now-available",
        "integration",
        "new-region"
      ]
    },
    {
      "id": "aws-news-f4c0e3221bd7",
      "title": "AWS HealthOmics introduces a Kiro Power and Kiro IDE extension for bioinformatics workflow development",
      "description": "AWS HealthOmics announces a Kiro Power and Kiro IDE extension to create, run, debug, and optimize HealthOmics workflows faster with AI agent-assisted development. With the HealthOmics extension for Kiro IDE, customers can create, modify, and analyze workflows in domain-specific languages including Nextflow and WDL directly in the Kiro interface. AWS HealthOmics is a HIPAA-eligible service that helps accelerate scientific breakthroughs at scale with fully managed bioinformatics workflows.\n  Kiro Powers is a repository of curated and pre-packaged Model Context Protocol (MCP) servers, steering files, and agent hooks to accelerate specialized software development and deployment use cases. The Kiro Power for HealthOmics packages the HealthOmics MCP server with guidance, giving the Kiro agent expertise in HealthOmics workflow creation and optimization. The HealthOmics Kiro IDE extension provides syntax highlighting, code completion, and troubleshooting guidance, along with HealthOmics engine compatibility checking, performance optimization recommendations, automated run analysis with failure diagnostics, and workflow import/export capabilities.\n  To get started, download and install the HealthOmics Kiro Power from https://kiro.dev/powers/ and HealthOmics Kiro IDE extension from Open VSX Registry.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-healthomics-introduces-kiro-plugin-for-bioinformatics-workflow-development/",
      "pubDate": "2026-02-09T21:03:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": []
    },
    {
      "id": "aws-news-608b6b9419e6",
      "title": "AWS Weekly Roundup: Claude Opus 4.6 in Amazon Bedrock, AWS Builder ID Sign in with Apple, and more (February 9, 2026)",
      "description": "Here are the notable launches and updates from last week that can help you build, scale, and innovate on AWS. Last week’s launches Here are the launches that got my attention this week. Let’s start with news related to compute and networking infrastructure: Introducing Amazon EC2 C8id, M8id, and R8id instances: These new Amazon EC2 […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-claude-opus-4-6-in-amazon-bedrock-aws-builder-id-sign-in-with-apple-and-more-february-9-2026/",
      "pubDate": "2026-02-09T20:42:04.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "nova",
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "nova",
        "ec2",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-422f564cfc67",
      "title": "Automated Reasoning checks rewriting chatbot reference implementation",
      "description": "This blog post dives deeper into the implementation architecture for the Automated Reasoning checks rewriting chatbot.",
      "link": "https://aws.amazon.com/blogs/machine-learning/automated-reasoning-checks-rewriting-chatbot-reference-implementation/",
      "pubDate": "2026-02-09T19:34:05.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "natural-language"
      ],
      "tags": []
    },
    {
      "id": "aws-news-dc88a6fd4ed0",
      "title": "Amazon Redshift now supports allocating extra compute for automatic optimizations",
      "description": "Amazon Redshift now supports allocating extra compute for automatic optimization features, known as autonomics. Database administrators managing Amazon Redshift workloads can now allocate additional resources for their clusters to enable autonomics even during periods of high user activity, eliminating the need to manually schedule optimizations such as Automatic Table Optimization (ATO), Automatic Table Sorting (ATS), Auto Vacuum, and Auto Analyze.\n  This enhancement extends Amazon Redshift's autonomics capabilities to automatically leverage extra compute resources, to run reliably without impacting user workloads. It also includes a cost control feature for provisioned clusters, allowing database administrators to limit the amount of resources available to autonomics. Additionally, the new SYS_AUTOMATIC_OPTIMIZATION system table enhances observability by providing detailed information on autonomics operations for both provisioned clusters and serverless workgroups.\n  This feature is available in all AWS Regions where Amazon Redshift is supported. To learn more, see Allocating extra compute resources for automatic database optimization.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-redshift-allocate-extra-compute-for-automatic-optimizations",
      "pubDate": "2026-02-09T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "redshift"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "redshift",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-5846bfa0757e",
      "title": "Scale LLM fine-tuning with Hugging Face and Amazon SageMaker AI",
      "description": "In this post, we show how this integrated approach transforms enterprise LLM fine-tuning from a complex, resource-intensive challenge into a streamlined, scalable solution for achieving better model performance in domain-specific applications.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scale-llm-fine-tuning-with-hugging-face-and-amazon-sagemaker-ai/",
      "pubDate": "2026-02-09T16:48:46.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "lex"
      ]
    },
    {
      "id": "aws-news-e0de1c85e10d",
      "title": "New Relic transforms productivity with generative AI on AWS",
      "description": "Working with the Generative AI Innovation Center, New Relic NOVA (New Relic Omnipresence Virtual Assistant) evolved from a knowledge assistant into a comprehensive productivity engine. We explore the technical architecture, development journey, and key lessons learned in building an enterprise-grade AI solution that delivers measurable productivity gains at scale.",
      "link": "https://aws.amazon.com/blogs/machine-learning/new-relic-transforms-productivity-with-generative-ai-on-aws/",
      "pubDate": "2026-02-09T16:45:16.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-88d1e4796f36",
      "title": "Accelerate agentic application development with a full-stack starter template for Amazon Bedrock AgentCore",
      "description": "In this post, you will learn how to deploy Fullstack AgentCore Solution Template (FAST) to your Amazon Web Services (AWS) account, understand its architecture, and see how to extend it for your requirements. You will learn how to build your own agent while FAST handles authentication, infrastructure as code (IaC), deployment pipelines, and service integration.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-agentic-application-development-with-a-full-stack-starter-template-for-amazon-bedrock-agentcore/",
      "pubDate": "2026-02-09T16:40:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "integration"
      ]
    },
    {
      "id": "aws-news-bc5baeadbafe",
      "title": "Introducing Multipart Download Support for AWS SDK for .NET Transfer Manager",
      "description": "The new multipart download support in AWS SDK for .NET Transfer Manager improves the performance of downloading large objects from Amazon Simple Storage Service (Amazon S3). Customers are looking for better performance and parallelization of their downloads, especially when working with large files or datasets. The AWS SDK for .NET Transfer Manager (version 4 only) […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-multipart-download-support-for-aws-sdk-for-net-transfer-manager/",
      "pubDate": "2026-02-09T16:27:06.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "support"
      ]
    },
    {
      "id": "aws-news-86cfec91c00f",
      "title": "Agent-to-agent collaboration: Using Amazon Nova 2 Lite and Amazon Nova Act for multi-agent systems",
      "description": "This post walks through how agent-to-agent collaboration on Amazon Bedrock works in practice, using Amazon Nova 2 Lite for planning and Amazon Nova Act for browser interaction, to turn a fragile single-agent setup into a predictable multi-agent system.",
      "link": "https://aws.amazon.com/blogs/machine-learning/agent-to-agent-collaboration-using-amazon-nova-2-lite-and-amazon-nova-act-for-multi-agent-systems/",
      "pubDate": "2026-02-09T16:00:28.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-07ee34afa737",
      "title": "Structured outputs on Amazon Bedrock: Schema-compliant AI responses",
      "description": "Today, we're announcing structured outputs on Amazon Bedrock—a capability that fundamentally transforms how you can obtain validated JSON responses from foundation models through constrained decoding for schema compliance. In this post, we explore the challenges of traditional JSON generation and how structured outputs solves them. We cover the two core mechanisms—JSON Schema output format and strict tool use—along with implementation details, best practices, and practical code examples.",
      "link": "https://aws.amazon.com/blogs/machine-learning/structured-outputs-on-amazon-bedrock-schema-compliant-ai-responses/",
      "pubDate": "2026-02-06T20:12:14.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-a64c5d13fd22",
      "title": "Manage Amazon SageMaker HyperPod clusters using the HyperPod CLI and SDK",
      "description": "In this post, we demonstrate how to use the CLI and the SDK to create and manage SageMaker HyperPod clusters in your AWS account. We walk through a practical example and dive deeper into the user workflow and parameter choices.",
      "link": "https://aws.amazon.com/blogs/machine-learning/manage-amazon-sagemaker-hyperpod-clusters-using-the-hyperpod-cli-and-sdk/",
      "pubDate": "2026-02-06T19:27:45.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-5354a6485a76",
      "title": "Amazon WorkSpaces Secure Browser now supports custom domain",
      "description": "Amazon WorkSpaces Secure Browser now supports custom domains for your WorkSpaces Secure Browser portals, enabling you to configure portal access through your own domain name instead of the default portal URL. This feature provides users with a more integrated experience using a domain that aligns with your organization's branding for each secure browser session.\n  As an administrator you simply add the custom domain in the WorkSpaces Secure browser portal and set up a reverse proxy (for example Amazon CloudFront). Once set up, traffic is routed through your reverse proxy to the portal endpoint, and WorkSpaces Secure Browser automatically redirects users to the configured custom domain after authentication and authorization. Authentication can be via AWS Identity Center or your own Identity Provider (IdP), supporting both IdP-initiated and service provider-initiated flows.\n  This feature is available at no additional cost in 10 AWS Regions, including US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt, London, Ireland), and Asia Pacific (Tokyo, Mumbai, Sydney, Singapore). WorkSpaces Secure Browser offers pay-as-you go pricing.\n  To get started, visit the Amazon WorkSpaces Secure Browser console to configure your custom domain for your WorkSpaces Secure Browser portal. For more information, see the custom domain section in the Amazon WorkSpaces Secure Browser’s documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-workspaces-secure-browser-custom-domains/",
      "pubDate": "2026-02-06T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudfront"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudfront",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-efdc8b897228",
      "title": "Amazon ECS Managed Instances now available in AWS European Sovereign Cloud",
      "description": "Amazon Elastic Container Service (Amazon ECS) Managed Instances is now available in the AWS European Sovereign Cloud. ECS Managed Instances is a fully managed compute option designed to eliminate infrastructure management overhead while giving you access to the full capabilities of Amazon EC2. By offloading infrastructure operations to AWS, you get the application performance you want and the simplicity you need while reducing your total cost of ownership.\n  Managed Instances dynamically scales EC2 instances to match your workload requirements and continuously optimizes task placement to reduce infrastructure costs. It also enhances your security posture through regular security patching initiated every 14 days. You can simply define your task requirements such as the number of vCPUs, memory size, and CPU architecture, and Amazon ECS automatically provisions, configures and operates most optimal EC2 instances within your AWS account using AWS-controlled access. You can also specify desired instance types in Managed Instances Capacity Provider configuration, including GPU-accelerated, network-optimized, and burstable performance, to run your workloads on the instance families you prefer.\n  To get started with ECS Managed Instances, use the AWS Console, Amazon ECS MCP Server, or your favorite infrastructure-as-code tooling to enable it in a new or existing Amazon ECS cluster. You will be charged for the management of compute provisioned, in addition to your regular Amazon EC2 costs. To learn more about ECS Managed Instances, visit the feature page, documentation, and AWS News launch blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/ecs-mi-european-sovereign-cloud",
      "pubDate": "2026-02-06T17:10:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "ecs"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "ecs",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-43e867f93eaa",
      "title": "Amazon Bedrock AgentCore Browser now supports browser profiles",
      "description": "Amazon Bedrock AgentCore Browser now supports browser profiles, enabling you to reuse authentication state across multiple browser sessions without repeated login flows. This feature reduces session setup time from minutes to tens of seconds for enterprise customers processing hundreds or thousands of automated browser sessions daily.\n \nBrowser profiles persist and reuse browser data including cookies and local storage across multiple sessions. You authenticate to a website once and save the session to a browser profile. When you start a new session using that saved profile, your authentication state is preserved, and you remain logged in. This enables agents to perform tasks on authenticated websites without manual login intervention. You can choose flexible session modes for both read-only and persistent operations, enabling parallel processing where multiple sessions use the same profile simultaneously.\n \nThis feature is available in all 14 AWS Regions where Amazon Bedrock AgentCore Browser is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), Asia Pacific (Seoul), and Canada (Central).\n \nTo learn more, visit the Browser Profiles documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-agentcore-browser-profiles",
      "pubDate": "2026-02-06T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-acb6f4f76a9c",
      "title": "Building fault-tolerant applications with AWS Lambda durable functions",
      "description": "Business applications often coordinate multiple steps that need to run reliably or wait for extended periods, such as customer onboarding, payment processing, or orchestrating large language model inference. These critical processes require completion despite temporary disruptions or system failures. Developers currently spend significant time implementing mechanisms to track progress, handle failures, and manage resources when […]",
      "link": "https://aws.amazon.com/blogs/compute/building-fault-tolerant-long-running-application-with-aws-lambda-durable-functions/",
      "pubDate": "2026-02-06T16:54:39.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-ffce1b1c279a",
      "title": "Evaluate generative AI models with an Amazon Nova rubric-based LLM judge on Amazon SageMaker AI (Part 2)",
      "description": "In this post, we explore the Amazon Nova rubric-based judge feature: what a rubric-based judge is, how the judge is trained, what metrics to consider, and how to calibrate the judge. We chare notebook code of the Amazon Nova rubric-based LLM-as-a-judge methodology to evaluate and compare the outputs of two different LLMs using SageMaker training jobs.",
      "link": "https://aws.amazon.com/blogs/machine-learning/evaluate-generative-ai-models-with-an-amazon-nova-rubric-based-llm-judge-on-amazon-sagemaker-ai-part-2/",
      "pubDate": "2026-02-06T16:29:45.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-29ddb9057340",
      "title": "AWS Config now supports 30 new resource types",
      "description": "AWS Config now supports 30 additional AWS resource types across key services including Amazon EKS, Amazon Q, and AWS IoT. This expansion provides greater coverage over your AWS environment, enabling you to more effectively discover, assess, audit, and remediate an even broader range of resources.\n  With this launch, if you have enabled recording for all resource types, then AWS Config will automatically track these new additions. The newly supported resource types are also available in Config rules and Config aggregators.\n  You can now use AWS Config to monitor the following newly supported resource types in all AWS Regions where the supported resources are available:\n  Resource Types:\n  \n \n \n  \nAWS::ApplicationSignals::ServiceLevelObjective \n   AWS::IoT::SoftwarePackage \n  \nAWS::ARCZonalShift::AutoshiftObserverNotificationStatus      \n   AWS::IoT::TopicRule \n  \nAWS::B2BI::Transformer \n   AWS::IoTWireless::Destination \n  \nAWS::CE::CostCategory \n   AWS::IoTWireless::DeviceProfile \n  \nAWS::CleanRooms::ConfiguredTable \n   AWS::IoTWireless::NetworkAnalyzerConfiguration  \n  \nAWS::CleanRooms::Membership \n   AWS::IoTWireless::TaskDefinition \n  \nAWS::CodeArtifact::PackageGroup \n   AWS::IoTWireless::WirelessGateway \n  \nAWS::Connect::Prompt \n   AWS::Kinesis::ResourcePolicy \n  \nAWS::EKS::Nodegroup \n   AWS::PCAConnectorSCEP::Connector \n  \nAWS::GameLift::MatchmakingRuleSet \n   AWS::QBusiness::Application \n  \nAWS::GameLift::Script \n   AWS::QuickSight::DataSet \n  \nAWS::Glue::Crawler \n   AWS::QuickSight::Dashboard \n  \nAWS::InternetMonitor::Monitor \n   AWS::Route53::DNSSEC \n  \nAWS::IoT::BillingGroup \n   AWS::SSM::PatchBaseline \n  \nAWS::IoT::ResourceSpecificLogging \n   AWS::Transfer::User",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-config-new-resource-types",
      "pubDate": "2026-02-06T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "eks",
        "kinesis",
        "glue",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "eks",
        "kinesis",
        "glue",
        "quicksight",
        "launch",
        "ga",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-6515e8f8245f",
      "title": "Amazon Connect Cases now supports CSV uploads to map related field options",
      "description": "Amazon Connect Cases now supports using a CSV file to define which field options appear based on other field values, making it easier to configure complex field relationships on case templates. Instead of manually defining valid options — such as applicable defect types based on product category — admins can upload a file to define these relationships at scale, reducing onboarding effort and configuration time.\n  Amazon Connect Cases is available in the following AWS regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town) AWS regions. To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-cases-csv-related-field-options",
      "pubDate": "2026-02-06T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-244a6a9a1248",
      "title": "AWS Network Firewall announces new price reductions",
      "description": "AWS Network Firewall has introduced two pricing improvements for customers. The service has added the hourly and data processing discounts on NAT Gateways that are service-chained with Network Firewall secondary endpoints. Additionally, AWS Network Firewall has removed additional data processing charges for Advanced Inspection, which enables Transport Layer Security (TLS) inspection of encrypted network traffic.\n \nPreviously, NAT Gateway discounts were limited to primary Network Firewall endpoints, and customers paid additional data processing charges when using Advanced Inspection for TLS inspection in select AWS regions. With these improvements, the NAT Gateway discounts now apply when service-chained with both primary and secondary firewall endpoints. Customers also no longer pay the additional data processing charge for Advanced Inspection that ranged from $0.001/GB to $0.009/GB in 13 AWS regions: Middle East (Bahrain), Asia Pacific (Hong Kong), Asia Pacific (Tokyo), Asia Pacific (Osaka), Asia Pacific (Mumbai), EU (Milan), South America (São Paulo), US West (N. California), Africa (Cape Town), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), and Asia Pacific (Melbourne).\n \nThese changes help to reduce costs for architectures that use Network Firewall's multiple VPC endpoint capability and TLS inspection features. Multiple VPC endpoints allow you to connect 50 VPCs per Availability Zone to a single Network Firewall, helping to reduce operational complexity and lower costs as you protect more VPCs. By removing additional data processing charges when using Advanced Inspection, customers can now implement TLS inspection more cost-effectively across their network security architecture.\n \nThese pricing improvements are available in all AWS regions where Network Firewall is offered and are applied automatically to eligible configurations. No action is required from customers.\n \nTo learn more, see AWS Network Firewall pricing and the AWS Network Firewall service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-network-firewall-new-price-reduction/",
      "pubDate": "2026-02-06T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-0b5861fc727a",
      "title": "Amazon ECR now supports additional metrics for monitoring repositories",
      "description": "Amazon Elastic Container Registry (ECR) now enables customers to monitor additional repository metrics through Amazon CloudWatch. These new metrics, RepositoryCount and ImagesPerRepositoryCount, help customers identify growth trends of images by repository as well as understand their trends for creating and deleting repositories. With these insights, customers can easily identify anomalous behavior and alert themselves when their usage approaches the service quota.\n  These metrics are available in all AWS commercial and AWS GovCloud (US) Regions at no additional cost. To learn more about Amazon ECR repository metrics, please review our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ecr-additional-repository-metrics/",
      "pubDate": "2026-02-06T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudwatch",
        "support"
      ]
    },
    {
      "id": "aws-news-792a0c53071f",
      "title": "How Associa transforms document classification with the GenAI IDP Accelerator and Amazon Bedrock",
      "description": "Associa collaborated with the AWS Generative AI Innovation Center to build a generative AI-powered document classification system aligning with Associa’s long-term vision of using generative AI to achieve operational efficiencies in document management. The solution automatically categorizes incoming documents with high accuracy, processes documents efficiently, and provides substantial cost savings while maintaining operational excellence. The document classification system, developed using the Generative AI Intelligent Document Processing (GenAI IDP) Accelerator, is designed to integrate seamlessly into existing workflows. It revolutionizes how employees interact with document management systems by reducing the time spent on manual classification tasks.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-associa-transforms-document-classification-with-the-genai-idp-accelerator-and-amazon-bedrock/",
      "pubDate": "2026-02-05T20:41:52.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-4c444fe2b470",
      "title": "A practical guide to Amazon Nova Multimodal Embeddings",
      "description": "In this post, you will learn how to configure and use Amazon Nova Multimodal Embeddings for media asset search systems, product discovery experiences, and document retrieval applications.",
      "link": "https://aws.amazon.com/blogs/machine-learning/a-practical-guide-to-amazon-nova-multimodal-embeddings/",
      "pubDate": "2026-02-05T20:35:34.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-eb570f9242d7",
      "title": "Reduce Mean Time to Resolution with an observability agent",
      "description": "In this post, we present an observability agent using OpenSearch Service and Amazon Bedrock AgentCore that can help surface root cause and get insights faster, handle multiple query-correlation cycles, and ultimately reduce MTTR even further.",
      "link": "https://aws.amazon.com/blogs/big-data/reduce-mean-time-to-resolution-with-an-observability-agent/",
      "pubDate": "2026-02-05T19:48:33.000Z",
      "source": "bigDataBlog",
      "services": [
        "bedrock",
        "agentcore",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-6b38347fc46f",
      "title": "Amazon OpenSearch Ingestion 101: Set CloudWatch alarms for key metrics",
      "description": "This post provides an in-depth look at setting up Amazon CloudWatch alarms for OpenSearch Ingestion pipelines. It goes beyond our recommended alarms to help identify bottlenecks in the pipeline, whether that’s in the sink, the OpenSearch clusters data is being sent to, the processors, or the pipeline not pulling or accepting enough from the source. This post will help you proactively monitor and troubleshoot your OpenSearch Ingestion pipelines.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-opensearch-ingestion-service-101-set-cloudwatch-alarms-for-key-metrics/",
      "pubDate": "2026-02-05T19:47:26.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch ingestion",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "opensearch",
        "opensearch ingestion",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-093fbdc9670f",
      "title": "Amazon EC2 G6e instances now available in the UAE region",
      "description": "Starting today, the Amazon EC2 G6e instances powered by NVIDIA L40S Tensor Core GPUs is now available in Middle East (UAE) Region. G6e instances can be used for a wide range of machine learning and spatial computing use cases.\n \nCustomers can use G6e instances to deploy large language models (LLMs) and diffusion models for generating images, video, and audio. Additionally, the G6e instances will unlock customers’ ability to create larger, more immersive 3D simulations and digital twins for spatial computing workloads. G6e instances feature up to 8 NVIDIA L40S Tensor Core GPUs with 48 GB of memory per GPU and third generation AMD EPYC processors. They also support up to 192 vCPUs, up to 400 Gbps of network bandwidth, up to 1.536 TB of system memory, and up to 7.6 TB of local NVMe SSD storage. \n  Amazon EC2 G6e instances are available today in the AWS US East (N. Virginia, Ohio), US West (Oregon), Asia Pacific (Tokyo, Seoul), Middle East (UAE) and Europe (Frankfurt, Spain, Stockholm) Regions. Customers can purchase G6e instances as On-Demand Instances, Reserved Instances, Spot Instances, or as part of Savings Plans.\n  To get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit the G6e instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-g6e-instances-uae-region/",
      "pubDate": "2026-02-05T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b8494c694c0a",
      "title": "AWS Builder ID now supports Sign in with Apple",
      "description": "AWS Builder ID, your profile for accessing AWS applications including AWS Builder Center, AWS Training and Certification, AWS re:Post, AWS Startups, and Kiro, now supports Sign in with Apple as a social login provider. This expansion of sign-in options builds on the existing Sign in with Google capability, providing Apple users with a streamlined way to access AWS resources without managing separate credentials on AWS.\n \n  \nWith Sign in with Apple integration, developers and builders can now enjoy access to their AWS Builder ID profile using their Apple Account credentials. This enhancement eliminates password management complexity, reduces forgotten password issues, and provides a frictionless experience for both new user registration and returning user sign-ins. Whether you're accessing development resources in AWS Builder Center, enrolling in certification programs, participating in community discussions on AWS re:Post, exploring startup resources, or using Kiro to code your next app, your Apple Account now serves as a secure gateway to your builder AWS journey. \n \n  \nTo learn more about AWS Builder ID and get started with Sign in with Apple, visit the AWS Builder ID documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-builder-id-sign-in-apple",
      "pubDate": "2026-02-05T19:20:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "ga",
        "enhancement",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-911bc5154c64",
      "title": "Amazon WorkSpaces launches Graphics G6, Gr6, and G6f bundles",
      "description": "Today, Amazon WorkSpaces announces the availability of 12 new Graphics G6, Gr6, and G6f WorkSpaces bundles built on the Amazon EC2 G6 family. These bundles expand customers’ options for running graphics-intensive and GPU-accelerated workloads, and are available on both Amazon WorkSpaces Personal and Amazon WorkSpaces Core.\n \nThe new bundles are designed to support a wide range of performance, memory, and cost requirements: G6 bundles include five sizes with 1:4 vCPU-to-memory configurations, suitable for graphic design, CAD/CAM, and ML model training workloads. Gr6 bundles include two sizes with memory-optimized 1:8 vCPU-to-memory configurations, designed for higher-memory workloads such as 3D rendering, seismic visualization, and GIS processing. G6f bundles include five sizes and offer fractional GPU options (1/8, 1/4, and 1/2 GPU), enabling cost-effective access to GPU acceleration for workloads that do not require a full GPU. All Graphics G6, Gr6, and G6f WorkSpaces support Windows Server 2022 and allow customers to bring their own Windows desktop licenses for Windows 11.\n \nThese bundles are available in 13 AWS Regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Paris, Frankfurt, London), Asia Pacific (Tokyo, Mumbai, Sydney, Seoul), South America (São Paulo), and AWS GovCloud (US-West and US-East).\n \nTo get started, create a Graphics G6, Gr6, or G6f WorkSpace using the Amazon WorkSpaces console. For pay-as-you-go pricing details, see the Amazon WorkSpaces Pricing Page and the Amazon WorkSpaces Core Pricing Page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-workspaces-personal-core-graphics-g6-gr6-g6f-bundles/",
      "pubDate": "2026-02-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "ec2",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-639bbb72d5dd",
      "title": "Amazon EC2 I7ie instances now available in AWS Canada (Central)",
      "description": "AWS is announcing Amazon EC2 I7ie instances are now available in AWS Canada (Central) regions. Designed for large storage I/O intensive workloads, I7ie instances are powered by 5th Gen Intel Xeon Processors with an all-core turbo frequency of 3.2 GHz, offering up to 40% better compute performance and 20% better price performance over existing I3en instances. I7ie instances offer up to 120TB local NVMe storage density (highest in the cloud) for storage optimized instances and offer up to twice as many vCPUs and memory compared to prior generation instances. Powered by 3rd generation AWS Nitro SSDs, I7ie instances deliver up to 65% better real-time storage performance, up to 50% lower storage I/O latency, and 65% lower storage I/O latency variability compared to I3en instances.\n  I7ie are high density storage optimized instances, ideal for workloads requiring fast local storage with high random read/write performance at very low latency consistency to access large data sets. These instances are available in 9 different virtual sizes and deliver up to 100Gbps of network bandwidth and 60Gbps of bandwidth for Amazon Elastic Block Store (EBS).\n  To learn more, visit the I7ie instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-i7ie-instances-available-aws-canada/",
      "pubDate": "2026-02-05T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-c39359ee94ef",
      "title": "AWS Glue launches native REST API connector for universal data integration",
      "description": "AWS Glue now offers a native REST-based connector that enables customers to easily read data from any source with a REST-based API. Customers can now create custom connectors to any REST-enabled data source and seamlessly integrate that data into their AWS Glue ETL (Extract, Transform, and Load) jobs. This capability extends AWS Glue's existing connectivity to 100+ non-AWS data sources through 60+ native connectors and additional options on AWS Marketplace.\n  Previously, connecting to proprietary systems or emerging platforms required customers to build custom connectors by providing specialized JARs with the necessary libraries. The new native REST API connector eliminates this complexity, making it easier to integrate data from any REST-enabled source. It reduces operational overhead by eliminating the need to install, update, or manage custom libraries, freeing teams from maintenance burdens. The connector also enhances flexibility, enabling organizations to quickly adapt to new data sources as business needs evolve. It also streamlines ETL management by allowing data engineers to focus on data transformation and business logic rather than spending time building and maintaining connector infrastructure.\n  The AWS Glue REST API connector is available in all AWS commercial regions where AWS Glue is available.\n  You can start using the AWS Glue REST API connector using AWS Glue APIs, AWS Command Line Interface (CLI), or AWS Software Development Kit (SDK). To get started, see AWS Glue documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-glue-rest-api-connector",
      "pubDate": "2026-02-05T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "glue",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "glue",
        "organizations",
        "launch",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-22acca8edad5",
      "title": "Amazon EC2 High Memory U7i-6TB instances now available in AWS GovCloud (US-West)",
      "description": "Amazon EC2 High Memory U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in AWS GovCloud (US-West). U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-u7i-6tb-instances-available/",
      "pubDate": "2026-02-05T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-3d65b6979e0c",
      "title": "Amazon EC2 capacity blocks for ML can be shared across multiple accounts",
      "description": "Amazon Web Services (AWS) is announcing the general availability of cross-account sharing for Amazon EC2 Capacity Blocks for ML. This capability allows organizations to share reserved GPU capacity across AWS accounts using AWS Resource Access Manager (RAM), helping optimize utilization and reduce costs.\n \nOrganizations can now purchase Capacity Blocks and provision them across multiple accounts, allowing different workloads to access a pool of reserved capacity at no additional cost. This capability helps teams coordinate ML infrastructure investments and keeps reserved GPU capacity in continuous use across different workloads.\n \nThis feature is available for all Instance Capacity Blocks in AWS Regions where EC2 Capacity Blocks for ML are offered. For a complete list of supported regions, refer to Capacity Blocks Supported Regions documentation. \n \nTo get started, create a Resource Share through AWS Resource Access Manager, add your Capacity Blocks for ML resources, and specify the target accounts you wish to share with. For more details, please refer to the Capacity Block Guide",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-capacity-blocks-multiple-accounts",
      "pubDate": "2026-02-05T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-c520cba1d654",
      "title": "Claude Opus 4.6 now available in Amazon Bedrock",
      "description": "Starting today, Amazon Bedrock supports Claude Opus 4.6. According to Anthropic, Opus 4.6 is their most intelligent model and the world's best model for coding, enterprise agents, and professional work. Claude Opus 4.6 brings advanced capabilities to Amazon Bedrock customers, including industry-leading performance for agentic tasks, complex coding projects, and enterprise-grade workflows that require deep reasoning and reliability.\n  Claude Opus 4.6 excels across use cases that require sophisticated reasoning and multi-step orchestration. For agentic workflows, it manages complex tasks across dozens of tools with industry-leading reliability, proactively spinning up subagents and working with less oversight. Developers can leverage Opus 4.6’s coding capabilities for long-horizon projects, complex implementations, and large-scale codebases—handling the full lifecycle from requirements gathering to implementation and maintenance. Enterprise teams can use the model to power end-to-end workflows with professional polish, including financial analysis that surfaces insights requiring days of manual compilation, cybersecurity applications that catch subtle attack patterns, and computer use workflows that move data between applications. The model supports both 200K and 1M context tokens (preview), enabling processing of extensive documents and codebases.\n  Claude Opus 4.6 is now available in Amazon Bedrock. For the full list of available regions, refer to the documentation. To learn more and get started with the model in Amazon Bedrock, read the About Amazon blog and visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/2/claude-opus-4.6-available-amazon-bedrock/",
      "pubDate": "2026-02-05T09:59:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "preview",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-52c73c6767c9",
      "title": "Amazon EC2 C8id, M8id, and R8id instances with up to 22.8 TB local NVMe storage are generally available",
      "description": "AWS launches Amazon EC2 C8id, M8id, and R8id instances backed by NVMe-based SSD block-level instance storage physically connected to the host server. These instances offer 3 times more vCPUs, memory, and local storage with up to 22.8TB of local NVMe-backed SSD block-level storage.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-ec2-c8id-m8id-and-r8id-instances-with-up-to-22-8-tb-local-nvme-storage-are-generally-available/",
      "pubDate": "2026-02-04T22:31:56.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "launch",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-76536849a1c8",
      "title": "AWS Batch now supports unmanaged compute environments for Amazon EKS",
      "description": "AWS Batch now extends its job scheduling capabilities to unmanaged compute environments on Amazon EKS. With unmanaged EKS compute environments, you can leverage AWS Batch's job orchestration while maintaining full control over your Kubernetes infrastructure for security, compliance, or operational requirements.\n  With this capability, you can create unmanaged compute environments through CreateComputeEnvironment API and AWS Batch console by selecting your existing EKS cluster and specifying a Kubernetes namespace, then associate your EKS nodes with the compute environment using kubectl labeling.\n  AWS Batch supports developers, scientists, and engineers in running efficient batch processing for ML model training, simulations, and analysis at any scale. Unmanaged compute environments on Amazon EKS are available today in all AWS regions where AWS Batch is available. For more information, see the AWS Batch User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-batch-on-eks-unmanaged-compute-environments",
      "pubDate": "2026-02-04T20:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-bffd31a2575d",
      "title": "Structured outputs now available in Amazon Bedrock",
      "description": "Amazon Bedrock now supports structured outputs, a capability that provides consistent, machine-readable responses from foundation models that adhere to your defined JSON schemas. Instead of prompting for valid JSON and adding extra checks in your application, you can specify the format you want and receive responses that match it—making production workflows more predictable and resilient.\n  Structured outputs helps with common production tasks such as extracting key fields and powering workflows that use APIs or tools, where small formatting errors can break downstream systems. By ensuring schema compliance, it reduces the need for custom validation logic and lowers operational overhead through fewer failed requests and retries—so you can confidently deploy AI applications that require predictable, machine-readable outputs. You can use structured outputs in two ways: define a JSON schema that describes the response format you want, or use strict tool definitions to ensure a model’s tool calls match your specifications.\n  Structured outputs is generally available for Anthropic Claude 4.5 models and select open-weight models across the Converse, ConverseStream, InvokeModel, and InvokeModelWithResponseStream APIs in all commercial AWS Regions where Amazon Bedrock is supported. To learn more about structured outputs and the supported models, visit the Amazon Bedrock documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/structured-outputs-available-amazon-bedrock/",
      "pubDate": "2026-02-04T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "generally-available",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-d7fcc4742b73",
      "title": "Amazon EC2 G7e instances now available in US West (Oregon) region",
      "description": "Starting today, Amazon EC2 G7e instances accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs are now available in US West (Oregon) region. G7e instances offer up to 2.3x inference performance compared to G6e.\n \nCustomers can use G7e instances to deploy large language models (LLMs), agentic AI models, multimodal generative AI models, and physical AI models. G7e instances offer the highest performance for spatial computing workloads as well as workloads that require both graphics and AI processing capabilities. G7e instances feature up to 8 NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, with 96 GB of memory per GPU, and 5th Generation Intel Xeon processors. They support up to 192 virtual CPUs (vCPUs) and up to 1600 Gbps of networking bandwidth. G7e instances support NVIDIA GPUDirect Peer to Peer (P2P) that boosts performance for multi-GPU workloads. Multi-GPU G7e instances also support NVIDIA GPUDirect Remote Direct Memory Access (RDMA) with EFA in EC2 UltraClusters, reducing latency for small-scale multi-node workloads.\n \nYou can use G7e instances for Amazon EC2 in the following AWS Regions: US West (Oregon), US East (N. Virginia) and US East (Ohio). You can purchase G7e instances as On-Demand Instances, Spot Instances, or as part of Savings Plans.\n \nTo get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit G7e instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-g7e-instances-oregon-region/",
      "pubDate": "2026-02-04T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-583e5c06e6da",
      "title": "Cartesia Sonic 3 text-to-speech model is now available on Amazon SageMaker JumpStart",
      "description": "Cartesia’s Sonic 3 model is now available in Amazon SageMaker JumpStart, expanding the portfolio of foundation models available to AWS customers. Sonic 3 is Cartesia's latest state space model (SSM) for streaming text-to-speech (TTS), delivering high naturalness, accurate transcript following, and industry-leading latency with fine-grained control over volume, speed, and emotion.\n \nSonic 3 supports 42 languages and provides advanced controllability through API parameters and SSML tags for volume, speed, and emotion adjustments. The model includes natural laughter support, stable voices optimized for voice agents, and emotive voices for expressive characters. With sub-100ms latency, Sonic 3 enables real-time conversational AI that captures human speech nuances including emotions and tonal shifts.\n  With SageMaker JumpStart, customers can deploy Sonic 3 with just a few clicks to address their voice AI use cases. To get started with this model, navigate to the SageMaker JumpStart model catalog in the SageMaker Studio or use the SageMaker Python SDK to deploy the model to your AWS account. For more information about deploying and using foundation models in SageMaker JumpStart, see the Amazon SageMaker JumpStart documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/cartesia-sonic-3-on-sagemaker-jumpstart",
      "pubDate": "2026-02-04T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-1a266f7162f6",
      "title": "Amazon ECS adds Network Load Balancer support for Linear and Canary deployments",
      "description": "Amazon Elastic Container Service (Amazon ECS) announces native support for linear and canary deployment strategies for ECS services using Network Load Balancers (NLB). Now, applications that commonly use NLB, such as those requiring TCP/UDP-based connections, low latency, long-lived connections, or static IP addresses, can take advantage of managed, incremental traffic shifting natively from ECS when rolling out updates.\n \nWith this launch, ECS customers using NLB can shift traffic in a controlled manner during deployments, such as moving traffic in increments or starting with a small percentage to validate changes before completing a rollout. These deployment strategies provide additional confidence during updates by allowing teams to observe application behavior at each traffic-shift step, and integrate with Amazon CloudWatch alarms to automatically stop or roll back deployments if issues are detected. This is especially valuable for workloads running behind an NLB, such as online gaming backends, financial transaction systems, and real-time messaging services.\n \nTo get started, select your NLB target groups, listener, and preferred deployment strategy in the ECS service configuration using the AWS Management Console, AWS CLI, or Infrastructure-as-Code tools. This can be enabled for both new and existing ECS services in all AWS commercial and AWS GovCloud (US) Regions. For more information, see the documentation for Amazon ECS linear deployments and Amazon ECS canary deployments.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ecs-nlb-linear-canary-deployments",
      "pubDate": "2026-02-04T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ecs",
        "cloudwatch",
        "launch",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-c38979a812e0",
      "title": "Apache Spark lineage now available in Amazon SageMaker Unified Studio for IDC based domains",
      "description": "Amazon SageMaker announces general availability of Data Lineage for Apache Spark jobs executed on Amazon EMR and AWS Glue in SageMaker Unified Studio for IDC based domains. Data Lineage provides you with the information you need to identify the root cause of complex issues and understand the impact of changes.\n  This feature supports lineage capture of schema and transformations of data assets and columns from Spark executions in EMR-EC2, EMR-Serverless, EMR-EKS, and AWS Glue. You can then explore this lineage visually as a graph in SageMaker Unified Studio or query it using APIs. You can also use lineage to compare transformations across Spark job's history.\n  Spark lineage is available in all existing SageMaker Unified Studio regions. For detailed information on how to get started with lineage using these new features, refer to the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/apache-spark-lineage-amazon-sageMaker-unified-studio",
      "pubDate": "2026-02-04T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "glue",
        "now-available",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-fe5f77e82b59",
      "title": "Introducing Amazon EC2 C8id, M8id, and R8id instances",
      "description": "AWS is announcing the general availability of new Amazon EC2 C8id, M8id, and R8id instances powered by custom Intel Xeon 6 processors. These instances deliver up to 43% higher performance and 3.3x more memory bandwidth compared to previous generation C6id, M6id, and R6id instances.\n  C8id, M8id, and R8id instances offer up to 384 vCPUs, 3TiB of memory, and 22.8TB of NVMe SSD storage, 3x more than previous generation instances. These instances deliver up to 46% higher performance for I/O intensive database workloads, and up to 30% faster query results for I/O intensive real-time data analytics than previous sixth-generation instances. Additionally, these instances support Instance Bandwidth Configuration, allowing 25% flexible allocation between network and EBS bandwidth, allocating resources optimally for each workload.\n  C8id instances are ideal for compute-intensive workloads such as high-performance web servers, batch processing, distributed analytics, ad serving, video encoding, and gaming servers. M8id instances are well-suited for balanced workloads including application servers, microservices, enterprise applications, and small to medium databases. R8id instances are ideal for memory-intensive workloads such as in-memory databases, real-time big data analytics, large in-memory caches, and scientific computing applications.\n  C8id, M8id and R8id instances are available in US East (N. Virginia), US East (Ohio), and US West (Oregon). R8id instances are additionally available in Europe (Frankfurt). Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information visit the Amazon EC2 instance type page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8id-m8id-r8id-instances/",
      "pubDate": "2026-02-04T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-c64424ec98ad",
      "title": "Amazon EC2 and VPC now display related resources for security groups",
      "description": "Amazon Web Services (AWS) is announcing the general availability of the \"Related resources\" tab for security groups in the Amazon EC2 and VPC consoles. This new feature provides customers with a consolidated view of all resources that depend on a specific security group, eliminating the need to manually check multiple services before making configuration changes. Security groups act as virtual firewalls that control inbound and outbound traffic for AWS resources, and understanding their dependencies is critical for maintaining secure and stable infrastructure.\n  Previously, customers managing complex security group configurations had to navigate through multiple AWS services individually to identify dependencies before modifying or deleting security groups. This manual process required checking EC2 instances, Elastic Network Interfaces, ElastiCache clusters, RDS databases, and other services one by one, making it time-consuming and error-prone. The \"Related resources\" tab streamlines this workflow by displaying all dependent resources in a single location, enabling customers to quickly assess the impact of proposed changes and make informed decisions with confidence. This enhancement is beneficial for organizations managing large-scale deployments where security groups may be attached to dozens or hundreds of resources across different services.\n  This feature is now available in all AWS commercial regions at no additional cost.\n  To learn more about managing security groups and viewing the \"Related resources\" tab in the Amazon EC2 and VPC consoles, see the Amazon EC2 User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-console-related-resources-generally-available",
      "pubDate": "2026-02-04T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "ec2",
        "rds",
        "organizations",
        "ga",
        "now-available",
        "new-feature",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-beef4a3ab9fb",
      "title": "Amazon EKS simplifies providing IAM permissions to EKS add-ons in AWS GovCloud (US) Regions",
      "description": "Amazon Elastic Kubernetes Service (EKS) now offers a direct integration between EKS add-ons and EKS Pod Identity in AWS GovCloud (US) Regions, streamlining the lifecycle management process for critical cluster operational software that needs to interact with AWS services outside the cluster.\n  EKS add-ons that enable integration with underlying AWS resources need IAM permissions to interact with AWS services. EKS Pod Identities simplify how Kubernetes applications obtain AWS IAM permissions. With today's launch, you can directly manage EKS Pod Identities using EKS add-ons operations through the EKS console, CLI, API, eksctl, and IAC tools like AWS CloudFormation, simplifying usage of Pod Identities for EKS add-ons. This integration expands the selection of Pod Identity compatible EKS add-ons available for installation through the EKS console during cluster creation.\n  EKS add-ons integration with Pod Identities is generally available in AWS GovCloud (US-East) and AWS GovCloud (US-West) Regions. To get started, see the EKS user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-eks-simplifies-iam-permissions-eks-addons",
      "pubDate": "2026-02-04T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "cloudformation",
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks",
        "cloudformation",
        "iam",
        "launch",
        "generally-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-579c56d79c87",
      "title": "Mastering millisecond latency and millions of events: The event-driven architecture behind the Amazon Key Suite",
      "description": "In this post, we explore how the Amazon Key team used Amazon EventBridge to modernize their architecture, transforming a tightly coupled monolithic system into a resilient, event-driven solution. We explore the technical challenges we faced, our implementation approach, and the architectural patterns that helped us achieve improved reliability and scalability. The post covers our solutions for managing event schemas at scale, handling multiple service integrations efficiently, and building an extensible architecture that accommodates future growth.",
      "link": "https://aws.amazon.com/blogs/architecture/mastering-millisecond-latency-and-millions-of-events-the-event-driven-architecture-behind-the-amazon-key-suite/",
      "pubDate": "2026-02-04T15:53:39.000Z",
      "source": "architectureBlog",
      "services": [
        "eventbridge"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "eventbridge",
        "integration"
      ]
    },
    {
      "id": "aws-news-aead7f5f943e",
      "title": "Amazon Redshift now supports autonomics for multi-cluster environments",
      "description": "Amazon Redshift now supports autonomics—automatic optimization features—for multi-cluster environments. Database administrators managing distributed Amazon Redshift workloads can now benefit from autonomics that work intelligently across multiple warehouses, eliminating manual performance tuning across consumer clusters.\n  This launch extends Amazon Redshift's autonomics capabilities, including Automatic Table Optimization (ATO), Automatic Table Sorting (ATS), Auto Vacuum, and Auto Analyze, to consider query patterns from all consumer clusters when managing table layouts and maintenance operations. Organizations where multiple business units access shared data can benefit from holistic optimization that considers all workload patterns, reducing manual optimization processes. This launch also includes a denylist feature, allowing you to exclude specific endpoints or AWS accounts from influencing optimization decisions—particularly useful for cross-organizational data sharing scenarios. These enhanced autonomics features are available at no additional cost for Amazon Redshift customers.\n  This feature is available in all AWS Regions that support Amazon Redshift. To learn more, see the Amazon Redshift Management Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-redshift-autonomics-for-multi-cluster",
      "pubDate": "2026-02-04T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "redshift",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "redshift",
        "organizations",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-b99ec838c4f5",
      "title": "AWS Batch now provides Array Job Status Summary in ListJobs API",
      "description": "AWS Batch now includes a status summary for Array Jobs in the ListJobs API response, giving you immediate visibility into the distribution of child job statuses without additional API calls. This enhancement helps you monitor large-scale workloads more efficiently.\n  When you call the ListJobs API for Array Jobs, the response now includes a statusSummary field that shows the count of child jobs in each state: SUBMITTED, PENDING, RUNNABLE, STARTING, RUNNING, SUCCEEDED, and FAILED. Previously, statusSummary field was only available in the response of DescribeJobs API call. Using the new field you can now monitor the progress of multiple array jobs in your queue with a single API call.. The response also includes a statusSummaryLastUpdatedAt timestamp, allowing you to assess the freshness of the status information. This transparency helps you make informed decisions about your workload management and troubleshooting.\n  This feature is particularly valuable for high-scale batch processing workloads in financial services, automotive, and other industries where monitoring thousands of parallel jobs is critical for operational visibility. Available today in all AWS Regions where AWS Batch is available. For more information, see the ListJobs API page in AWS Batch API Reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-batch-array-job-status-summary/",
      "pubDate": "2026-02-03T22:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-2d2cff21bbac",
      "title": "Amazon DynamoDB global tables now support replication across multiple AWS accounts",
      "description": "Amazon DynamoDB global tables now support replication across multiple AWS accounts. DynamoDB global tables is a fully managed, serverless, multi-Region, and multi-active database used by tens of thousands of customers to power business-critical applications. With this new capability, you can replicate tables across AWS accounts and Regions to improve resiliency, isolate workloads at the account level, and apply distinct security and governance controls.\n  For multi-account global tables, DynamoDB automatically replicates tables across AWS accounts and Regions. This capability allows you to strengthen fault tolerance and helps ensure applications remain highly available even during account-level disruptions, while allowing customers to align data placement with organizational and security requirements. Multi-account global tables are ideal for customers that adopt multi-account strategies or use AWS Organizations to improve security isolation, enforce data perimeter guardrails, implement disaster recovery (DR), or separate workloads by business unit.\n  Multi-account global tables is available in all AWS Regions and is billed according to existing global tables pricing.\n  To get started, see the DynamoDB global tables documentation, and visit the AWS developer guide to learn more about the benefits of using a multi-account strategy for your AWS environment.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/dynamodb-gt-multi-account/",
      "pubDate": "2026-02-03T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "dynamodb",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "dynamodb",
        "organizations",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-9f38d8860c00",
      "title": "AWS Marketplace introduces localized billing for Professional Services from AWS EMEA",
      "description": "AWS Marketplace now offers a more localized experience for Europe, Middle East, and Africa (EMEA) customers purchasing Professional Service solutions via AWS EMEA Marketplace Operator.\n  Customers can now procure Professional Services using localized payment methods and receive invoices from AWS EMEA. This removes previous procurement barriers caused by complex payment remittance processes between different AWS entities, which made it difficult for EMEA customers to purchase Professional Services through AWS Marketplace.\n  Key benefits include support for SEPA (Single Euro Payment Area) payment methods and invoicing consistency from the same AWS entity covering all AWS Marketplace purchases via AWS EMEA Marketplace Operator. This capability is ideal for EMEA customers purchasing consulting, implementation, or managed services through AWS Marketplace. It also benefits organizations that prefer local payment methods such as SEPA direct debit, want to consolidate AWS and Marketplace billing, or are seeking a simpler procurement experience for Professional Services.\n  This capability is available for EMEA customers who purchase professional services solutions in AWS Marketplace, with AWS EMEA as the Marketplace Operator. To learn more about purchasing Professional Services products in AWS Marketplace and receive invoices issued by AWS EMEA, visit the AWS Marketplace Buyer Guide and AWS EMEA Marketplace FAQs. For more information on how to add a bank account for SEPA, see Managing Your SEPA Direct Debit Payment Method in the AWS Billing and Cost Management user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-marketplace-localized-billing-professional/",
      "pubDate": "2026-02-03T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-b7988a0ad294",
      "title": "Use Amazon MSK Connect and Iceberg Kafka Connect to build a real-time data lake",
      "description": "In this post, we demonstrate how to use Iceberg Kafka Connect with Amazon Managed Streaming for Apache Kafka (Amazon MSK) Connect to accelerate real-time data ingestion into data lakes, simplifying the synchronization process from transactional databases to Apache Iceberg tables.",
      "link": "https://aws.amazon.com/blogs/big-data/use-amazon-msk-connect-and-iceberg-kafka-connect-to-build-a-real-time-data-lake/",
      "pubDate": "2026-02-03T18:42:38.000Z",
      "source": "bigDataBlog",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kafka",
        "msk"
      ]
    },
    {
      "id": "aws-news-68e81d0b319e",
      "title": "Optimizing Flink’s join operations on Amazon EMR with Alluxio",
      "description": "In this post, we show you how to implement real-time data correlation using Apache Flink to join streaming order data with historical customer and product information, enabling you to make informed decisions based on comprehensive, up-to-date analytics. We also introduce an optimized solution to automatically load Hive dimension table data into Alluxio Universal Flash Storage (UFS) through the Alluxio cache layer. This enables Flink to perform temporal joins on changing data, accurately reflecting the content of a table at specific points in time.",
      "link": "https://aws.amazon.com/blogs/big-data/optimizing-flinks-join-operations-on-amazon-emr-with-alluxio/",
      "pubDate": "2026-02-03T18:41:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-d26c33084ae7",
      "title": "AWS Lake Formation is now available in Asia Pacific (New Zealand) Region",
      "description": "AWS Lake Formation is now available in the Asia Pacific (New Zealand) Region, enabling you to centrally manage and scale fine-grained data access permissions and share data securely within and outside your organization.\n  AWS Lake Formation is a service that allows you to define where your data resides and what data access and security policies you want to apply. Your users can then access the centralized AWS Glue Data Catalog which describes available data sets and their appropriate usage. Your users can then usethese data sets with their choice of analytics and machine learning services, like Amazon EMR for Apache Spark, Amazon Redshift, AWS Glue, Amazon QuickSight, and Amazon Athena.\n  To learn more about Lake Formation, visit the documentation. For AWS Lake Formation Region availability, please see the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/AWS-Lake-Formation-Asia-Pacific-New-Zealand-Region",
      "pubDate": "2026-02-03T18:14:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "emr",
        "redshift",
        "glue",
        "athena",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "emr",
        "redshift",
        "glue",
        "athena",
        "quicksight",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-1a035f6d1d3a",
      "title": "Amazon Connect launches an appeals workflow for agent performance evaluations",
      "description": "Amazon Connect now provides an integrated workflow to capture and resolve agent appeals of performance evaluations, enhancing evaluation fairness and agent engagement. When agents disagree with an evaluation, they can appeal the evaluation along with their reasoning directly within the Connect UI. For example, an agent who received a low evaluation score for active listening on a conversation, may appeal their evaluation by citing specific examples where they actively listened and acknowledged the customer’s problem. Designated managers then receive automated email notifications to review and resolve the appeal. Additionally, managers can monitor which evaluations have been appealed, and track their status, ensuring timely resolution of appeals.\n  This feature is available in all regions where Amazon Connect is offered. To learn more, please visit our documentation and our webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-connect-appeals-workflow-agent-performance-evaluations/",
      "pubDate": "2026-02-03T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-827f71faba2a",
      "title": "AWS Management Console now displays Account Name on the Navigation bar for easier account identification",
      "description": "Today, AWS announces the general availability of displaying account name in AWS Management Console across all Public Regions. AWS customers now have an easy way to identify their accounts at a glance. Users can now quickly distinguish between accounts visually using the account name that appears in the navigation bar for all authorized users in that account.\n  AWS customers manage multiple accounts to separate their workloads, such as maintaining distinct accounts for development and production environments or for different business units. Previously, users had to rely on account numbers to identify accounts. With this new feature, all authorized users can quickly identify the account using its name on the navigation bar.\n  The account name display feature is available at no additional cost in all public AWS Regions. To get started, make sure your administrator has enabled the feature (visit our managed policy documentation) and sign in to AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/console-displays-account-name-on-nav-bar",
      "pubDate": "2026-02-03T17:18:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga",
        "new-feature"
      ]
    },
    {
      "id": "aws-news-f78f98456849",
      "title": "AWS IAM Identity Center enables account access and application use in multiple AWS Regions",
      "description": "IAM Identity Center helps you configure the single sign-on experience of your workforce to AWS accounts and applications. You can now replicate IAM Identity Center from the primary AWS Region where you first enabled it to additional Regions of your choice. This feature enhances resilience of user access to AWS accounts and helps you deploy AWS applications in the AWS Regions that best align with your business needs such as application data residency and proximity to users.\n \nWhen you enable this feature, IAM Identity Center automatically replicates your identities, entitlements, and other information from the primary Region to additional Regions. If IAM Identity Center is affected by a disruption in the primary Region, IAM Identity Center users continue to have access to their AWS accounts using the already provisioned entitlements in the additional Regions. \n \nAWS application administrators can use the standard application deployment workflow to deploy their application in an additional Region. They can assign users to the application in that Region, while you continue to administer IAM Identity Center in the primary Region.\n  IAM Identity Center multi-Region support is currently available in the 17 enabled-by-default commercial AWS Regions for organization instances of IAM Identity Center connected to an external identity provider, such as Okta. The IAM Identity Center organization instance must be configured with a multi-Region customer managed KMS key (CMK). To find out which AWS applications support deployment in additional Regions, visit AWS applications that you can use with IAM Identity Center. Standard AWS KMS charges apply for storing and using CMKs. IAM Identity Center is provided at no additional cost. To learn more about IAM Identity Center, visit the product detail page. To get started, see the IAM Identity Center User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-iam-identity-center-multi-region-aws-account-access-and-application-deployment",
      "pubDate": "2026-02-03T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam",
        "iam identity center"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "iam",
        "iam identity center",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-9bd6f4063326",
      "title": "Amazon Quick Suite Enables Easy Resolution of Ambiguous Map Locations",
      "description": "Quick Sight in Amazon Quick Suite now enables authors to resolve or update ambiguous locations directly on map visuals for accurate geographical data visualization. When Quick Suite encounters location names that exist in multiple regions—such as cities like Springfield or Abbeville that appear in multiple U.S. states—users can now explicitly define the correct geographical context through three resolution methods: adding supporting geospatial fields to create location hierarchies, searching for specific locations from Quick Suite's geographical database, or entering exact latitude and longitude coordinates for precise positioning.\n  These enhancements address visualization accuracy needs for organizations working with datasets containing common location names that could refer to multiple places. With location mapping, dashboard authors can ensure their geospatial visuals correctly represent their data's geographical context, leading to more reliable insights. The feature provides clear status tracking with Unmatched, Matched, and Unused location indicators, helping users understand and manage their location mappings effectively. Users can resolve ambiguous locations directly from map visuals by selecting \"Resolve now\" or accessing \"Geo data match\" options.\n  This feature is now available in all Amazon Quick Suite regions where Quick Sight is supported. Discover how to create maps and geospatial charts in Quick Suite and learn more about this new feature in our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/quick-ambiguous-locations-resolution",
      "pubDate": "2026-02-03T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "amazon q",
        "organizations",
        "ga",
        "now-available",
        "new-feature",
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-9f6b6118d34d",
      "title": "Oracle Database@AWS is now available in the Canada Central and Sydney AWS Regions",
      "description": "Oracle Database@AWS is now available in two additional AWS Regions: CA-Central-1 (Canada Central) and AP-Southeast-2 (Sydney), starting with one Availability Zone (AZ) in each Region. Oracle Database@AWS enables you to access database services on Oracle Cloud Infrastructure (OCI) managed Oracle Exadata systems within AWS data centers. As a result, customers can easily migrate their on-premises Oracle Exadata and Oracle Real Application Clusters (RAC) applications to a like-for-like environment on AWS, and also benefit from integrations with AWS services such as AWS Key Management Service (KMS) for data encryption and AWS CloudWatch for monitoring. With expansion to the Canada Central and Sydney Regions, customers with data residency requirements in Canada and Australia can migrate their on-premises Oracle Exadata and RAC applications to AWS.\n  With this expansion, Oracle Database@AWS services are now available in seven Regions: US-East-1 (N. Virginia), US-West-2 (Oregon), US-East-2 (Ohio), EU-Central-1 (Frankfurt), AP-Northeast-1 (Tokyo), CA-Central-1 (Canada Central) and AP-Southeast-2 (Sydney). To use Oracle Database@AWS services, request a private offer from Oracle through the AWS Marketplace, and use AWS Management Console to setup and use your databases.\n  To learn more, visit Oracle Database@AWS overview and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/oracle-database-aws-available-canada-central-sydney-aws-regions",
      "pubDate": "2026-02-03T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudwatch",
        "now-available",
        "integration",
        "expansion"
      ]
    },
    {
      "id": "aws-news-7240408be297",
      "title": "DeepSeek OCR, MiniMax M2.1, and Qwen3-VL-8B-Instruct models are now available on SageMaker JumpStart",
      "description": "Today, AWS announced the availability of DeepSeek OCR, MiniMax M2.1, and Qwen3-VL-8B-Instruct in Amazon SageMaker JumpStart, expanding the portfolio of foundation models available to AWS customers. These three models bring specialized capabilities spanning document intelligence, multilingual coding, advanced multimodal reasoning, and vision-language understanding, enabling customers to build sophisticated AI applications across diverse use cases on AWS infrastructure.\n  These models address different enterprise AI challenges with specialized capabilities:\n DeepSeek OCR explores visual-text compression for document processing. It can extract structured information from forms, invoices, diagrams, and complex documents with dense text layouts.\n MiniMax M2.1 is optimized for coding, tool use, instruction following, and long-horizon planning. It automates multilingual software development and executes complex, multi-step office workflows, empowering developers to build autonomous applications.\n Qwen3-VL-8B-Instruct delivers ssuperior text understanding and generation, deeper visual perception and reasoning, extended context length, enhanced spatial and video dynamics comprehension, and stronger agent interaction capabilities.\n With SageMaker JumpStart, customers can deploy any of these models with just a few clicks to address their specific AI use cases.\n  To get started with these models, navigate to the SageMaker JumpStart model catalog in the SageMaker console or use the SageMaker Python SDK to deploy the models to your AWS account. For more information about deploying and using foundation models in SageMaker JumpStart, see the Amazon SageMaker JumpStart documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/new-models-on-sagemaker-jumpstart",
      "pubDate": "2026-02-02T21:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "lex",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-5f799d8bb52c",
      "title": "Build Production-Ready Drug Discovery and Robotics Pipelines with NVIDIA NIMs on SageMaker JumpStart",
      "description": "Amazon SageMaker JumpStart now enables one-click deployment of four NVIDIA NIMs models purpose-built for biosciences and physical AI: ProteinMPNN, Nemotron-3.5B-Instruct, MSA Search NIM, and Cosmos Reason. NVIDIA NIM™ provides prebuilt, optimized inference microservices for rapidly deploying the latest AI models on any NVIDIA-accelerated infrastructure. These models bring advanced capabilities spanning protein design, reasoning with configurable outputs, and physical world understanding, enabling customers to accelerate biosciences research, drug discovery, and embodied AI applications on AWS infrastructure.\n \nProteinMPNN enables fast and efficient protein sequence optimization guided by structural data. This NIM generates high-quality sequences with enhanced binding affinity and stability, validated through experimental results. Designed for scalability and flexibility, ProteinMPNN integrates seamlessly into protein engineering workflows, transforming applications like enzyme design and therapeutic development.\n \nMSA Search NIM supports GPU-accelerated Multiple Sequence Alignment (MSA) of a query amino acid sequence against a set of protein sequence databases. These databases are searched for similar sequences to the query and then the collection of sequences are aligned to establish similar regions even when the proteins have different lengths and motifs.\n \nNemotron-3.5B-Instruct delivers high reasoning performance, native tool calling support, and extended context processing with 256k token context window. This model employs an efficient hybrid Mixture-of-Experts (MoE) architecture to ensure higher throughput than its predecessors for agentic and coding workloads, while maintaining the reasoning depth of a larger model. It is ideal for building multi-agent workflows, developer productivity tools, processes automation, and for scientific and mathematical reasoning analysis, amongst others.\n \nCosmos Reason is an open , customizable, reasoning vision language model (VLM) for physical AI and robotics. It enables robots and vision AI agents to reason like humans, using prior knowledge, physics understanding, and common sense to understand and act in the real world. This model understands space, time, and fundamental physics, and can serve as a planning model to reason what steps an embodied agent might take next.\n \nWith SageMaker JumpStart, customers can deploy any of these models with just a few clicks to address their specific AI use cases.\n \nTo get started with these models, navigate to the SageMaker JumpStart model catalog in the SageMaker console or use the SageMaker Python SDK to deploy the models to your AWS account. For more information about deploying and using foundation models in SageMaker JumpStart, see the Amazon SageMaker JumpStart documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/accelerate-biosciences-and-robotics-with-NVIDIA-NIMs-on-sagemaker-jumpstart",
      "pubDate": "2026-02-02T21:24:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "lex",
        "experimental",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-12d384e9f746",
      "title": "Announcing memory-optimized instance bundles for Amazon Lightsail",
      "description": "Amazon Lightsail now offers memory-optimized instance bundles with up to 512 GB memory. The new instance bundles are available in 7 sizes, with Linux and Windows operating system (OS) and application blueprints, for both IPv6-only and dual-stack networking types. You can create instances using the new bundles with pre-configured OS and application blueprints including WordPress, cPanel & WHM, Plesk, Drupal, Magento, MEAN, LAMP, Node.js, Ruby on Rails, Amazon Linux, Ubuntu, CentOS, Debian, AlmaLinux, and Windows.\n  The new memory-optimized instance bundles enable you to run memory-intensive workloads that require high RAM-to-vCPU ratios in Lightsail. These high-memory instance bundles are ideal for workloads such as in-memory databases, real-time big data analytics, in-memory caching systems, high-performance computing (HPC) applications, and large-scale enterprise applications that process extensive datasets in memory.\n  These new bundles are now available in all AWS Regions where Amazon Lightsail is available. For more information on pricing, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-lightsail-memory-optimized-instances/",
      "pubDate": "2026-02-02T21:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-50526bbbaf99",
      "title": "Federate access to Amazon SageMaker Unified Studio with AWS IAM Identity Center and Ping Identity",
      "description": "In this post, we show how to set up workforce access with SageMaker Unified Studio using Ping Identity as an external IdP with IAM Identity Center.",
      "link": "https://aws.amazon.com/blogs/big-data/federate-access-to-amazon-sagemaker-unified-studio-with-aws-iam-identity-center-and-ping-identity/",
      "pubDate": "2026-02-02T20:39:39.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam",
        "iam identity center"
      ]
    },
    {
      "id": "aws-news-9087a4267b52",
      "title": "AWS STS now supports validation of select identity provider specific claims from Google, GitHub, CircleCI and OCI",
      "description": "AWS Security Token Service (STS) now supports validation of select identity provider specific claims from Google, GitHub, CircleCI and Oracle Cloud Infrastructure in IAM role trust policies and resource control policies for OpenID Connect (OIDC) federation into AWS via the AssumeRoleWithWebIdentity API. \n  With this new capability, you can reference these custom claims as condition keys in IAM role trust policies and resource control policies, expanding your ability to implement fine-grained access control for federated identities and help you establish your data perimeters. This enhancement builds upon IAM's existing OIDC federation capabilities, which allow you to grant temporary AWS credentials to users authenticated through external OIDC-compatible identity providers.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-sts-supports-validation-identity-provider-claims",
      "pubDate": "2026-02-02T20:17:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "iam",
        "enhancement",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-5c22e7d77495",
      "title": "AWS Multi-party approval now requires one-time password verification for voting",
      "description": "AWS Multi-Party Approval now requires approvers to verify their voting actions with a one-time password (OTP) sent to their registered AWS Identity Center email address. This additional security layer prevents AWS IAM Identity Center administrators from bypassing multi-party approval controls by impersonating approvers through credential resets or authentication endpoint modifications. When approvers access the Approval Portal and attempt to cast their vote on protected operations, the system generates a six-digit verification code and sends it to their email. Approvers enter this code within 10 minutes to complete their vote, with up to three attempts allowed.\n  The OTP verification process activates only when approvers submit their vote decision, they can review all approval request details before verification is required. If approvers don't receive the email or the code expires, they can request a new code through the interface.\n  AWS Multi-party approval with OTP verification for voting is available in all AWS Regions where Mulit-party approval is offered at no additional charge. To learn more, visit the AWS Multi-party approval documentation",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-multi-party-approval-requires-one-time-password-verification-for-voting",
      "pubDate": "2026-02-02T20:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam",
        "iam identity center"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "iam",
        "iam identity center"
      ]
    },
    {
      "id": "aws-news-22cf1591c116",
      "title": "Amazon RDS for MySQL now supports new minor versions 8.0.45 and 8.4.8",
      "description": "Amazon Relational Database Service (Amazon RDS) for MySQL now supports MySQL minor versions 8.0.45 and 8.4.8, the latest minors released by the MySQL community. We recommend upgrading to the newer minor versions to fix known security vulnerabilities in prior versions of MySQL and to benefit from bug fixes, performance improvements, and new functionality added by the MySQL community. Learn more about the enhancements in RDS for MySQL 8.0.45 and 8.4.8 in the Amazon RDS user guide.\n  You can leverage automatic minor version upgrades to automatically upgrade your databases to more recent minor versions during scheduled maintenance windows. You can also use Amazon RDS Managed Blue/Green deployments for safer, simpler, and faster updates to your MySQL instances. Learn more about upgrading your database instances, including automatic minor version upgrades and Blue/Green Deployments, in the Amazon RDS User Guide.\n  Amazon RDS for MySQL makes it simple to set up, operate, and scale MySQL deployments in the cloud. Learn more about pricing details and regional availability at Amazon RDS for MySQL. Create or update a fully managed Amazon RDS for MySQL database in the Amazon RDS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-rds-mysql-minor-versions/",
      "pubDate": "2026-02-02T18:47:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "update",
        "improvement",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-0d95209fba55",
      "title": "Amazon CloudFront announces mutual TLS support for origins",
      "description": "Amazon CloudFront announces support for mutual TLS authentication (mTLS) for origins, a security protocol that enables customers to verify that requests to their origin servers come only from their authorized CloudFront distributions using TLS certificates. This certificate-based authentication provides cryptographic verification of CloudFront's identity, eliminating the need for customers to manage custom security controls.\n  Previously, verifying that requests came from CloudFront distributions required customers to build and maintain custom authentication solutions like shared secret headers or IP allow-lists, particularly for public or externally hosted origins. These approaches required ongoing operational overhead to rotate secrets, update allow-lists, and maintain custom code. Now with origin mTLS support, customers can implement a standardized, certificate-based authentication approach that eliminates this operational burden. This enables organizations to enforce strict authentication for their proprietary content, ensuring that only verified CloudFront distributions can establish connections to backend infrastructure ranging from AWS origins and on-premises servers to third-party cloud providers and external CDNs. Customers can leverage client certificates issued by AWS Private Certificate Authority or third-party private Certificate Authorities, which they import through AWS Certificate Manager.\n  Customers can configure origin mTLS using the AWS Management Console, CLI, SDK, CDK, or CloudFormation. Origin mTLS is supported for all origins that support mutual TLS on AWS such as Application Load Balancer and API Gateway, as well as on-premises and custom origins. There is no additional charge for origin mTLS. Origin mTLS is also available in the Business and Premium flat-rate pricing plans. For detailed implementation guidance and best practices, visit the CloudFront origin mutual TLS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-cloudfront-mutual-tls-for-origins/",
      "pubDate": "2026-02-02T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "cloudfront",
        "api gateway",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "cloudformation",
        "cloudfront",
        "api gateway",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-dc8deec80cd2",
      "title": "AWS announces Flexible Cost Allocation in AWS GovCloud (US)",
      "description": "AWS Network Firewall now supports flexible cost allocation through AWS Transit Gateway native attachments in AWS GovCloud (US) Regions, enabling you to automatically distribute data processing costs across different AWS accounts. Customers can create metering policies to apply data processing charges based on their organization's chargeback requirements instead of consolidating all expenses in the firewall owner account.\n  This capability helps security and network teams better manage centralized firewall costs by distributing charges to application teams based on actual usage. Organizations can now maintain centralized security controls while automatically allocating inspection costs to the appropriate business units or application owners, eliminating the need for custom cost management solutions.\n  Flexible cost allocation is available in AWS GovCloud (US-East) and AWS GovCloud (US-West) Regions. You can enable these features using the AWS Management Console, AWS Command Line Interface (CLI) and the AWS Software Development Kit (SDK).\n  There are no additional charges for using this attachment or flexible cost allocation beyond standard pricing of AWS Network Firewall and AWS Transit Gateway. To get started, visit the Flexible Cost Allocation on AWS Transit Gateway service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-flexible-cost-allocation-govcloud/",
      "pubDate": "2026-02-02T17:40:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-ac16fd5dbc76",
      "title": "AWS Weekly Roundup: Amazon Bedrock agent workflows, Amazon SageMaker private connectivity, and more (February 2, 2026)",
      "description": "Over the past week, we passed Laba festival, a traditional marker in the Chinese calendar that signals the final stretch leading up to the Lunar New Year. For many in China, it’s a moment associated with reflection and preparation, wrapping up what the year has carried, and turning attention toward what lies ahead. Looking forward, […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-bedrock-agent-workflows-amazon-sagemaker-private-connectivity-and-more-february-2-2026/",
      "pubDate": "2026-02-02T17:19:48.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-8e05d89e5343",
      "title": "Amazon Connect now provides APIs to test and simulate voice interactions",
      "description": "Amazon Connect now offers APIs to configure and run tests that simulate contact center experiences, making it easy to validate workflows, self-service voice interactions, and their outcomes. With these APIs, you can programmatically configure test parameters, including the caller's phone number or customer profile, the reason for the call (such as \"I need to check my order status\"), the expected responses (such as \"Your request has been processed\"), and business conditions like after-hours scenarios or full call queues. With this launch, you can also integrate testing directly into CI/CD pipelines, run multiple tests simultaneously to validate workflows at scale, and enable automated regression testing as part of your deployment cycles. These capabilities allow you to rapidly validate changes to your workflows and confidently deploy new customer experiences to production.\n \nTo learn more about these features, see the Amazon Connect API Reference and Amazon Connect Administrator Guide. These features are available in Asia Pacific (Mumbai), Africa (Cape Town), Europe (Frankfurt), US East (N. Virginia), Asia Pacific (Seoul), Europe (London), Asia Pacific (Tokyo), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), and Canada (Central) regions. To learn more about Amazon Connect, AWS’s AI-native customer experience solution, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-provides-apis-test-simulate-voice-interactions/",
      "pubDate": "2026-02-02T16:30:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-c0c49cd38ca2",
      "title": "AWS HealthImaging adds JPEG XL support",
      "description": "AWS HealthImaging now supports storing and retrieving lossy compressed medical images in the JPEG XL transfer syntax (1.2.840.10008.1.2.4.112). It is now simpler than ever to integrate HealthImaging with applications that require JPEG XL encoded DICOM data, such as digital pathology whole slide imaging systems.\n \nWith this launch, HealthImaging stores your JPEG XL Lossy image data without transcoding, which maintains the fidelity of your data and reduces your storage costs. Further, you can retrieve stored image frames in the JPEG XL format without the latency of transcoding at retrieval time.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-healthimaging-adds-jpeg-xl",
      "pubDate": "2026-02-02T16:29:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-b3a6b988e927",
      "title": "Amazon CloudWatch Application Signals now supports integration with Kiro powers",
      "description": "Today, AWS announces Amazon CloudWatch Application Signals integration with Kiro powers, enabling developers and operators to investigate application health issues faster with AI agent-assisted workflows in Kiro. Kiro Powers is a repository of curated and pre-packaged Model Context Protocol (MCP) servers, steering files, and hooks validated by Kiro partners to accelerate specialized software development and deployment use cases.\n  Kiro power for Amazon CloudWatch Application Signals packages the Application Signals MCP server with targeted observability guidance, giving the Kiro agent instant context for service health monitoring, SLO compliance, and investigation workflows. With Kiro power for Application Signals, developers can now accelerate troubleshooting their distributed applications in minutes instead of spending hours, directly in their IDE. For example, developers triaging an SLO or isolating an impacted service or operation, the Kiro power will dynamically load the relevant guidance and operational signals, so AI agents receive only the context needed for the specific task at hand.\n \nAmazon CloudWatch Application Signals Kiro power Kiro power is available within Kiro IDE and Kiro powers webpage for one-click installation in all AWS Regions. To learn more about Application signals MCP server, visit our documentation. Amazon CloudWatch Application Signals helps you monitor and improve application performance on AWS by automatically collecting application telemetry and enabling you to track application health, performance, and service relationships. To get started, see the Amazon CloudWatch Application Signals documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/cloudwatch-application-signals-kiro-powers",
      "pubDate": "2026-01-30T20:16:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudwatch",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-35e897f61587",
      "title": "Amazon Connect launches improved wait time estimates",
      "description": "Amazon Connect now delivers improved estimated wait time metrics for queues and enqueued contacts, empowering organizations. This allows contact centers to set accurate customer expectations, provide convenient options such as callbacks when hold times are extended, and balance workloads effectively across multiple queues. By leveraging the improved estimated wait time metrics, contact centers can make more strategic routing choices across queues while gaining enhanced visibility for better resource planning. For example, a customer calling about billing during peak hours with a 15-minute wait is seamlessly transferred to a cross-trained team with 2-minute availability, getting help faster without repeating their issue. The metric works seamlessly with routing criteria and agent proficiency configurations.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-connect-launches-improved-wait-time/",
      "pubDate": "2026-01-30T19:40:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-9d73697199bf",
      "title": "Sovereign failover – Design for digital sovereignty using the AWS European Sovereign Cloud",
      "description": "This post explores the architectural patterns, challenges, and best practices for building cross-partition failover, covering network connectivity, authentication, and governance. By understanding these constraints, you can design resilient cloud-native applications that balance regulatory compliance with operational continuity.",
      "link": "https://aws.amazon.com/blogs/architecture/sovereign-failover-design-for-digital-sovereignty-using-the-aws-european-sovereign-cloud/",
      "pubDate": "2026-01-30T19:09:35.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": []
    },
    {
      "id": "aws-news-d3a02636592d",
      "title": "Amazon SageMaker Unified Studio now supports AWS PrivateLink",
      "description": "Today, Amazon SageMaker announced a new capability allowing you to establish connectivity between your Amazon Virtual Private Cloud (VPC) and Amazon SageMaker Unified Studio without customer data traffic going through the public internet. Customers needing to go beyond the standard data transfer protocol (HTTPS/TLS2) can choose to configure their VPC so data transfer stays within the AWS network.\n  Through AWS PrivateLink, Network Administrators can now onboard AWS service endpoints to their VPC used by Amazon SageMaker Unified Studio. With the endpoints are onboarded, IAM policies used by Amazon SageMaker will enforce that customer data stay within the AWS network.\n  Amazon SageMaker private access using AWS PrivateLink is available in all AWS Regions where Amazon SageMaker Unified Studio is supported, including: Asia Pacific (Tokyo), Europe (Ireland), US East (N. Virginia), US East (Ohio), US West (Oregon), Europe (Frankfurt), South America (São Paulo), Asia Pacific (Seoul), Europe (London), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central), Asia Pacific (Mumbai), Europe (Paris), Europe (Stockholm)\n  To learn more, visit Amazon SageMaker then get started with the network isolation documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-sagemaker-unified-studio-aws-privatelink/",
      "pubDate": "2026-01-30T19:08:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "iam"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-de8fee3e90e2",
      "title": "Amazon ECS now publishes container health status as a CloudWatch metric",
      "description": "Amazon Elastic Container Service (Amazon ECS) now publishes container health status as a new metric in CloudWatch Container Insights with enhanced observability. Customers can now track the operational health of their containers through a dedicated CloudWatch metric and create alarms to respond proactively to unhealthy containers.\n  When customers configure a container health check in the container definition of an ECS task definition, Container Insights now publishes the UnHealthyContainerHealthStatus metric in the ECS/ContainerInsights namespace. The metric reports 0 for HEALTHY and 1 for UNHEALTHY. Container health state information is also available in embedded metric format (EMF) logs, providing additional context while health checks are being evaluated during the UNKNOWN state. The metric is available across cluster, service, task, and container-level dimensions, enabling customers to monitor health at their preferred level of granularity. Customers can create CloudWatch alarms on the metric to receive notifications when containers become unhealthy, allowing teams to take immediate action and maintain application reliability.\n  To get started, enable Container Insights with enhanced observability on your ECS cluster and configure a container health check in your task definition to start collecting the metric in CloudWatch. Container health metric is available in all AWS Regions where Amazon ECS Container Insights is supported. For more information, see the Amazon ECS container health checks documentation and the CloudWatch Container Insights documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ecs-container-health-status-metric/",
      "pubDate": "2026-01-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ecs",
        "cloudwatch",
        "support"
      ]
    },
    {
      "id": "aws-news-e885c03017e1",
      "title": "AWS Lambda launches enhanced observability for Kafka event source mappings",
      "description": "AWS Lambda launches enhanced observability for Kafka event source mappings (ESM) that provides Amazon CloudWatch Logs and metrics to monitor event polling setup, scaling, and processing state of Kafka events. This capability allows customers to quickly diagnose setup issues and take timely corrective actions to operate resilient data streaming workloads. This capability is available for both Amazon Managed Streaming for Apache Kafka (Amazon MSK) and self-managed Apache Kafka (SMK) event source mappings.\n  Customers use Kafka event source mappings (ESM) with their Lambda functions to build mission-critical applications. However, the lack of visibility into event polling setup, scaling, and processing state for events slows down troubleshooting for issues resulting from faulty permissions, misconfiguration, or function errors, which increases mean time to resolution and adds operational overhead. With this launch, customers can enable CloudWatch Logs and metrics to monitor their Kafka polling setup, scaling, and event processing state. Customers can select from multiple log level options that provide logs ranging from warnings and errors to detailed information about event processing progress. Similarly, customers can enable one or more metrics groups—EventCount, ErrorCount, and KafkaMetrics—to monitor various aspects of event processing. Customers can view all their metrics and logs via a dedicated monitoring page on AWS Console for ESM. This capability allows customers to utilize their observability tooling to quickly diagnose setup issues and track performance metrics to meet their stringent business requirements.\n  This feature is available in all AWS Commercial Regions where AWS Lambda's Provisioned mode for Kafka ESM is available.\n  You can enable ESM logs and metrics for your Kafka ESM using AWS Lambda's Create and Update ESM APIs, AWS Console, AWS CLI, AWS SDK, AWS CloudFormation, and AWS SAM. To learn more about these capabilities, visit the Lambda Kafka ESM developer documentation. These logs and metrics are charged at standard CloudWatch pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-Lambda-observability-for-kafka-esm/",
      "pubDate": "2026-01-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudformation",
        "kafka",
        "msk",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "cloudformation",
        "kafka",
        "msk",
        "cloudwatch",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-a5ee2c4193c6",
      "title": "New Partner Revenue Measurement gives visibility into AWS service consumption",
      "description": "Today, AWS announces the launch of Partner Revenue Measurement, a new capability that gives AWS Partners visibility into how their solutions impact AWS service consumption across partner-managed and customer-managed accounts.\n \nPartner Revenue Measurement allows Partners to better understand their AWS revenue impact and product consumption patterns. Partners can now tag AWS resources using the product code from their AWS Marketplace listing with tag key: aws-apn-id and tag value: pc:<AWS Marketplace product-code> to quantify and measure the AWS revenue impact of that solution.\n \nPartner Revenue Measurement is generally available in all commercial regions. To learn more about implementing Partner Revenue Measurement, review the onboarding guide for more information.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/new-partner-revenue-measurement",
      "pubDate": "2026-01-30T17:05:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "generally-available",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-7d122c4fc702",
      "title": "Amazon GameLift Streams expands streaming capability to six new regions",
      "description": "Starting today, Amazon GameLift Streams provides streaming capabilities in six new locations - eu-west-2 (London), eu-north-1 (Stockholm), sa-east-1 (São Paulo), ap-south-1 (Mumbai), ap-northeast-2 (Seoul), and ap-southeast-2 (Sydney) for all customers.\n  New streaming locations enable customers to provide low latency streaming experiences to their players in Europe, South America, India, and Asia regions. Additionally, these locations increase overall GPU availability, enabling customers to scale their streaming services more effectively.\n  The service supports all stream classes in these new regions.\n  To get started, customers need to edit Location and capacity configurations to add new locations to their new or existing stream groups via console or CLI.\n  For more details, see Amazon GameLift Streams developer guide: AWS Regions and remote locations",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/glstreams-new-regions",
      "pubDate": "2026-01-30T16:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-294ebadd8ed1",
      "title": "Serverless ICYMI Q4 2025",
      "description": "Stay current with the latest serverless innovations that can transform your applications. In this 31st quarterly recap, discover the most impactful AWS serverless launches, features, and resources from Q4 2025 that you might have missed.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-icymi-q4-2025/",
      "pubDate": "2026-01-30T15:23:57.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova",
        "launch"
      ]
    },
    {
      "id": "aws-news-2a19d23bfcf0",
      "title": "Announcing the AWS Digital Sovereignty Well-Architected Lens",
      "description": "As organizations accelerate cloud adoption, meeting digital sovereignty requirements has become essential to build trust with customers and regulators worldwide. The challenge isn’t whether to adopt the cloud—it’s how to do so while meeting sovereignty requirements, using a multidisciplinary approach. Even though requirements vary by geography, organizations commonly address them through technical and operational controls […]",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-aws-digital-sovereignty-well-architected-lens/",
      "pubDate": "2026-01-30T00:10:22.000Z",
      "source": "architectureBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-56b859ccdae9",
      "title": "Build a trusted foundation for data and AI using Alation and Amazon SageMaker Unified Studio",
      "description": "The Alation and SageMaker Unified Studio integration helps organizations bridge the gap between fast analytics and ML development and the governance requirements most enterprises face. By cataloging metadata from SageMaker Unified Studio in Alation, you gain a governed, discoverable view of how assets are created and used. In this post, we demonstrate who benefits from this integration, how it works, the specific metadata it synchronizes, and provide a complete deployment guide for your environment.",
      "link": "https://aws.amazon.com/blogs/big-data/build-a-trusted-foundation-for-data-and-ai-using-alation-and-amazon-sagemaker-unified-studio/",
      "pubDate": "2026-01-29T23:33:30.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "organizations",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-2bbf3449a6da",
      "title": "More room to build: serverless services now support payloads up to 1 MB",
      "description": "To support cloud applications that increasingly depend on rich contextual data, AWS is raising the maximum payload size from 256 KB to 1 MB for asynchronous AWS Lambda function invocations, Amazon Amazon SQS, and Amazon EventBridge. Developers can use this enhancement to build and maintain context-rich event-driven systems and reduce the need for complex workarounds such as data chunking or external large object storage.",
      "link": "https://aws.amazon.com/blogs/compute/more-room-to-build-serverless-services-now-support-payloads-up-to-1-mb/",
      "pubDate": "2026-01-29T22:16:14.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "lambda",
        "eventbridge",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "lambda",
        "eventbridge",
        "sqs",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-578522f933b9",
      "title": "How Artera enhances prostate cancer diagnostics using AWS",
      "description": "In this post, we explore how Artera used Amazon Web Services (AWS) to develop and scale their AI-powered prostate cancer test, accelerating time to results and enabling personalized treatment recommendations for patients.",
      "link": "https://aws.amazon.com/blogs/architecture/how-artera-enhances-prostate-cancer-diagnostics-using-aws/",
      "pubDate": "2026-01-29T17:06:57.000Z",
      "source": "architectureBlog",
      "services": [
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize"
      ]
    },
    {
      "id": "aws-news-0aaa039509ca",
      "title": "How Tipico democratized data transformations using Amazon Managed Workflows for Apache Airflow and AWS Batch",
      "description": "Tipico is the number one name in sports betting in Germany. Every day, we connect millions of fans to the thrill of sport, combining technology, passion, and trust to deliver fast, secure, and exciting betting, both online and in more than a thousand retail shops across Germany. We also bring this experience to Austria, where we proudly operate a strong sports betting business. In this post, we show how Tipico built a unified data transformation platform using Amazon Managed Workflows for Apache Airflow (Amazon MWAA) and AWS Batch.",
      "link": "https://aws.amazon.com/blogs/big-data/how-tipico-democratized-data-transformations-using-amazon-managed-workflows-for-apache-airflow-and-aws-batch/",
      "pubDate": "2026-01-28T17:56:00.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-fba5027dd519",
      "title": "Modernize game intelligence with generative AI on Amazon Redshift",
      "description": "In this post, we discuss how you can use Amazon Redshift as a knowledge base to provide additional context to your LLM. We share best practices and explain how you can improve the accuracy of responses from the knowledge base by following these best practices.",
      "link": "https://aws.amazon.com/blogs/big-data/modernize-game-intelligence-with-generative-ai-on-amazon-redshift/",
      "pubDate": "2026-01-28T17:54:53.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "redshift",
        "ga"
      ]
    },
    {
      "id": "aws-news-91aabbbbb459",
      "title": "Get started faster with one-click onboarding, serverless notebooks, and AI agents in Amazon SageMaker Unified Studio",
      "description": "Using Amazon SageMaker Unified Studio serverless notebooks, AI-assisted development, and unified governance, you can speed up your data and AI workflows across data team functions while maintaining security and compliance. In this post, we walk you through how these new capabilities in SageMaker Unified Studio can help you consolidate your fragmented data tools, reduce time to insight, and collaborate across your data teams.",
      "link": "https://aws.amazon.com/blogs/big-data/get-started-faster-with-one-click-onboarding-serverless-notebooks-and-ai-agents-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2026-01-27T18:54:19.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "unified studio"
      ]
    },
    {
      "id": "aws-news-a76018245791",
      "title": "Create a customizable cross-company log lake, Part II: Build and add Amazon Bedrock",
      "description": "In this post, you learn how to build Log Lake, a customizable cross-company data lake for compliance-related use cases that combines AWS CloudTrail and Amazon CloudWatch logs. You'll discover how to set up separate tables for writing and reading, implement event-driven partition management using AWS Lambda, and transform raw JSON files into read-optimized Apache ORC format using AWS Glue jobs. Additionally, you'll see how to extend Log Lake by adding Amazon Bedrock model invocation logs to enable human review of agent actions with elevated permissions, and how to use an AI agent to query your log data without writing SQL.",
      "link": "https://aws.amazon.com/blogs/big-data/create-a-customizable-cross-company-log-lake-part-ii-build-and-add-amazon-bedrock/",
      "pubDate": "2026-01-27T17:46:45.000Z",
      "source": "bigDataBlog",
      "services": [
        "bedrock",
        "lambda",
        "glue",
        "cloudwatch"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lambda",
        "glue",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-a46fe547dc8a",
      "title": "Secure Apache Spark writes to Amazon S3 on Amazon EMR with dynamic AWS KMS encryption",
      "description": "When processing data at scale, many organizations use Apache Spark on Amazon EMR to run shared clusters that handle workloads across tenants, business units, or classification levels. In such multi-tenant environments, different datasets often require distinct AWS Key Management Service (AWS KMS) keys to enforce strict access controls and meet compliance requirements. At the same […]",
      "link": "https://aws.amazon.com/blogs/big-data/secure-apache-spark-writes-to-amazon-s3-on-amazon-emr-with-dynamic-aws-kms-encryption/",
      "pubDate": "2026-01-27T17:45:38.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "emr",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "s3",
        "emr",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-c6f04aaa0638",
      "title": "Top 10 best practices for Amazon EMR Serverless",
      "description": "Amazon EMR Serverless is a deployment option for Amazon EMR that you can use to run open source big data analytics frameworks such as Apache Spark and Apache Hive without having to configure, manage, or scale clusters and servers. Based on insights from hundreds of customer engagements, in this post, we share the top 10 best practices for optimizing your EMR Serverless workloads for performance, cost, and scalability. Whether you're getting started with EMR Serverless or looking to fine-tune existing production workloads, these recommendations will help you build efficient, cost-effective data processing pipelines.",
      "link": "https://aws.amazon.com/blogs/big-data/top-10-best-practices-for-amazon-emr-serverless/",
      "pubDate": "2026-01-26T17:44:53.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "emr",
        "ga"
      ]
    },
    {
      "id": "aws-news-9b88459c7e3c",
      "title": "AWS Weekly Roundup: Amazon EC2 G7e instances, Amazon Corretto updates, and more (January 26, 2026)",
      "description": "Hey! It’s my first post for 2026, and I’m writing to you while watching our driveway getting dug out. I hope wherever you are you are safe and warm and your data is still flowing! This week brings exciting news for customers running GPU-intensive workloads, with the launch of our newest graphics and AI inference […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ec2-g7e-instances-with-nvidia-blackwell-gpus-january-26-2026/",
      "pubDate": "2026-01-26T16:25:46.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-9c4a35876569",
      "title": "Announcing Amazon EC2 G7e instances accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs",
      "description": "AWS introduces Amazon EC2 G7e instances accelerated by the NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs with up to 2.3 times inference performance. G7e instances deliver cost-effective performance for generative AI inference workloads and the highest performance for graphics workloads.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-amazon-ec2-g7e-instances-accelerated-by-nvidia-rtx-pro-6000-blackwell-server-edition-gpus/",
      "pubDate": "2026-01-20T21:22:56.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-4de7cccc6dd0",
      "title": "AWS Weekly Roundup: Kiro CLI latest features, AWS European Sovereign Cloud, EC2 X8i instances, and more (January 19, 2026)",
      "description": "At the end of 2025 I was happy to take a long break to enjoy the incredible summers that the southern hemisphere provides. I’m back and writing my first post in 2026 which also happens to be my last post for the AWS News Blog (more on this later). The AWS community is starting the […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-kiro-cli-latest-features-aws-european-sovereign-cloud-ec2-x8i-instances-and-more-january-19-2026/",
      "pubDate": "2026-01-20T00:24:38.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-480e3eb14bac",
      "title": "Simplify network segmentation for AWS Outposts racks with multiple local gateway routing domains",
      "description": "AWS now supports multiple local gateway (LGW) routing domains on AWS Outposts racks to simplify network segmentation. Network segmentation is the practice of splitting a computer network into isolated subnetworks, or network segments. This reduces the attack surface so that if a host on one network segment is compromised, the hosts on the other network segments are not affected. Many customers in regulated industries such as manufacturing, health care and life sciences, banking, and others implement network segmentation as part of their on-premises network security standards to reduce the impact of a breach and help address compliance requirements.",
      "link": "https://aws.amazon.com/blogs/compute/simplify-network-segmentation-for-aws-outposts-racks-with-multiple-local-gateway-routing-domains/",
      "pubDate": "2026-01-16T18:49:35.000Z",
      "source": "computeBlog",
      "services": [
        "rds",
        "outposts"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "outposts",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-de9d2d19ffe3",
      "title": "Amazon EC2 X8i instances powered by custom Intel Xeon 6 processors are generally available for memory-intensive workloads",
      "description": "AWS is announcing the general availability of Amazon EC2 X8i instances, next-generation memory optimized instances powered by custom Intel Xeon 6 processors available only on AWS. X8i instances are SAP-certified and deliver the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-ec2-x8i-instances-powered-by-custom-intel-xeon-6-processors-are-generally-available-for-memory-intensive-workloads/",
      "pubDate": "2026-01-15T22:52:17.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-298dd0715dfd",
      "title": "Opening the AWS European Sovereign Cloud",
      "description": "Deutsch | English | Español | Français | Italiano As a European citizen, I understand first-hand the importance of digital sovereignty, especially for our public sector organisations and highly regulated industries. Today, I’m delighted to share that the AWS European Sovereign Cloud is now generally available to all customers. We first announced our plans to […]",
      "link": "https://aws.amazon.com/blogs/aws/opening-the-aws-european-sovereign-cloud/",
      "pubDate": "2026-01-15T07:12:54.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "generally-available",
        "ga"
      ]
    },
    {
      "id": "aws-news-6ae9097450e3",
      "title": "Optimizing storage performance for Amazon EKS on AWS Outposts",
      "description": "Amazon Elastic Kubernetes Service (Amazon EKS) on \nAWS Outposts brings the power of managed \nKubernetes to your on-premises infrastructure. Use Amazon EKS on Outposts rack to create hybrid cloud deployments that maintain consistent AWS experiences across environments. As organizations increasingly adopt edge computing and hybrid architectures, storage optimization and performance tuning become critical for successful workload deployment.",
      "link": "https://aws.amazon.com/blogs/compute/optimizing-storage-performance-for-amazon-eks-on-aws-outposts/",
      "pubDate": "2026-01-13T18:57:12.000Z",
      "source": "computeBlog",
      "services": [
        "eks",
        "organizations",
        "outposts"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "eks",
        "organizations",
        "outposts",
        "ga"
      ]
    },
    {
      "id": "aws-news-b534fc68b2dc",
      "title": "How Salesforce migrated from Cluster Autoscaler to Karpenter across their fleet of 1,000 EKS clusters",
      "description": "This blog post examines how Salesforce, operating one of the world's largest Kubernetes deployments, successfully migrated from Cluster Autoscaler to Karpenter across their fleet of 1,000 plus Amazon Elastic Kubernetes Service (Amazon EKS) clusters.",
      "link": "https://aws.amazon.com/blogs/architecture/how-salesforce-migrated-from-cluster-autoscaler-to-karpenter-across-their-fleet-of-1000-eks-clusters/",
      "pubDate": "2026-01-12T20:03:32.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-a998df60ab8a",
      "title": "AWS Weekly Roundup: AWS Lambda for .NET 10, AWS Client VPN quickstart, Best of AWS re:Invent, and more (January 12, 2026)",
      "description": "At the beginning of January, I tend to set my top resolutions for the year, a way to focus on what I want to achieve. If AI and cloud computing are on your resolution list, consider creating an AWS Free Tier account to receive up to $200 in credits and have 6 months of risk-free […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-lambda-for-net-10-aws-client-vpn-quickstart-best-of-aws-reinvent-and-more-january-12-2026/",
      "pubDate": "2026-01-12T17:39:47.000Z",
      "source": "newsBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-fb80ad15392c",
      "title": ".NET 10 runtime now available in AWS Lambda",
      "description": "Amazon Web Services (AWS) Lambda now supports .NET 10 as both a managed runtime and base container image. .NET is a popular language for building serverless applications. Developers can now use the new features and enhancements in .NET when creating serverless applications on Lambda. This includes support for file-based apps to streamline your projects by implementing functions using just a single file.",
      "link": "https://aws.amazon.com/blogs/compute/net-10-runtime-now-available-in-aws-lambda/",
      "pubDate": "2026-01-08T21:01:05.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "new-feature",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-582af0ab873e",
      "title": "Happy New Year! AWS Weekly Roundup: 10,000 AIdeas Competition, Amazon EC2, Amazon ECS Managed Instances and more (January 5, 2026)",
      "description": "Happy New Year! I hope the holidays gave you time to recharge and spend time with your loved ones. Like every year, I took a few weeks off after AWS re:Invent to rest and plan ahead. I used some of that downtime to plan the next cohort for Become a Solutions Architect (BeSA). BeSA is […]",
      "link": "https://aws.amazon.com/blogs/aws/happy-new-year-aws-weekly-roundup-10000-aideas-competition-amazon-ec2-amazon-ecs-managed-instances-and-more-january-5-2026/",
      "pubDate": "2026-01-05T17:10:37.000Z",
      "source": "newsBlog",
      "services": [
        "ec2",
        "ecs",
        "eks"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "ecs",
        "eks",
        "ga"
      ]
    },
    {
      "id": "aws-news-93e908d04930",
      "title": "AWS Weekly Roundup: Amazon ECS, Amazon CloudWatch, Amazon Cognito and more (December 15, 2025)",
      "description": "Can you believe it? We’re nearly at the end of 2025. And what a year it’s been! From re:Invent recap events, to AWS Summits, AWS Innovate, AWS re:Inforce, Community Days, and DevDays and, recently, adding that cherry on the cake, re:Invent 2025, we have lived through a year filled with exciting moments and technology advancements […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ecs-amazon-cloudwatch-amazon-cognito-and-more-december-15-2025/",
      "pubDate": "2025-12-15T16:42:05.000Z",
      "source": "newsBlog",
      "services": [
        "nova",
        "ecs",
        "cloudwatch"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "nova",
        "ecs",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-36722fddcb63",
      "title": "Building zero trust generative AI applications in healthcare with AWS Nitro Enclaves",
      "description": "In healthcare, generative AI is transforming how \nmedical professionals analyze data, \nsummarize clinical notes, and \ngenerate insights to improve patient outcomes. From \nautomating medical documentation to assisting in \ndiagnostic reasoning, large language models (LLMs) have the potential to augment clinical workflows and accelerate research. However, these innovations also introduce significant privacy, security, and intellectual property challenges.",
      "link": "https://aws.amazon.com/blogs/compute/building-zero-trust-generative-ai-applications-in-healthcare-with-aws-nitro-enclaves/",
      "pubDate": "2025-12-12T19:06:03.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-b56aaf668b93",
      "title": "Architecting conversational observability for cloud applications",
      "description": "In this post, we walk through building a generative AI–powered troubleshooting assistant for Kubernetes. The goal is to give engineers a faster, self-service way to diagnose and resolve cluster issues, cut down Mean Time to Recovery (MTTR), and reduce the cycles experts spend finding the root cause of issues in complex distributed systems.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-conversational-observability-for-cloud-applications/",
      "pubDate": "2025-12-11T15:59:39.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-30581ecb3d79",
      "title": "How BASF’s Agriculture Solutions drives traceability and climate action by tokenizing cotton value chains using Amazon Managed Blockchain",
      "description": "BASF Agricultural Solutions combines innovative products and digital tools with practical farmer knowledge. This post explores how Amazon Managed Blockchain can drive a positive change in the agricultural industry by tokenizing food and cotton value chains for traceability, climate action, and circularity.",
      "link": "https://aws.amazon.com/blogs/architecture/how-basfs-agriculture-solutions-drives-traceability-and-climate-action-by-tokenizing-cotton-value-chains-using-amazon-managed-blockchain/",
      "pubDate": "2025-12-10T17:41:52.000Z",
      "source": "architectureBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-c8a3488015cc",
      "title": "AWS SDK for JavaScript aligns with Node.js release schedule",
      "description": "This post is about AWS SDK for JavaScript v3 announcing end of support for Node.js versions based on Node.js release schedule, and it is not about AWS Lambda. For the latter, refer to the Lambda runtime deprecation policy. In the second week of January 2026, the AWS SDK for JavaScript v3 (JS SDK) will start […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-javascript-aligns-with-node-js-release-schedule/",
      "pubDate": "2025-12-08T17:32:10.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "support"
      ]
    },
    {
      "id": "aws-news-632e1959900f",
      "title": "AWS Weekly Roundup: AWS re:Invent keynote recap, on-demand videos, and more (December 8, 2025)",
      "description": "The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our top announcements of AWS re:Invent 2025 that you can […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinvent-keynote-recap-on-demand-videos-and-more-december-8-2025/",
      "pubDate": "2025-12-08T17:05:29.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "announcement"
      ]
    },
    {
      "id": "aws-news-f8633d530b1e",
      "title": "She architects: Bringing unique perspectives to innovative solutions at AWS",
      "description": "Have you ever wondered what it is really like to be a woman in tech at one of the world's leading cloud companies? Or maybe you are curious about how diverse perspectives drive innovation beyond the buzzwords? Today, we are providing an insider's perspective on the role of a solutions architect (SA) at Amazon Web Services (AWS). However, this is not a typical corporate success story. We are three women who have navigated challenges, celebrated wins, and found our unique paths in the world of cloud architecture, and we want to share our real stories with you.",
      "link": "https://aws.amazon.com/blogs/architecture/she-architects-bringing-unique-perspectives-to-innovative-solutions-at-aws/",
      "pubDate": "2025-12-08T16:37:15.000Z",
      "source": "architectureBlog",
      "services": [
        "nova",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-ad98b700a350",
      "title": "Amazon Bedrock adds reinforcement ﬁne-tuning simplifying how developers build smarter, more accurate AI models",
      "description": "Amazon Bedrock now supports reinforcement fine-tuning delivering 66% accuracy gains on average over base models.",
      "link": "https://aws.amazon.com/blogs/aws/improve-model-accuracy-with-reinforcement-fine-tuning-in-amazon-bedrock/",
      "pubDate": "2025-12-03T16:08:14.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f27f0877e40c",
      "title": "New serverless customization in Amazon SageMaker AI accelerates model fine-tuning",
      "description": "Accelerate AI model development with new training features that enable rapid recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/new-serverless-customization-in-amazon-sagemaker-ai-accelerates-model-fine-tuning/",
      "pubDate": "2025-12-03T16:08:03.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-20b1f9fc07df",
      "title": "Introducing checkpointless and elastic training on Amazon SageMaker HyperPod",
      "description": "Accelerate AI model development with new training features that enable instant recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-checkpointless-and-elastic-training-on-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-12-03T16:07:52.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-4139ea9a5e0b",
      "title": "Announcing replication support and Intelligent-Tiering for Amazon S3 Tables",
      "description": "New features enable automatic cost optimization through intelligent storage tiering and simplified table replication across AWS Regions and accounts.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-replication-support-and-intelligent-tiering-for-amazon-s3-tables/",
      "pubDate": "2025-12-02T16:19:14.000Z",
      "source": "newsBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-64738829059d",
      "title": "Amazon S3 Storage Lens adds performance metrics, support for billions of prefixes, and export to S3 Tables",
      "description": "New capabilities help optimize application performance, analyze unlimited prefixes, and simplify metrics analysis through S3 Tables integration.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-s3-storage-lens-adds-performance-metrics-support-for-billions-of-prefixes-and-export-to-s3-tables/",
      "pubDate": "2025-12-02T16:15:12.000Z",
      "source": "newsBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-17e673125d4d",
      "title": "Amazon Bedrock AgentCore adds quality evaluations and policy controls for deploying trusted AI agents",
      "description": "Deploy AI agents with confidence using new quality evaluations and policy controls—enabling precise boundaries on agent actions, continuous quality monitoring, and experience-based learning while maintaining natural conversation flows.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-bedrock-agentcore-adds-quality-evaluations-and-policy-controls-for-deploying-trusted-ai-agents/",
      "pubDate": "2025-12-02T16:14:36.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-c6bdf0af2db1",
      "title": "Build multi-step applications and AI workflows with AWS Lambda durable functions",
      "description": "New Lambda capability lets you build applications that coordinate multiple steps reliably over extended periods—from seconds to up to one year—without paying for idle compute time when waiting for external events or human decisions.",
      "link": "https://aws.amazon.com/blogs/aws/build-multi-step-applications-and-ai-workflows-with-aws-lambda-durable-functions/",
      "pubDate": "2025-12-02T16:12:19.000Z",
      "source": "newsBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-0dbe89f3f79b",
      "title": "Orchestrating large-scale document processing with AWS Step Functions and Amazon Bedrock batch inference",
      "description": "Organizations often have large volumes of documents containing valuable information that remains locked away and unsearchable. This solution addresses the need for a \nscalable, automated text extraction and knowledge base pipeline that transforms static document collections into intelligent, searchable repositories for generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-large-scale-document-processing-with-aws-step-functions-and-amazon-bedrock-batch-inference/",
      "pubDate": "2025-11-26T21:41:51.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock",
        "step functions",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "step functions",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-1c031b337189",
      "title": "Secure Amazon Elastic VMware Service (Amazon EVS) with AWS Network Firewall",
      "description": "In this post, we demonstrate how to utilize AWS Network Firewall to secure an Amazon EVS environment, using a centralized inspection architecture across an EVS cluster, VPCs, on-premises data centers and the internet. We walk through the implementation steps to deploy this architecture using AWS Network Firewall and AWS Transit Gateway.",
      "link": "https://aws.amazon.com/blogs/architecture/secure-amazon-elastic-vmware-service-amazon-evs-with-aws-network-firewall/",
      "pubDate": "2025-11-26T16:22:03.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-c9da28428aee",
      "title": "Node.js 24 runtime now available in AWS Lambda",
      "description": "You can now develop AWS Lambda functions using Node.js 24, either as a managed runtime or using the container base image. Node.js 24 is in active LTS status and ready for production use. It is expected to be supported with security patches and bugfixes until April 2028. The Lambda runtime for Node.js 24 includes a new implementation of the […]",
      "link": "https://aws.amazon.com/blogs/compute/node-js-24-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-25T22:19:46.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-7cb737e81dc9",
      "title": "The attendee’s guide to hybrid cloud and edge computing at AWS re:Invent 2025",
      "description": "AWS re:Invent 2025 returns to Las Vegas, Nevada, from December 1–5, 2025. This year, we’re offering a comprehensive lineup of sessions and booth activities to help you build resilient, performant, and scalable applications wherever you need them—in the cloud, on premises, or at the edge.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-hybrid-cloud-and-edge-computing-at-aws-reinvent-2025/",
      "pubDate": "2025-11-25T19:27:19.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-e5767083a6d4",
      "title": "Optimize unused capacity with Amazon EC2 interruptible capacity reservations",
      "description": "Organizations running critical workloads on Amazon Elastic Compute Cloud (Amazon EC2) reserve compute capacity using On-Demand Capacity Reservations (ODCR) to have availability when needed. However, reserved capacity can intermittently sit idle during off-peak periods, between deployments, or when workloads scale down. This unused capacity represents a missed opportunity for cost optimization and resource efficiency across the organization.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-unused-capacity-with-amazon-ec2-interruptible-capacity-reservations/",
      "pubDate": "2025-11-25T01:09:16.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-5403d33b1bbc",
      "title": "How potential performance upside with AWS Graviton helps reduce your costs further",
      "description": "Amazon Web Services (AWS) provides many mechanisms to optimize the price performance of workloads running on Amazon Elastic Compute Cloud (Amazon EC2), and the selection of the optimal infrastructure to run on can be one of the most impactful levers. When we started building the AWS Graviton processor, our goal was to optimize AWS Graviton […]",
      "link": "https://aws.amazon.com/blogs/compute/how-potential-performance-upside-with-aws-graviton-helps-reduce-your-costs-further/",
      "pubDate": "2025-11-24T19:11:55.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton"
      ]
    },
    {
      "id": "aws-news-7d35cf5f9ae9",
      "title": "Enhancing API security with Amazon API Gateway TLS security policies",
      "description": "In this post, you will learn how the new Amazon API Gateway’s enhanced TLS security policies help you meet standards such as PCI DSS, Open Banking, and FIPS, while strengthening how your APIs handle TLS negotiation. This new capability increases your security posture without adding operational complexity, and provides you with a single, consistent way to standardize TLS configuration across your API Gateway infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/enhancing-api-security-with-amazon-api-gateway-tls-security-policies/",
      "pubDate": "2025-11-21T21:17:52.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "rds",
        "api gateway"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "api gateway",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-9d3d32287870",
      "title": "Improving throughput of serverless streaming workloads for Kafka",
      "description": "Event-driven applications often need to process data in real-time. When you use AWS Lambda to process records from Apache Kafka topics, you frequently encounter two typical requirements: you need to process very high volumes of records in close to real-time, and you want your consumers to have the ability to scale rapidly to handle traffic spikes. Achieving both necessitates understanding how Lambda consumes Kafka streams, where the potential bottlenecks are, and how to optimize configurations for high throughput and best performance.",
      "link": "https://aws.amazon.com/blogs/compute/improving-throughput-of-serverless-streaming-workloads-for-kafka/",
      "pubDate": "2025-11-21T20:02:57.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "rds",
        "kafka"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "rds",
        "kafka"
      ]
    },
    {
      "id": "aws-news-b3a3371e0c90",
      "title": "Build scalable REST APIs using Amazon API Gateway private integration with Application Load Balancer",
      "description": "Today, we announced \nAmazon API Gateway REST API’s support for private integration with \nApplication Load Balancers (ALBs). You can use this new capability to securely expose your VPC-based applications through your REST APIs without exposing your ALBs to the public internet.",
      "link": "https://aws.amazon.com/blogs/compute/build-scalable-rest-apis-using-amazon-api-gateway-private-integration-with-application-load-balancer/",
      "pubDate": "2025-11-21T19:28:04.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "api gateway",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-df24f6f1c182",
      "title": "Building multi-tenant SaaS applications with AWS Lambda’s new tenant isolation mode",
      "description": "Today, AWS is announcing tenant isolation for AWS Lambda, enabling you to process function invocations in separate execution environments for each end-user or tenant invoking your Lambda function. This capability simplifies building secure multi-tenant SaaS applications by managing tenant-level compute environment isolation and request routing, allowing you to focus on core business logic rather than implementing tenant-aware compute environment isolation.",
      "link": "https://aws.amazon.com/blogs/compute/building-multi-tenant-saas-applications-with-aws-lambdas-new-tenant-isolation-mode/",
      "pubDate": "2025-11-20T17:47:17.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-b04be71f4d69",
      "title": "Improve API discoverability with the new Amazon API Gateway Portal",
      "description": "In this post, we will show how you can use the new portal feature to create customizable portals with enhanced security features in minutes, with APIs from multiple accounts, without managing any infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/improve-api-discoverability-with-the-new-amazon-api-gateway-portal/",
      "pubDate": "2025-11-20T00:41:25.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-9150859a247c",
      "title": "Building an AI gateway to Amazon Bedrock with Amazon API Gateway",
      "description": "In this post, we'll explore a reference architecture that helps enterprises govern their Amazon Bedrock implementations using Amazon API Gateway. This pattern enables key capabilities like authorization controls, usage quotas, and real-time response streaming. We'll examine the architecture, provide deployment steps, and discuss potential enhancements to help you implement AI governance at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/building-an-ai-gateway-to-amazon-bedrock-with-amazon-api-gateway/",
      "pubDate": "2025-11-19T23:33:41.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "api gateway"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "api gateway",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-4934fd40d9d8",
      "title": "Architecting for AI excellence: AWS launches three Well-Architected Lenses at re:Invent 2025",
      "description": "At re:Invent 2025, we introduce one new lens and two significant updates to the AWS Well-Architected Lenses specifically focused on AI workloads: the Responsible AI Lens, the Machine Learning (ML) Lens, and the Generative AI Lens. Together, these lenses provide comprehensive guidance for organizations at different stages of their AI journey, whether you're just starting to experiment with machine learning or already deploying complex AI applications at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-for-ai-excellence-aws-launches-three-well-architected-lenses-at-reinvent-2025/",
      "pubDate": "2025-11-19T19:36:31.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-61647c9310e0",
      "title": "Announcing the updated AWS Well-Architected Generative AI Lens",
      "description": "We are delighted to announce an update to the AWS Well-Architected Generative AI Lens. This update features several new sections of the Well-Architected Generative AI Lens, including new best practices, advanced scenario guidance, and improved preambles on responsible AI, data architecture, and agentic workflows.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-generative-ai-lens/",
      "pubDate": "2025-11-19T19:36:28.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-5044b6bc98c4",
      "title": "Announcing the updated AWS Well-Architected Machine Learning Lens",
      "description": "We are excited to announce the updated AWS Well-Architected Machine Learning Lens, now enhanced with the latest capabilities and best practices for building machine learning (ML) workloads on AWS.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-machine-learning-lens/",
      "pubDate": "2025-11-19T19:36:25.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-360e834c997a",
      "title": "BASF Digital Farming builds a STAC-based solution on Amazon EKS",
      "description": "This post was co-written with Frederic Haase and Julian Blau with BASF Digital Farming GmbH. At xarvio – BASF Digital Farming, our mission is to empower farmers around the world with cutting-edge digital agronomic decision-making tools. Central to this mission is our crop optimization platform, xarvio FIELD MANAGER, which delivers actionable insights through a range […]",
      "link": "https://aws.amazon.com/blogs/architecture/basf-digital-farming-builds-a-stac-based-solution-on-amazon-eks/",
      "pubDate": "2025-10-22T16:21:09.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-24029d05087c",
      "title": "What’s New in the AWS Deploy Tool for .NET",
      "description": "Version 2.0 of the AWS Deploy Tool for .NET is now available. This new major version introduces several foundational upgrades to improve the deployment experience for .NET applications on AWS. The tool comes with new minimum runtime requirements. We have upgraded it to require .NET 8 because the predecessor, .NET 6, is now out of […]",
      "link": "https://aws.amazon.com/blogs/developer/whats-new-in-the-aws-deploy-tool-for-net/",
      "pubDate": "2025-10-14T13:25:42.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-2f3bd8791ed1",
      "title": "Modernization of real-time payment orchestration on AWS",
      "description": "The global real-time payments market is experiencing significant growth. According to Fortune Business Insights, the market was valued at USD 24.91 billion in 2024 and is projected to grow to USD 284.49 billion by 2032, with a CAGR of 35.4%. Similarly, Grand View Research reports that the global mobile payment market, valued at USD 88.50 […]",
      "link": "https://aws.amazon.com/blogs/architecture/modernization-of-real-time-payment-orchestration-on-aws/",
      "pubDate": "2025-10-01T23:34:00.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": []
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-4fbb29739c17",
      "title": "General Availability Release of the Migration Tool for the AWS SDK for Java 2.x",
      "description": "The AWS SDK for Java 1.x (v1) entered maintenance mode on July 31, 2024, and will reach end-of-support on December 31, 2025. We recommend that you migrate to the AWS SDK for Java 2.x (v2) to access new features, enhanced performance, and continued support from AWS. To help you migrate efficiently, we’ve created a migration […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-release-of-the-migration-tool-for-the-aws-sdk-for-java-2-x/",
      "pubDate": "2025-09-26T16:47:36.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-875544c87826",
      "title": "Preview Release of the AWS SDK Java 2.x HTTP Client built on Apache HttpClient 5.5.x",
      "description": "The AWS SDK for Java 2.x introduces the Apache 5 SDK HTTP client which is built on Apache HttpClient 5.5.x. This new SDK HTTP client is available alongside our existing SDK HTTP clients: Apache HttpClient 4.5.x, Netty, URL Connection, and AWS CRT HttpClient. To differentiate the use of Apache HttpClient 4.5.x and Apache HttpClient 5.5.x, […]",
      "link": "https://aws.amazon.com/blogs/developer/preview-release-of-theaws-sdk-java-2-x-http-client-built-on-apache-httpclient-5-5-x/",
      "pubDate": "2025-07-18T03:36:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-6606f79cd3d5",
      "title": "AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available",
      "description": "Today, we are excited to announce the general availability of the AWS .NET Distributed Cache Provider for Amazon DynamoDB. This is a seamless, serverless caching solution that enables .NET developers to efficiently manage their caching needs across distributed systems. Consistent caching is a difficult problem in distributed architectures, where maintaining data integrity and performance across […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-net-distributed-cache-provider-for-amazon-dynamodb-now-generally-available/",
      "pubDate": "2025-07-03T13:49:25.000Z",
      "source": "developersAndDevOps",
      "services": [
        "dynamodb"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "dynamodb",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-ae25b45e1a62",
      "title": "AWS Tools for PowerShell V5 now Generally Available",
      "description": "This blog was co-authored by Afroz Mohammed and Jonathan Nunn, Software Developers on the AWS PowerShell team. We’re excited to announce the general availability of the AWS Tools for PowerShell version 5, a major update that brings new features and improvements in security, along with a few breaking changes. New Features You can now cancel […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-tools-for-powershell-v5-now-generally-available/",
      "pubDate": "2025-06-23T22:59:33.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "new-feature",
        "update",
        "improvement"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-27b43a8f9a42",
      "title": "Deploy to ARM-Based Compute with AWS Deploy Tool for .NET",
      "description": "We’re excited to announce that the AWS Deploy Tool for .NET now supports deploying .NET applications to select ARM-based compute platforms on AWS! Whether you’re deploying from Visual Studio or using the .NET CLI, you can now target cost-effective ARM infrastructure like AWS Graviton with the same streamlined experience you’re used to. Why deploy to […]",
      "link": "https://aws.amazon.com/blogs/developer/deploy-to-arm-based-compute-with-aws-deploy-tool-for-net/",
      "pubDate": "2025-05-08T20:16:40.000Z",
      "source": "developersAndDevOps",
      "services": [
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "graviton",
        "support"
      ]
    },
    {
      "id": "aws-news-4d3126ea3a15",
      "title": "General Availability of AWS SDK for .NET V4.0",
      "description": "Version 4.0 of the AWS SDK for .NET has been released for general availability (GA). V4 has been in development for a little over a year in our SDK’s public GitHub repository with 13 previews being released. This new version contains performance improvements, consistency with other AWS SDKs, and bug and usability fixes that required […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-of-aws-sdk-for-net-v4-0/",
      "pubDate": "2025-04-28T20:05:16.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-49859f1bef68",
      "title": "Introducing the AWS IoT Device SDK for Swift (Developer Preview)",
      "description": "Today, AWS launches the developer preview of the AWS IoT Device SDK for Swift. The IoT Device SDK for Swift empowers Swift developers to create IoT applications for Linux and Apple macOS, iOS, and tvOS platforms using the MQTT 5 protocol. The SDK supports Swift 5.10+ and is designed to help developers easily integrate with […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-the-aws-iot-device-sdk-for-swift-developer-preview/",
      "pubDate": "2025-03-31T16:26:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-dd08a704e7e9",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 2)",
      "description": "In Part 1 of our blog posts for .NET Aspire and AWS Lambda, we showed you how .NET Aspire can be used for running and debugging .NET Lambda functions. In this part, Part 2, we’ll show you how to take advantage of the .NET Aspire programming model for best practices and for connecting dependent resources […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-2/",
      "pubDate": "2025-03-04T17:54:04.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-4185fb6b40aa",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 1)",
      "description": "In a recent post we gave some background on .NET Aspire and introduced our AWS integrations with .NET Aspire that integrate AWS into the .NET dev inner loop for building applications. The integrations included how to provision application resources with AWS CloudFormation or AWS Cloud Development Kit (AWS CDK) and using Amazon DynamoDB local for […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-1/",
      "pubDate": "2025-03-03T21:16:42.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda",
        "dynamodb",
        "cloudformation"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "dynamodb",
        "cloudformation",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-866c6557a5ec",
      "title": "Integrating AWS with .NET Aspire",
      "description": ".NET Aspire is a new way of building cloud-ready applications. In particular, it provides an orchestration for local environments in which to run, connect, and debug the components of distributed applications. Those components can be .NET projects, databases, containers, or executables. .NET Aspire is designed to have integrations with common components used in distributed applications. […]",
      "link": "https://aws.amazon.com/blogs/developer/integrating-aws-with-net-aspire/",
      "pubDate": "2025-02-11T20:39:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "integration"
      ]
    }
  ]
}