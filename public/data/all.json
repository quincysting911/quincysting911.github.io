{
  "lastUpdated": "2026-02-22T06:34:04.200Z",
  "totalItems": 205,
  "sources": {
    "whatsNew": 95,
    "mlBlog": 20,
    "newsBlog": 19,
    "bigDataBlog": 18,
    "architectureBlog": 17,
    "computeBlog": 19,
    "developersAndDevOps": 17
  },
  "items": [
    {
      "id": "aws-news-4e0d4aa0a42c",
      "title": "Amazon SageMaker AI in 2025, a year in review part 1: Flexible Training Plans and improvements to price performance for inference workloads",
      "description": "In 2025, Amazon SageMaker AI saw dramatic improvements to core infrastructure offerings along four dimensions: capacity, price performance, observability, and usability. In this series of posts, we discuss these various improvements and their benefits. In Part 1, we discuss capacity improvements with the launch of Flexible Training Plans. We also describe improvements to price performance for inference workloads. In Part 2, we discuss enhancements made to observability, model customization, and model hosting.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-ai-in-2025-a-year-in-review-part-1-flexible-training-plans-and-improvements-to-price-performance-for-inference-workloads/",
      "pubDate": "2026-02-20T20:26:47.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "lex",
        "launch",
        "improvement",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-483d69a57214",
      "title": "Amazon SageMaker AI in 2025, a year in review part 2: Improved observability and enhanced features for SageMaker AI model customization and hosting",
      "description": "In 2025, Amazon SageMaker AI made several improvements designed to help you train, tune, and host generative AI workloads. In Part 1 of this series, we discussed Flexible Training Plans and price performance improvements made to inference components. In this post, we discuss enhancements made to observability, model customization, and model hosting. These improvements facilitate a whole new class of customer use cases to be hosted on SageMaker AI.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-ai-in-2025-a-year-in-review-part-2-improved-observability-and-enhanced-features-for-sagemaker-ai-model-customization-and-hosting/",
      "pubDate": "2026-02-20T20:26:30.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "lex",
        "improvement",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-d0d9e18dde1d",
      "title": "Integrate external tools with Amazon Quick Agents using Model Context Protocol (MCP)",
      "description": "In this post, you’ll use a six-step checklist to build a new MCP server or validate and adjust an existing MCP server for Amazon Quick integration. The Amazon Quick User Guide describes the MCP client behavior and constraints. This is a “How to” guide for detailed implementation required by 3P partners to integrate with Amazon Quick with MCP.",
      "link": "https://aws.amazon.com/blogs/machine-learning/integrate-external-tools-with-amazon-quick-agents-using-model-context-protocol-mcp/",
      "pubDate": "2026-02-20T16:26:21.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "integration"
      ]
    },
    {
      "id": "aws-news-68cfb6f99faa",
      "title": "Amazon RDS for Oracle now supports January 2026 Release Update and Spatial Patch Bundle",
      "description": "Amazon Relational Database Service (Amazon RDS) for Oracle now supports the Oracle January 2026 Release Update (RU) for Oracle Database versions 19c and 21c, and the corresponding Spatial Patch Bundle for Oracle Database version 19c. We recommend upgrading to the January 2026 RU as it includes security updates for Oracle database products. The Spatial Patch Bundle update delivers important fixes for Oracle Spatial and Graph functionality to provide reliable and optimal performance for spatial operations. \n  You can apply the January 2026 RU from the Amazon RDS Management Console, or by using the AWS SDK or CLI. To automatically apply updates to your database instance during your maintenance window, enable Automatic Minor Version Upgrade. You can apply the Spatial Patch Bundle update for new database instances, or upgrade existing instances to engine version '19.0.0.0.ru-2026-01.spb-1.r1' by selecting the \"Spatial Patch Bundle Engine Versions\" checkbox in the AWS Console. \n  You can use AWS Organizations upgrade rollout policy to stagger automatic minor version upgrades for your Amazon RDS database instances such that automatic minor version upgrades are first applied to non-production environments, allowing you time to validate before the upgrades are applied to production environments. For additional details, refer to Amazon RDS for Oracle documentation on using AWS Organizations upgrade rollout policy for automatic minor version upgrades.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-rd-for-oracle-jan-release-update-spatial-patch-bundle/",
      "pubDate": "2026-02-20T08:38:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-86cc833a7d39",
      "title": "AWS IAM Identity Center is now available in the Asia Pacific (New Zealand) AWS Region",
      "description": "You can now deploy AWS IAM Identity Center in 38 AWS Regions, including Asia Pacific (New Zealand).\n  IAM Identity Center is the recommended service for managing workforce access to AWS applications. It enables you to connect your existing source of workforce identities to AWS once and offer your users single sign on experience across AWS. It powers the personalized experiences offered by AWS applications, such as Amazon Q, and the ability to define and audit user-aware access to data in AWS services, such as Amazon Redshift. It can also help you manage access to multiple AWS accounts from a central place. IAM Identity Center is available at no additional cost in these AWS Regions.\n  To learn more about IAM Identity Center, visit the product detail page. To get started, see the IAM Identity Center user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-iam-identity-center-asia-pacific-new-zealand-region/",
      "pubDate": "2026-02-19T22:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center",
        "now-available"
      ]
    },
    {
      "id": "aws-news-e40d7347f41b",
      "title": "Amazon EC2 G7e instances now available in Asia Pacific (Tokyo) region",
      "description": "Starting today, Amazon EC2 G7e instances accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs are now available in  Asia Pacific (Tokyo) region. G7e instances offer up to 2.3x inference performance compared to G6e.\n \nCustomers can use G7e instances to deploy large language models (LLMs), agentic AI models, multimodal generative AI models, and physical AI models. G7e instances offer the highest performance for spatial computing workloads as well as workloads that require both graphics and AI processing capabilities. G7e instances feature up to 8 NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, with 96 GB of memory per GPU, and 5th Generation Intel Xeon processors. They support up to 192 virtual CPUs (vCPUs) and up to 1600 Gbps of networking bandwidth. G7e instances support NVIDIA GPUDirect Peer to Peer (P2P) that boosts performance for multi-GPU workloads. Multi-GPU G7e instances also support NVIDIA GPUDirect Remote Direct Memory Access (RDMA) with EFA in EC2 UltraClusters, reducing latency for small-scale multi-node workloads.\n \nYou can use G7e instances for Amazon EC2 in the following AWS Regions: US West (Oregon), US East (N. Virginia, Ohio) and Asia Pacific (Tokyo). You can purchase G7e instances as On-Demand Instances, Spot Instances, or as part of Savings Plans.\n \nTo get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit G7e instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-g7e-instances-tokyo-region/",
      "pubDate": "2026-02-19T19:11:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-184ff00c4302",
      "title": "Aurora DSQL launches new Go, Python, and Node.js connectors that simplify IAM authentication",
      "description": "Today we are announcing the release of Aurora DSQL Connectors for Go (pgx), Python (asyncpg), and Node.js (WebSocket for Postgres.js) that simplify IAM authentication for customers using standard PostgreSQL drivers to connect to Aurora DSQL clusters. These connectors act as transparent authentication layers that automatically handle IAM token generation, eliminating the need to write token generation code or manually supply IAM tokens. Tokens are automatically generated for each connection, ensuring valid tokens are always used while maintaining full compatibility with existing PostgreSQL driver features. The Postgres.js connector additionally supports WebSocket protocol, enabling customers to connect to DSQL clusters in environments where TCP connections are not available.\n  These connectors streamline authentication and eliminate security risks associated with traditional user-generated passwords. All three connectors support custom IAM credential providers, giving customers flexibility in how they manage their AWS credentials.\n  To get started, visit the Connectors for Aurora DSQL documentation page. For code examples, visit our Github page for pgx for Go, asyncpg for Python, and Websocket for Postgres.js. Get started with Aurora DSQL for free with the AWS Free Tier. To learn more about Aurora DSQL, visit the webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aurora-dsql-launches-go-python-nodejs-connectors",
      "pubDate": "2026-02-19T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds",
        "iam"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "iam",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-f2a2ebebbf85",
      "title": "Amazon MQ now supports ActiveMQ minor version 5.19",
      "description": "Amazon MQ now supports ActiveMQ minor version 5.19, which introduces several improvements and fixes compared to the previous version of ActiveMQ supported by Amazon MQ. Amazon MQ manages the patch version upgrades for your brokers. All brokers on ActiveMQ version 5.19 will be automatically upgraded to the next compatible and secure patch version in your scheduled maintenance window.\n \nIf you are utilizing prior versions of ActiveMQ, such as 5.18, we strongly recommend you to upgrade to ActiveMQ 5.19. You can easily perform this upgrade with just a few clicks in the AWS Management Console. To learn more about upgrading, consult the ActiveMQ Version Management section in the Amazon MQ Developer Guide. To learn more about the changes in ActiveMQ 5.19, see the Amazon MQ release notes. This version is available across all AWS Regions where Amazon MQ is available.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-mq-activemq-5-19/",
      "pubDate": "2026-02-19T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "q developer",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-ee449f2b77f8",
      "title": "Build AI workflows on Amazon EKS with Union.ai and Flyte",
      "description": "In this post, we explain how you can use the Flyte Python SDK to orchestrate and scale AI/ML workflows. We explore how the Union.ai 2.0 system enables deployment of Flyte on Amazon Elastic Kubernetes Service (Amazon EKS), integrating seamlessly with AWS services like Amazon Simple Storage Service (Amazon S3), Amazon Aurora, AWS Identity and Access Management (IAM), and Amazon CloudWatch. We explore the solution through an AI workflow example, using the new Amazon S3 Vectors service.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-ai-workflows-on-amazon-eks-with-union-ai-and-flyte/",
      "pubDate": "2026-02-19T16:28:21.000Z",
      "source": "mlBlog",
      "services": [
        "s3 vectors",
        "s3",
        "eks",
        "iam",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3 vectors",
        "s3",
        "eks",
        "iam",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-edadc2bb22a2",
      "title": "Amazon Quick now supports key pair authentication to Snowflake data source",
      "description": "In this blog post, we will guide you through establishing data source connectivity between Amazon Quick Sight and Snowflake through secure key pair authentication.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-quick-suite-now-supports-key-pair-authentication-to-snowflake-data-source/",
      "pubDate": "2026-02-19T16:06:41.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "support"
      ]
    },
    {
      "id": "aws-news-bf2dd084032f",
      "title": "Amazon SNS now supports sending SMS in additional AWS Regions",
      "description": "Customers that use Amazon Simple Notification Service (Amazon SNS) in the Asia Pacific (New Zealand) and Asia Pacific (Taipei) Regions can now send text messages (SMS) to subscribers in more than 200 countries and territories.\n  \n \nAmazon SNS is a fully managed pub/sub messaging service that enables message delivery to multiple endpoints including AWS Lambda, Amazon SQS, Amazon Data Firehose, mobile devices, and email. With this launch, customers using SNS in these Regions can send SMS messages via AWS End User Messaging. Amazon SNS now supports the ability to send SMS in 32 AWS Regions.\n  More information:\n  \n \n \n  \nTo learn more about sending SMS messages with SNS, visit Mobile text messaging with Amazon SNS.\n \n  \nFor the list of supported countries and regions, visit Supported countries and regions.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-sns-sms-region-expansion",
      "pubDate": "2026-02-19T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "sns",
        "sqs"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "sns",
        "sqs",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-1e5f34c0d5f5",
      "title": "Amazon EC2 M8i-flex instances are now available in additional AWS regions",
      "description": "Starting today, Amazon EC2 M8i-flex instances are now available in Asia Pacific (Malaysia, Seoul, Singapore, Tokyo), Europe (Frankfurt) and Canada (Central) regions. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. The M8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver up to 20% better performance than M7i-flex instances, with even higher gains for specific workloads. The M8i-flex instances are up to 30% faster for PostgreSQL databases, up to 60% faster for NGINX web applications, and up to 40% faster for AI deep learning recommendation models compared to M7i-flex instances.\n  M8i-flex instances are the easiest way to get price performance benefits for a majority of general-purpose workloads like web and application servers, microservices, small and medium data stores, virtual desktops, and enterprise applications. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  To get started, sign in to the AWS Management Console. For more information about the M8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-m8i-flex-instances-FRA-ICN-KUL-NRT-SIN-YUL-region/",
      "pubDate": "2026-02-19T02:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-08e9f45f3f3c",
      "title": "Build unified intelligence with Amazon Bedrock AgentCore",
      "description": "In this post, we demonstrate how to build unified intelligence systems using Amazon Bedrock AgentCore through our real-world implementation of the Customer Agent and Knowledge Engine (CAKE).",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-unified-intelligence-with-amazon-bedrock-agentcore/",
      "pubDate": "2026-02-18T23:54:29.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-91f61eda3045",
      "title": "How CyberArk uses Apache Iceberg and Amazon Bedrock to deliver up to 4x support productivity",
      "description": "CyberArk is a global leader in identity security. Centered on intelligent privilege controls, it provides comprehensive security for human, machine, and AI identities across business applications, distributed workforces, and hybrid cloud environments. In this post, we show you how CyberArk redesigned their support operations by combining Iceberg’s intelligent metadata management with AI-powered automation from Amazon Bedrock. You’ll learn how to simplify data processing flows, automate log parsing for diverse formats, and build autonomous investigation workflows that scale automatically.",
      "link": "https://aws.amazon.com/blogs/big-data/how-cyberark-uses-apache-iceberg-and-amazon-bedrock-to-deliver-up-to-4x-support-productivity/",
      "pubDate": "2026-02-18T20:17:24.000Z",
      "source": "bigDataBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-fa285336edf8",
      "title": "Best practices for right-sizing Amazon OpenSearch Service domains",
      "description": "In this post, we guide you through the steps to determine if your OpenSearch Service domain is right-sized, using AWS tools and best practices to optimize your configuration for workloads like log analytics, search, vector search, or synthetic data testing.",
      "link": "https://aws.amazon.com/blogs/big-data/best-practices-for-right-sizing-amazon-opensearch-service-domains/",
      "pubDate": "2026-02-18T20:16:21.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-2aad6a140c91",
      "title": "Evaluating AI agents: Real-world lessons from building agentic systems at Amazon",
      "description": "In this post, we present a comprehensive evaluation framework for Amazon agentic AI systems that addresses the complexity of agentic AI applications at Amazon through two core components: a generic evaluation workflow that standardizes assessment procedures across diverse agent implementations, and an agent evaluation library that provides systematic measurements and metrics in Amazon Bedrock AgentCore Evaluations, along with Amazon use case-specific evaluation approaches and metrics.",
      "link": "https://aws.amazon.com/blogs/machine-learning/evaluating-ai-agents-real-world-lessons-from-building-agentic-systems-at-amazon/",
      "pubDate": "2026-02-18T19:21:28.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex"
      ]
    },
    {
      "id": "aws-news-679794ccdee2",
      "title": "Amazon Aurora DSQL now integrates with Kiro powers and AI agent skills",
      "description": "Today, AWS announces Amazon Aurora DSQL integration with Kiro powers and AI agent skills, enabling developers to build Aurora DSQL-backed applications faster with AI agent-assisted development. These integrations bundle the Aurora DSQL Model Context Protocol (MCP) server with development best practices, so AI agents can help you with Aurora DSQL schema design, performance optimization, and database operations out of the box.\n  Kiro powers is a registry of curated and pre-packaged MCP servers, steering files, and agent hooks to accelerate specialized software development and deployment use cases. With the Kiro power for Aurora DSQL, agents have instant access to specialized knowledge, so developers can work confidently without any prior context, reducing trial-and-error development cycles. The power is available within the Kiro IDE for one-click installation.\n  The Aurora DSQL skill extends the same capabilities to additional AI coding agents through the Skills CLI. Developers can install the skill with a single command and select their preferred agents including Kiro CLI, Claude Code, Gemini, Codex, Cursor, Copilot, Cline, Windsurf, Roo, OpenCode, and more. When developers work on database tasks, the agent dynamically loads relevant skill guidance, including Aurora DSQL Postgres-compatible SQL patterns, distributed database design, and IAM authentication, eliminating the need to repeatedly provide the same context across conversations. As Aurora DSQL adds new features, future skill releases will include updated patterns and guidance, ensuring that agents always have current best practices.\n \nFor more information on the Aurora DSQL Kiro power and agent skills, visit the Aurora DSQL steering documentation and GitHub page. Get started with Aurora DSQL for free with the AWS Free Tier.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-aurora-dsql-integrates-with-kiro-powers-and-agent-skills",
      "pubDate": "2026-02-18T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "iam",
        "new-feature",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-a46279b99abf",
      "title": "Amazon Connect Cases now supports AWS Service Quotas",
      "description": "Amazon Connect Cases now supports AWS Service Quotas, giving administrators a centralized way to view applied limits, monitor utilization, and scale case workloads without hitting unexpected service constraints. You can request quota increases directly from the Service Quotas console, and eligible requests are automatically approved without manual intervention.\n  Amazon Connect Cases is available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town). To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-cases-aws-service-quotas",
      "pubDate": "2026-02-18T17:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-276cd7d4064e",
      "title": "Amazon Managed Grafana now supports AWS KMS customer managed keys",
      "description": "Amazon Managed Grafana now supports customer-managed keys (CMK) through AWS Key Management Service (KMS), enabling you to encrypt data stored in in your Amazon Managed Grafana workspaces with your own encryption keys. Amazon Managed Grafana is a fully managed service based on open-source Grafana that makes it easier for you to visualize and analyze your operational data at scale.\n \nAmazon Managed Grafana provides encryption at rest using AWS owned keys by default. With this launch, you now have an option to use a customer-managed key when creating an Amazon Managed Grafana workspace. This allows you to add a self-managed security layer, helping you meet your organization’s compliance and regulatory requirements.\n \nThis feature is now available in all regions where Amazon Managed Grafana is generally available, except in AWS GovCloud (US) Regions. To get started with Amazon Managed Grafana, refer Amazon Managed Grafana user guide. To learn more about Amazon Managed Grafana, visit the product page and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-managed-grafana-customer-managed-keys",
      "pubDate": "2026-02-18T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "grafana"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "grafana",
        "launch",
        "generally-available",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-66dfe66bb907",
      "title": "AWS Clean Rooms announces support for remote Apache Iceberg REST catalogs",
      "description": "AWS Clean Rooms now supports catalog federation for remote Iceberg catalogs. This capability simplifies clean room setup by providing direct, secure access to Iceberg tables stored in Amazon S3 and cataloged in remote catalogs—without requiring table metadata replication. Organizations can now use AWS Glue catalog federation to provide direct access to their existing Iceberg REST catalog in a Clean Rooms collaboration. For example, a media publisher with data cataloged in the AWS Glue Data Catalog and an advertiser with data cataloged in a remote Iceberg catalog can analyze their collective datasets to evaluate advertising spend—without having to build ETL data pipelines or share underlying data with one another.\n  AWS Clean Rooms helps companies and their partners easily analyze and collaborate on their collective datasets without revealing or copying one another’s underlying data. For more information about the AWS Regions where AWS Clean Rooms is available, see the AWS Regions table. To learn more about collaborating with AWS Clean Rooms, visit AWS Clean Rooms.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-clean-rooms-remote-iceberg-catalogs",
      "pubDate": "2026-02-18T12:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "glue",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "s3",
        "glue",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-21f037077d83",
      "title": "Amazon OpenSearch Service expands support for Graviton4 (c8g,m8g & r8g ) instances",
      "description": "Amazon OpenSearch Service expands support for the latest generation Graviton4-based Amazon EC2 instance families. These new instance types are compute optimized (c8g), general purpose (m8g), and memory optimized (r8g, r8gd) instances.\n  AWS Graviton4 processors provide up to 30% better performance than AWS Graviton3 processors with c8g, m8g and r8g & r8gd offering the best price performance for compute-intensive, general purpose, and memory-intensive workloads respectively. To learn more about Graviton4 improvements, please see the blog on r8g instances and the blog on c8g & m8g instances.\n  Amazon OpenSearch Service Graviton4 instances are supported for all OpenSearch versions, and Elasticsearch (open source) versions 7.9 and 7.10.\n  Apart from the regions already supported, one or more than one Graviton4 instance types are now also available in following region: Asia Pacific (Hong Kong), Asia Pacific (Hyderabad), Asia Pacific (Jakarta), Asia Pacific (Melbourne), Asia Pacific (Osaka), Asia Pacific (Thailand), Europe (Milan), Europe (Paris), Europe (Zurich), Middle East (UAE), AWS GovCloud (US-West) and AWS GovCloud (US-East).\n  For region specific availability & pricing, visit our pricing page. To learn more about Amazon OpenSearch Service and its capabilities, visit our product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-opensearch-service-expands-support-graviton4-based-instances",
      "pubDate": "2026-02-18T05:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "opensearch",
        "opensearch service",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "opensearch",
        "opensearch service",
        "graviton",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-4c5f420d9248",
      "title": "Amazon OpenSearch Service now supports storage optimized  i7i  instances",
      "description": "Amazon OpenSearch Service now supports latest generation x86 based high performance Storage Optimized i7i instances. Powered by 5th generation Intel Xeon Scalable processors, I7i instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances.\n  I7i instances have 3rd generation AWS Nitro SSDs with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances. Built on the AWS Nitro System, these instances oﬄoad CPU virtualization, storage, and networking functions to dedicated hardware and software enhancing the performance and security for your workloads.\n  Amazon OpenSearch Service supports i7i instances in following AWS Regions US East (N. Virginia, Ohio), US West (N. California, Oregon), Canada (Central), Canada West (Calgary), Europe (Frankfurt, Ireland, London, Milan, Spain, Stockholm, Zurich ), Africa (Cape Town), Asia Pacific (Hong Kong, Hyderabad, Jakarta, Malaysia, Melbourne, Mumbai, Osaka, Seoul, Singapore, Sydney, Tokyo), Middle East (UAE), South America (São Paulo) & AWS GovCloud (US-West).\n  For region specific availability & pricing, visit our pricing page. To learn more about Amazon OpenSearch Service and its capabilities, visit our product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-opensearch-service-supports-i7i-instances",
      "pubDate": "2026-02-18T04:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-e96c2723cd22",
      "title": "Amazon EC2 R8i and R8i-flex instances are now available in Europe (Ireland) region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8i and R8i-flex instances are available in the Europe (Ireland) region. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. The R8i and R8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver 20% higher performance than R7i instances, with even higher gains for specific workloads. They are up to 30% faster for PostgreSQL databases, up to 60% faster for NGINX web applications, and up to 40% faster for AI deep learning recommendation models compared to R7i.\n  R8i-flex, our first memory-optimized Flex instances, are the easiest way to get price performance benefits for a majority of memory-intensive workloads. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  R8i instances are a great choice for all memory-intensive workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. R8i instances offer 13 sizes including 2 bare metal sizes and the new 96xlarge size for the largest applications. R8i instances are SAP-certified and deliver 142,100 aSAPS, delivering exceptional performance for mission-critical SAP workloads.\n  To get started, sign in to the AWS Management Console. For more information about the R8i and R8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-r8i-r8i-flex-instances-DUB-region/",
      "pubDate": "2026-02-17T23:45:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-42bc4e753a25",
      "title": "Amazon Bedrock reinforcement fine-tuning adds support for open-weight models with OpenAI-compatible APIs",
      "description": "Amazon Bedrock now extends reinforcement fine-tuning (RFT) support to popular open-weight models, including OpenAI GPT-OSS and Qwen models, and introduces OpenAI-compatible fine-tuning APIs. These capabilities make it easier for developers to improve open-weight model accuracy without requiring deep machine learning expertise or large volumes of labeled data. Reinforcement fine-tuning in Amazon Bedrock automates the end-to-end customization workflow, allowing models to learn from feedback on multiple possible responses using a small set of prompts, rather than traditional large training datasets. Reinforcement fine-tuning enables customers to use smaller, faster, and more cost-effective model variants while maintaining high quality.\n  Organizations often struggle to adapt foundation models to their unique business requirements, forcing tradeoffs between generic models with limited performance and complex, expensive customization pipelines that require specialized infrastructure and expertise. Amazon Bedrock removes this complexity by providing a fully managed, secure reinforcement fine-tuning experience. Customers define reward functions using verifiable rule-based graders or AI-based judges, including built-in templates for both objective tasks such as code generation and math reasoning, and subjective tasks such as instruction following or conversational quality. During training, customers can use AWS Lambda functions for custom grading logic, and access intermediate model checkpoints to evaluate, debug, and select the best-performing model, improving iteration speed and training efficiency. All proprietary data remains within AWS’s secure, governed environment throughout the customization process.\n  Models supported at this launch are: qwen.qwen3-32b and openai.gpt-oss-20b. After fine-tuning completes, customers can immediately use the resulting fine tuned model for on-demand inference through Amazon Bedrock’s OpenAI-compatible APIs - Responses API and Chat Completions API, without any additional deployment steps. To learn more, see the Amazon Bedrock documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-reinforcement-fine-tuning-openai",
      "pubDate": "2026-02-17T21:17:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "lambda",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "lambda",
        "organizations",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-0741cca3886c",
      "title": "Amazon Aurora MySQL 3.12 (compatible with MySQL 8.0.44) is now generally available",
      "description": "Starting today, Amazon Aurora MySQL - Compatible Edition 3 (with MySQL 8.0 compatibility) will support MySQL 8.0.44 through Aurora MySQL v3.12.\n  In addition to many security enhancements and bug fixes, Aurora MySQL v3.12 contains several availability improvements. For more details, refer to the Aurora MySQL 3.12 and MySQL 8.0.44 release notes. To upgrade to Aurora MySQL 3.12, you can initiate a minor version upgrade manually by modifying your DB cluster, or you can enable the “Auto minor version upgrade” option when creating or modifying a DB cluster. This release is available in all AWS regions where Aurora MySQL is available.\n  Amazon Aurora is designed for unparalleled high performance and availability at global scale with full MySQL and PostgreSQL compatibility. It provides built-in security, continuous backups, serverless compute, up to 15 read replicas, automated multi-Region replication, and integrations with other Amazon Web Services services. To get started with Amazon Aurora, take a look at our getting started page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-aurora-mysql-312-available/",
      "pubDate": "2026-02-17T20:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "improvement",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-892f4e62054e",
      "title": "Introducing Agent Plugins for AWS",
      "description": "Deploying applications to AWS typically involves researching service options, estimating costs, and writing infrastructure-as-code tasks that can slow down development workflows. Agent plugins extend coding agents with specialized skills, enabling them to handle these AWS-specific tasks directly within your development environment. Today, we’re announcing Agent Plugins for AWS (Agent Plugins), an open source repository of […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-agent-plugins-for-aws/",
      "pubDate": "2026-02-17T19:13:25.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": []
    },
    {
      "id": "aws-news-fce7e3d09543",
      "title": "Amazon Connect now includes agent time-off requests in draft schedules",
      "description": "Amazon Connect now includes agent time-off requests in draft schedules, making it easier for you to view why an agent was not scheduled on a particular day or part of the day. For example, when generating schedules for next month, you can see that an agent who typically works Monday to Friday wasn't scheduled for the first week because they're on leave without needing to check the published schedules or troubleshooting configuration as to why agent was not scheduled. This launch helps schedulers quickly identify coverage gaps and adjust schedules before publishing them to agents.\n  This feature is available in all AWS Regions where Amazon Connect agent scheduling is available. To learn more about Amazon Connect agent scheduling, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/02/amazon-connect-time-off-draft-schedules",
      "pubDate": "2026-02-17T18:50:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-e5005a6f8779",
      "title": "Amazon Managed Service for Apache Flink application lifecycle management with Terraform",
      "description": "In this post, you’ll learn how to use Terraform to automate and streamline your Apache Flink application lifecycle management on Amazon Managed Service for Apache Flink. We’ll walk you through the complete lifecycle including deployment, updates, scaling, and troubleshooting common issues. This post builds upon our two-part blog series “Deep dive into the Amazon Managed Service for Apache Flink application lifecycle\".",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-managed-service-for-apache-flink-application-lifecycle-management-with-terraform/",
      "pubDate": "2026-02-17T17:49:36.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-6198fe4bbf23",
      "title": "Build a data pipeline from Google Search Console to Amazon Redshift using AWS Glue",
      "description": "In this post, we explore how AWS Glue extract, transform, and load (ETL) capabilities connect Google applications and Amazon Redshift, helping you unlock deeper insights and drive data-informed decisions through automated data pipeline management. We walk you through the process of using AWS Glue to integrate data from Google Search Console and write it to Amazon Redshift.",
      "link": "https://aws.amazon.com/blogs/big-data/build-a-data-pipeline-from-google-search-console-to-amazon-redshift-using-aws-glue/",
      "pubDate": "2026-02-17T17:48:25.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift",
        "glue"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "redshift",
        "glue"
      ]
    },
    {
      "id": "aws-news-8f5cee2fa771",
      "title": "Amazon Connect now supports multi-line text fields on case templates",
      "description": "Amazon Connect now supports larger, multi-line text fields on case templates allowing agents to capture detailed free-form notes and structured data directly within cases. These fields expand vertically to accommodate multiple paragraphs, making it easier to document root cause analysis, transaction details, investigation findings, or customer-facing updates.\n  Amazon Connect Cases is available in the following AWS regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town) AWS regions. To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-cases-multiline-text-fields/",
      "pubDate": "2026-02-17T17:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-383e9c5a8202",
      "title": "Amazon EC2 C8a instances now available in the Europe (Frankfurt) and Europe (Ireland) region",
      "description": "Starting today, the compute-optimized Amazon EC2 C8a instances are available in the Europe (Frankfurt) and Europe (Ireland) regions. C8a instances are powered by 5th Gen AMD EPYC processors (formerly code named Turin) with a maximum frequency of 4.5 GHz, delivering up to 30% higher performance and up to 19% better price-performance compared to C7a instances.\n  C8a instances deliver 33% more memory bandwidth compared to C7a instances, making these instances ideal for latency sensitive workloads. Compared to Amazon EC2 C7a instances, they are up to 57% faster for GroovyJVM allowing better response times for Java-based applications. C8a instances offer 12 sizes including 2 bare metal sizes. This range of instance sizes allows customers to precisely match their workload requirements.\n  C8a instances are built on AWS Nitro System and are ideal for high performance, compute-intensive workloads such as batch processing, distributed analytics, high performance computing (HPC), ad serving, highly-scalable multiplayer gaming, and video encoding.\n  To get started, sign in to the AWS Management Console. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information visit the Amazon EC2 C8a instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8a-instances-europe-frankfurt-europe-ireland-regions",
      "pubDate": "2026-02-17T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-2fec70e32e81",
      "title": "Amazon MSK now supports dual-stack (IPv4 and IPv6) connectivity for existing clusters",
      "description": "Amazon Managed Streaming for Apache Kafka (Amazon MSK) now supports dual-stack connectivity (IPv4 and IPv6) for existing MSK Provisioned and MSK Serverless clusters. This capability enables customers to connect to Amazon MSK using both IPv4 and IPv6 protocols, in addition to the existing IPv4-only option. It helps customers modernize applications for IPv6 environments while maintaining IPv4 compatibility, making it easier to meet compliance requirements and prepare for future network architectures.\n  Amazon MSK is a fully managed service for Apache Kafka that makes it easier for customers to build and run applications that use Apache Kafka as a data store. Previously, MSK Provisioned and Serverless clusters exclusively utilized IPv4 addressing for all connectivity options. With this new capability, customers can now enable dual-stack connectivity (IPv4 and IPv6) on existing MSK clusters using Amazon MSK Console, AWS CLI, SDK, or CloudFormation by modifying the Network Type parameter for a cluster from IPv4 to dual-stack. Upon successful update, MSK provisions IPv6-enabled network interfaces while maintaining existing IPv4 connectivity, ensuring uninterrupted service. To retrieve new IPv6 bootstrap broker strings for MSK clusters, customers can use the GetBootstrapBrokers API to obtain the necessary connection information. All MSK Provisioned and Serverless clusters will retain IPv4-only connectivity unless explicitly updated.\n  Dual-stack connectivity for existing MSK Provisioned and Serverless clusters is now available in all AWS Regions where Amazon MSK is available, at no additional cost. To learn more about Amazon MSK dual-stack support, refer to the Amazon MSK developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-msk-dual-stack-ipv4-and-ipv6",
      "pubDate": "2026-02-17T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "kafka",
        "msk"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudformation",
        "kafka",
        "msk",
        "now-available",
        "update",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-d55a123294c6",
      "title": "Claude Sonnet 4.6 now available in Amazon Bedrock",
      "description": "Starting today, Amazon Bedrock supports Claude Sonnet 4.6, which offers frontier performance across coding, agents, and professional work at scale. According to Anthropic, Claude Sonnet 4.6 is their best computer use model yet, allowing organizations to deploy browser-based automation across business tools with near-human reliability. Claude Sonnet 4.6 approaches Opus 4.6 intelligence at a lower cost. It enables faster, high-quality task completion, making it ideal for high-volume coding and knowledge work use cases. \n \n \n \nClaude Sonnet 4.6 serves as a direct upgrade to Sonnet 4.5 across use cases that require consistent conversational quality and efficient multi-step orchestration. For search and chat applications, it delivers reliable performance across single and multi-turn exchanges at a price point that makes high-volume deployment practical, maintaining quality standards while optimizing for scale. Developers can leverage Claude Sonnet 4.6’s for agentic workflows, seamlessly filling both lead agent and subagent roles in multi-model pipelines with precise workflow management and context compaction capabilities. Enterprise teams can use Claude Sonnet 4.6 to power domain-specific applications with professional precision, including spreadsheet and financial model creation that accelerates analysis workflows, compliance review processes that require meticulous attention to detail, and data summarization tasks where iteration speed and accuracy are paramount. Claude Sonnet 4.6 requires only minor prompting adjustments from Sonnet 4.5, ensuring smooth migration for existing implementations. \n \n \n \nClaude Sonnet 4.6 is now available in Amazon Bedrock. For the full list of available regions, refer to the documentation. To learn more and get started with Claude Sonnet 4.6 in Amazon Bedrock, read the About Amazon blog and visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/claude-sonnet-4.6-available-in-amazon-bedrock/",
      "pubDate": "2026-02-17T15:43:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "rds",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "rds",
        "organizations",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-aa80f8ab4dc6",
      "title": "AWS Tools Installer V2 Preview",
      "description": "We are excited to offer a preview of AWS Tools Installer V2 which addresses customer feedback for faster and more reliable bulk installation of AWS Tools for PowerShell modules.",
      "link": "https://aws.amazon.com/blogs/developer/aws-tools-installer-v2-preview/",
      "pubDate": "2026-02-17T00:28:42.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-9698c9ec38ce",
      "title": "Amazon EC2 Hpc8a Instances powered by 5th Gen AMD EPYC processors are now available",
      "description": "Amazon EC2 Hpc8a instances, powered by 5th Gen AMD EPYC processors, deliver up to 40% higher performance, increased memory bandwidth, and 300 Gbps Elastic Fabric Adapter networking, helping customers accelerate compute-intensive simulations, engineering workloads, and tightly coupled HPC applications.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-ec2-hpc8a-instances-powered-by-5th-gen-amd-epyc-processors-are-now-available/",
      "pubDate": "2026-02-16T23:12:37.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a7709e940494",
      "title": "AWS HealthImaging launches additional metrics for monitoring data stores",
      "description": "AWS HealthImaging has launched additional metrics through Amazon CloudWatch that enable monitoring storage at the account and data store levels. These new metrics help customers better understand their medical imaging storage and growth trends over time.\n  HealthImaging now provides customers with granular CloudWatch metrics to monitor their data stores. Customers can track storage by volume, number of image sets, and the number of DICOM studies, series, and instances. These metrics provide the insights needed to manage both single-tenant and multi-tenant workloads at petabyte scale. To learn more, visit Using Amazon CloudWatch with HealthImaging.\n  AWS HealthImaging is a HIPAA-eligible service that empowers healthcare providers and their software partners to store, analyze, and share medical images. AWS HealthImaging is generally available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-healthimaging-additional-metrics/",
      "pubDate": "2026-02-16T22:38:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudwatch",
        "launch",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-c4a04b172090",
      "title": "Announcing new high performance computing Amazon EC2 Hpc8a instances",
      "description": "AWS announces Amazon EC2 Hpc8a instances, the next generation of high performance computing optimized instance, powered by 5th Gen AMD EPYC processors (formerly code named Turin). With a maximum frequency of 4.5GHz, Hpc8a instances deliver up to 40% higher performance and up to 25% better price performance compared to Hpc7a instances, helping customers accelerate compute-intensive workloads while optimizing costs.\n  \n Built on the latest sixth-generation AWS Nitro Cards, Hpc8a instances are designed for compute-intensive, latency-sensitive HPC workloads. They are ideal for tightly coupled applications such as computational fluid dynamics (CFD), weather forecasting, explicit finite element analysis (FEA), and multiphysics simulations that require fast inter-node communication and consistent high performance.\n  Hpc8a instances feature 192 cores, 768 GiB memory and 300 Gbps of Elastic Fabric Adapter (EFA) network bandwidth, enabling fast, low-latency cluster scaling for large-scale HPC workloads. Compared to Hpc7a instances, Hpc8a instances also provide up to 42% higher memory bandwidth, further improving performance for memory-intensive simulations and scientific computing workloads.\n  Hpc8a instances are available today in US East (Ohio) and Europe (Stockholm). Customers can purchase Hpc8a instances via Savings Plans or On-Demand instances. To get started, sign in to the AWS Management Console. For more information visit the Amazon EC2 Hpc8a instance page or AWS news blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/announcing-amazon-ec2-hpc8a-instances/",
      "pubDate": "2026-02-16T21:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "forecast",
        "ec2",
        "rds"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "forecast",
        "ec2",
        "rds"
      ]
    },
    {
      "id": "aws-news-1ad7f754b385",
      "title": "Announcing Amazon SageMaker Inference for custom Amazon Nova models",
      "description": "AWS launches Amazon SageMaker Inference for custom Amazon Nova models. You can now configure the instance types, auto-scaling policies, and concurrency settings for custom Nova model deployments to best meet their needs.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-inference-for-custom-amazon-nova-models/",
      "pubDate": "2026-02-16T21:25:23.000Z",
      "source": "newsBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "launch"
      ]
    },
    {
      "id": "aws-news-8c012d5af99e",
      "title": "Announcing Amazon DocumentDB long-term support (LTS) on 5.0",
      "description": "Starting today, Amazon DocumentDB (with MongoDB compatibility) offers Long-Term Support (LTS) on DocumentDB 5.0, enabling customers to reduce database upgrade frequency and maintenance overhead. LTS versions will receive only critical stability and security patches without introducing new features.\n  To get started, create a new DocumentDB cluster engine version 5.0.0, or patch your existing engine version 5.0.0 cluster during your next maintenance window. Verify you're running the required Engine Patch Version by connecting to your cluster and running db.runCommand({getEngineVersion: 1}). Ensure you're running Engine Patch Version 3.0.17983 or later.\n  This LTS release is available in all Amazon Web Services regions where DocumentDB is offered. For more details about DocumentDB LTS, and how to check to see what engine patch version you’re on, refer to the Long-Term Support (LTS) release for Amazon DocumentDB.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/announcing-amazon-documentdb-5-0-long-term-support",
      "pubDate": "2026-02-16T19:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-dc0ca48d2f86",
      "title": "Verisk cuts processing time and storage costs with Amazon Redshift and lakehouse",
      "description": "Verisk, a catastrophe modeling SaaS provider serving insurance and reinsurance companies worldwide, cut processing time from hours to minutes-level aggregations while reducing storage costs by implementing a lakehouse architecture with Amazon Redshift and Apache Iceberg. If you’re managing billions of catastrophe modeling records across hurricanes, earthquakes, and wildfires, this approach eliminates the traditional compute-versus-cost trade-off by separating storage from processing power. In this post, we examine Verisk’s lakehouse implementation, focusing on four architectural decisions that delivered measurable improvements.",
      "link": "https://aws.amazon.com/blogs/big-data/verisk-cuts-processing-time-and-storage-costs-with-amazon-redshift-and-lakehouse/",
      "pubDate": "2026-02-16T18:10:44.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "redshift",
        "rds",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-41daa9042379",
      "title": "Amazon OpenSearch Service 101: T-shirt size your domain for e-commerce search",
      "description": "While general sizing guidelines for OpenSearch Service domains are covered in detail in OpenSearch Service documentation, in this post we specifically focus on T-shirt-sizing OpenSearch Service domains for e-commerce search workloads. T-shirt sizing simplifies complex capacity planning by categorizing workloads into sizes like XS, S, M, L, XL based on key workload parameters such as data volume and query concurrency.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-opensearch-service-101-t-shirt-size-your-domain-for-e-commerce-search/",
      "pubDate": "2026-02-16T18:09:35.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-54e6be67a9ef",
      "title": "AWS Weekly Roundup: Amazon EC2 M8azn instances, new open weights models in Amazon Bedrock, and more (February 16, 2026)",
      "description": "I joined AWS in 2021, and since then I’ve watched the Amazon Elastic Compute Cloud (Amazon EC2) instance family grow at a pace that still surprises me. From AWS Graviton-powered instances to specialized accelerated computing options, it feels like every few months there’s a new instance type landing that pushes performance boundaries further. As of […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ec2-m8azn-instances-new-open-weights-models-in-amazon-bedrock-and-more-february-16-2026/",
      "pubDate": "2026-02-16T17:28:52.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "ec2",
        "graviton"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "ec2",
        "graviton"
      ]
    },
    {
      "id": "aws-news-6c4b40553766",
      "title": "AWS Glue 5.1 is now available in 18 additional regions",
      "description": "AWS Glue 5.1 is now available in eighteen additional AWS Regions: Africa (Cape Town), Asia Pacific (Hyderabad, Jakarta, Melbourne, Osaka, Seoul, Taipei), Canada (Calgary, Central), Europe (London, Milan, Paris, Zurich), Israel (Tel Aviv), Mexico (Central), Middle East (Bahrain, UAE), and US West (N. California).\n \nAWS Glue is a serverless, scalable data integration service that simplifies discovering, preparing, moving, and integrating data from multiple sources. AWS Glue 5.1 upgrades core engines to Apache Spark 3.5.6, Python 3.11, and Scala 2.12.18, bringing performance and security enhancements. It also updates support for open table format libraries, including Apache Hudi 1.0.2, Apache Iceberg 1.10.0, and Delta Lake 3.3.2. Additionally, AWS Glue 5.1 introduces support for Apache Iceberg format version 3.0, adding default column values, deletion vectors for merge-on-read tables, multi-argument transforms, and row lineage tracking. This release also extends AWS Lake Formation fine-grained access control to write operations (both DML and DDL) for Spark DataFrames and Spark SQL. Previously, this capability was limited to read operations only. AWS Glue 5.1 also adds full-table access control in Apache Spark for Apache Hudi and Delta Lake tables, providing more comprehensive security options for your data.\n  With this expansion, AWS Glue 5.1 is now available in thirty-three AWS Regions.\n \nYou can get started with AWS Glue 5.1 using AWS Glue APIs, AWS Command Line Interface (CLI), AWS Software Development Kit (SDK), AWS Glue Studio, or Amazon SageMaker Unified Studio. To learn more, visit the AWS Glue product page and our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-glue-5-1-eighteen-additional-regions",
      "pubDate": "2026-02-16T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "glue"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "glue",
        "ga",
        "now-available",
        "update",
        "enhancement",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-967466177807",
      "title": "Amazon EC2 M7i instances are now available in the Israel (Tel Aviv) Region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) M7i instances powered by custom 4th Gen Intel Xeon Scalable processors (code-named Sapphire Rapids) are available in the Israel (Tel Aviv) region. These custom processors, available only on AWS, offer up to 15% better performance over comparable x86-based Intel processors utilized by other cloud providers.\n  M7i deliver up to 15% better price-performance compared to M6i. M7i instances are a great choice for workloads that need the largest instance sizes or continuous high CPU usage, such as gaming servers, CPU-based machine learning (ML), and video-streaming. M7i offer larger instance sizes, up to 48xlarge, and two bare metal sizes (metal-24xl, metal-48xl). These bare-metal sizes support built-in Intel accelerators: Data Streaming Accelerator, In-Memory Analytics Accelerator, and QuickAssist Technology that are used to facilitate efficient offload and acceleration of data operations and optimize performance for workloads.\n  To learn more, visit Amazon EC2 M7i Instances. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-m7i-israel-tel-aviv-regions",
      "pubDate": "2026-02-16T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-a41a75592569",
      "title": "AWS Backup announces PrivateLink support for SAP HANA on AWS",
      "description": "AWS Backup now supports AWS PrivateLink for SAP HANA systems running on Amazon EC2. This enables customers to route all backup traffic through private network connections without traversing the public internet, helping organizations meet security and compliance requirements for regulated workloads.\n \nCustomers in regulated industries such as financial services, healthcare, and government agencies often require that all traffic remain on private networks. Previously, while SAP HANA application workloads could use AWS PrivateLink for secure, private communication with AWS services, backup traffic to AWS Backup had to traverse public endpoints. With this release, you can now use AWS PrivateLink for AWS Backup storage endpoints, ensuring your SAP HANA workloads on EC2 maintain end-to-end private connectivity for both application traffic and backup data. This helps organizations subject to HIPAA, EU/US Privacy Shield, and PCI DSS regulations implement fully private data protection strategies.\n \nThis feature is available in all AWS Regions where AWS Backup supports SAP HANA databases on EC2. To get started, update your Backint agent and add the backup-storage VPCE to your VPC.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-announces-privatelink-sap-hana-aws/",
      "pubDate": "2026-02-16T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-1e249c19f8e8",
      "title": "Kiro is now available in AWS GovCloud (US) Regions",
      "description": "Kiro brings agentic AI development capabilities to workloads with elevated compliance needs in AWS GovCloud (US-East) and AWS GovCloud (US-West) Regions. Kiro is an agentic AI with an integrated development environment (IDE) and command-line interface (CLI) that helps you go from prototype to production with spec-driven development. From simple to complex tasks, Kiro works alongside you to turn prompts into detailed specs, then into working code, docs, and tests—so what you build is exactly what you want and ready to share with your team.\n  Kiro's agents help you solve challenging problems and automate tasks like generating documentation and unit tests. With native Model Context Protocol (MCP) support, Kiro connects to documentation, databases, APIs, and other enterprise resources, providing capability for mission-critical development workflows.\n  Kiro in AWS GovCloud (US) Regions uses enterprise authentication via AWS IAM Identity Center. To learn more about building with Kiro in AWS GovCloud (US), read the blog post. For more details about Kiro in AWS GovCloud (US), visit the GovCloud documentation or contact your AWS account team for more information. To learn more about Kiro, visit the Kiro product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/kiro-launch-aws-govcloud-us/",
      "pubDate": "2026-02-16T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ecs",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ecs",
        "iam",
        "iam identity center",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-9ac22c4b7599",
      "title": "Amazon EC2 supports nested virtualization on virtual Amazon EC2 instances",
      "description": "Starting today, customers can create nested environments within virtualized Amazon EC2 instances. Previously, customers could only create and manage virtual machines inside bare metal EC2 instances. With this launch, customers can create nested virtual machines by running KVM or Hyper-V on virtual EC2 instances. Customers can leverage this capability for use cases such as running emulators for mobile applications, simulating in-vehicle hardware for automobiles, and running Windows Subsystem for Linux on Windows workstations.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-nested-virtualization-on-virtual",
      "pubDate": "2026-02-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-190fdcd4ca2e",
      "title": "Amazon EC2 High Memory U7i instances now available in additional regions",
      "description": "Amazon EC2 High Memory instances are now available in new regions - U7i-6tb.112xlarge instances in AWS South America (Sao Paulo) and Europe (Milan), U7i-12tb.224xlarge in AWS GovCloud (US-East), and U7in-16tb.224xlarge instances in Europe (London). U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TiB of DDR5 memory, U7i-12tb instances offer 12TiB of DDR5 memory, and U7in-16tb instances offer 16TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs and support up to 100Gbps Elastic Block Storage (EBS) and deliver up to 100Gbps of network bandwidth. U7i-12tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) and deliver up to 100Gbps of network bandwidth. U7in-16tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) and deliver up to 200Gbps of network bandwidth for faster data loading and backups. All U7i instances support ENA Express. \n \nU7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-highmem-instances-available/",
      "pubDate": "2026-02-13T23:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-354bc14bf132",
      "title": "Customize AI agent browsing with proxies, profiles, and extensions in Amazon Bedrock AgentCore Browser",
      "description": "Today, we are announcing three new capabilities that address these requirements: proxy configuration, browser profiles, and browser extensions. Together, these features give you fine-grained control over how your AI agents interact with the web. This post will walk through each capability with configuration examples and practical use cases to help you get started.",
      "link": "https://aws.amazon.com/blogs/machine-learning/customize-ai-agent-browsing-with-proxies-profiles-and-extensions-in-amazon-bedrock-agentcore-browser/",
      "pubDate": "2026-02-13T22:57:34.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-d8aeb689a1ea",
      "title": "Common streaming data enrichment patterns in Amazon Managed Service for Apache Flink",
      "description": "This post was originally published in March 2024 and updated in February 2026. Stream data processing allows you to act on data in real time. Real-time data analytics can help you have on-time and optimized responses while improving overall customer experience. Apache Flink is a distributed computation framework that allows for stateful real-time data processing. It […]",
      "link": "https://aws.amazon.com/blogs/big-data/common-streaming-data-enrichment-patterns-in-amazon-managed-service-for-apache-flink/",
      "pubDate": "2026-02-13T19:46:16.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-6f3849266f26",
      "title": "AWS Batch now provides Job Queue and Share Utilization Visibility",
      "description": "AWS Batch now provides Queue and Share Utilization Visibility, giving you insights into how your workloads are distributed across compute resources. This feature introduces queue utilization data in job queue snapshots, revealing compute capacity used by your first-in-first-out (FIFO) and fair share job queues, along with capacity consumption by individual fair share allocations. Additionally, the ListServiceJobs API now includes a scheduledAt timestamp for AWS Batch service jobs, allowing you to track when jobs are scheduled for execution.\n  Queue and Share Utilization Visibility helps you understand which fair-share allocations consume the most capacity and pinpoint the specific jobs driving resource consumption. You can monitor overall queue utilization and drill down into active shares to optimize resource distribution, or filter jobs by share identifier to analyze consumption patterns and scheduling behavior across your workloads.\n  You can access this feature using the GetJobQueueSnapshot, ListJobs, and ListServiceJobs APIs, or through the AWS Batch Management Console by navigating to your job queue details page and selecting the new Share Utilization tab. This feature is available today in all AWS Regions where AWS Batch is available. To learn more, visit the Job Queue Snapshot, List Jobs, and List Service Jobs pages of the AWS Batch API Reference Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-batch-provides-job-queue-share-utilization",
      "pubDate": "2026-02-13T17:30:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-426c2cf99ac0",
      "title": "Amazon Connect launches in-app notifications to surface critical operational alerts to business users",
      "description": "Amazon Connect now supports in-app notifications in the workspace header, visible from any page, so your team can stay informed without interrupting their workflow— whether configuring, analyzing data, or servicing customers. A notification icon appears in the header of every workspace page, with a badge indicating unread messages. Click the icon to view messages, access relevant resources through embedded links, and manage read/unread status—all without navigating away from your current task. For example, if all supervisors need to complete a certain training by end of week, a notification can be published to non-compliant users to remind them.\n  The new notification APIs enable you to programmatically send targeted messages to specific audiences within your organization, ensuring teams stay aware of urgent updates, policy changes, and action items requiring immediate attention. Amazon Connect will also leverage this capability to deliver system updates and important announcements.\n  In-app notifications are available in all AWS regions where Amazon Connect is available and offer public API and AWS CloudFormation support. To learn more about in-app notifications, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-in-app-notifications",
      "pubDate": "2026-02-13T17:20:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudformation",
        "launch",
        "ga",
        "update",
        "support",
        "announcement"
      ]
    },
    {
      "id": "aws-news-86a52dfe7164",
      "title": "Amazon Connect now provides real time AI-powered overviews and recommended next actions for Tasks",
      "description": "Amazon Connect now provides AI-powered Task overviews with suggested next actions so agents can understand work items faster and resolve them more quickly. For example, when an agent receives a Task to process a refund request submitted through an online form, Amazon Connect summarizes earlier activities such as verifying order details, checking return eligibility, and confirming the payment method, and then presents recommended next steps to complete the refund.\n  To enable this feature, add the Connect assistant flow block to your flows before a Task contact is assigned to your agent. You can guide the recommendations of your generative AI-powered Tasks assistant by adding knowledge bases.\n  This new feature is available in all AWS regions where Amazon Connect real time agent assistance is available. To learn more and get started, refer to the help documentation, pricing page, or visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/connect-tasks-ai-assistance",
      "pubDate": "2026-02-13T17:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-32455357f2c9",
      "title": "Amazon RDS now supports backup configuration when restoring snapshots",
      "description": "Amazon Relational Database Service (RDS) and Amazon Aurora now offer greater flexibility for restore operations to view and modify backup retention period and preferred backup window prior to and upon restoring database snapshots. The backup retention period lets you specify how many days backups are retained, while the preferred backup window allows you to set your desired backup schedule.\n  Previously, restored database instances and clusters inherited backup parameter values from snapshot metadata and could only be modified after restore was complete. This launch introduces two enhancements - you can now view the backup retention period and preferred backup window settings as part of automated backups and snapshots, providing visibility into backup configurations before initiating restore operation. Additionally, you can now specify or modify the backup retention period and preferred backup window when restoring database instances and clusters, eliminating the need to modify the instance or cluster after restoration.\n  These enhancements are available for all Amazon RDS database engines (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, and DB2) and Amazon Aurora (MySQL-Compatible and PostgreSQL-Compatible editions) in all AWS commercial regions and AWS GovCloud (US) regions where RDS and Aurora are supported and respective database engines are available. You can use these features through the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs at no additional cost. For more information, see Amazon RDS and Amazon Aurora User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-aurora-backup-configuration-restoring-snapshots/",
      "pubDate": "2026-02-13T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "launch",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-c19f2f91df70",
      "title": "Announcing Amazon EC2 C8i, M8i, and R8i instances on second-generation AWS Outposts racks",
      "description": "AWS is announcing local support for the latest generation of x86-powered Amazon EC2 instances on second-generation AWS Outposts racks, including C8i compute-optimized instances, M8i general-purpose instances, and R8i memory-optimized instances. These new instances deliver 20% better performance and 2.5x more memory bandwidth compared to the C7i, M7i, and R7i instances on second-generation Outposts racks. In addition, C8i, M8i, and R8i instances on second-generation Outposts racks deliver 20% more compute capacity than C7i, M7i, and R7i instances within the same rack space and power draw, enabling better space and energy efficiency for your on-premises workloads.\n  C8i, M8i, and R8i instances on second-generation Outposts racks are powered by custom Intel Xeon 6 processors available only on AWS and are ideal for a broad range of on-premises workloads requiring enhanced performance, such as larger databases, more memory-intensive applications, advanced real-time big data analytics, high-performance video encoding and streaming, and CPU-based edge inference with more sophisticated machine learning (ML) models.\n  To learn more about second-generation Outposts racks, refer to the Outposts racks product page and the user guide. For the most updated list of countries and territories and the AWS Regions where second-generation Outposts racks are supported, check out the Outposts rack FAQs page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8i-m8i-and-r8i-instances-on-aws-outposts/",
      "pubDate": "2026-02-12T22:34:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "outposts"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "outposts",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-86e8f3e987b4",
      "title": "Amazon Bedrock adds support for the latest open-weight models in Asia Pacific (Sydney)",
      "description": "Amazon Bedrock is a fully managed service that provides secure, enterprise-grade access to high-performing foundation models from leading AI companies, enabling you to build and scale generative AI applications. Today, Amazon Bedrock announced support for the latest open-weight models in Asia Pacific (Sydney) using both the bedrock-runtime and the bedrock-mantle endpoint. These include models from industry-leading providers, including DeepSeek, Google, MiniMax, Mistral, Moonshot AI, MiniMax, Nvidia, and OpenAI. The bedrock-runtime endpoint provides Region-specific endpoints for making inference requests for models hosted in Amazon Bedrock using the InvokeModel/Converse/Chat Completions APIs. The bedrock-mantle endpoint provides Region-specific endpoints for making inference requests for models hosted in Amazon Bedrock using the OpenAI-compatible endpoints. It is powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. \n \n\n To learn more and get started, visit the Amazon Bedrock console or the Amazon Bedrock service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-support-latest-open-weight-models-asia-pacific-sydney/",
      "pubDate": "2026-02-12T22:14:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "support"
      ]
    },
    {
      "id": "aws-news-e68e4d57a409",
      "title": "Amazon S3 Access Grants are now available in the AWS Asia Pacific (Taipei) Region",
      "description": "You can now create Amazon S3 Access Grants in the AWS Asia Pacific (Taipei) Region.\n \nAmazon S3 Access Grants map identities in directories such as Microsoft Entra ID, or AWS Identity and Access Management (IAM) principals, to datasets in S3. This helps you manage data permissions at scale by automatically granting S3 access to end users based on their corporate identity.\n \nVisit the AWS Region Table for complete regional availability information. To learn more about Amazon S3 Access Grants, visit our product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-s3-access-grants-are-available-in-taipei",
      "pubDate": "2026-02-12T21:47:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "iam",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a0fbcc6e4099",
      "title": "Amazon Bedrock expands support for AWS PrivateLink",
      "description": "Amazon Bedrock is a fully managed service that provides secure, enterprise-grade access to high-performing foundation models from leading AI companies. It enables you to build and scale generative AI applications. Amazon Bedrock already supported AWS PrivateLink for the bedrock-runtime endpoint. Now, with this launch, you can also use AWS PrivateLink to privately access your applications using the bedrock-mantle endpoint. The bedrock-mantle endpoint is powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock. It provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and delivers out-of-the-box compatibility with OpenAI API specifications.\n \nAWS PrivateLink support for OpenAI API-compatible endpoints is available in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Jakarta), Asia Pacific (Tokyo), Asia Pacific (Mumbai), Asia Pacific (Sydney), South America (São Paulo), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Milan), Europe (Stockholm), and South America (Sao Paulo) AWS Regions. To learn more and get started, visit the Amazon Bedrock console or the Amazon Bedrock service documentation. To get started with Amazon Bedrock OpenAI API-compatible service endpoints, visit the OpenAI API compatibility documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-expands-aws-privatelink-support-openai-api-endpoints/",
      "pubDate": "2026-02-12T21:40:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "launch",
        "support",
        "new-model"
      ]
    },
    {
      "id": "aws-news-4ac2d5c3fee1",
      "title": "AI meets HR: Transforming talent acquisition with Amazon Bedrock",
      "description": "In this post, we show how to create an AI-powered recruitment system using Amazon Bedrock, Amazon Bedrock Knowledge Bases, AWS Lambda, and other AWS services to enhance job description creation, candidate communication, and interview preparation while maintaining human oversight.",
      "link": "https://aws.amazon.com/blogs/machine-learning/ai-meets-hr-transforming-talent-acquisition-with-amazon-bedrock/",
      "pubDate": "2026-02-12T20:18:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lambda"
      ]
    },
    {
      "id": "aws-news-5dc8f40dd93f",
      "title": "Build long-running MCP servers on Amazon Bedrock AgentCore with Strands Agents integration",
      "description": "In this post, we provide you with a comprehensive approach to achieve this. First, we introduce a context message strategy that maintains continuous communication between servers and clients during extended operations. Next, we develop an asynchronous task management framework that allows your AI agents to initiate long-running processes without blocking other operations. Finally, we demonstrate how to bring these strategies together with Amazon Bedrock AgentCore and Strands Agents to build production-ready AI agents that can handle complex, time-intensive operations reliably.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-long-running-mcp-servers-on-amazon-bedrock-agentcore-with-strands-agents-integration/",
      "pubDate": "2026-02-12T20:16:20.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "integration"
      ]
    },
    {
      "id": "aws-news-48e777b8ef81",
      "title": "AWS expands Resource Control Policies support to Amazon DynamoDB",
      "description": "AWS Resource Control Policies (RCPs) now support Amazon DynamoDB. RCPs are a type of organization policy that you can use to manage permissions in your organization. RCPs offer central control over the maximum available permissions for resources in your organization.\n \nWith this expansion, you can now use RCPs to manage permissions for Amazon DynamoDB. For example, you can create policies that prevent identities outside your organization from accessing DynamoDB, helping you build a data perimeter and enforce baseline security standards across your AWS environment.  \n \nRCPs are available in all AWS commercial Regions and AWS GovCloud (US) Regions. To learn more about RCPs and view the full list of supported AWS services, visit the Resource control policies (RCPs) documentation in the AWS Organizations User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-expands-resource-control-policies-amazon",
      "pubDate": "2026-02-12T20:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "dynamodb",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "dynamodb",
        "rds",
        "organizations",
        "ga",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-dc4b03f3c7f7",
      "title": "Amazon Bedrock increases default quotas for Anthropic’s Claude Sonnet 4.5 model in AWS GovCloud (US)",
      "description": "Amazon Bedrock has increased the default quotas for Anthropic’s Claude Sonnet 4.5 in AWS GovCloud (US-West) and AWS GovCloud (US-East) to 5,000,000 tokens per minute and 1,000 requests per minute, aligning with commercial AWS regions. This 25x increase enables customers to scale their AI workloads more effectively in regulated environments.\n Claude Sonnet 4.5 is Anthropic's latest Sonnet model, excelling at building complex agents, coding, and long-horizon tasks while maintaining optimal speed and cost-efficiency for high-volume use-cases.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-s4.5-quota-aws-govcloud-us",
      "pubDate": "2026-02-12T19:52:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex"
      ]
    },
    {
      "id": "aws-news-7e0632d6192f",
      "title": "AI Troubleshooting in the AWS Support Center Console now supports 7 additional languages",
      "description": "AI troubleshooting in the AWS Support Center Console is now available in seven languages in addition to English: Japanese, Korean, Mandarin (Simplified), Mandarin (Traditional), Spanish, Portuguese, French. AWS Support Center Console is the primary interface where customers manage their AWS support experience, including creating and tracking support cases. Previously, AI troubleshooting capabilities were only available in English, creating a barrier for customers who prefer to work in their native language. With this launch, customers can now interact with AI-powered troubleshooting assistance in their preferred language.\n  AWS Support's AI troubleshooting helps customers resolve issues faster by providing immediate, contextual recommendations while they create a support case. For example, a Japanese developer troubleshooting an EC2 connectivity issue can now receive AI-generated insights and potential solutions in Japanese, reducing the time needed to understand and implement fixes. This capability is seamlessly integrated into the support experience and is available to all customers regardless of support plan, ensuring that language is no longer a barrier to self-service support.\n  All customers regardless of support plan can access the experience by selecting a supported language in their console settings and clicking the “Try it now” link in the banner at the top of the AWS Support Center Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/ai-troubleshooting-in-aws-support-center/",
      "pubDate": "2026-02-12T18:39:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ec2",
        "launch",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-fc86dccc391a",
      "title": "Amazon RDS for PostgreSQL supports minor versions  18.2, 17.8, 16.12, 15.16 and 14.21",
      "description": "Amazon Relational Database Service (RDS) for PostgreSQL now supports the latest minor versions 18.2, 17.8, 16.12, 15.16, and 14.21. We recommend that you upgrade to the latest minor versions to fix known security vulnerabilities in prior versions of PostgreSQL, and to benefit from the bug fixes added by the PostgreSQL community. This release also includes new extension pg_stat_monitor that enables you to collect performance metrics and evaluate query performance insights in a unified view.\n  You can upgrade your databases during scheduled maintenance windows using automatic minor version upgrades. To simplify operations at scale, enable automatic minor version upgrades and use the AWS Organizations Upgrade Rollout Policy to orchestrate thousands of upgrades in phases, first to development environments before upgrading production systems. You can also use Amazon RDS Blue/Green deployments with physical replication to minimize downtime for minor version upgrades.\n  Amazon RDS for PostgreSQL makes it simple to set up, operate, and scale PostgreSQL deployments in the cloud. See Amazon RDS for PostgreSQL Pricing for pricing details and regional availability. Create or update a fully managed Amazon RDS database in the Amazon RDS Management Console or by using the AWS Command Line Interface (CLI).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-minor-version-18-2-17-8-16-12-15-16-14-21",
      "pubDate": "2026-02-12T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-88d55215552f",
      "title": "Amazon EC2 X8i instances are now available in Europe (Stockholm)",
      "description": "Amazon Web Services (AWS) is announcing the general availability of Amazon EC2 X8i instances, next-generation memory optimized instances powered by custom Intel Xeon 6 processors available only on AWS. X8i instances are SAP-certified and deliver the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. They deliver up to 43% higher performance, 1.5x more memory capacity (up to 6TB), and 3.3x more memory bandwidth compared to previous generation X2i instances.\n  X8i instances are designed for memory-intensive workloads like SAP HANA, large databases, data analytics, and Electronic Design Automation (EDA). Compared to X2i instances, X8i instances offer up to 50% higher SAPS performance, up to 47% faster PostgreSQL performance, 88% faster Memcached performance, and 46% faster AI inference performance. X8i instances come in 14 sizes, from large to 96xlarge, including two bare metal options.\n  X8i instances are available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Europe (Frankfurt) and Europe (Stockholm).\n  To get started, visit the AWS Management Console. X8i instances can be purchased via Savings Plans, On-Demand instances, and Spot instances. For more information visit X8i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-x8i-instances-ARN-region/",
      "pubDate": "2026-02-12T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-52a5cdfbb2f8",
      "title": "Announcing new Amazon EC2 general purpose M8azn instances",
      "description": "AWS is announcing the general availability of new Amazon EC2 M8azn instances, general purpose high-frequency high-network instances powered by fifth generation AMD EPYC (formerly code named Turin) processors, offering the highest maximum CPU frequency, 5GHz in the cloud. M8azn instances offer up to 2x compute performance compared to previous generation M5zn instances, and up to 24% higher performance than M8a instances.\n  M8azn instances deliver up to 4.3x higher memory bandwidth and 10x larger L3 cache compared to M5zn instances allowing latency-sensitive and compute-intensive workloads to achieve results faster. These instances also offer up to 2x networking throughput and up to 3x EBS throughput versus M5zn instances. Built on the AWS Nitro System using sixth generation Nitro Cards, these instances are ideal for applications such as real-time financial analytics, high-performance computing, high-frequency trading (HFT), CI/CD, intensive gaming, and simulation modeling for the automotive, aerospace, energy, and telecommunication industries. M8azn instances feature a 4:1 ratio of memory to vCPU and are available in 9 sizes ranging from 2 to 96 vCPUs with up to 384 GiB of memory, including two bare metal variants.\n  M8azn instances are available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Tokyo), and Europe (Frankfurt) Regions. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. To get started, sign in to the AWS Management Console. For more information visit the Amazon EC2 M8azn instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-m8azn-instances-generally-available",
      "pubDate": "2026-02-12T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ec2",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-5602fd73e43a",
      "title": "Amazon S3 Tables add partition and sort order definition in the CreateTable API",
      "description": "Amazon S3 Tables announce partition and sort order definition support for the CreateTable API. This enhancement simplifies setting these properties programmatically, making it easier to manage and optimize data in tables when they are created.\n  To use this feature, you can specify fields for partition transforms and sort order in the CreateTable API call. You can also define these properties when you create tables using the AWS CLI or the AWS SDK.\n  To create tables with partition and sort order, upgrade to the latest version of the AWS CLI and AWS SDKs. This support is available in all AWS Regions where S3 Tables are available. To learn more, visit the Amazon S3 Tables overview page and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/s3-tables-partition-and-sort-order-createtable-api/",
      "pubDate": "2026-02-12T11:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-231b224caaba",
      "title": "AWS Backup adds cross-Region database snapshot copy to logically air-gapped vaults",
      "description": "AWS Backup now supports single-action database snapshot copies to logically air-gapped vaults across AWS Regions. This capability is available for Amazon Aurora, Amazon Neptune, and Amazon DocumentDB snapshots, eliminating the need for an intermediate copying step in target Regions.\n \nYou can perform cross-Region and cross-account snapshot copies to protect against incidents like ransomware events and Region outages that might affect your production accounts or primary Regions. Previously, this required a two-step process—first copying snapshots to the target Region in a backup vault, then copying them to the logically air-gapped vault in the same Region. Now, you can complete this in one step, achieving faster recovery point objectives (RPOs) while eliminating costs associated with intermediate copies. This streamlined process also removes the need for custom scripts or AWS Lambda functions to monitor intermediate copy status.\n \nThis feature is available for Amazon Aurora, Amazon Neptune and Amazon DocumentDB, in all Regions where AWS Backup supports these databases and logically air-gapped vaults. You can start using this feature today through the AWS Management Console, AWS Command Line Interface (CLI), or AWS SDKs. To get started, refer to the AWS Backup documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-adds-cross-region-database-snapshot-logically-air-gapped-vaults/",
      "pubDate": "2026-02-12T11:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-6a19d601fcb1",
      "title": "Amazon Connect  launches granular access controls for analytics dashboards",
      "description": "Amazon Connect dashboards now provides granular access controls for analytics dashboards. This enables you to apply resource tags that control who is able to see metrics for specific resources such as agents, queues, and routing profiles. You can now filter metrics using tags to view aggregate metrics for agents or queues that share the same tags. For example, you can tag agents with Department:Customer Service to restrict dashboard metrics visibility to Customer Service team managers.\n \n\n Amazon Connect dashboards are available in all AWS commercial and AWS GovCloud (US-West) regions where Amazon Connect is offered. To learn more about dashboards, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-launches-granular-access",
      "pubDate": "2026-02-12T07:26:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-22def9800bc5",
      "title": "Amazon Athena adds 1-minute reservations and new capacity control features",
      "description": "Amazon Athena is a serverless interactive query service that makes it easy to analyze data using SQL. With Athena, there’s no infrastructure to manage, you simply submit queries and get results. Capacity Reservations is a feature of Athena that addresses the need to run critical workloads by providing dedicated serverless capacity for workloads you specify. In this post, we highlight three new capabilities that make Capacity Reservations more flexible and easier to manage: reduced minimums for fine-grained capacity adjustments, an autoscaling solution for dynamic workloads, and capacity cost and performance controls.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-athena-adds-1-minute-reservations-and-new-capacity-control-features/",
      "pubDate": "2026-02-11T22:16:01.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex",
        "athena"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "athena"
      ]
    },
    {
      "id": "aws-news-f20129c0b05f",
      "title": "AWS Payment Cryptography Achieves Cartes Bancaires Approval",
      "description": "Today, AWS Payment Cryptography has become one of the first cloud-based payment cryptography services to obtain approval from Groupement des Cartes Bancaires (CB), France's national card payment network. This CB approval, combined with existing compliance credentials, enables customers to run payment workloads in AWS while helping customers maintain CB compliance.\n  Organizations such as acquirers, payment facilitators, networks, switches, processors, and issuing banks that are moving workloads to the cloud can rely on AWS Payment Cryptography’s CB approval as part of their compliance frameworks. Organizations processing card payments typically require Hardware Security Modules (HSM) to perform cryptography in a compliant manner. AWS Payment Cryptography provides equivalent functionality in an elastic, scalable service, eliminating the operational burden of procuring and manage standalone payment HSMs. Customers can leverage the service’s shared responsibility model with PCI PIN, PCI P2PE, PCI 3DS, PCI DSS, SOC-2, CSA STAR and ISO27001 certifications as well as the additional CB approval.\n  AWS Payment Cryptography is available in the following AWS Regions: Canada (Montreal), US East (Ohio, N. Virginia), US West (Oregon), Europe (Ireland, Frankfurt, London, Paris), Africa (Cape Town) and Asia Pacific (Singapore, Tokyo, Osaka, Mumbai, Hyderabad, Sydney).\n  To start using the service, please download the latest AWS CLI/SDK and see the AWS Payment Cryptography user guide for more information including further compliance details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/payment-cryptography-cartes-bancaires",
      "pubDate": "2026-02-11T21:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-d53fbf6dc1eb",
      "title": "Amazon Connect launches after contact work timeout configuration for tasks, chats, and emails",
      "description": "Amazon Connect now supports the ability to configure agents with after contact work timeout settings for chat, tasks, emails, and callbacks. After contact work timeouts improve agent efficiency by time-boxing the amount of time each agent can spend doing after contact work for a contact, before being automatically set back to a ready state so they can be offered another contact. You can now enable these settings at the channel level for each agent to further optimize how agents spend their time. For example, you could choose to enable a shorter ACW timeout for emails while maintaining a longer ACW timeout for voice contacts to give agents a cool-down period between phone calls to prepare for the next customer interaction.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-omnichannel-acw-timeouts",
      "pubDate": "2026-02-11T20:14:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-e106de24be50",
      "title": "Amazon Connect launches auto-accept for tasks, chats, and emails",
      "description": "Amazon Connect now supports the ability to configure agents with auto-accept settings for chat, tasks, emails, and callbacks. When auto-accept is enabled, incoming contacts are automatically connected to available agents instead of waiting on the agent to manually accept or reject each contact, ensuring that customers receive timely assistance. Previously, these settings were available only for inbound voice contacts. You can now enable these settings at the channel level for each agent to further optimize how agents spend their time. For example, you could choose to enable auto-accept for tasks while keeping auto-accept disabled for voice calls to ensure that the agent is connected to a voice call only once they indicate they are ready.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-omnichannel-auto-accept",
      "pubDate": "2026-02-11T20:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-95cd2d9f146e",
      "title": "NVIDIA Nemotron 3 Nano 30B MoE model is now available in Amazon SageMaker JumpStart",
      "description": "Today we’re excited to announce that the NVIDIA Nemotron 3 Nano 30B model with  3B active parameters is now generally available in the Amazon SageMaker JumpStart model catalog. You can accelerate innovation and deliver tangible business value with Nemotron 3 Nano on Amazon Web Services (AWS) without having to manage model deployment complexities. You can power your generative AI applications with Nemotron capabilities using the managed deployment capabilities offered by SageMaker JumpStart.",
      "link": "https://aws.amazon.com/blogs/machine-learning/nvidia-nemotron-3-nano-30b-is-now-available-in-amazon-sagemaker-jumpstart/",
      "pubDate": "2026-02-11T19:38:47.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker",
        "jumpstart",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "jumpstart",
        "lex",
        "generally-available",
        "now-available"
      ]
    },
    {
      "id": "aws-news-35989e7c7eae",
      "title": "Amazon Aurora DSQL is now available in additional AWS Regions",
      "description": "Amazon Aurora DSQL is now available with single-Region clusters in Asia Pacific (Melbourne), Asia Pacific (Sydney), Canada (Central), and Canada West (Calgary). Aurora DSQL is the fastest serverless, distributed SQL database that enables you to build always available applications with virtually unlimited scalability, the highest availability, and zero infrastructure management. It is designed to make scaling and resilience effortless for your applications and offers the fastest distributed SQL reads and writes.\n  With this launch, Aurora DSQL is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Canada (Central), Canada West (Calgary), Asia Pacific (Melbourne), Asia Pacific (Sydney), Asia Pacific (Osaka), Asia Pacific (Tokyo), Asia Pacific (Seoul), Europe (Ireland), Europe (London), Europe (Frankfurt), and Europe (Paris).\n  Get started with Aurora DSQL for free with the AWS Free Tier. To learn more, visit the Aurora DSQL webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-aurora-dsql-additional-aws-regions",
      "pubDate": "2026-02-11T19:30:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-681847d4f879",
      "title": "Amazon MSK now supports broker logs on Express Brokers",
      "description": "Amazon Managed Streaming for Apache Kafka (MSK) now supports broker logs for Express brokers at no additional cost. With access to broker logs, you can troubleshoot client connectivity and availability issues and get insights into broker behavior during rebalances or fail-overs. You can also easily integrate Kafka operational telemetry into existing observability pipelines using pre-built integrations with Amazon CloudWatch Logs and Amazon S3. Broker Logs are available for both new and existing Express brokers . You can enable them from the Amazon MSK Console or AWS CLI. To learn how to setup broker log delivery, see the Amazon MSK broker logs documentation.\n  MSK Express brokers are designed to deliver up to three times more throughput per broker, scale up to 20 times faster, and reduce recovery time by 90 percent compared to Standard brokers running Apache Kafka. Express broker logs are supported in all AWS regions where express brokers are available. With Amazon MSK, you spend more time innovating on applications and less time managing clusters. Visit the Amazon MSK developer guide to get started.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-msk-express-brokers-support-broker-logs",
      "pubDate": "2026-02-11T19:23:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "s3",
        "kafka",
        "msk",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova",
        "s3",
        "kafka",
        "msk",
        "cloudwatch",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-e198bdd73bc5",
      "title": "AWS announces 6 new locations for AWS Data Transfer Terminal",
      "description": "AWS Data Transfer Terminal is now available in six additional locations in Seattle and Phoenix (US), London (UK), Paris (France), Sydney (Australia), and Tokyo (Japan), expanding availability alongside existing locations in San Francisco, Los Angeles, and New York City (US), and Munich (Germany). AWS Data Transfer Terminal is a secure, physical location where you can bring your storage devices and upload data to AWS including Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), and others using a high throughput network connection.\n  Data Transfer Terminals are ideal for customers who need to transfer large amounts of data to the AWS quickly and securely. Common use cases span various industries and applications, including video production data for processing in the media and entertainment industry, training data for Advanced Driver Assistance Systems (ADAS) in the automotive industry, migrating legacy data in the financial services industry, and uploading equipment sensor data in the industrial and agricultural sectors. Once uploaded, you can immediately leverage AWS services like Amazon Athena for analysis, Amazon SageMaker for machine learning, or Amazon Elastic Compute Cloud (Amazon EC2) for application development, reducing data processing time from weeks to minutes.\n  To learn more, visit the Data Transfer Terminal product page and documentation. To get started, make a reservation at your nearby Data Transfer Terminal in the AWS Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-data-transfer-terminal-6-new-locations/",
      "pubDate": "2026-02-11T19:02:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "s3",
        "ec2",
        "eks",
        "athena"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "ec2",
        "eks",
        "athena",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-8ffc4d07b41b",
      "title": "AWS Elastic Beanstalk now supports GitHub Actions for automated application deployment",
      "description": "AWS Elastic Beanstalk now enables you to use GitHub Actions to automatically deploy web applications when you push code or configuration changes to your GitHub repository, streamlining your continuous integration and continuous deployment (CI/CD) pipeline for scalable web applications.\n \nGitHub Actions allow development teams to automate their software delivery process, enabling CI/CD workflows that automatically build, test, and deploy code changes whenever developers push updates to their repositories. Teams deploying to Elastic Beanstalk can now benefit from enhanced automation that handles deployment package creation, S3 uploads, version management, and environment monitoring. The new GitHub Action provides a simplified way to deploy applications to Elastic Beanstalk using declarative configuration in GitHub Actions workflows, offering comprehensive automation for the entire deployment lifecycle. This action automatically creates applications and environments when needed, manages deployment packages with configurable exclusions, and integrates seamlessly with IAM using OpenID Connect (OIDC) authentication.\n \nTo get started, add the \"aws-elasticbeanstalk-deploy\" action to your GitHub Actions workflow file with configuration parameters for your application deployment. The action supports configuring environment settings and platform versions, optional health monitoring and deployment validation, intelligent retry logic for reliable deployments, and S3 bucket management for deployment artifacts. To learn more, visit the README for the AWS Elastic Beanstalk Deploy GitHub action.\n \nYou can use this GitHub Action for your Elastic Beanstalk applications in all commercial AWS Regions where Elastic Beanstalk is available.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-elastic-beanstalk-github-action",
      "pubDate": "2026-02-11T19:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "iam",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-b81c3d11b6ea",
      "title": "AWS Lake Formation enhances cross-account sharing",
      "description": "AWS Lake Formation now enhances cross-account sharing, allowing you to share hundreds of thousands of tables across accounts. You can centralize permissions in Lake Formation for resources such as catalogs, databases, and tables for multi-account analytics environments that require fine-grained access controls at scale.\n  You can share Data Catalog resources (databases, tables, and columns) with external IAM principals, AWS accounts, AWS Organizations, and organizational units (OUs). Lake Formation sets up a single AWS Resource Access Manager resource share for an unlimited number of tables to another account, eliminating previous resource association limits per resource type. To get started, upgrade to cross-account version 5 through the Lake Formation console or API. Any new cross-account permission grants will automatically use wildcard patterns in the AWS Resource Access Manager resource shares instead of individual resource associations. All existing cross-account shares continue to function, and all existing Lake Formation APIs remain compatible.\n \nTo learn more, visit the AWS Lake Formation product page and documentation. For AWS Lake Formation Region availability, please see the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-lake-formation-cross-account-sharing",
      "pubDate": "2026-02-11T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "iam",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-6cf8e8c43707",
      "title": "MSK simplifies Kafka topic management with new APIs and console integration",
      "description": "Amazon Managed Streaming for Apache Kafka (Amazon MSK) now offers three new APIs (CreateTopic, UpdateTopic, and DeleteTopic), making it easier to manage your Kafka topics for your MSK provisioned clusters without the need to set up and maintain Kafka admin clients. You can programmatically create, update, and delete Kafka topics using your familiar interfaces including AWS CLI, AWS SDKs, and AWS CloudFormation. With these APIs, you can define topic properties such as replication factor and partition count, along with configuration settings like retention and cleanup policies. The new APIs together with the ListTopics and DescribeTopic APIs are integrated into the Amazon MSK console, bringing all topic operstions to one place. You can now create or update topics with just a few clicks using guided defaults while gaining comprehensive visibility into topic configurations, partition-level information, and metrics.\n  These MSK topic management capabilities are available at no additional cost for all Amazon MSK provisioned clusters using Kafka version 3.6 and above across AWS regions where Amazon MSK is offered. To start using these features, you'll need to set up the appropriate IAM permissions. To learn more on how to get started, see the Amazon MSK Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-msk-kafka-topics-public-apis/",
      "pubDate": "2026-02-11T17:46:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "iam",
        "kafka",
        "msk"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudformation",
        "iam",
        "kafka",
        "msk",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-9bbc90812487",
      "title": "Amazon EC2 R8i and R8i-flex instances are now available in additional AWS regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8i and R8i-flex instances are available in the Asia Pacific (New Zealand) and Middle East (UAE) regions. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. The R8i and R8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver 20% higher performance than R7i instances, with even higher gains for specific workloads. They are up to 30% faster for PostgreSQL databases, up to 60% faster for NGINX web applications, and up to 40% faster for AI deep learning recommendation models compared to R7i.\n  R8i-flex, our first memory-optimized Flex instances, are the easiest way to get price performance benefits for a majority of memory-intensive workloads. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  R8i instances are a great choice for all memory-intensive workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. R8i instances offer 13 sizes including 2 bare metal sizes and the new 96xlarge size for the largest applications. R8i instances are SAP-certified and deliver 142,100 aSAPS, delivering exceptional performance for mission-critical SAP workloads.\n  To get started, sign in to the AWS Management Console. For more information about the R8i and R8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-r8i-r8i-flex-instances-AKL-DXB-region/",
      "pubDate": "2026-02-11T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a0980a66101f",
      "title": "Amazon EC2 C8i and C8i-flex instances are now available in Europe (Paris), Canada (Central), and US West (N. California) regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8i and C8i-flex instances are available in the Europe (Paris), Canada (Central), and US West (N. California) regions. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. These C8i and C8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver up to 20% higher performance than C7i and C7i-flex instances, with even higher gains for specific workloads. The C8i and C8i-flex are up to 60% faster for NGINX web applications, up to 40% faster for AI deep learning recommendation models, and 35% faster for Memcached stores compared to C7i and C7i-flex.\n  C8i-flex are the easiest way to get price performance benefits for a majority of compute intensive workloads like web and application servers, databases, caches, Apache Kafka, Elasticsearch, and enterprise applications. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  C8i instances are a great choice for all memory-intensive workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. C8i instances offer 13 sizes including 2 bare metal sizes and the new 96xlarge size for the largest applications.\n  To get started, sign in to the AWS Management Console. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information about the new C8i and C8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8i-c8i-flex-instances-europe-paris-canada-central-uswest-ncalifornia-regions",
      "pubDate": "2026-02-11T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "kafka"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "kafka",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-ddcbfc655623",
      "title": "Amazon RDS for MariaDB now supports community MariaDB minor versions 10.6.25, 10.11.16, 11.4.10, and 11.8.6",
      "description": "Amazon Relational Database Service (Amazon RDS) for MariaDB now supports community MariaDB minor versions 10.6.25, 10.11.16, 11.4.10, and 11.8.6. We recommend that you upgrade to the latest minor versions to fix known security vulnerabilities in prior versions of MariaDB, and to benefit from the bug fixes, performance improvements, and new functionality added by the MariaDB community.\n  You can leverage automatic minor version upgrades to automatically upgrade your databases to more recent minor versions during scheduled maintenance windows. You can also leverage Amazon RDS Managed Blue/Green deployments for safer, simpler, and faster updates to your MariaDB instances. Learn more about upgrading your database instances, including automatic minor version upgrades and Blue/Green Deployments, in the Amazon RDS User Guide.\n  Amazon RDS for MariaDB makes it straightforward to set up, operate, and scale MariaDB deployments in the cloud. Learn more about pricing details and regional availability at Amazon RDS for MariaDB. Create or update a fully managed Amazon RDS database in the Amazon RDS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-rds-mariadb-community-versions/",
      "pubDate": "2026-02-11T16:23:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-123e63417c8b",
      "title": "Amazon DocumentDB (with MongoDB compatibility) is Now Available in the Asia Pacific (Melbourne) Region",
      "description": "Amazon DocumentDB (with MongoDB compatibility) is now available in the Asia Pacific (Melbourne) region adding to the list of available regions where you can use Amazon DocumentDB.\n \nAmazon DocumentDB is a fully managed, native JSON database that makes it simple and cost-effective to operate critical document workloads at virtually any scale without managing infrastructure. Amazon DocumentDB is designed to give you the scalability and durability you need when operating mission-critical MongoDB workloads. Storage scales automatically up to 128TiB without any impact to your application. In addition, Amazon DocumentDB natively integrates with AWS Database Migration Service (DMS), Amazon CloudWatch, AWS CloudTrail, AWS Lambda, AWS Backup and more. Amazon DocumentDB supports millions of requests per second and can be scaled out to 15 low latency read replicas in minutes with no application downtime.\n \nTo learn more about Amazon DocumentDB, please visit the Amazon DocumentDB product page and pricing page.\n \nYou can create a Amazon DocumentDB cluster from the AWS Management console, AWS Command Line Interface (CLI), or SDK.",
      "link": "https://aws.amazon.comabout-aws/whats-new/2026/02/amazon-documentdb-mongodb-compatibility-asia-pacific-melbourne-region",
      "pubDate": "2026-02-11T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "cloudwatch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-3537a41f10b9",
      "title": "Amazon DocumentDB (with MongoDB compatibility) is Now Available in the Europe (Zurich) Region",
      "description": "Amazon DocumentDB (with MongoDB compatibility) is now available in the Europe (Zurich) region adding to the list of available regions where you can use Amazon DocumentDB.\n \nAmazon DocumentDB is a fully managed, native JSON database that makes it simple and cost-effective to operate critical document workloads at virtually any scale without managing infrastructure. Amazon DocumentDB is designed to give you the scalability and durability you need when operating mission-critical MongoDB workloads. Storage scales automatically up to 128TiB without any impact to your application. In addition, Amazon DocumentDB natively integrates with AWS Database Migration Service (DMS), Amazon CloudWatch, AWS CloudTrail, AWS Lambda, AWS Backup and more. Amazon DocumentDB supports millions of requests per second and can be scaled out to 15 low latency read replicas in minutes with no application downtime.\n \nTo learn more about Amazon DocumentDB, please visit the Amazon DocumentDB product page and pricing page.\n \nYou can create a Amazon DocumentDB cluster from the AWS Management console, AWS Command Line Interface (CLI), or SDK.",
      "link": "https://aws.amazon.comabout-aws/whats-new/2026/02/amazon-documentdb-mongodb-compatibility-europe-zurich-region",
      "pubDate": "2026-02-11T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "cloudwatch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f28ad49fa3a4",
      "title": "Swann provides Generative AI to millions of IoT Devices using Amazon Bedrock",
      "description": "This post shows you how to implement intelligent notification filtering using Amazon Bedrock and its gen-AI capabilities. You'll learn model selection strategies, cost optimization techniques, and architectural patterns for deploying gen-AI at IoT scale, based on Swann Communications deployment across millions of devices.",
      "link": "https://aws.amazon.com/blogs/machine-learning/swann-provides-generative-ai-to-millions-of-iot-devices-using-amazon-bedrock/",
      "pubDate": "2026-02-11T15:48:15.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-0b76fca6e392",
      "title": "How LinqAlpha assesses investment theses using Devil’s Advocate on Amazon Bedrock",
      "description": "LinqAlpha is a Boston-based multi-agent AI system built specifically for institutional investors. The system supports and streamlines agentic workflows across company screening, primer generation, stock price catalyst mapping, and now, pressure-testing investment ideas through a new AI agent called Devil’s Advocate. In this post, we share how LinqAlpha uses Amazon Bedrock to build and scale Devil’s Advocate.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-linqalpha-assesses-investment-theses-using-devils-advocate-on-amazon-bedrock/",
      "pubDate": "2026-02-11T15:45:30.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "support"
      ]
    },
    {
      "id": "aws-news-4e118507f390",
      "title": "Amazon Connect introduces audio enhancements for noisy environments",
      "description": "Today, AWS announces the release of Audio Enhancement for Amazon Connect, helping improve audio quality and reliability for voice calls in noisy contact center environments. With this launch, you can enable Audio Enhancement for your agents so that end customers can hear them more clearly, even in the presence of background noise within the contact center environment.\n  The Audio Enhancement capability suppresses agent-side background noises and isolates agent voices, removing the effect of background noise and chatter in busy contact center environments. Audio Enhancement offers two specialized modes to match different agent setups. The \"Voice Isolation\" mode suppresses noises as well as background speech within the contact center, while the \"Noise Suppression\" mode only suppresses background noises. Contact center administrators can enable these capabilities for agents through the User Management page and select the appropriate mode based on their equipment and setup. Agents with proper permissions can also adjust their settings directly from the Contact Control Panel to optimize for their current environment.\n  The Audio Enhancement capability is available in all commercial AWS Regions where Amazon Connect is offered.\n  To learn more about Amazon Connect Audio Enhancement, please see the Amazon Connect website and the Amazon Connect Administrator Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-audio-enhancements",
      "pubDate": "2026-02-11T13:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-39b93afa34c1",
      "title": "Amazon Bedrock AgentCore Browser now supports proxy configuration",
      "description": "Amazon Bedrock AgentCore Browser now supports customer-provided proxy configuration, enabling customers to route browser sessions through their own proxy infrastructure for geo-targeting, regional content access, and compliance requirements. Organizations can access geo-restricted content, verify region-specific pricing, and validate localized application behavior across markets. Customers in regulated industries such as healthcare and financial services can route traffic through corporate proxy infrastructure to meet security policies while automating critical business processes.\n  Browser proxies help eliminate re-authentication cycles due to rotating IPs, while providing stable, controllable egress addresses for IP allowlisting requirements. The feature currently supports both HTTP and HTTPS protocols with secure credential management through AWS Secrets Manager. This enhancement is particularly valuable for healthcare organizations accessing portals with strict IP allowlisting, financial services companies with rigorous egress policies, and enterprises routing traffic through corporate proxy infrastructure that provides auditing and security policy enforcement.\n  This feature is available in all fourteen AWS Regions where Amazon Bedrock AgentCore Browser is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), and Europe (Stockholm).\n  To learn more, visit the Browser Proxies documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/bedrock-agentcore-browser-proxy",
      "pubDate": "2026-02-11T06:16:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "secrets manager",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "secrets manager",
        "organizations",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-4cbce46f295e",
      "title": "How Zalando innovates their Fast-Serving layer by migrating to Amazon Redshift",
      "description": "In this post, we show how Zalando migrated their fast-serving layer data warehouse to Amazon Redshift to achieve better price-performance and scalability.",
      "link": "https://aws.amazon.com/blogs/big-data/how-zalando-innovates-their-fast-serving-layer-by-migrating-to-amazon-redshift/",
      "pubDate": "2026-02-10T23:37:35.000Z",
      "source": "bigDataBlog",
      "services": [
        "nova",
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova",
        "redshift"
      ]
    },
    {
      "id": "aws-news-79a047a8ae20",
      "title": "Amazon SageMaker HyperPod now supports node actions from the console",
      "description": "Amazon SageMaker HyperPod now enables you to manage individual cluster nodes directly from the AWS Console. HyperPod cluster operators managing large-scale AI/ML workloads often need to connect to nodes for troubleshooting, reboot unresponsive instances, or replace degraded nodes. Connecting to a node previously required manually constructing SSM connection strings, while node recovery actions such as reboot and replace required CLI commands — the console now provides a single interface for all node actions.\n  With node actions in the console, you can now connect to any node via AWS Systems Manager (SSM). The console provides pre-populated SSM CLI commands with copy-to-clipboard support, and direct SSM session launch in the console. While SageMaker HyperPod clusters already support automatic replacement and reboot of unhealthy instances, there are scenarios such as memory overruns or undetectable hardware degradation that may require manual intervention. Now, node actions in the console provide a consistent approach to manually reboot nodes to recover from transient issues, delete unhealthy nodes, and replace nodes, with batch operations supporting multiple node actions simultaneously, enabling you to resolve node issues in minutes. This capability is especially valuable when running time-sensitive AI training and inference workloads where minimizing downtime is essential.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is supported. You can perform all these node actions in the HyperPod Cluster management page on console. Click on the respective links to learn more about replace/reboot and connecting to a node.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-sagemaker-hyperpod-node-actions/",
      "pubDate": "2026-02-10T19:15:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-0d02aec495a3",
      "title": "How Amazon uses Amazon Nova models to automate operational readiness testing for new fulfillment centers",
      "description": "In this post, we discuss how Amazon Nova in Amazon Bedrock can be used to implement an AI-powered image recognition solution that automates the detection and validation of module components, significantly reducing manual verification efforts and improving accuracy.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-uses-amazon-nova-models-to-automate-operational-readiness-testing-for-new-fulfillment-centers/",
      "pubDate": "2026-02-10T18:34:09.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-2c6246a1ff48",
      "title": "Iberdrola enhances IT operations using Amazon Bedrock AgentCore",
      "description": "Iberdrola, one of the world’s largest utility companies, has embraced cutting-edge AI technology to revolutionize its IT operations in ServiceNow. Through its partnership with AWS, Iberdrola implemented different agentic architectures using Amazon Bedrock AgentCore, targeting three key areas: optimizing change request validation in the draft phase, enriching incident management with contextual intelligence, and simplifying change model selection using conversational AI. These innovations reduce bottlenecks, help teams accelerate ticket resolution, and deliver consistent and high-quality data handling throughout the organization.",
      "link": "https://aws.amazon.com/blogs/machine-learning/iberdrola-enhances-it-operations-using-amazon-bedrock-agentcore/",
      "pubDate": "2026-02-10T18:31:57.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-8115f2327170",
      "title": "Building real-time voice assistants with Amazon Nova Sonic compared to cascading architectures",
      "description": "Amazon Nova Sonic delivers real-time, human-like voice conversations through the bidirectional streaming interface. In this post, you learn how Amazon Nova Sonic can solve some of the challenges faced by cascaded approaches, simplify building voice AI agents, and provide natural conversational capabilities. We also provide guidance on when to choose each approach to help you make informed decisions for your voice AI projects.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-real-time-voice-assistants-with-amazon-nova-sonic-compared-to-cascading-architectures/",
      "pubDate": "2026-02-10T18:29:05.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-814a29034488",
      "title": "Amazon EC2 C8id, M8id, and R8id instances are available in additional regions",
      "description": "Amazon Elastic Compute Cloud (EC2) C8id, M8id, and R8id instances powered by custom Intel Xeon 6 processors feature up to 384 vCPUs, 3TiB of memory, and 22.8TB of NVMe SSD storage and deliver up to 43% higher performance and 3.3x more memory bandwidth compared to previous generation C6id, M6id, and R6id instances. Starting today, C8id and M8id instances are available in Europe (Frankfurt) and Asia Pacific (Tokyo) regions, with M8id also available in Europe (Spain) region. Additionally, R8id instances are now available in Europe (Spain) and Asia Pacific (Tokyo) regions.\n  These instances deliver up to 46% higher performance for I/O intensive database workloads, and up to 30% faster query results for I/O intensive real-time data analytics than previous sixth-generation instances. Additionally, these instances support Instance Bandwidth Configuration, allowing 25% flexible allocation between network and EBS bandwidth, allocating resources optimally for each workload.\n  C8id instances are ideal for compute-intensive workloads such as high-performance web servers, batch processing, distributed analytics, ad serving, video encoding, and gaming servers. M8id instances are well-suited for balanced workloads including application servers, microservices, enterprise applications, and small to medium databases. R8id instances are ideal for memory-intensive workloads such as in-memory databases, real-time big data analytics, large in-memory caches, and scientific computing applications.\n  C8id, M8id and R8id instances are available in US East (N. Virginia, Ohio), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Tokyo) regions. M8id and R8id instances are additionally available in Europe (Spain) region. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information visit the Amazon EC2 instance type page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/c8id-m8id-and-r8id-in-additional-regions/",
      "pubDate": "2026-02-10T18:21:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-df2c20ddea76",
      "title": "Amazon Athena now supports 1-minute reservations and 4 DPU minimum capacity",
      "description": "Amazon Athena now supports 1-minute Capacity Reservations and a lower minimum capacity of 4 Data Processing Units (DPUs) for all reservations. Now, you can get started with less capacity and make more frequent, fine-grained adjustments to match your workload patterns—with no long-term commitments and cost savings up to 95% for short-duration query workloads.\n  Capacity Reservations provides dedicated serverless compute and is ideal for workloads requiring query prioritization and concurrency controls. You pay only for capacity that you reserve and there are no data scanned charges. Reserved capacity works seamlessly with existing Athena queries and workgroups—simply attach workgroups to a reservation and submit queries with no changes in your SQL queries or application code required.\n  To learn more, see the Athena User Guide and Athena pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-athena-one-minute-capacity-reservations/",
      "pubDate": "2026-02-10T16:52:00.000Z",
      "source": "whatsNew",
      "services": [
        "athena"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "athena",
        "support"
      ]
    },
    {
      "id": "aws-news-47906801ca88",
      "title": "Amazon Bedrock adds support for six fully-managed open weights models",
      "description": "Amazon Bedrock now supports six new models spanning frontier reasoning and agentic coding: DeepSeek V3.2, MiniMax M2.1, GLM 4.7, GLM 4.7 Flash, Kimi K2.5, and Qwen3 Coder Next. These six models bring customers access to the most capable open weights models available today, delivering frontier-class performance at significantly lower inference costs. They collectively cover the full spectrum of enterprise AI workloads: DeepSeek V3.2 and Kimi K2.5 push the frontier on reasoning and agentic intelligence, GLM 4.7 and Minimax 2.1 set new standards for autonomous coding with massive output windows, and Qwen3 Coder Next and GLM 4.7 Flash offer lightweight, cost-efficient alternatives purpose-built for production deployment.\n \nThese models on Amazon Bedrock are powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock, provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and provides out-of-the-box compatibility with OpenAI API specifications.\n \nTo learn more and get started, visit Amazon Bedrock console or the service documentation here. To get started with Amazon Bedrock OpenAI API-compatible service endpoints, visit documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-adds-support-six-open-weights-models",
      "pubDate": "2026-02-10T16:02:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "rds",
        "support",
        "new-model"
      ]
    },
    {
      "id": "aws-news-2baacc65d7a9",
      "title": "Amazon OpenSearch Serverless now supports Collection Groups",
      "description": "Amazon OpenSearch Serverless now supports Collection Groups, a new capability that enables you to share OpenSearch Compute Units (OCUs) across collections with different AWS KMS keys. This new capability delivers enhanced cost optimization through a shared compute model that reduces overall OCU expenses while maintaining collection-level security and access controls. Additionally, Collection Groups introduce the ability to specify minimum OCU allocations alongside maximum OCU limits, allowing you to provision compute capacity upfront at startup for more predictable performance.\n  Collection Groups are particularly valuable for multi-tenant workloads where different tenants require data encryption with separate KMS keys while still benefiting from shared compute resources. By grouping collections together, you can optimize OCU utilization across workloads, reduce costs through resource sharing, and maintain the security isolation required by different encryption keys. The minimum OCU setting ensures your collections have guaranteed baseline capacity from the moment they start, eliminating cold start delays and providing consistent performance for latency-sensitive applications.\n  Collection groups are available in all regions where Amazon OpenSearch Serverless is currently available. To learn more about configuring and managing collection groups, visit the Amazon OpenSearch Serverless documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-opensearch-serverless-supports-collection-groups/",
      "pubDate": "2026-02-10T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "opensearch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-cf2d10da92a8",
      "title": "Amazon EKS Auto Mode Announces Enhanced Logging for its Managed Kubernetes Capabilities",
      "description": "Amazon Elastic Kubernetes Service (Amazon EKS) Auto Mode’s managed capabilities can now be configured as log delivery sources using Amazon CloudWatch Vended Logs. This integration enables customers to monitor and troubleshoot their EKS Auto Mode clusters more effectively by automatically collecting logs from Auto Mode’s managed Kubernetes capabilities for compute autoscaling, block storage, load balancing, and pod networking.\n  Customers can configure log delivery for Auto Mode capabilities using CloudWatch APIs or the AWS Console. Each Auto Mode capability can be configured as a CloudWatch Vended Logs delivery source, enabling reliable, secure log delivery with built-in AWS authentication and authorization at a reduced price compared to standard CloudWatch Logs. Customers can deliver these logs to CloudWatch Logs, Amazon S3, or Amazon Kinesis Data Firehose destinations.\n  This feature is available today in all regions where EKS Auto Mode is available. Standard CloudWatch Logs, S3, or Kinesis charges apply depending on the chosen destination.\n  To learn more about EKS Auto Mode logging capabilities, visit the Amazon EKS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-eks-auto-mode-enhanced-logging",
      "pubDate": "2026-02-10T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "eks",
        "kinesis",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "eks",
        "kinesis",
        "cloudwatch",
        "integration"
      ]
    },
    {
      "id": "aws-news-dd23c1677fba",
      "title": "AWS CloudWatch Alarm Mute Rules eliminate alert fatigue",
      "description": "Amazon CloudWatch now supports Alarm Mute Rules, enabling customers to temporarily mute alarm notifications during planned deployments, maintenance windows, and off-hours without compromising monitoring visibility. This new capability helps eliminate alert fatigue while maintaining complete situational awareness across their infrastructure.\n  Alarm Mute Rules transform operational workflows by allowing teams to create one-time or recurring rules that silence notifications for up to 100 individual alarms around deployment calendars, scheduled maintenance activities, or predictable off-hours periods when non-critical alerts become disruptive. Customers can configure actions for OK, ALARM, and INSUFFICIENT_DATA states, and when mute rules expire, any previously muted actions are automatically triggered as long as the alarm remains in the same state it was in when the actions were muted, ensuring critical issues are never overlooked while preventing unnecessary alert fatigue.\n  This eliminates the operational risk of forgotten script-based workarounds and reduces alert noise during planned activities, enabling engineering teams to focus on core business initiatives rather than managing notification fatigue.\n \n\n CloudWatch Alarm Mute Rules is available today in all AWS Regions supporting alarm-level muting.\n \nTo get started, see CloudWatch User Guide for Alarm Mute Rules. You can create mute rules through the Amazon CloudWatch Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-cloudwatch-alarm-muting-rules",
      "pubDate": "2026-02-10T09:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudwatch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-9d4e4d6f3cb9",
      "title": "Amazon EC2 C8gn instances are now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8gn instances, powered by the latest-generation AWS Graviton4 processors, are available in the AWS Region Asia Pacific (Seoul, Melbourne), Canada (Central), Europe (Spain), and AWS GovCloud (US-East, US-West). The new instances provide up to 30% better compute performance than Graviton3-based Amazon EC2 C7gn instances. Amazon EC2 C8gn instances feature the latest 6th generation AWS Nitro Cards, and offer up to 600 Gbps network bandwidth, the highest network bandwidth among network optimized EC2 instances. \n  \n Take advantage of the enhanced networking capabilities of C8gn to scale performance and throughput, while optimizing the cost of running network-intensive workloads such as network virtual appliances, data analytics, CPU-based artificial intelligence and machine learning (AI/ML) inference. \n  \n For increased scalability, C8gn instances offer instance sizes up to 48xlarge, up to 384 GiB of memory, and up to 60 Gbps of bandwidth to Amazon Elastic Block Store (EBS). C8gn instances support Elastic Fabric Adapter (EFA) networking on the 16xlarge, 24xlarge, 48xlarge, metal-24xl, and metal-48xl sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters. \n  \n C8gn instances are available in the following AWS Regions: US East (N. Virginia, Ohio), US West (Oregon, N.California), Europe (Frankfurt, Stockholm, Ireland, London, Spain), Asia Pacific (Singapore, Malaysia, Sydney, Thailand, Mumbai, Seoul, Melbourne), Middle East (UAE), Africa (Cape Town), Canada West (Calgary, Central), AWS GovCloud (US-East, US-West).\n  \n To learn more, see Amazon C8gn Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-c8gn-instances-additional-regions",
      "pubDate": "2026-02-09T23:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "rds",
        "graviton",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-326540a6a823",
      "title": "Using Amazon SageMaker Unified Studio Identity center (IDC) and IAM-based domains together",
      "description": "In this post, we demonstrate how to access an Amazon SageMaker Unified Studio IDC-based domain with a new IAM-based domain using role reuse and attribute-based access control.",
      "link": "https://aws.amazon.com/blogs/big-data/using-amazon-sagemaker-unified-studio-identity-center-idc-and-iam-based-domains-together/",
      "pubDate": "2026-02-09T22:27:10.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam"
      ]
    },
    {
      "id": "aws-news-4fccc11c5096",
      "title": "Orchestrate end-to-end scalable ETL pipeline with Amazon SageMaker workflows",
      "description": "This post explores how to build and manage a comprehensive extract, transform, and load (ETL) pipeline using SageMaker Unified Studio workflows through a code-based approach. We demonstrate how to use a single, integrated interface to handle all aspects of data processing, from preparation to orchestration, by using AWS services including Amazon EMR, AWS Glue, Amazon Redshift, and Amazon MWAA. This solution streamlines the data pipeline through a single UI.",
      "link": "https://aws.amazon.com/blogs/big-data/orchestrate-end-to-end-scalable-etl-pipeline-with-amazon-sagemaker-workflows/",
      "pubDate": "2026-02-09T22:14:13.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "emr",
        "redshift",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "emr",
        "redshift",
        "glue"
      ]
    },
    {
      "id": "aws-news-9164d1ec8b97",
      "title": "Amazon Neptune Analytics is now available in 7 additional regions",
      "description": "Amazon Neptune Analytics is now available in Middle East (Bahrain), Middle East (UAE), Israel (Tel Aviv), Africa (Cape Town), Canada (Calgary), Asia Pacific (Malaysia), and Europe (Zurich) regions. You can now create and manage Neptune Analytics graphs in these new regions and run advanced graph analytics.\n  Amazon Neptune is a serverless graph database for connected data, improves the accuracy of AI applications, and lowers operational burden and costs. Neptune instantly scales graph workloads removing the need to manage capacity. By modeling data as a graph, Neptune captures context that improves accuracy and explainability of generative AI applications. To make AI application development easier, Neptune offers fully managed GraphRAG with Amazon Bedrock Knowledge Bases, and integrations with Strands AI Agents SDK and popular agentic memory tools. It also easily analyzes tens of billions of relationships across structured and unstructured data within seconds delivering strategic insights. Neptune is the only database and analytics engine that gives you the power of connected data with the enterprise capabilities and value of AWS.\n  To get started, you can create a new Neptune Analytics graphs using the AWS Management Console, or AWS CLI. For more information on pricing and region availability, refer to the Neptune pricing page and AWS Region Table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-neptune-analytics-in-seven-additional-regions",
      "pubDate": "2026-02-09T21:45:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "ga",
        "now-available",
        "integration",
        "new-region"
      ]
    },
    {
      "id": "aws-news-f4c0e3221bd7",
      "title": "AWS HealthOmics introduces a Kiro Power and Kiro IDE extension for bioinformatics workflow development",
      "description": "AWS HealthOmics announces a Kiro Power and Kiro IDE extension to create, run, debug, and optimize HealthOmics workflows faster with AI agent-assisted development. With the HealthOmics extension for Kiro IDE, customers can create, modify, and analyze workflows in domain-specific languages including Nextflow and WDL directly in the Kiro interface. AWS HealthOmics is a HIPAA-eligible service that helps accelerate scientific breakthroughs at scale with fully managed bioinformatics workflows.\n  Kiro Powers is a repository of curated and pre-packaged Model Context Protocol (MCP) servers, steering files, and agent hooks to accelerate specialized software development and deployment use cases. The Kiro Power for HealthOmics packages the HealthOmics MCP server with guidance, giving the Kiro agent expertise in HealthOmics workflow creation and optimization. The HealthOmics Kiro IDE extension provides syntax highlighting, code completion, and troubleshooting guidance, along with HealthOmics engine compatibility checking, performance optimization recommendations, automated run analysis with failure diagnostics, and workflow import/export capabilities.\n  To get started, download and install the HealthOmics Kiro Power from https://kiro.dev/powers/ and HealthOmics Kiro IDE extension from Open VSX Registry.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/01/aws-healthomics-introduces-kiro-plugin-for-bioinformatics-workflow-development/",
      "pubDate": "2026-02-09T21:03:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": []
    },
    {
      "id": "aws-news-608b6b9419e6",
      "title": "AWS Weekly Roundup: Claude Opus 4.6 in Amazon Bedrock, AWS Builder ID Sign in with Apple, and more (February 9, 2026)",
      "description": "Here are the notable launches and updates from last week that can help you build, scale, and innovate on AWS. Last week’s launches Here are the launches that got my attention this week. Let’s start with news related to compute and networking infrastructure: Introducing Amazon EC2 C8id, M8id, and R8id instances: These new Amazon EC2 […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-claude-opus-4-6-in-amazon-bedrock-aws-builder-id-sign-in-with-apple-and-more-february-9-2026/",
      "pubDate": "2026-02-09T20:42:04.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "nova",
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "nova",
        "ec2",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-422f564cfc67",
      "title": "Automated Reasoning checks rewriting chatbot reference implementation",
      "description": "This blog post dives deeper into the implementation architecture for the Automated Reasoning checks rewriting chatbot.",
      "link": "https://aws.amazon.com/blogs/machine-learning/automated-reasoning-checks-rewriting-chatbot-reference-implementation/",
      "pubDate": "2026-02-09T19:34:05.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "natural-language"
      ],
      "tags": []
    },
    {
      "id": "aws-news-dc88a6fd4ed0",
      "title": "Amazon Redshift now supports allocating extra compute for automatic optimizations",
      "description": "Amazon Redshift now supports allocating extra compute for automatic optimization features, known as autonomics. Database administrators managing Amazon Redshift workloads can now allocate additional resources for their clusters to enable autonomics even during periods of high user activity, eliminating the need to manually schedule optimizations such as Automatic Table Optimization (ATO), Automatic Table Sorting (ATS), Auto Vacuum, and Auto Analyze.\n  This enhancement extends Amazon Redshift's autonomics capabilities to automatically leverage extra compute resources, to run reliably without impacting user workloads. It also includes a cost control feature for provisioned clusters, allowing database administrators to limit the amount of resources available to autonomics. Additionally, the new SYS_AUTOMATIC_OPTIMIZATION system table enhances observability by providing detailed information on autonomics operations for both provisioned clusters and serverless workgroups.\n  This feature is available in all AWS Regions where Amazon Redshift is supported. To learn more, see Allocating extra compute resources for automatic database optimization.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-redshift-allocate-extra-compute-for-automatic-optimizations",
      "pubDate": "2026-02-09T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "redshift"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "redshift",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-5846bfa0757e",
      "title": "Scale LLM fine-tuning with Hugging Face and Amazon SageMaker AI",
      "description": "In this post, we show how this integrated approach transforms enterprise LLM fine-tuning from a complex, resource-intensive challenge into a streamlined, scalable solution for achieving better model performance in domain-specific applications.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scale-llm-fine-tuning-with-hugging-face-and-amazon-sagemaker-ai/",
      "pubDate": "2026-02-09T16:48:46.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "lex"
      ]
    },
    {
      "id": "aws-news-e0de1c85e10d",
      "title": "New Relic transforms productivity with generative AI on AWS",
      "description": "Working with the Generative AI Innovation Center, New Relic NOVA (New Relic Omnipresence Virtual Assistant) evolved from a knowledge assistant into a comprehensive productivity engine. We explore the technical architecture, development journey, and key lessons learned in building an enterprise-grade AI solution that delivers measurable productivity gains at scale.",
      "link": "https://aws.amazon.com/blogs/machine-learning/new-relic-transforms-productivity-with-generative-ai-on-aws/",
      "pubDate": "2026-02-09T16:45:16.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "ga"
      ]
    },
    {
      "id": "aws-news-88d1e4796f36",
      "title": "Accelerate agentic application development with a full-stack starter template for Amazon Bedrock AgentCore",
      "description": "In this post, you will learn how to deploy Fullstack AgentCore Solution Template (FAST) to your Amazon Web Services (AWS) account, understand its architecture, and see how to extend it for your requirements. You will learn how to build your own agent while FAST handles authentication, infrastructure as code (IaC), deployment pipelines, and service integration.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-agentic-application-development-with-a-full-stack-starter-template-for-amazon-bedrock-agentcore/",
      "pubDate": "2026-02-09T16:40:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "integration"
      ]
    },
    {
      "id": "aws-news-bc5baeadbafe",
      "title": "Introducing Multipart Download Support for AWS SDK for .NET Transfer Manager",
      "description": "The new multipart download support in AWS SDK for .NET Transfer Manager improves the performance of downloading large objects from Amazon Simple Storage Service (Amazon S3). Customers are looking for better performance and parallelization of their downloads, especially when working with large files or datasets. The AWS SDK for .NET Transfer Manager (version 4 only) […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-multipart-download-support-for-aws-sdk-for-net-transfer-manager/",
      "pubDate": "2026-02-09T16:27:06.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "support"
      ]
    },
    {
      "id": "aws-news-5354a6485a76",
      "title": "Amazon WorkSpaces Secure Browser now supports custom domain",
      "description": "Amazon WorkSpaces Secure Browser now supports custom domains for your WorkSpaces Secure Browser portals, enabling you to configure portal access through your own domain name instead of the default portal URL. This feature provides users with a more integrated experience using a domain that aligns with your organization's branding for each secure browser session.\n  As an administrator you simply add the custom domain in the WorkSpaces Secure browser portal and set up a reverse proxy (for example Amazon CloudFront). Once set up, traffic is routed through your reverse proxy to the portal endpoint, and WorkSpaces Secure Browser automatically redirects users to the configured custom domain after authentication and authorization. Authentication can be via AWS Identity Center or your own Identity Provider (IdP), supporting both IdP-initiated and service provider-initiated flows.\n  This feature is available at no additional cost in 10 AWS Regions, including US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt, London, Ireland), and Asia Pacific (Tokyo, Mumbai, Sydney, Singapore). WorkSpaces Secure Browser offers pay-as-you go pricing.\n  To get started, visit the Amazon WorkSpaces Secure Browser console to configure your custom domain for your WorkSpaces Secure Browser portal. For more information, see the custom domain section in the Amazon WorkSpaces Secure Browser’s documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-workspaces-secure-browser-custom-domains/",
      "pubDate": "2026-02-06T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudfront"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudfront",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-efdc8b897228",
      "title": "Amazon ECS Managed Instances now available in AWS European Sovereign Cloud",
      "description": "Amazon Elastic Container Service (Amazon ECS) Managed Instances is now available in the AWS European Sovereign Cloud. ECS Managed Instances is a fully managed compute option designed to eliminate infrastructure management overhead while giving you access to the full capabilities of Amazon EC2. By offloading infrastructure operations to AWS, you get the application performance you want and the simplicity you need while reducing your total cost of ownership.\n  Managed Instances dynamically scales EC2 instances to match your workload requirements and continuously optimizes task placement to reduce infrastructure costs. It also enhances your security posture through regular security patching initiated every 14 days. You can simply define your task requirements such as the number of vCPUs, memory size, and CPU architecture, and Amazon ECS automatically provisions, configures and operates most optimal EC2 instances within your AWS account using AWS-controlled access. You can also specify desired instance types in Managed Instances Capacity Provider configuration, including GPU-accelerated, network-optimized, and burstable performance, to run your workloads on the instance families you prefer.\n  To get started with ECS Managed Instances, use the AWS Console, Amazon ECS MCP Server, or your favorite infrastructure-as-code tooling to enable it in a new or existing Amazon ECS cluster. You will be charged for the management of compute provisioned, in addition to your regular Amazon EC2 costs. To learn more about ECS Managed Instances, visit the feature page, documentation, and AWS News launch blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/ecs-mi-european-sovereign-cloud",
      "pubDate": "2026-02-06T17:10:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "ecs"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "ecs",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-43e867f93eaa",
      "title": "Amazon Bedrock AgentCore Browser now supports browser profiles",
      "description": "Amazon Bedrock AgentCore Browser now supports browser profiles, enabling you to reuse authentication state across multiple browser sessions without repeated login flows. This feature reduces session setup time from minutes to tens of seconds for enterprise customers processing hundreds or thousands of automated browser sessions daily.\n \nBrowser profiles persist and reuse browser data including cookies and local storage across multiple sessions. You authenticate to a website once and save the session to a browser profile. When you start a new session using that saved profile, your authentication state is preserved, and you remain logged in. This enables agents to perform tasks on authenticated websites without manual login intervention. You can choose flexible session modes for both read-only and persistent operations, enabling parallel processing where multiple sessions use the same profile simultaneously.\n \nThis feature is available in all 14 AWS Regions where Amazon Bedrock AgentCore Browser is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), Asia Pacific (Seoul), and Canada (Central).\n \nTo learn more, visit the Browser Profiles documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-bedrock-agentcore-browser-profiles",
      "pubDate": "2026-02-06T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-acb6f4f76a9c",
      "title": "Building fault-tolerant applications with AWS Lambda durable functions",
      "description": "Business applications often coordinate multiple steps that need to run reliably or wait for extended periods, such as customer onboarding, payment processing, or orchestrating large language model inference. These critical processes require completion despite temporary disruptions or system failures. Developers currently spend significant time implementing mechanisms to track progress, handle failures, and manage resources when […]",
      "link": "https://aws.amazon.com/blogs/compute/building-fault-tolerant-long-running-application-with-aws-lambda-durable-functions/",
      "pubDate": "2026-02-06T16:54:39.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-29ddb9057340",
      "title": "AWS Config now supports 30 new resource types",
      "description": "AWS Config now supports 30 additional AWS resource types across key services including Amazon EKS, Amazon Q, and AWS IoT. This expansion provides greater coverage over your AWS environment, enabling you to more effectively discover, assess, audit, and remediate an even broader range of resources.\n  With this launch, if you have enabled recording for all resource types, then AWS Config will automatically track these new additions. The newly supported resource types are also available in Config rules and Config aggregators.\n  You can now use AWS Config to monitor the following newly supported resource types in all AWS Regions where the supported resources are available:\n  Resource Types:\n  \n \n \n  \nAWS::ApplicationSignals::ServiceLevelObjective \n   AWS::IoT::SoftwarePackage \n  \nAWS::ARCZonalShift::AutoshiftObserverNotificationStatus      \n   AWS::IoT::TopicRule \n  \nAWS::B2BI::Transformer \n   AWS::IoTWireless::Destination \n  \nAWS::CE::CostCategory \n   AWS::IoTWireless::DeviceProfile \n  \nAWS::CleanRooms::ConfiguredTable \n   AWS::IoTWireless::NetworkAnalyzerConfiguration  \n  \nAWS::CleanRooms::Membership \n   AWS::IoTWireless::TaskDefinition \n  \nAWS::CodeArtifact::PackageGroup \n   AWS::IoTWireless::WirelessGateway \n  \nAWS::Connect::Prompt \n   AWS::Kinesis::ResourcePolicy \n  \nAWS::EKS::Nodegroup \n   AWS::PCAConnectorSCEP::Connector \n  \nAWS::GameLift::MatchmakingRuleSet \n   AWS::QBusiness::Application \n  \nAWS::GameLift::Script \n   AWS::QuickSight::DataSet \n  \nAWS::Glue::Crawler \n   AWS::QuickSight::Dashboard \n  \nAWS::InternetMonitor::Monitor \n   AWS::Route53::DNSSEC \n  \nAWS::IoT::BillingGroup \n   AWS::SSM::PatchBaseline \n  \nAWS::IoT::ResourceSpecificLogging \n   AWS::Transfer::User",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-config-new-resource-types",
      "pubDate": "2026-02-06T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "eks",
        "kinesis",
        "glue",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "eks",
        "kinesis",
        "glue",
        "quicksight",
        "launch",
        "ga",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-6515e8f8245f",
      "title": "Amazon Connect Cases now supports CSV uploads to map related field options",
      "description": "Amazon Connect Cases now supports using a CSV file to define which field options appear based on other field values, making it easier to configure complex field relationships on case templates. Instead of manually defining valid options — such as applicable defect types based on product category — admins can upload a file to define these relationships at scale, reducing onboarding effort and configuration time.\n  Amazon Connect Cases is available in the following AWS regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town) AWS regions. To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-connect-cases-csv-related-field-options",
      "pubDate": "2026-02-06T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-244a6a9a1248",
      "title": "AWS Network Firewall announces new price reductions",
      "description": "AWS Network Firewall has introduced two pricing improvements for customers. The service has added the hourly and data processing discounts on NAT Gateways that are service-chained with Network Firewall secondary endpoints. Additionally, AWS Network Firewall has removed additional data processing charges for Advanced Inspection, which enables Transport Layer Security (TLS) inspection of encrypted network traffic.\n \nPreviously, NAT Gateway discounts were limited to primary Network Firewall endpoints, and customers paid additional data processing charges when using Advanced Inspection for TLS inspection in select AWS regions. With these improvements, the NAT Gateway discounts now apply when service-chained with both primary and secondary firewall endpoints. Customers also no longer pay the additional data processing charge for Advanced Inspection that ranged from $0.001/GB to $0.009/GB in 13 AWS regions: Middle East (Bahrain), Asia Pacific (Hong Kong), Asia Pacific (Tokyo), Asia Pacific (Osaka), Asia Pacific (Mumbai), EU (Milan), South America (São Paulo), US West (N. California), Africa (Cape Town), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), and Asia Pacific (Melbourne).\n \nThese changes help to reduce costs for architectures that use Network Firewall's multiple VPC endpoint capability and TLS inspection features. Multiple VPC endpoints allow you to connect 50 VPCs per Availability Zone to a single Network Firewall, helping to reduce operational complexity and lower costs as you protect more VPCs. By removing additional data processing charges when using Advanced Inspection, customers can now implement TLS inspection more cost-effectively across their network security architecture.\n \nThese pricing improvements are available in all AWS regions where Network Firewall is offered and are applied automatically to eligible configurations. No action is required from customers.\n \nTo learn more, see AWS Network Firewall pricing and the AWS Network Firewall service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-network-firewall-new-price-reduction/",
      "pubDate": "2026-02-06T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-0b5861fc727a",
      "title": "Amazon ECR now supports additional metrics for monitoring repositories",
      "description": "Amazon Elastic Container Registry (ECR) now enables customers to monitor additional repository metrics through Amazon CloudWatch. These new metrics, RepositoryCount and ImagesPerRepositoryCount, help customers identify growth trends of images by repository as well as understand their trends for creating and deleting repositories. With these insights, customers can easily identify anomalous behavior and alert themselves when their usage approaches the service quota.\n  These metrics are available in all AWS commercial and AWS GovCloud (US) Regions at no additional cost. To learn more about Amazon ECR repository metrics, please review our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ecr-additional-repository-metrics/",
      "pubDate": "2026-02-06T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudwatch",
        "support"
      ]
    },
    {
      "id": "aws-news-eb570f9242d7",
      "title": "Reduce Mean Time to Resolution with an observability agent",
      "description": "In this post, we present an observability agent using OpenSearch Service and Amazon Bedrock AgentCore that can help surface root cause and get insights faster, handle multiple query-correlation cycles, and ultimately reduce MTTR even further.",
      "link": "https://aws.amazon.com/blogs/big-data/reduce-mean-time-to-resolution-with-an-observability-agent/",
      "pubDate": "2026-02-05T19:48:33.000Z",
      "source": "bigDataBlog",
      "services": [
        "bedrock",
        "agentcore",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-6b38347fc46f",
      "title": "Amazon OpenSearch Ingestion 101: Set CloudWatch alarms for key metrics",
      "description": "This post provides an in-depth look at setting up Amazon CloudWatch alarms for OpenSearch Ingestion pipelines. It goes beyond our recommended alarms to help identify bottlenecks in the pipeline, whether that’s in the sink, the OpenSearch clusters data is being sent to, the processors, or the pipeline not pulling or accepting enough from the source. This post will help you proactively monitor and troubleshoot your OpenSearch Ingestion pipelines.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-opensearch-ingestion-service-101-set-cloudwatch-alarms-for-key-metrics/",
      "pubDate": "2026-02-05T19:47:26.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch ingestion",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "opensearch",
        "opensearch ingestion",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-093fbdc9670f",
      "title": "Amazon EC2 G6e instances now available in the UAE region",
      "description": "Starting today, the Amazon EC2 G6e instances powered by NVIDIA L40S Tensor Core GPUs is now available in Middle East (UAE) Region. G6e instances can be used for a wide range of machine learning and spatial computing use cases.\n \nCustomers can use G6e instances to deploy large language models (LLMs) and diffusion models for generating images, video, and audio. Additionally, the G6e instances will unlock customers’ ability to create larger, more immersive 3D simulations and digital twins for spatial computing workloads. G6e instances feature up to 8 NVIDIA L40S Tensor Core GPUs with 48 GB of memory per GPU and third generation AMD EPYC processors. They also support up to 192 vCPUs, up to 400 Gbps of network bandwidth, up to 1.536 TB of system memory, and up to 7.6 TB of local NVMe SSD storage. \n  Amazon EC2 G6e instances are available today in the AWS US East (N. Virginia, Ohio), US West (Oregon), Asia Pacific (Tokyo, Seoul), Middle East (UAE) and Europe (Frankfurt, Spain, Stockholm) Regions. Customers can purchase G6e instances as On-Demand Instances, Reserved Instances, Spot Instances, or as part of Savings Plans.\n  To get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit the G6e instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-g6e-instances-uae-region/",
      "pubDate": "2026-02-05T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b8494c694c0a",
      "title": "AWS Builder ID now supports Sign in with Apple",
      "description": "AWS Builder ID, your profile for accessing AWS applications including AWS Builder Center, AWS Training and Certification, AWS re:Post, AWS Startups, and Kiro, now supports Sign in with Apple as a social login provider. This expansion of sign-in options builds on the existing Sign in with Google capability, providing Apple users with a streamlined way to access AWS resources without managing separate credentials on AWS.\n \n  \nWith Sign in with Apple integration, developers and builders can now enjoy access to their AWS Builder ID profile using their Apple Account credentials. This enhancement eliminates password management complexity, reduces forgotten password issues, and provides a frictionless experience for both new user registration and returning user sign-ins. Whether you're accessing development resources in AWS Builder Center, enrolling in certification programs, participating in community discussions on AWS re:Post, exploring startup resources, or using Kiro to code your next app, your Apple Account now serves as a secure gateway to your builder AWS journey. \n \n  \nTo learn more about AWS Builder ID and get started with Sign in with Apple, visit the AWS Builder ID documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-builder-id-sign-in-apple",
      "pubDate": "2026-02-05T19:20:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "ga",
        "enhancement",
        "integration",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-911bc5154c64",
      "title": "Amazon WorkSpaces launches Graphics G6, Gr6, and G6f bundles",
      "description": "Today, Amazon WorkSpaces announces the availability of 12 new Graphics G6, Gr6, and G6f WorkSpaces bundles built on the Amazon EC2 G6 family. These bundles expand customers’ options for running graphics-intensive and GPU-accelerated workloads, and are available on both Amazon WorkSpaces Personal and Amazon WorkSpaces Core.\n \nThe new bundles are designed to support a wide range of performance, memory, and cost requirements: G6 bundles include five sizes with 1:4 vCPU-to-memory configurations, suitable for graphic design, CAD/CAM, and ML model training workloads. Gr6 bundles include two sizes with memory-optimized 1:8 vCPU-to-memory configurations, designed for higher-memory workloads such as 3D rendering, seismic visualization, and GIS processing. G6f bundles include five sizes and offer fractional GPU options (1/8, 1/4, and 1/2 GPU), enabling cost-effective access to GPU acceleration for workloads that do not require a full GPU. All Graphics G6, Gr6, and G6f WorkSpaces support Windows Server 2022 and allow customers to bring their own Windows desktop licenses for Windows 11.\n \nThese bundles are available in 13 AWS Regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Paris, Frankfurt, London), Asia Pacific (Tokyo, Mumbai, Sydney, Seoul), South America (São Paulo), and AWS GovCloud (US-West and US-East).\n \nTo get started, create a Graphics G6, Gr6, or G6f WorkSpace using the Amazon WorkSpaces console. For pay-as-you-go pricing details, see the Amazon WorkSpaces Pricing Page and the Amazon WorkSpaces Core Pricing Page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-workspaces-personal-core-graphics-g6-gr6-g6f-bundles/",
      "pubDate": "2026-02-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "ec2",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-639bbb72d5dd",
      "title": "Amazon EC2 I7ie instances now available in AWS Canada (Central)",
      "description": "AWS is announcing Amazon EC2 I7ie instances are now available in AWS Canada (Central) regions. Designed for large storage I/O intensive workloads, I7ie instances are powered by 5th Gen Intel Xeon Processors with an all-core turbo frequency of 3.2 GHz, offering up to 40% better compute performance and 20% better price performance over existing I3en instances. I7ie instances offer up to 120TB local NVMe storage density (highest in the cloud) for storage optimized instances and offer up to twice as many vCPUs and memory compared to prior generation instances. Powered by 3rd generation AWS Nitro SSDs, I7ie instances deliver up to 65% better real-time storage performance, up to 50% lower storage I/O latency, and 65% lower storage I/O latency variability compared to I3en instances.\n  I7ie are high density storage optimized instances, ideal for workloads requiring fast local storage with high random read/write performance at very low latency consistency to access large data sets. These instances are available in 9 different virtual sizes and deliver up to 100Gbps of network bandwidth and 60Gbps of bandwidth for Amazon Elastic Block Store (EBS).\n  To learn more, visit the I7ie instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-i7ie-instances-available-aws-canada/",
      "pubDate": "2026-02-05T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-c39359ee94ef",
      "title": "AWS Glue launches native REST API connector for universal data integration",
      "description": "AWS Glue now offers a native REST-based connector that enables customers to easily read data from any source with a REST-based API. Customers can now create custom connectors to any REST-enabled data source and seamlessly integrate that data into their AWS Glue ETL (Extract, Transform, and Load) jobs. This capability extends AWS Glue's existing connectivity to 100+ non-AWS data sources through 60+ native connectors and additional options on AWS Marketplace.\n  Previously, connecting to proprietary systems or emerging platforms required customers to build custom connectors by providing specialized JARs with the necessary libraries. The new native REST API connector eliminates this complexity, making it easier to integrate data from any REST-enabled source. It reduces operational overhead by eliminating the need to install, update, or manage custom libraries, freeing teams from maintenance burdens. The connector also enhances flexibility, enabling organizations to quickly adapt to new data sources as business needs evolve. It also streamlines ETL management by allowing data engineers to focus on data transformation and business logic rather than spending time building and maintaining connector infrastructure.\n  The AWS Glue REST API connector is available in all AWS commercial regions where AWS Glue is available.\n  You can start using the AWS Glue REST API connector using AWS Glue APIs, AWS Command Line Interface (CLI), or AWS Software Development Kit (SDK). To get started, see AWS Glue documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-glue-rest-api-connector",
      "pubDate": "2026-02-05T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "glue",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "glue",
        "organizations",
        "launch",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-22acca8edad5",
      "title": "Amazon EC2 High Memory U7i-6TB instances now available in AWS GovCloud (US-West)",
      "description": "Amazon EC2 High Memory U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in AWS GovCloud (US-West). U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-u7i-6tb-instances-available/",
      "pubDate": "2026-02-05T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-3d65b6979e0c",
      "title": "Amazon EC2 capacity blocks for ML can be shared across multiple accounts",
      "description": "Amazon Web Services (AWS) is announcing the general availability of cross-account sharing for Amazon EC2 Capacity Blocks for ML. This capability allows organizations to share reserved GPU capacity across AWS accounts using AWS Resource Access Manager (RAM), helping optimize utilization and reduce costs.\n \nOrganizations can now purchase Capacity Blocks and provision them across multiple accounts, allowing different workloads to access a pool of reserved capacity at no additional cost. This capability helps teams coordinate ML infrastructure investments and keeps reserved GPU capacity in continuous use across different workloads.\n \nThis feature is available for all Instance Capacity Blocks in AWS Regions where EC2 Capacity Blocks for ML are offered. For a complete list of supported regions, refer to Capacity Blocks Supported Regions documentation. \n \nTo get started, create a Resource Share through AWS Resource Access Manager, add your Capacity Blocks for ML resources, and specify the target accounts you wish to share with. For more details, please refer to the Capacity Block Guide",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-capacity-blocks-multiple-accounts",
      "pubDate": "2026-02-05T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-c520cba1d654",
      "title": "Claude Opus 4.6 now available in Amazon Bedrock",
      "description": "Starting today, Amazon Bedrock supports Claude Opus 4.6. According to Anthropic, Opus 4.6 is their most intelligent model and the world's best model for coding, enterprise agents, and professional work. Claude Opus 4.6 brings advanced capabilities to Amazon Bedrock customers, including industry-leading performance for agentic tasks, complex coding projects, and enterprise-grade workflows that require deep reasoning and reliability.\n  Claude Opus 4.6 excels across use cases that require sophisticated reasoning and multi-step orchestration. For agentic workflows, it manages complex tasks across dozens of tools with industry-leading reliability, proactively spinning up subagents and working with less oversight. Developers can leverage Opus 4.6’s coding capabilities for long-horizon projects, complex implementations, and large-scale codebases—handling the full lifecycle from requirements gathering to implementation and maintenance. Enterprise teams can use the model to power end-to-end workflows with professional polish, including financial analysis that surfaces insights requiring days of manual compilation, cybersecurity applications that catch subtle attack patterns, and computer use workflows that move data between applications. The model supports both 200K and 1M context tokens (preview), enabling processing of extensive documents and codebases.\n  Claude Opus 4.6 is now available in Amazon Bedrock. For the full list of available regions, refer to the documentation. To learn more and get started with the model in Amazon Bedrock, read the About Amazon blog and visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/2/claude-opus-4.6-available-amazon-bedrock/",
      "pubDate": "2026-02-05T09:59:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "preview",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-52c73c6767c9",
      "title": "Amazon EC2 C8id, M8id, and R8id instances with up to 22.8 TB local NVMe storage are generally available",
      "description": "AWS launches Amazon EC2 C8id, M8id, and R8id instances backed by NVMe-based SSD block-level instance storage physically connected to the host server. These instances offer 3 times more vCPUs, memory, and local storage with up to 22.8TB of local NVMe-backed SSD block-level storage.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-ec2-c8id-m8id-and-r8id-instances-with-up-to-22-8-tb-local-nvme-storage-are-generally-available/",
      "pubDate": "2026-02-04T22:31:56.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "launch",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-76536849a1c8",
      "title": "AWS Batch now supports unmanaged compute environments for Amazon EKS",
      "description": "AWS Batch now extends its job scheduling capabilities to unmanaged compute environments on Amazon EKS. With unmanaged EKS compute environments, you can leverage AWS Batch's job orchestration while maintaining full control over your Kubernetes infrastructure for security, compliance, or operational requirements.\n  With this capability, you can create unmanaged compute environments through CreateComputeEnvironment API and AWS Batch console by selecting your existing EKS cluster and specifying a Kubernetes namespace, then associate your EKS nodes with the compute environment using kubectl labeling.\n  AWS Batch supports developers, scientists, and engineers in running efficient batch processing for ML model training, simulations, and analysis at any scale. Unmanaged compute environments on Amazon EKS are available today in all AWS regions where AWS Batch is available. For more information, see the AWS Batch User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-batch-on-eks-unmanaged-compute-environments",
      "pubDate": "2026-02-04T20:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-bffd31a2575d",
      "title": "Structured outputs now available in Amazon Bedrock",
      "description": "Amazon Bedrock now supports structured outputs, a capability that provides consistent, machine-readable responses from foundation models that adhere to your defined JSON schemas. Instead of prompting for valid JSON and adding extra checks in your application, you can specify the format you want and receive responses that match it—making production workflows more predictable and resilient.\n  Structured outputs helps with common production tasks such as extracting key fields and powering workflows that use APIs or tools, where small formatting errors can break downstream systems. By ensuring schema compliance, it reduces the need for custom validation logic and lowers operational overhead through fewer failed requests and retries—so you can confidently deploy AI applications that require predictable, machine-readable outputs. You can use structured outputs in two ways: define a JSON schema that describes the response format you want, or use strict tool definitions to ensure a model’s tool calls match your specifications.\n  Structured outputs is generally available for Anthropic Claude 4.5 models and select open-weight models across the Converse, ConverseStream, InvokeModel, and InvokeModelWithResponseStream APIs in all commercial AWS Regions where Amazon Bedrock is supported. To learn more about structured outputs and the supported models, visit the Amazon Bedrock documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/structured-outputs-available-amazon-bedrock/",
      "pubDate": "2026-02-04T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "generally-available",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-d7fcc4742b73",
      "title": "Amazon EC2 G7e instances now available in US West (Oregon) region",
      "description": "Starting today, Amazon EC2 G7e instances accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs are now available in US West (Oregon) region. G7e instances offer up to 2.3x inference performance compared to G6e.\n \nCustomers can use G7e instances to deploy large language models (LLMs), agentic AI models, multimodal generative AI models, and physical AI models. G7e instances offer the highest performance for spatial computing workloads as well as workloads that require both graphics and AI processing capabilities. G7e instances feature up to 8 NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, with 96 GB of memory per GPU, and 5th Generation Intel Xeon processors. They support up to 192 virtual CPUs (vCPUs) and up to 1600 Gbps of networking bandwidth. G7e instances support NVIDIA GPUDirect Peer to Peer (P2P) that boosts performance for multi-GPU workloads. Multi-GPU G7e instances also support NVIDIA GPUDirect Remote Direct Memory Access (RDMA) with EFA in EC2 UltraClusters, reducing latency for small-scale multi-node workloads.\n \nYou can use G7e instances for Amazon EC2 in the following AWS Regions: US West (Oregon), US East (N. Virginia) and US East (Ohio). You can purchase G7e instances as On-Demand Instances, Spot Instances, or as part of Savings Plans.\n \nTo get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit G7e instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-g7e-instances-oregon-region/",
      "pubDate": "2026-02-04T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-583e5c06e6da",
      "title": "Cartesia Sonic 3 text-to-speech model is now available on Amazon SageMaker JumpStart",
      "description": "Cartesia’s Sonic 3 model is now available in Amazon SageMaker JumpStart, expanding the portfolio of foundation models available to AWS customers. Sonic 3 is Cartesia's latest state space model (SSM) for streaming text-to-speech (TTS), delivering high naturalness, accurate transcript following, and industry-leading latency with fine-grained control over volume, speed, and emotion.\n \nSonic 3 supports 42 languages and provides advanced controllability through API parameters and SSML tags for volume, speed, and emotion adjustments. The model includes natural laughter support, stable voices optimized for voice agents, and emotive voices for expressive characters. With sub-100ms latency, Sonic 3 enables real-time conversational AI that captures human speech nuances including emotions and tonal shifts.\n  With SageMaker JumpStart, customers can deploy Sonic 3 with just a few clicks to address their voice AI use cases. To get started with this model, navigate to the SageMaker JumpStart model catalog in the SageMaker Studio or use the SageMaker Python SDK to deploy the model to your AWS account. For more information about deploying and using foundation models in SageMaker JumpStart, see the Amazon SageMaker JumpStart documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/cartesia-sonic-3-on-sagemaker-jumpstart",
      "pubDate": "2026-02-04T19:30:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-1a266f7162f6",
      "title": "Amazon ECS adds Network Load Balancer support for Linear and Canary deployments",
      "description": "Amazon Elastic Container Service (Amazon ECS) announces native support for linear and canary deployment strategies for ECS services using Network Load Balancers (NLB). Now, applications that commonly use NLB, such as those requiring TCP/UDP-based connections, low latency, long-lived connections, or static IP addresses, can take advantage of managed, incremental traffic shifting natively from ECS when rolling out updates.\n \nWith this launch, ECS customers using NLB can shift traffic in a controlled manner during deployments, such as moving traffic in increments or starting with a small percentage to validate changes before completing a rollout. These deployment strategies provide additional confidence during updates by allowing teams to observe application behavior at each traffic-shift step, and integrate with Amazon CloudWatch alarms to automatically stop or roll back deployments if issues are detected. This is especially valuable for workloads running behind an NLB, such as online gaming backends, financial transaction systems, and real-time messaging services.\n \nTo get started, select your NLB target groups, listener, and preferred deployment strategy in the ECS service configuration using the AWS Management Console, AWS CLI, or Infrastructure-as-Code tools. This can be enabled for both new and existing ECS services in all AWS commercial and AWS GovCloud (US) Regions. For more information, see the documentation for Amazon ECS linear deployments and Amazon ECS canary deployments.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ecs-nlb-linear-canary-deployments",
      "pubDate": "2026-02-04T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ecs",
        "cloudwatch",
        "launch",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-c38979a812e0",
      "title": "Apache Spark lineage now available in Amazon SageMaker Unified Studio for IDC based domains",
      "description": "Amazon SageMaker announces general availability of Data Lineage for Apache Spark jobs executed on Amazon EMR and AWS Glue in SageMaker Unified Studio for IDC based domains. Data Lineage provides you with the information you need to identify the root cause of complex issues and understand the impact of changes.\n  This feature supports lineage capture of schema and transformations of data assets and columns from Spark executions in EMR-EC2, EMR-Serverless, EMR-EKS, and AWS Glue. You can then explore this lineage visually as a graph in SageMaker Unified Studio or query it using APIs. You can also use lineage to compare transformations across Spark job's history.\n  Spark lineage is available in all existing SageMaker Unified Studio regions. For detailed information on how to get started with lineage using these new features, refer to the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2026/02/apache-spark-lineage-amazon-sageMaker-unified-studio",
      "pubDate": "2026-02-04T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "glue",
        "now-available",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-579c56d79c87",
      "title": "Mastering millisecond latency and millions of events: The event-driven architecture behind the Amazon Key Suite",
      "description": "In this post, we explore how the Amazon Key team used Amazon EventBridge to modernize their architecture, transforming a tightly coupled monolithic system into a resilient, event-driven solution. We explore the technical challenges we faced, our implementation approach, and the architectural patterns that helped us achieve improved reliability and scalability. The post covers our solutions for managing event schemas at scale, handling multiple service integrations efficiently, and building an extensible architecture that accommodates future growth.",
      "link": "https://aws.amazon.com/blogs/architecture/mastering-millisecond-latency-and-millions-of-events-the-event-driven-architecture-behind-the-amazon-key-suite/",
      "pubDate": "2026-02-04T15:53:39.000Z",
      "source": "architectureBlog",
      "services": [
        "eventbridge"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "eventbridge",
        "integration"
      ]
    },
    {
      "id": "aws-news-b7988a0ad294",
      "title": "Use Amazon MSK Connect and Iceberg Kafka Connect to build a real-time data lake",
      "description": "In this post, we demonstrate how to use Iceberg Kafka Connect with Amazon Managed Streaming for Apache Kafka (Amazon MSK) Connect to accelerate real-time data ingestion into data lakes, simplifying the synchronization process from transactional databases to Apache Iceberg tables.",
      "link": "https://aws.amazon.com/blogs/big-data/use-amazon-msk-connect-and-iceberg-kafka-connect-to-build-a-real-time-data-lake/",
      "pubDate": "2026-02-03T18:42:38.000Z",
      "source": "bigDataBlog",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kafka",
        "msk"
      ]
    },
    {
      "id": "aws-news-68e81d0b319e",
      "title": "Optimizing Flink’s join operations on Amazon EMR with Alluxio",
      "description": "In this post, we show you how to implement real-time data correlation using Apache Flink to join streaming order data with historical customer and product information, enabling you to make informed decisions based on comprehensive, up-to-date analytics. We also introduce an optimized solution to automatically load Hive dimension table data into Alluxio Universal Flash Storage (UFS) through the Alluxio cache layer. This enables Flink to perform temporal joins on changing data, accurately reflecting the content of a table at specific points in time.",
      "link": "https://aws.amazon.com/blogs/big-data/optimizing-flinks-join-operations-on-amazon-emr-with-alluxio/",
      "pubDate": "2026-02-03T18:41:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-50526bbbaf99",
      "title": "Federate access to Amazon SageMaker Unified Studio with AWS IAM Identity Center and Ping Identity",
      "description": "In this post, we show how to set up workforce access with SageMaker Unified Studio using Ping Identity as an external IdP with IAM Identity Center.",
      "link": "https://aws.amazon.com/blogs/big-data/federate-access-to-amazon-sagemaker-unified-studio-with-aws-iam-identity-center-and-ping-identity/",
      "pubDate": "2026-02-02T20:39:39.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam",
        "iam identity center"
      ]
    },
    {
      "id": "aws-news-ac16fd5dbc76",
      "title": "AWS Weekly Roundup: Amazon Bedrock agent workflows, Amazon SageMaker private connectivity, and more (February 2, 2026)",
      "description": "Over the past week, we passed Laba festival, a traditional marker in the Chinese calendar that signals the final stretch leading up to the Lunar New Year. For many in China, it’s a moment associated with reflection and preparation, wrapping up what the year has carried, and turning attention toward what lies ahead. Looking forward, […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-bedrock-agent-workflows-amazon-sagemaker-private-connectivity-and-more-february-2-2026/",
      "pubDate": "2026-02-02T17:19:48.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-9d73697199bf",
      "title": "Sovereign failover – Design for digital sovereignty using the AWS European Sovereign Cloud",
      "description": "This post explores the architectural patterns, challenges, and best practices for building cross-partition failover, covering network connectivity, authentication, and governance. By understanding these constraints, you can design resilient cloud-native applications that balance regulatory compliance with operational continuity.",
      "link": "https://aws.amazon.com/blogs/architecture/sovereign-failover-design-for-digital-sovereignty-using-the-aws-european-sovereign-cloud/",
      "pubDate": "2026-01-30T19:09:35.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": []
    },
    {
      "id": "aws-news-294ebadd8ed1",
      "title": "Serverless ICYMI Q4 2025",
      "description": "Stay current with the latest serverless innovations that can transform your applications. In this 31st quarterly recap, discover the most impactful AWS serverless launches, features, and resources from Q4 2025 that you might have missed.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-icymi-q4-2025/",
      "pubDate": "2026-01-30T15:23:57.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova",
        "launch"
      ]
    },
    {
      "id": "aws-news-56b859ccdae9",
      "title": "Build a trusted foundation for data and AI using Alation and Amazon SageMaker Unified Studio",
      "description": "The Alation and SageMaker Unified Studio integration helps organizations bridge the gap between fast analytics and ML development and the governance requirements most enterprises face. By cataloging metadata from SageMaker Unified Studio in Alation, you gain a governed, discoverable view of how assets are created and used. In this post, we demonstrate who benefits from this integration, how it works, the specific metadata it synchronizes, and provide a complete deployment guide for your environment.",
      "link": "https://aws.amazon.com/blogs/big-data/build-a-trusted-foundation-for-data-and-ai-using-alation-and-amazon-sagemaker-unified-studio/",
      "pubDate": "2026-01-29T23:33:30.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "organizations",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-2bbf3449a6da",
      "title": "More room to build: serverless services now support payloads up to 1 MB",
      "description": "To support cloud applications that increasingly depend on rich contextual data, AWS is raising the maximum payload size from 256 KB to 1 MB for asynchronous AWS Lambda function invocations, Amazon Amazon SQS, and Amazon EventBridge. Developers can use this enhancement to build and maintain context-rich event-driven systems and reduce the need for complex workarounds such as data chunking or external large object storage.",
      "link": "https://aws.amazon.com/blogs/compute/more-room-to-build-serverless-services-now-support-payloads-up-to-1-mb/",
      "pubDate": "2026-01-29T22:16:14.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "lambda",
        "eventbridge",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "lambda",
        "eventbridge",
        "sqs",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-578522f933b9",
      "title": "How Artera enhances prostate cancer diagnostics using AWS",
      "description": "In this post, we explore how Artera used Amazon Web Services (AWS) to develop and scale their AI-powered prostate cancer test, accelerating time to results and enabling personalized treatment recommendations for patients.",
      "link": "https://aws.amazon.com/blogs/architecture/how-artera-enhances-prostate-cancer-diagnostics-using-aws/",
      "pubDate": "2026-01-29T17:06:57.000Z",
      "source": "architectureBlog",
      "services": [
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize"
      ]
    },
    {
      "id": "aws-news-0aaa039509ca",
      "title": "How Tipico democratized data transformations using Amazon Managed Workflows for Apache Airflow and AWS Batch",
      "description": "Tipico is the number one name in sports betting in Germany. Every day, we connect millions of fans to the thrill of sport, combining technology, passion, and trust to deliver fast, secure, and exciting betting, both online and in more than a thousand retail shops across Germany. We also bring this experience to Austria, where we proudly operate a strong sports betting business. In this post, we show how Tipico built a unified data transformation platform using Amazon Managed Workflows for Apache Airflow (Amazon MWAA) and AWS Batch.",
      "link": "https://aws.amazon.com/blogs/big-data/how-tipico-democratized-data-transformations-using-amazon-managed-workflows-for-apache-airflow-and-aws-batch/",
      "pubDate": "2026-01-28T17:56:00.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-9b88459c7e3c",
      "title": "AWS Weekly Roundup: Amazon EC2 G7e instances, Amazon Corretto updates, and more (January 26, 2026)",
      "description": "Hey! It’s my first post for 2026, and I’m writing to you while watching our driveway getting dug out. I hope wherever you are you are safe and warm and your data is still flowing! This week brings exciting news for customers running GPU-intensive workloads, with the launch of our newest graphics and AI inference […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ec2-g7e-instances-with-nvidia-blackwell-gpus-january-26-2026/",
      "pubDate": "2026-01-26T16:25:46.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-9c4a35876569",
      "title": "Announcing Amazon EC2 G7e instances accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs",
      "description": "AWS introduces Amazon EC2 G7e instances accelerated by the NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs with up to 2.3 times inference performance. G7e instances deliver cost-effective performance for generative AI inference workloads and the highest performance for graphics workloads.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-amazon-ec2-g7e-instances-accelerated-by-nvidia-rtx-pro-6000-blackwell-server-edition-gpus/",
      "pubDate": "2026-01-20T21:22:56.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-4de7cccc6dd0",
      "title": "AWS Weekly Roundup: Kiro CLI latest features, AWS European Sovereign Cloud, EC2 X8i instances, and more (January 19, 2026)",
      "description": "At the end of 2025 I was happy to take a long break to enjoy the incredible summers that the southern hemisphere provides. I’m back and writing my first post in 2026 which also happens to be my last post for the AWS News Blog (more on this later). The AWS community is starting the […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-kiro-cli-latest-features-aws-european-sovereign-cloud-ec2-x8i-instances-and-more-january-19-2026/",
      "pubDate": "2026-01-20T00:24:38.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-480e3eb14bac",
      "title": "Simplify network segmentation for AWS Outposts racks with multiple local gateway routing domains",
      "description": "AWS now supports multiple local gateway (LGW) routing domains on AWS Outposts racks to simplify network segmentation. Network segmentation is the practice of splitting a computer network into isolated subnetworks, or network segments. This reduces the attack surface so that if a host on one network segment is compromised, the hosts on the other network segments are not affected. Many customers in regulated industries such as manufacturing, health care and life sciences, banking, and others implement network segmentation as part of their on-premises network security standards to reduce the impact of a breach and help address compliance requirements.",
      "link": "https://aws.amazon.com/blogs/compute/simplify-network-segmentation-for-aws-outposts-racks-with-multiple-local-gateway-routing-domains/",
      "pubDate": "2026-01-16T18:49:35.000Z",
      "source": "computeBlog",
      "services": [
        "rds",
        "outposts"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "outposts",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-de9d2d19ffe3",
      "title": "Amazon EC2 X8i instances powered by custom Intel Xeon 6 processors are generally available for memory-intensive workloads",
      "description": "AWS is announcing the general availability of Amazon EC2 X8i instances, next-generation memory optimized instances powered by custom Intel Xeon 6 processors available only on AWS. X8i instances are SAP-certified and deliver the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-ec2-x8i-instances-powered-by-custom-intel-xeon-6-processors-are-generally-available-for-memory-intensive-workloads/",
      "pubDate": "2026-01-15T22:52:17.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-298dd0715dfd",
      "title": "Opening the AWS European Sovereign Cloud",
      "description": "Deutsch | English | Español | Français | Italiano As a European citizen, I understand first-hand the importance of digital sovereignty, especially for our public sector organisations and highly regulated industries. Today, I’m delighted to share that the AWS European Sovereign Cloud is now generally available to all customers. We first announced our plans to […]",
      "link": "https://aws.amazon.com/blogs/aws/opening-the-aws-european-sovereign-cloud/",
      "pubDate": "2026-01-15T07:12:54.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "generally-available",
        "ga"
      ]
    },
    {
      "id": "aws-news-6ae9097450e3",
      "title": "Optimizing storage performance for Amazon EKS on AWS Outposts",
      "description": "Amazon Elastic Kubernetes Service (Amazon EKS) on \nAWS Outposts brings the power of managed \nKubernetes to your on-premises infrastructure. Use Amazon EKS on Outposts rack to create hybrid cloud deployments that maintain consistent AWS experiences across environments. As organizations increasingly adopt edge computing and hybrid architectures, storage optimization and performance tuning become critical for successful workload deployment.",
      "link": "https://aws.amazon.com/blogs/compute/optimizing-storage-performance-for-amazon-eks-on-aws-outposts/",
      "pubDate": "2026-01-13T18:57:12.000Z",
      "source": "computeBlog",
      "services": [
        "eks",
        "organizations",
        "outposts"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "eks",
        "organizations",
        "outposts",
        "ga"
      ]
    },
    {
      "id": "aws-news-b534fc68b2dc",
      "title": "How Salesforce migrated from Cluster Autoscaler to Karpenter across their fleet of 1,000 EKS clusters",
      "description": "This blog post examines how Salesforce, operating one of the world's largest Kubernetes deployments, successfully migrated from Cluster Autoscaler to Karpenter across their fleet of 1,000 plus Amazon Elastic Kubernetes Service (Amazon EKS) clusters.",
      "link": "https://aws.amazon.com/blogs/architecture/how-salesforce-migrated-from-cluster-autoscaler-to-karpenter-across-their-fleet-of-1000-eks-clusters/",
      "pubDate": "2026-01-12T20:03:32.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-a998df60ab8a",
      "title": "AWS Weekly Roundup: AWS Lambda for .NET 10, AWS Client VPN quickstart, Best of AWS re:Invent, and more (January 12, 2026)",
      "description": "At the beginning of January, I tend to set my top resolutions for the year, a way to focus on what I want to achieve. If AI and cloud computing are on your resolution list, consider creating an AWS Free Tier account to receive up to $200 in credits and have 6 months of risk-free […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-lambda-for-net-10-aws-client-vpn-quickstart-best-of-aws-reinvent-and-more-january-12-2026/",
      "pubDate": "2026-01-12T17:39:47.000Z",
      "source": "newsBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-fb80ad15392c",
      "title": ".NET 10 runtime now available in AWS Lambda",
      "description": "Amazon Web Services (AWS) Lambda now supports .NET 10 as both a managed runtime and base container image. .NET is a popular language for building serverless applications. Developers can now use the new features and enhancements in .NET when creating serverless applications on Lambda. This includes support for file-based apps to streamline your projects by implementing functions using just a single file.",
      "link": "https://aws.amazon.com/blogs/compute/net-10-runtime-now-available-in-aws-lambda/",
      "pubDate": "2026-01-08T21:01:05.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "new-feature",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-582af0ab873e",
      "title": "Happy New Year! AWS Weekly Roundup: 10,000 AIdeas Competition, Amazon EC2, Amazon ECS Managed Instances and more (January 5, 2026)",
      "description": "Happy New Year! I hope the holidays gave you time to recharge and spend time with your loved ones. Like every year, I took a few weeks off after AWS re:Invent to rest and plan ahead. I used some of that downtime to plan the next cohort for Become a Solutions Architect (BeSA). BeSA is […]",
      "link": "https://aws.amazon.com/blogs/aws/happy-new-year-aws-weekly-roundup-10000-aideas-competition-amazon-ec2-amazon-ecs-managed-instances-and-more-january-5-2026/",
      "pubDate": "2026-01-05T17:10:37.000Z",
      "source": "newsBlog",
      "services": [
        "ec2",
        "ecs",
        "eks"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2",
        "ecs",
        "eks",
        "ga"
      ]
    },
    {
      "id": "aws-news-93e908d04930",
      "title": "AWS Weekly Roundup: Amazon ECS, Amazon CloudWatch, Amazon Cognito and more (December 15, 2025)",
      "description": "Can you believe it? We’re nearly at the end of 2025. And what a year it’s been! From re:Invent recap events, to AWS Summits, AWS Innovate, AWS re:Inforce, Community Days, and DevDays and, recently, adding that cherry on the cake, re:Invent 2025, we have lived through a year filled with exciting moments and technology advancements […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ecs-amazon-cloudwatch-amazon-cognito-and-more-december-15-2025/",
      "pubDate": "2025-12-15T16:42:05.000Z",
      "source": "newsBlog",
      "services": [
        "nova",
        "ecs",
        "cloudwatch"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "nova",
        "ecs",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-36722fddcb63",
      "title": "Building zero trust generative AI applications in healthcare with AWS Nitro Enclaves",
      "description": "In healthcare, generative AI is transforming how \nmedical professionals analyze data, \nsummarize clinical notes, and \ngenerate insights to improve patient outcomes. From \nautomating medical documentation to assisting in \ndiagnostic reasoning, large language models (LLMs) have the potential to augment clinical workflows and accelerate research. However, these innovations also introduce significant privacy, security, and intellectual property challenges.",
      "link": "https://aws.amazon.com/blogs/compute/building-zero-trust-generative-ai-applications-in-healthcare-with-aws-nitro-enclaves/",
      "pubDate": "2025-12-12T19:06:03.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-b56aaf668b93",
      "title": "Architecting conversational observability for cloud applications",
      "description": "In this post, we walk through building a generative AI–powered troubleshooting assistant for Kubernetes. The goal is to give engineers a faster, self-service way to diagnose and resolve cluster issues, cut down Mean Time to Recovery (MTTR), and reduce the cycles experts spend finding the root cause of issues in complex distributed systems.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-conversational-observability-for-cloud-applications/",
      "pubDate": "2025-12-11T15:59:39.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-30581ecb3d79",
      "title": "How BASF’s Agriculture Solutions drives traceability and climate action by tokenizing cotton value chains using Amazon Managed Blockchain",
      "description": "BASF Agricultural Solutions combines innovative products and digital tools with practical farmer knowledge. This post explores how Amazon Managed Blockchain can drive a positive change in the agricultural industry by tokenizing food and cotton value chains for traceability, climate action, and circularity.",
      "link": "https://aws.amazon.com/blogs/architecture/how-basfs-agriculture-solutions-drives-traceability-and-climate-action-by-tokenizing-cotton-value-chains-using-amazon-managed-blockchain/",
      "pubDate": "2025-12-10T17:41:52.000Z",
      "source": "architectureBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-c8a3488015cc",
      "title": "AWS SDK for JavaScript aligns with Node.js release schedule",
      "description": "This post is about AWS SDK for JavaScript v3 announcing end of support for Node.js versions based on Node.js release schedule, and it is not about AWS Lambda. For the latter, refer to the Lambda runtime deprecation policy. In the second week of January 2026, the AWS SDK for JavaScript v3 (JS SDK) will start […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-javascript-aligns-with-node-js-release-schedule/",
      "pubDate": "2025-12-08T17:32:10.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "support"
      ]
    },
    {
      "id": "aws-news-632e1959900f",
      "title": "AWS Weekly Roundup: AWS re:Invent keynote recap, on-demand videos, and more (December 8, 2025)",
      "description": "The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our top announcements of AWS re:Invent 2025 that you can […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinvent-keynote-recap-on-demand-videos-and-more-december-8-2025/",
      "pubDate": "2025-12-08T17:05:29.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "announcement"
      ]
    },
    {
      "id": "aws-news-f8633d530b1e",
      "title": "She architects: Bringing unique perspectives to innovative solutions at AWS",
      "description": "Have you ever wondered what it is really like to be a woman in tech at one of the world's leading cloud companies? Or maybe you are curious about how diverse perspectives drive innovation beyond the buzzwords? Today, we are providing an insider's perspective on the role of a solutions architect (SA) at Amazon Web Services (AWS). However, this is not a typical corporate success story. We are three women who have navigated challenges, celebrated wins, and found our unique paths in the world of cloud architecture, and we want to share our real stories with you.",
      "link": "https://aws.amazon.com/blogs/architecture/she-architects-bringing-unique-perspectives-to-innovative-solutions-at-aws/",
      "pubDate": "2025-12-08T16:37:15.000Z",
      "source": "architectureBlog",
      "services": [
        "nova",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-ad98b700a350",
      "title": "Amazon Bedrock adds reinforcement ﬁne-tuning simplifying how developers build smarter, more accurate AI models",
      "description": "Amazon Bedrock now supports reinforcement fine-tuning delivering 66% accuracy gains on average over base models.",
      "link": "https://aws.amazon.com/blogs/aws/improve-model-accuracy-with-reinforcement-fine-tuning-in-amazon-bedrock/",
      "pubDate": "2025-12-03T16:08:14.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f27f0877e40c",
      "title": "New serverless customization in Amazon SageMaker AI accelerates model fine-tuning",
      "description": "Accelerate AI model development with new training features that enable rapid recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/new-serverless-customization-in-amazon-sagemaker-ai-accelerates-model-fine-tuning/",
      "pubDate": "2025-12-03T16:08:03.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-20b1f9fc07df",
      "title": "Introducing checkpointless and elastic training on Amazon SageMaker HyperPod",
      "description": "Accelerate AI model development with new training features that enable instant recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-checkpointless-and-elastic-training-on-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-12-03T16:07:52.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-4139ea9a5e0b",
      "title": "Announcing replication support and Intelligent-Tiering for Amazon S3 Tables",
      "description": "New features enable automatic cost optimization through intelligent storage tiering and simplified table replication across AWS Regions and accounts.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-replication-support-and-intelligent-tiering-for-amazon-s3-tables/",
      "pubDate": "2025-12-02T16:19:14.000Z",
      "source": "newsBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-0dbe89f3f79b",
      "title": "Orchestrating large-scale document processing with AWS Step Functions and Amazon Bedrock batch inference",
      "description": "Organizations often have large volumes of documents containing valuable information that remains locked away and unsearchable. This solution addresses the need for a \nscalable, automated text extraction and knowledge base pipeline that transforms static document collections into intelligent, searchable repositories for generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-large-scale-document-processing-with-aws-step-functions-and-amazon-bedrock-batch-inference/",
      "pubDate": "2025-11-26T21:41:51.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock",
        "step functions",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "step functions",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-1c031b337189",
      "title": "Secure Amazon Elastic VMware Service (Amazon EVS) with AWS Network Firewall",
      "description": "In this post, we demonstrate how to utilize AWS Network Firewall to secure an Amazon EVS environment, using a centralized inspection architecture across an EVS cluster, VPCs, on-premises data centers and the internet. We walk through the implementation steps to deploy this architecture using AWS Network Firewall and AWS Transit Gateway.",
      "link": "https://aws.amazon.com/blogs/architecture/secure-amazon-elastic-vmware-service-amazon-evs-with-aws-network-firewall/",
      "pubDate": "2025-11-26T16:22:03.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-c9da28428aee",
      "title": "Node.js 24 runtime now available in AWS Lambda",
      "description": "You can now develop AWS Lambda functions using Node.js 24, either as a managed runtime or using the container base image. Node.js 24 is in active LTS status and ready for production use. It is expected to be supported with security patches and bugfixes until April 2028. The Lambda runtime for Node.js 24 includes a new implementation of the […]",
      "link": "https://aws.amazon.com/blogs/compute/node-js-24-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-25T22:19:46.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-7cb737e81dc9",
      "title": "The attendee’s guide to hybrid cloud and edge computing at AWS re:Invent 2025",
      "description": "AWS re:Invent 2025 returns to Las Vegas, Nevada, from December 1–5, 2025. This year, we’re offering a comprehensive lineup of sessions and booth activities to help you build resilient, performant, and scalable applications wherever you need them—in the cloud, on premises, or at the edge.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-hybrid-cloud-and-edge-computing-at-aws-reinvent-2025/",
      "pubDate": "2025-11-25T19:27:19.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-e5767083a6d4",
      "title": "Optimize unused capacity with Amazon EC2 interruptible capacity reservations",
      "description": "Organizations running critical workloads on Amazon Elastic Compute Cloud (Amazon EC2) reserve compute capacity using On-Demand Capacity Reservations (ODCR) to have availability when needed. However, reserved capacity can intermittently sit idle during off-peak periods, between deployments, or when workloads scale down. This unused capacity represents a missed opportunity for cost optimization and resource efficiency across the organization.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-unused-capacity-with-amazon-ec2-interruptible-capacity-reservations/",
      "pubDate": "2025-11-25T01:09:16.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-5403d33b1bbc",
      "title": "How potential performance upside with AWS Graviton helps reduce your costs further",
      "description": "Amazon Web Services (AWS) provides many mechanisms to optimize the price performance of workloads running on Amazon Elastic Compute Cloud (Amazon EC2), and the selection of the optimal infrastructure to run on can be one of the most impactful levers. When we started building the AWS Graviton processor, our goal was to optimize AWS Graviton […]",
      "link": "https://aws.amazon.com/blogs/compute/how-potential-performance-upside-with-aws-graviton-helps-reduce-your-costs-further/",
      "pubDate": "2025-11-24T19:11:55.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton"
      ]
    },
    {
      "id": "aws-news-7d35cf5f9ae9",
      "title": "Enhancing API security with Amazon API Gateway TLS security policies",
      "description": "In this post, you will learn how the new Amazon API Gateway’s enhanced TLS security policies help you meet standards such as PCI DSS, Open Banking, and FIPS, while strengthening how your APIs handle TLS negotiation. This new capability increases your security posture without adding operational complexity, and provides you with a single, consistent way to standardize TLS configuration across your API Gateway infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/enhancing-api-security-with-amazon-api-gateway-tls-security-policies/",
      "pubDate": "2025-11-21T21:17:52.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "rds",
        "api gateway"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "api gateway",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-9d3d32287870",
      "title": "Improving throughput of serverless streaming workloads for Kafka",
      "description": "Event-driven applications often need to process data in real-time. When you use AWS Lambda to process records from Apache Kafka topics, you frequently encounter two typical requirements: you need to process very high volumes of records in close to real-time, and you want your consumers to have the ability to scale rapidly to handle traffic spikes. Achieving both necessitates understanding how Lambda consumes Kafka streams, where the potential bottlenecks are, and how to optimize configurations for high throughput and best performance.",
      "link": "https://aws.amazon.com/blogs/compute/improving-throughput-of-serverless-streaming-workloads-for-kafka/",
      "pubDate": "2025-11-21T20:02:57.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "rds",
        "kafka"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "rds",
        "kafka"
      ]
    },
    {
      "id": "aws-news-b3a3371e0c90",
      "title": "Build scalable REST APIs using Amazon API Gateway private integration with Application Load Balancer",
      "description": "Today, we announced \nAmazon API Gateway REST API’s support for private integration with \nApplication Load Balancers (ALBs). You can use this new capability to securely expose your VPC-based applications through your REST APIs without exposing your ALBs to the public internet.",
      "link": "https://aws.amazon.com/blogs/compute/build-scalable-rest-apis-using-amazon-api-gateway-private-integration-with-application-load-balancer/",
      "pubDate": "2025-11-21T19:28:04.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "api gateway",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-df24f6f1c182",
      "title": "Building multi-tenant SaaS applications with AWS Lambda’s new tenant isolation mode",
      "description": "Today, AWS is announcing tenant isolation for AWS Lambda, enabling you to process function invocations in separate execution environments for each end-user or tenant invoking your Lambda function. This capability simplifies building secure multi-tenant SaaS applications by managing tenant-level compute environment isolation and request routing, allowing you to focus on core business logic rather than implementing tenant-aware compute environment isolation.",
      "link": "https://aws.amazon.com/blogs/compute/building-multi-tenant-saas-applications-with-aws-lambdas-new-tenant-isolation-mode/",
      "pubDate": "2025-11-20T17:47:17.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-b04be71f4d69",
      "title": "Improve API discoverability with the new Amazon API Gateway Portal",
      "description": "In this post, we will show how you can use the new portal feature to create customizable portals with enhanced security features in minutes, with APIs from multiple accounts, without managing any infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/improve-api-discoverability-with-the-new-amazon-api-gateway-portal/",
      "pubDate": "2025-11-20T00:41:25.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-9150859a247c",
      "title": "Building an AI gateway to Amazon Bedrock with Amazon API Gateway",
      "description": "In this post, we'll explore a reference architecture that helps enterprises govern their Amazon Bedrock implementations using Amazon API Gateway. This pattern enables key capabilities like authorization controls, usage quotas, and real-time response streaming. We'll examine the architecture, provide deployment steps, and discuss potential enhancements to help you implement AI governance at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/building-an-ai-gateway-to-amazon-bedrock-with-amazon-api-gateway/",
      "pubDate": "2025-11-19T23:33:41.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "api gateway"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "api gateway",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-4934fd40d9d8",
      "title": "Architecting for AI excellence: AWS launches three Well-Architected Lenses at re:Invent 2025",
      "description": "At re:Invent 2025, we introduce one new lens and two significant updates to the AWS Well-Architected Lenses specifically focused on AI workloads: the Responsible AI Lens, the Machine Learning (ML) Lens, and the Generative AI Lens. Together, these lenses provide comprehensive guidance for organizations at different stages of their AI journey, whether you're just starting to experiment with machine learning or already deploying complex AI applications at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-for-ai-excellence-aws-launches-three-well-architected-lenses-at-reinvent-2025/",
      "pubDate": "2025-11-19T19:36:31.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-61647c9310e0",
      "title": "Announcing the updated AWS Well-Architected Generative AI Lens",
      "description": "We are delighted to announce an update to the AWS Well-Architected Generative AI Lens. This update features several new sections of the Well-Architected Generative AI Lens, including new best practices, advanced scenario guidance, and improved preambles on responsible AI, data architecture, and agentic workflows.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-generative-ai-lens/",
      "pubDate": "2025-11-19T19:36:28.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-5044b6bc98c4",
      "title": "Announcing the updated AWS Well-Architected Machine Learning Lens",
      "description": "We are excited to announce the updated AWS Well-Architected Machine Learning Lens, now enhanced with the latest capabilities and best practices for building machine learning (ML) workloads on AWS.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-machine-learning-lens/",
      "pubDate": "2025-11-19T19:36:25.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-360e834c997a",
      "title": "BASF Digital Farming builds a STAC-based solution on Amazon EKS",
      "description": "This post was co-written with Frederic Haase and Julian Blau with BASF Digital Farming GmbH. At xarvio – BASF Digital Farming, our mission is to empower farmers around the world with cutting-edge digital agronomic decision-making tools. Central to this mission is our crop optimization platform, xarvio FIELD MANAGER, which delivers actionable insights through a range […]",
      "link": "https://aws.amazon.com/blogs/architecture/basf-digital-farming-builds-a-stac-based-solution-on-amazon-eks/",
      "pubDate": "2025-10-22T16:21:09.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-24029d05087c",
      "title": "What’s New in the AWS Deploy Tool for .NET",
      "description": "Version 2.0 of the AWS Deploy Tool for .NET is now available. This new major version introduces several foundational upgrades to improve the deployment experience for .NET applications on AWS. The tool comes with new minimum runtime requirements. We have upgraded it to require .NET 8 because the predecessor, .NET 6, is now out of […]",
      "link": "https://aws.amazon.com/blogs/developer/whats-new-in-the-aws-deploy-tool-for-net/",
      "pubDate": "2025-10-14T13:25:42.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-2f3bd8791ed1",
      "title": "Modernization of real-time payment orchestration on AWS",
      "description": "The global real-time payments market is experiencing significant growth. According to Fortune Business Insights, the market was valued at USD 24.91 billion in 2024 and is projected to grow to USD 284.49 billion by 2032, with a CAGR of 35.4%. Similarly, Grand View Research reports that the global mobile payment market, valued at USD 88.50 […]",
      "link": "https://aws.amazon.com/blogs/architecture/modernization-of-real-time-payment-orchestration-on-aws/",
      "pubDate": "2025-10-01T23:34:00.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": []
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-4fbb29739c17",
      "title": "General Availability Release of the Migration Tool for the AWS SDK for Java 2.x",
      "description": "The AWS SDK for Java 1.x (v1) entered maintenance mode on July 31, 2024, and will reach end-of-support on December 31, 2025. We recommend that you migrate to the AWS SDK for Java 2.x (v2) to access new features, enhanced performance, and continued support from AWS. To help you migrate efficiently, we’ve created a migration […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-release-of-the-migration-tool-for-the-aws-sdk-for-java-2-x/",
      "pubDate": "2025-09-26T16:47:36.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-7e2f23dd38ac",
      "title": "Simplify multi-tenant encryption with a cost-conscious AWS KMS key strategy",
      "description": "In this post, we explore an efficient approach to managing encryption keys in a multi-tenant SaaS environment through centralization, addressing challenges like key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. We demonstrate how implementing a centralized key management strategy using a single AWS KMS key per tenant can maintain security and compliance while reducing operational overhead as organizations scale.",
      "link": "https://aws.amazon.com/blogs/architecture/simplify-multi-tenant-encryption-with-a-cost-conscious-aws-kms-key-strategy/",
      "pubDate": "2025-08-21T21:54:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-875544c87826",
      "title": "Preview Release of the AWS SDK Java 2.x HTTP Client built on Apache HttpClient 5.5.x",
      "description": "The AWS SDK for Java 2.x introduces the Apache 5 SDK HTTP client which is built on Apache HttpClient 5.5.x. This new SDK HTTP client is available alongside our existing SDK HTTP clients: Apache HttpClient 4.5.x, Netty, URL Connection, and AWS CRT HttpClient. To differentiate the use of Apache HttpClient 4.5.x and Apache HttpClient 5.5.x, […]",
      "link": "https://aws.amazon.com/blogs/developer/preview-release-of-theaws-sdk-java-2-x-http-client-built-on-apache-httpclient-5-5-x/",
      "pubDate": "2025-07-18T03:36:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-6606f79cd3d5",
      "title": "AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available",
      "description": "Today, we are excited to announce the general availability of the AWS .NET Distributed Cache Provider for Amazon DynamoDB. This is a seamless, serverless caching solution that enables .NET developers to efficiently manage their caching needs across distributed systems. Consistent caching is a difficult problem in distributed architectures, where maintaining data integrity and performance across […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-net-distributed-cache-provider-for-amazon-dynamodb-now-generally-available/",
      "pubDate": "2025-07-03T13:49:25.000Z",
      "source": "developersAndDevOps",
      "services": [
        "dynamodb"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "dynamodb",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-ae25b45e1a62",
      "title": "AWS Tools for PowerShell V5 now Generally Available",
      "description": "This blog was co-authored by Afroz Mohammed and Jonathan Nunn, Software Developers on the AWS PowerShell team. We’re excited to announce the general availability of the AWS Tools for PowerShell version 5, a major update that brings new features and improvements in security, along with a few breaking changes. New Features You can now cancel […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-tools-for-powershell-v5-now-generally-available/",
      "pubDate": "2025-06-23T22:59:33.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "new-feature",
        "update",
        "improvement"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-27b43a8f9a42",
      "title": "Deploy to ARM-Based Compute with AWS Deploy Tool for .NET",
      "description": "We’re excited to announce that the AWS Deploy Tool for .NET now supports deploying .NET applications to select ARM-based compute platforms on AWS! Whether you’re deploying from Visual Studio or using the .NET CLI, you can now target cost-effective ARM infrastructure like AWS Graviton with the same streamlined experience you’re used to. Why deploy to […]",
      "link": "https://aws.amazon.com/blogs/developer/deploy-to-arm-based-compute-with-aws-deploy-tool-for-net/",
      "pubDate": "2025-05-08T20:16:40.000Z",
      "source": "developersAndDevOps",
      "services": [
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "graviton",
        "support"
      ]
    },
    {
      "id": "aws-news-4d3126ea3a15",
      "title": "General Availability of AWS SDK for .NET V4.0",
      "description": "Version 4.0 of the AWS SDK for .NET has been released for general availability (GA). V4 has been in development for a little over a year in our SDK’s public GitHub repository with 13 previews being released. This new version contains performance improvements, consistency with other AWS SDKs, and bug and usability fixes that required […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-of-aws-sdk-for-net-v4-0/",
      "pubDate": "2025-04-28T20:05:16.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-49859f1bef68",
      "title": "Introducing the AWS IoT Device SDK for Swift (Developer Preview)",
      "description": "Today, AWS launches the developer preview of the AWS IoT Device SDK for Swift. The IoT Device SDK for Swift empowers Swift developers to create IoT applications for Linux and Apple macOS, iOS, and tvOS platforms using the MQTT 5 protocol. The SDK supports Swift 5.10+ and is designed to help developers easily integrate with […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-the-aws-iot-device-sdk-for-swift-developer-preview/",
      "pubDate": "2025-03-31T16:26:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-dd08a704e7e9",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 2)",
      "description": "In Part 1 of our blog posts for .NET Aspire and AWS Lambda, we showed you how .NET Aspire can be used for running and debugging .NET Lambda functions. In this part, Part 2, we’ll show you how to take advantage of the .NET Aspire programming model for best practices and for connecting dependent resources […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-2/",
      "pubDate": "2025-03-04T17:54:04.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    }
  ]
}