{
  "lastUpdated": "2025-12-06T06:14:34.616Z",
  "totalItems": 204,
  "sources": {
    "whatsNew": 97,
    "mlBlog": 20,
    "newsBlog": 20,
    "bigDataBlog": 17,
    "architectureBlog": 16,
    "computeBlog": 18,
    "developersAndDevOps": 16
  },
  "items": [
    {
      "id": "aws-news-8273e71b1636",
      "title": "Amazon OpenSearch Service now supports automatic semantic enrichment",
      "description": "Amazon OpenSearch Service now brings automatic semantic enrichment to managed clusters, matching the capability we launched for OpenSearch Serverless earlier this year. This feature allows you to leverage the power of semantic search with minimal configuration effort.\n  Traditional lexical search only matches exact phrases, often missing relevant content. Automatic semantic enrichment understands context and meaning, delivering more relevant results. For example, a search for \"eco-friendly transportation options\" finds matches about \"electric vehicles\" or \"public transportation\"—even when these exact terms aren't present. This new capability handles all semantic processing automatically, eliminating the need to manage machine learning models. It supports both English-only and multi-lingual variants, covering 15 languages including Arabic, French, Hindi, Japanese, Korean, and more. You pay only for actual usage during data ingestion, billed as OpenSearch Compute Unit (OCU) - Semantic Search. View the pricing page for cost details and a pricing example.\n  This feature is now available for Amazon OpenSearch Service domains running OpenSearch version 2.19 or later. Currently, this feature supports non-VPC domains in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm).\n  Get started with our documentation on automatic semantic enrichment.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/opensearch-service-automatic-semantic-enrichment/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service",
        "launch",
        "ga",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-7756d1765b26",
      "title": "TwelveLabs’ Pegasus 1.2 model now in 23 new AWS regions via Global cross-region inference",
      "description": "Amazon Bedrock introduces Global cross-Region inference for TwelveLabs' Pegasus 1.2, expanding model availability to 23 new regions in addition to the seven regions where the model was already available. You can now also access the model in all EU regions in Amazon Bedrock using Geographic cross-Region inference. Geographic cross-Region inference is ideal for workloads with data residency or compliance requirements within a specific geographic boundary, while Global cross-Region inference is recommended for applications that prioritize availability and performance across multiple geographies.\n  Pegasus 1.2 is a powerful video-first language model that can generate text based on the visual, audio, and textual content within videos. Specifically designed for long-form video, it excels at video-to-text generation and temporal understanding. With Pegasus 1.2's availability in these additional regions, you can now build video-intelligence applications closer to your data and end users, reducing latency and simplifying your architecture.\n  For a complete list of supported inference profiles and regions for Pegasus 1.2, refer to the Cross-Region Inference documentation. To get started with Pegasus 1.2, visit the Amazon Bedrock console. To learn more, read the product page and Amazon Bedrock documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/twelvelabs-pegasus-available-with-global-cross-region-inference/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-c46520142038",
      "title": "SES Mail Manager is now available in 10 additional AWS Regions, 27 total",
      "description": "Amazon SES announces that the SES Mail Manager product is now available in 10 additional commercial AWS Regions. This expands coverage from the current 17 commercial AWS Regions where Mail Manager is launched, meaning that Mail Manager is now offered in all commercial Regions where SES offers its core Outbound service.\n  SES Mail Manager allows customers to configure email routing and delivery mechanisms for their domains, and to have a single view of email governance, risk, and compliance solutions for all email workloads. Organizations commonly deploy Mail Manager to replace legacy hosted mail relays or simplify integration with third-party mailbox providers and email security solutions. Mail Manager also supports onward delivery to WorkMail mailboxes, built-in archiving with search and export capabilities, and integration with third-party security add-ons directly within the console.\n  The 10 new Mail Manager Regions include Middle East (Bahrain), Asia Pacific (Jakarta), Africa (Cape Town), Middle East (UAE), Asia Pacific (Hyderabad), Asia Pacific (Malaysia), Europe (Milan), Israel (Tel Aviv), Canada West (Calgary), and Europe (Zurich). The full list of Mail Manager Region availability is here. \n  To learn more, see the Amazon SES Mail Manager product page and the SES Mail Manager documentation. You can start using Mail Manager in these new Regions through the Amazon SES console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ses-mail-manager-10-regions/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "launch",
        "ga",
        "now-available",
        "integration",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-01ad74db6ed9",
      "title": "Amazon SES adds VPC support for API endpoints",
      "description": "Today, Amazon Simple Email Service (SES) added support for accessing SES API endpoints through Virtual Private Cloud (VPC) endpoints. Customers use VPC endpoints to enable access to SES APIs for sending emails and managing their SES resource configuration. This release helps customers increase security in their VPCs.\n  Previously, customers who ran their workloads in a VPC could access SES APIs by configuring an internet gateway resource in their VPC. This enabled traffic from the VPC to flow into the internet, and reach SES public API endpoints. Now, customers can use the VPC endpoints to access SES APIs without the need for an internet gateway, reducing the chances for activity in the VPC to be exposed to the internet..\n  SES supports VPC for SES API endpoints in all AWS Regions where SES is available.\n  For more information, see the documentation for information about setting up VPC endpoints with Amazon SES.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ses-vpc-api-endpoints/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-ad34366e53a8",
      "title": "Amazon Connect launches WhatsApp channel for Outbound Campaigns",
      "description": "Amazon Connect Outbound Campaigns now supports WhatsApp, expanding on the WhatsApp Business messaging capabilities that already allow customers to contact your agents. You can now engage customers through proactive, automated campaigns on their preferred messaging platform, delivering timely communications such as appointment reminders, payment notifications, order updates, and product recommendations directly through WhatsApp. Setting up WhatsApp campaigns uses the same familiar Amazon Connect interface, where you can define your target audience, choose personalized message templates, schedule delivery times, and apply compliance guardrails, just as you do for SMS, voice, and email campaigns.\n  Previously, Outbound Campaigns supported SMS, email, and voice channels, while WhatsApp was available only for customers to initiate conversations with your agents. With WhatsApp support in Outbound Campaigns, you can now proactively reach customers through an additional messaging platform while maintaining a unified campaign management experience. You can personalize WhatsApp messages using real-time customer data, track delivery and engagement metrics, and manage communication frequency and timing to ensure compliance. This expansion provides greater flexibility to connect with customers on their preferred platforms while streamlining your omnichannel outreach strategy.\n  This feature is available in all AWS Regions where Amazon Connect Outbound Campaigns is supported. To learn more, visit the Amazon Connect Outbound Campaigns documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/connect-whatsapp-channel-outbound-campaigns/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "personalize"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "personalize",
        "launch",
        "ga",
        "update",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-4d9478a7f155",
      "title": "Amazon SageMaker now supports self-service migration of Notebook instances to latest platform versions",
      "description": "Amazon SageMaker Notebook instance now supports self-service migration, allowing you to update your notebook instance platform identifier through the UpdateNotebookInstance API. This enables you to seamlessly transition from unsupported platform identifiers (notebook-al1-v1, notebook-al2-v1, notebook-al2-v2) to supported versions (notebook-al2-v3, notebook-al2023-v1).\n  With the new PlatformIdentifier parameter in the UpdateNotebookInstance API, you can update to newer versions of the Notebook instance platform while preserving your existing data and configurations. The platform identifier determines which Operating System and JupyterLab version combination your notebook instance runs. This self-service capability simplifies the migration process and helps you keep your notebook instances current.\n  This feature is supported through AWS CLI (version 2.31.27 or newer) and SDK, and is available in all AWS Regions where Amazon SageMaker Notebook instances are supported. To learn more, see Update a Notebook Instance in the Amazon SageMaker Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-self-service-migration-notebook-instances",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-0424929cc700",
      "title": "AWS Elastic Beanstalk now supports Node.js 24 on Amazon Linux 2023",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Node.js 24 applications on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest features and improvements in Node.js while taking advantage of the enhanced security and performance of AL2023.\n \nAWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Node.js 24 on AL2023 delivers updates to the V8 JavaScript engine, npm 11, and security and performance improvements. Developers can create Elastic Beanstalk environments running Node.js 24 on AL2023 through the Elastic Beanstalk Console, CLI, or API.\n \nThis platform is available in all commercial AWS Regions where Elastic Beanstalk is available, including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n \nTo learn more about Node.js 24 on Amazon Linux 2023, see the AWS Elastic Beanstalk Developer guide. For additional information, visit the AWS Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-beanstalk-node-js-24-linux-2023/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-99629c57268b",
      "title": "Amazon Connect Customer Profiles launches new segmentation capabilities (Beta)",
      "description": "Amazon Connect Customer Profiles now offers new segmentation capabilities powered by Spark SQL (Beta), enabling you to build sophisticated customer segments using your complete Customer Profiles data with AI assistance.\n  You can:\n  \n \n \nAccess complete profile data: Use both custom objects and standard objects for segmentation\n \n \nLeverage SQL capabilities: Join objects, filter with statistical functions like percentiles, and standardize date fields for complex analysis\n \n \nBuild segments with AI assistance: Use natural language prompts with the Segment AI assistant to automatically generate segment definitions in Spark SQL, or write SQL directly\n \n \nValidate before deployment: Review AI-generated SQL, view natural language explanations, and get automatic segment estimates\n \n \nFor example, you can create segments like \"customers who called customer services more than 3 times in the past month about new purchases they made\" or \"high-value customers in the 90th percentile of lifetime spend\" to enable precise targeting for outbound campaigns and personalized customer experiences.\n  These new segmentation capabilities are offered alongside existing segmentation features. Both integrate seamlessly with segment membership calls, Flow blocks, and Outbound Campaigns, allowing you to choose the approach that best fits your use case.\n  Getting started: Enable Data store from the Customer Profiles page to use the new segmentation capabilities\n  Availability: Available in all AWS regions where Amazon Connect Customer Profiles is offered.\n  For more information, see Build customer segments in Amazon Connect in the Amazon Connect Administrator Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-connect-customer-profiles/",
      "pubDate": "2025-12-05T15:04:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "personalize"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "personalize",
        "launch",
        "beta"
      ]
    },
    {
      "id": "aws-news-5a5afa48e9ee",
      "title": "Amazon Q now can analyze SES email sending",
      "description": "Today, Amazon Q (Q) added support for analyzing email sending in Amazon Simple Email Service (SES). Now customers can ask Q questions about their SES resource setup and usage patterns, and Q will help them optimize their configuration and troubleshoot deliverability problems. This makes it easier to manage SES operational activities with less technical knowledge.\n  Previously, customers could use SES features such as Virtual Deliverability Manager to manage and explore their SES resource configuration and usage. SES provided convenient dashboard views and query tools to help customers find information, however customers needed deep understanding of email sending concepts to interact with the service. Now, customers can ask Q for help in optimizing resource configuration and troubleshooting deliverability challenges. Q will evaluate customer’s usage patterns and SES resource configuration, find the answers customers need, and help them understand the context without requiring pre-knowledge or manual exploration.\n  Q supports SES resource analysis in all AWS Regions where SES and Q are available.\n  For more information, see the Q documentation for information about interacting with SES through Q.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-q-analyze-ses-email-sending/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "support"
      ]
    },
    {
      "id": "aws-news-39665ab10ff1",
      "title": "AWS launches simplified enablement of AWS CloudTrail events in Amazon CloudWatch",
      "description": "Today, AWS launches simplified enablement of AWS CloudTrail events in Amazon CloudWatch, a monitoring and logging service that helps you collect, monitor, and analyze log data from your AWS resources and applications. With this launch, you can now centrally configure collection of CloudTrail events in CloudWatch alongside other popular AWS log sources such as Amazon VPC flow logs and Amazon EKS Control Plane Logs. CloudWatch's ingestion experience provides a consolidated view that simplifies collecting telemetry from different sources for accounts in your AWS Organization thus ensuring comprehensive monitoring and data collection across your AWS environment.\n  This new integration leverages service-linked channels (SLCs) to receive events from CloudTrail without requiring trails, and also provides additional benefits such as safety-checks and termination protection. You incur both CloudTrail event delivery charges and CloudWatch Logs ingestion fees based on custom logs pricing.\n  To learn more about enablement of CloudTrail events in CloudWatch and supported AWS regions, visit the Amazon CloudWatch documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/key-enhancements-cloudtrail-events-cloudwatch/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "cloudwatch",
        "launch",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-116745600502",
      "title": "AWS Elastic Beanstalk now supports Python 3.14 on Amazon Linux 2023",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Python 3.14 applications on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest features and improvements in Python while taking advantage of the enhanced security and performance of AL2023.\n \nAWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Python 3.14 on AL2023 delivers enhanced interactive interpreter capabilities, improved error messages, important security and API improvements. Developers can create Elastic Beanstalk environments running Python 3.14 on AL2023 through the Elastic Beanstalk Console, CLI, or API.\n \nThis platform is available in all commercial AWS Regions where Elastic Beanstalk is available, including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n \nTo learn more about Python 3.14 on Amazon Linux 2023, see the AWS Elastic Beanstalk Developer guide. For additional information, visit the AWS Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-beanstalk-python-314-linux-2023/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-6e0869a825a5",
      "title": "Amazon Bedrock now supports Responses API from OpenAI",
      "description": "Amazon Bedrock now supports Responses API on new OpenAI API-compatible service endpoints. Responses API enables developers to achieve asynchronous inference for long-running inference workloads, simplifies tool use integration for agentic workflows, and also supports stateful conversation management. Instead of requiring developers to pass the entire conversation history with each request, Responses API enables them to automatically rebuild context without manual history management. These new service endpoints support both streaming and non-streaming modes, enable reasoning effort support within Chat Completions API, and require only a base URL change for developers to integrate within existing codebases with OpenAI SDK compatibility.\n  \n Chat Completions with reasoning effort support is available for all Amazon Bedrock models powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock, provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and provides out-of-the-box compatibility with OpenAI API specifications. Responses API support is available today starting with OpenAI's GPT OSS 20B/120B models, with support for other models coming soon.\n To get started, visit the service documentation here",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-bedrock-responses-api-from-openai/",
      "pubDate": "2025-12-04T12:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "integration",
        "support",
        "coming-soon",
        "new-model"
      ]
    },
    {
      "id": "aws-news-509a6eaf3b64",
      "title": "Announcing new Amazon EC2 M9g instances powered by AWS Graviton5 processors (Preview)",
      "description": "Starting today, new general purpose Amazon Elastic Compute Cloud (Amazon EC2) M9g instances, powered by AWS Graviton5 processors, are available in preview. AWS Graviton5 is the latest in the Graviton family of processors that are custom designed by AWS to provide the best price performance for workloads in Amazon EC2. These instances offer up to 25% better compute performance, and higher networking and Amazon Elastic Block Store (Amazon EBS) bandwidth than AWS Graviton4-based M8g instances. They are up to 30% faster for databases, up to 35% faster web applications, and up to 35% faster for machine learning workloads compared to M8g.\n  M9g instances are built on the AWS Nitro System, a collection of hardware and software innovations designed by AWS. The AWS Nitro System enables the delivery of efficient, flexible, and secure cloud services with isolated multitenancy, private networking, and fast local storage. Amazon EC2 M9g instances are ideal for workloads such as application servers, microservices, gaming servers, midsize data stores, and caching fleets.\n  To learn more or request access to the M9g preview, see Amazon EC2 M9g instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-m9g-instances-graviton5-processors-preview/",
      "pubDate": "2025-12-04T09:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex",
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "lex",
        "ec2",
        "graviton",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-ad98b700a350",
      "title": "Amazon Bedrock adds reinforcement ﬁne-tuning simplifying how developers build smarter, more accurate AI models",
      "description": "Amazon Bedrock now supports reinforcement fine-tuning delivering 66% accuracy gains on average over base models.",
      "link": "https://aws.amazon.com/blogs/aws/improve-model-accuracy-with-reinforcement-fine-tuning-in-amazon-bedrock/",
      "pubDate": "2025-12-03T16:08:14.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f27f0877e40c",
      "title": "New serverless customization in Amazon SageMaker AI accelerates model fine-tuning",
      "description": "Accelerate AI model development with new training features that enable rapid recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/new-serverless-customization-in-amazon-sagemaker-ai-accelerates-model-fine-tuning/",
      "pubDate": "2025-12-03T16:08:03.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-20b1f9fc07df",
      "title": "Introducing checkpointless and elastic training on Amazon SageMaker HyperPod",
      "description": "Accelerate AI model development with new training features that enable instant recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-checkpointless-and-elastic-training-on-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-12-03T16:07:52.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-54eab717f389",
      "title": "Amazon SageMaker HyperPod now supports checkpointless training",
      "description": "Amazon SageMaker HyperPod now supports checkpointless training, a new foundational model training capability that mitigates the need for a checkpoint-based job-level restart for fault recovery. Checkpointless training maintains forward training momentum despite failures, reducing recovery time from hours to minutes. This represents a fundamental shift from traditional checkpoint-based recovery, where failures require pausing the entire training cluster, diagnosing issues manually, and restoring from saved checkpoints, a process that can leave expensive AI accelerators idle for hours, costing your organization wasted compute.\n \nCheckpointless training transforms this paradigm by preserving the model training state across the distributed cluster, automatically swapping out faulty training nodes on the fly and using peer-to-peer state transfer from healthy accelerators for failure recovery. By mitigating checkpoint dependencies during recovery, checkpointless training can help your organization save on idle AI accelerator costs and accelerate time. Even at larger scales, checkpointless training on Amazon SageMaker HyperPod enables upwards of 95% training goodput on cluster sizes with thousands of AI accelerators.\n \nCheckpointless training on SageMaker HyperPod is available in all AWS Regions where Amazon SageMaker HyperPod is currently available. You can enable checkpointless training with zero code changes using HyperPod recipes for popular publicly available models such as Llama and GPT OSS. For custom model architectures, you can integrate checkpointless training components with minimal modifications for PyTorch-based workflows, making it accessible to your teams regardless of their distributed training expertise.\n \nTo get started, visit the Amazon SageMaker HyperPod product page and see the checkpointless training GitHub page for implementation guidance.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-hyperpod-checkpointless-training",
      "pubDate": "2025-12-03T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "rds"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "rds",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-15dab4dd881e",
      "title": "New serverless model customization capability in Amazon SageMaker AI",
      "description": "Amazon Web Services (AWS) announces a new serverless model customization capability that empowers AI developers to quickly customize popular models with supervised fine-tuning and the latest techniques like reinforcement learning. Amazon SageMaker AI is a fully managed service that brings together a broad set of tools to enable high-performance, low-cost AI model development for any use case. \n \nMany AI developers seek to customize models with proprietary data for improved accuracy, but this often requires lengthy iteration cycles. For example, AI developers must define a use case and prepare data, select a model and customization technique, train the model, then evaluate the model for deployment. Now AI developers can simplify the end-to-end model customization workflow, from data preparation to evaluation and deployment, and accelerate the process. With an easy-to-use interface, AI developers can quickly get started and customize popular models, including Amazon Nova, Llama, Qwen, DeepSeek, and GPT-OSS, with their own data. They can use supervised fine-tuning and the latest customization techniques such as reinforcement learning and direct preference optimization. In addition, AI developers can use the AI agent-guided workflow (in preview), and use natural language to generate synthetic data, analyze data quality, and handle model training and evaluation—all entirely serverless. \n \nYou can use this easy-to-use interface in the following AWS Regions: Europe (Ireland), US East (N. Virginia), Asia Pacific (Tokyo), and US West (Oregon). To join the waitlist to access the AI agent-guided workflow, visit the sign-up page. \n \nTo learn more, visit the SageMaker AI model customization page and blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/new-serverless-model-customization-capability-amazon-sagemaker-ai",
      "pubDate": "2025-12-03T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "preview"
      ]
    },
    {
      "id": "aws-news-a465d0dd13ac",
      "title": "Announcing TypeScript support in Strands Agents (preview) and more",
      "description": "In May, we open sourced the Strands Agents SDK, an open source python framework that takes a model-driven approach to building and running AI agents in just a few lines of code. Today, we’re announcing that TypeScript support is available in preview. Now, developers can choose between Python and TypeScript for building Strands Agents.\n  TypeScript support in Strands has been designed to provide an idiomatic TypeScript experience with full type safety, async/await support, and modern JavaScript/TypeScript patterns. Strands can be easily run in client applications, in browsers, and server-side applications in runtimes like AWS Lambda and Bedrock AgentCore. Developers can also build their entire stack in Typescript using the AWS CDK.\n  We’re also announcing three additional updates for the Strands SDK. First, edge device support for Strands Agents is generally available, extending the SDK with bidirectional streaming and additional local model providers like llama.cpp that let you run agents on small-scale devices using local models. Second, Strands steering is now available as an experimental feature, giving developers a modular prompting mechanism that provides feedback to the agent at the right moment in its lifecycle, steering agents toward a desired outcome without rigid workflows. Finally, Strands evaluations is available in preview. Evaluations gives developers the ability to systematically validate agent behavior, measure improvements, and deploy with confidence during development cycles.\n  Head to the Strands Agents GitHub to get started building.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/typescript-strands-agents-preview",
      "pubDate": "2025-12-03T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lambda",
        "preview",
        "experimental",
        "generally-available",
        "now-available",
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-ef3aea785303",
      "title": "Introducing elastic training on Amazon SageMaker HyperPod",
      "description": "Amazon SageMaker HyperPod now supports elastic training, enabling organizations to accelerate foundation model training by automatically scaling training workloads based on resource availability and workload priorities. This represents a fundamental shift from training with a fixed set of resources, as it saves hours of engineering time spent reconfiguring training jobs based on compute availability.\n \nAny change in compute availability previously required manually halting training, reconfiguring training parameters, and restarting jobs—a process that requires distributed training expertise and leaves expensive AI accelerators sitting idle during training job reconfiguration. Elastic training automatically expands training jobs to absorb idle AI accelerators and seamlessly contracting when higher-priority workloads need resources—all without halting training entirely.\n \nBy eliminating manual reconfiguration overhead and ensuring continuous utilization of available compute, elastic training can help save time previously spent on infrastructure management, reduce costs by maximizing cluster utilization, and accelerate time-to-market. Training can start immediately with minimal resources and grow opportunistically as capacity becomes available.\n \nSageMaker HyperPod is available in all regions where Amazon SageMaker HyperPod is currently available. Organizations can enable elastic training with zero code changes using HyperPod recipes for publicly available models including Llama and GPT OSS. For custom model architectures, customers can integrate elastic training capabilities through lightweight configuration updates and minimal code modifications, making it accessible to teams without requiring distributed systems expertise.\n \nTo get started, visit the Amazon SageMaker HyperPod product page and see the elastic training documentation for implementation guidance.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-training-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-12-03T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-06f56a16182f",
      "title": "Amazon Bedrock now supports reinforcement fine-tuning delivering 66% accuracy gains on average over base models",
      "description": "Amazon Bedrock now supports reinforcement fine-tuning, helping you improve model accuracy without needing deep machine learning expertise or large sums of labeled data. Amazon Bedrock automates the reinforcement fine-tuning workflow, making this advanced model customization technique accessible to everyday developers. Models learn to align with your specific requirements using a small set of prompts rather than the large sums of data needed for traditional fine-tuning methods, enabling teams to get started quickly. This capability teaches models through feedback on multiple possible responses to the same prompt, improving their judgement of what makes a good response. Reinforcement fine-tuning in Amazon Bedrock delivers 66% accuracy gains on average over base models so you can use smaller, faster, and more cost-effective model variants while maintaining high quality.\n \nOrganizations struggle to adapt AI models to their unique business needs, forcing them to choose between generic models with average performance or expensive, complex customization that requires specialized talent, infrastructure, and risky data movement. Reinforcement fine-tuning in Amazon Bedrock removes this complexity by making advanced model customization fast, automated, and secure. You can train models by uploading training data directly from your computer or choose from datasets already stored in Amazon S3, eliminating the need for any labeled datasets. You can define reward functions using verifiable rule-based graders or AI-based judges along with built-in templates to optimize your models for both objective tasks such as code generation or math reasoning, and subjective tasks such as instruction following or chatbot interactions. Your proprietary data never leaves AWS's secure, governed environment during the entire customization process, mitigating security and compliance concerns.\n \nYou can get started with reinforcement fine-tuning in Amazon Bedrock through the Amazon Bedrock console and via the Amazon Bedrock APIs. At launch, you can use reinforcement fine-tuning with Amazon Nova 2 Lite with support for additional models coming soon. To learn more about reinforcement fine-tuning in Amazon Bedrock, read the launch blog, pricing page, and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/bedrock-reinforcement-fine-tuning-66-base-models/",
      "pubDate": "2025-12-03T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "lex",
        "s3",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "lex",
        "s3",
        "organizations",
        "launch",
        "ga",
        "support",
        "coming-soon"
      ]
    },
    {
      "id": "aws-news-4139ea9a5e0b",
      "title": "Announcing replication support and Intelligent-Tiering for Amazon S3 Tables",
      "description": "New features enable automatic cost optimization through intelligent storage tiering and simplified table replication across AWS Regions and accounts.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-replication-support-and-intelligent-tiering-for-amazon-s3-tables/",
      "pubDate": "2025-12-02T16:19:14.000Z",
      "source": "newsBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-64738829059d",
      "title": "Amazon S3 Storage Lens adds performance metrics, support for billions of prefixes, and export to S3 Tables",
      "description": "New capabilities help optimize application performance, analyze unlimited prefixes, and simplify metrics analysis through S3 Tables integration.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-s3-storage-lens-adds-performance-metrics-support-for-billions-of-prefixes-and-export-to-s3-tables/",
      "pubDate": "2025-12-02T16:15:12.000Z",
      "source": "newsBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-17e673125d4d",
      "title": "Amazon Bedrock AgentCore adds quality evaluations and policy controls for deploying trusted AI agents",
      "description": "Deploy AI agents with confidence using new quality evaluations and policy controls—enabling precise boundaries on agent actions, continuous quality monitoring, and experience-based learning while maintaining natural conversation flows.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-bedrock-agentcore-adds-quality-evaluations-and-policy-controls-for-deploying-trusted-ai-agents/",
      "pubDate": "2025-12-02T16:14:36.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-c6bdf0af2db1",
      "title": "Build multi-step applications and AI workflows with AWS Lambda durable functions",
      "description": "New Lambda capability lets you build applications that coordinate multiple steps reliably over extended periods—from seconds to up to one year—without paying for idle compute time when waiting for external events or human decisions.",
      "link": "https://aws.amazon.com/blogs/aws/build-multi-step-applications-and-ai-workflows-with-aws-lambda-durable-functions/",
      "pubDate": "2025-12-02T16:12:19.000Z",
      "source": "newsBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-61eba6194632",
      "title": "New capabilities to optimize costs and improve scalability on Amazon RDS for SQL Server and Oracle",
      "description": "Manage development, testing, and production database workloads more efficiently with new features including Developer Edition support for SQL Server, M7i/R7i instance support with optimize CPU, and expanded storage options up to 256 TiB.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-rds-for-oracle-and-rds-for-sql-server-add-new-capabilities-to-enhance-performance-and-optimize-costs/",
      "pubDate": "2025-12-02T16:09:29.000Z",
      "source": "newsBlog",
      "services": [
        "rds"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "rds",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-0da1e0b931e3",
      "title": "Introducing Database Savings Plans for AWS Databases",
      "description": "New pricing model helps maintain cost efficiency while providing flexibility with database services and deployment options.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-database-savings-plans-for-aws-databases/",
      "pubDate": "2025-12-02T16:09:26.000Z",
      "source": "newsBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-013962572343",
      "title": "Amazon CloudWatch introduces unified data management and analytics for operations, security, and compliance",
      "description": "Reduce data management complexity and costs with automatic normalization across sources, native analytics integration, and built-in support for industry-standard formats like OCSF and Apache Iceberg.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-cloudwatch-introduces-unified-data-management-and-analytics-for-operations-security-and-compliance/",
      "pubDate": "2025-12-02T16:07:11.000Z",
      "source": "newsBlog",
      "services": [
        "lex",
        "cloudwatch"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex",
        "cloudwatch",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-c1b325cf4a05",
      "title": "New and enhanced AWS Support plans add AI capabilities to expert guidance",
      "description": "Prevent cloud infrastructure issues before they impact your business with AWS Support plans that combine AI-powered insights with expert guidance, offering faster response times and proactive monitoring across performance, security, and cost dimensions.",
      "link": "https://aws.amazon.com/blogs/aws/new-and-enhanced-aws-support-plans-add-ai-capabilities-to-expert-guidance/",
      "pubDate": "2025-12-02T16:07:03.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-9a0b50c6aecc",
      "title": "Amazon OpenSearch Service improves vector database performance and cost with GPU acceleration and auto-optimization",
      "description": "Build and optimize large-scale vector databases up to 10 times faster and at a quarter of the cost with new GPU acceleration and auto-optimization capabilities that automatically balance search quality, speed, and resource usage.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-opensearch-service-improves-vector-database-performance-and-cost-with-gpu-acceleration-and-auto-optimization/",
      "pubDate": "2025-12-02T16:06:41.000Z",
      "source": "newsBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-b8ed46f35335",
      "title": "Amazon S3 Vectors now generally available with increased scale and performance",
      "description": "Scale vector storage and querying to new heights with S3 Vectors' general availability—now supporting up to 1 billion vectors per index, 100ms query latencies, and expanded regional availability, while reducing costs up to 90% compared to specialized databases.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-s3-vectors-now-generally-available-with-increased-scale-and-performance/",
      "pubDate": "2025-12-02T16:06:11.000Z",
      "source": "newsBlog",
      "services": [
        "s3 vectors",
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3 vectors",
        "s3",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-46fcd3d2ef15",
      "title": "Amazon Bedrock adds 18 fully managed open weight models, including the new Mistral Large 3 and Ministral 3 models",
      "description": "Access fully managed foundation models from leading providers like Google, Kimi AI, MiniMax AI, Mistral AI, NVIDIA, OpenAI, and Qwen, including the new Mistral Large 3 and Ministral 3 3B, 8B, and 14B models through Amazon Bedrock.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-bedrock-adds-fully-managed-open-weight-models/",
      "pubDate": "2025-12-02T16:05:57.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-f26b55b865f0",
      "title": "Introducing Amazon EC2 X8aedz instances powered by 5th Gen AMD EPYC processors for memory-intensive workloads",
      "description": "New memory-optimized instances deliver up to 5 GHz processor speeds and 3 TiB of memory—ideal for electronic design automation workloads and memory-intensive databases requiring high single-threaded performance.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-amazon-ec2-x8aedz-instances-powered-by-5th-gen-amd-epyc-processors-for-memory-intensive-workloads/",
      "pubDate": "2025-12-02T16:05:44.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-5919cd15a7c0",
      "title": "AWS DevOps Agent helps you accelerate incident response and improve system reliability (preview)",
      "description": "New service acts as an always-on DevOps engineer, helping you respond to incidents, identify root causes, and prevent future issues through systematic analysis of incidents and operational patterns.",
      "link": "https://aws.amazon.com/blogs/aws/aws-devops-agent-helps-you-accelerate-incident-response-and-improve-system-reliability-preview/",
      "pubDate": "2025-12-02T16:05:42.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-36085772e181",
      "title": "Accelerate AI development using Amazon SageMaker AI with serverless MLflow",
      "description": "Simplify AI experimentation with zero-infrastructure MLflow that launches in minutes, scales automatically, and seamlessly integrates with SageMaker's model customization and pipeline capabilities.",
      "link": "https://aws.amazon.com/blogs/aws/accelerate-ai-development-using-amazon-sagemaker-ai-with-serverless-mlflow/",
      "pubDate": "2025-12-02T16:02:56.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "launch"
      ]
    },
    {
      "id": "aws-news-fec165d010fd",
      "title": "Announcing Amazon EC2 General purpose M8azn instances (Preview)",
      "description": "Starting today, new general purpose high-frequency high-network Amazon Elastic Compute Cloud (Amazon EC2) M8azn instances are available for preview. These instances are powered by fifth generation AMD EPYC (formerly code named Turin) processors, offering the highest maximum CPU frequency, 5GHz in the cloud. The M8azn instances offer up to 2x compute performance versus previous generation M5zn instances. These instances also deliver 24% higher performance than M8a instances.\n  M8azn instances are built on the AWS Nitro System, a collection of hardware and software innovations designed by AWS. The AWS Nitro System enables the delivery of efficient, flexible, and secure cloud services with isolated multitenancy, private networking, and fast local storage. These instances are ideal for applications such as gaming, high-performance computing, high-frequency trading (HFT), CI/CD, and simulation modeling for the automotive, aerospace, energy, and telecommunication industries.\n  To learn more or request access to the M8azn instances preview, visit the Amazon EC2 M8a page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-amazon-ec2-m8azn-preview",
      "pubDate": "2025-12-02T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "lex",
        "ec2",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-6329b7ab5837",
      "title": "Amazon FSx for NetApp ONTAP now integrates with Amazon S3 for seamless data access",
      "description": "Access FSx for NetApp ONTAP file data through S3 to enable AI/ML workloads and analytics—letting you use enterprise file data with Bedrock, SageMaker, and analytics services while it remains in your file system.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-fsx-for-netapp-ontap-now-integrates-with-amazon-s3-for-seamless-data-access/",
      "pubDate": "2025-12-02T15:59:54.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "sagemaker",
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "s3"
      ]
    },
    {
      "id": "aws-news-af1340576455",
      "title": "Introducing Amazon Nova 2 Lite, a fast, cost-effective reasoning model",
      "description": "New fast, cost-effective model supports extended thinking with adjustable reasoning depth, letting you control the balance between speed, intelligence, and cost while building AI applications for everyday workloads.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-amazon-nova-2-lite-a-fast-cost-effective-reasoning-model/",
      "pubDate": "2025-12-02T15:59:40.000Z",
      "source": "newsBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "nova",
        "support"
      ]
    },
    {
      "id": "aws-news-5263fab16fcb",
      "title": "New AWS Security Agent secures applications proactively from design to deployment (preview)",
      "description": "Scale your AppSec expertise with AI-powered design reviews, code analysis, and contextual penetration testing that understand your unique security requirements and application architecture.",
      "link": "https://aws.amazon.com/blogs/aws/new-aws-security-agent-secures-applications-proactively-from-design-to-deployment-preview/",
      "pubDate": "2025-12-02T15:58:41.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-11d5bd89eb5c",
      "title": "Announcing Amazon Nova 2 Sonic for real-time conversational AI",
      "description": "Today, Amazon announces the availability of Amazon Nova 2 Sonic, our speech-to-speech model for natural, real-time conversational AI.  It offers best-in-class streaming speech understanding with robustness to background noise and users’ speaking styles, efficient dialog handling, and speech generation with expressive voices that can speak natively in multiple languages (Polyglot voices). It has superior reasoning, instruction following, and tool invocation accuracy over the previous model.\n \nNova 2 Sonic builds on the capabilities introduced in the original Nova Sonic model with new features including expanded language support (Portuguese and Hindi), polyglot voices that enable the model to speak different languages with native expressivity using the same voice, and turn-taking controllability to allow developers to set low, medium, or high pause sensitivity. The model also adds cross-modal interaction, allowing users to seamlessly switch between voice and text in the same session, asynchronous tool calling to support multi-step tasks without interrupting conversation flow, and a one-million token context window for sustained interactions.\n \nDevelopers can integrate Nova Sonic 2 directly into real-time voice systems using Amazon Bedrock’s bidirectional streaming API. Nova Sonic 2 now also seamlessly integrates with Amazon Connect and other leading telephony providers, including Vonage, Twilio, and AudioCodes, as well as open source frameworks such as LiveKit and Pipecat.\n \nAmazon Nova 2 Sonic is available in Amazon Bedrock in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Tokyo), and Europe (Stockholm). To learn more, read the AWS News Blog and the Amazon Nova Sonic User Guide. To get started with Nova Sonic 2 in Amazon Bedrock, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-nova-2-sonic-real-time-conversational-ai/",
      "pubDate": "2025-12-02T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-32f783e29c54",
      "title": "Announcing the Apache Spark upgrade agent for Amazon EMR",
      "description": "AWS announces the Apache Spark upgrade agent, a new capability that accelerates Apache Spark version upgrades for Amazon EMR on EC2 and EMR Serverless. The agent converts complex upgrade processes that typically take months into projects spanning weeks through automated code analysis and transformation. Organizations invest substantial engineering resources analyzing API changes, resolving conflicts, and validating applications during Spark upgrades. The agent introduces conversational interfaces where engineers express upgrade requirements in natural language, while maintaining full control over code modifications.\n  The Apache Spark upgrade agent automatically identifies API changes and behavioral modifications across PySpark and Scala applications. Engineers can initiate upgrades directly from SageMaker Unified Studio, Kiro CLI or IDE of their choice with the help of MCP (Model Context Protocol) compatibility. During the upgrade process, the agent analyzes existing code and suggests specific changes, and engineers can review and approve before implementation. The agent validates functional correctness through data quality validations. The agent currently supports upgrades from Spark 2.4 to 3.5 and maintains data processing accuracy throughout the upgrade process.\n  The Apache Spark upgrade agent is now available in all AWS Regions where SageMaker Unified Studio is available. To start using the agent, visit SageMaker Unified Studio and select IDE Spaces or install the Kiro CLI. For detailed implementation guidance, reference documentation, and migration examples, visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/apache-spark-upgrade-agent-amazon-emr",
      "pubDate": "2025-12-02T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "organizations",
        "ga",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-b0ecbb4e838e",
      "title": "Amazon RDS for SQL Server now supports Developer Edition",
      "description": "Amazon Relational Database Service (Amazon RDS) for SQL Server now offers Microsoft SQL Server 2022 Developer Edition. SQL Server Developer Edition is a free edition of SQL Server that contains all the features of Enterprise Edition and can be used in any non-production environment. This enables customers to build, test, and demonstrate applications using SQL Server while reducing costs and maintaining consistency with their production database configurations.\n  Previously, customers that created Amazon RDS for SQL Server instances for development and test environments had to use SQL Server Standard Edition or SQL Server Enterprise Edition, which resulted in additional database licensing costs for non-production usage. Now, customers can lower the cost of their Amazon RDS development and testing instances by using SQL Server Developer Edition. Furthermore, Amazon RDS for SQL Server features such as automated backups, automated software updates, monitoring, and encryption for development and testing purposes will work on Developer Edition.\n  The license for Microsoft SQL Server Developer Edition strictly limits its use to development and testing purposes. It cannot be used in a production environment, or for any commercial purposes that directly serve end-users. For more information, refer to the Amazon RDS for SQL Server User Guide. See Amazon RDS for SQL Server Pricing for pricing details and regional availability.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-rds-sql-server-supports-developer-edition/",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-a835beefc96f",
      "title": "Amazon S3 Storage Lens adds performance metrics, support for billions of prefixes, and export to S3 Tables",
      "description": "Amazon S3 Storage Lens provides organization-wide visibility into your storage usage and activity to help optimize costs, improve performance, and strengthen data protection. Today, we are adding three new capabilities to S3 Storage Lens that give you deeper insights into your S3 storage usage and application performance: performance metrics that provide insights into how your applications interact with S3 data, analytics for billions of prefixes in your buckets, and metrics export directly to S3 Tables for easier querying and analysis.\n  We are adding three specific types of performance metrics. Access pattern metrics identify inefficient requests, including those that are too small and create unnecessary network overhead. Request origin metrics, such as cross-Region request counts, show when applications access data across regions, impacting latency and costs. Object access count metrics reveal when applications frequently read a small subset of objects that could be optimized through caching or moving to high-performance storage.\n  We are expanding the prefix analytics in S3 Storage Lens to enable analyzing billions of prefixes per bucket, whereas previously metrics were limited to the largest prefixes that met minimum size and depth thresholds. This gives you visibility into storage usage and activity across all your prefixes. Finally, we are making it possible to export metrics directly to managed S3 Tables, making them immediately available for querying with AWS analytics services like Amazon QuickSight and enabling you to join this data with other AWS service data for deeper insights.\n  To get started, enable performance metrics or expanded prefixes in your S3 Storage Lens advanced metrics dashboard configuration. These capabilities are available in all AWS Regions, except for AWS China Regions and AWS GovCloud (US) Regions. You can enable metrics export to managed S3 Tables in both free and advanced dashboard configurations in AWS Regions where S3 Tables are available. To learn more, visit the S3 Storage Lens overview page, documentation, S3 pricing page, and read the AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-s3-storage-lens-performance-metrics-prefixes-export-tables",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "s3",
        "quicksight"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "amazon q",
        "s3",
        "quicksight",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-0af7d0f0d0e9",
      "title": "Amazon FSx for NetApp ONTAP now supports Amazon S3 access",
      "description": "You can now attach Amazon S3 Access Points to your Amazon FSx for NetApp ONTAP file systems so that you can access your file data as if it were in S3. With this new capability, your file data in FSx for NetApp ONTAP is effortlessly accessible for use with the broad range of artificial intelligence, machine learning, and analytics services and applications that work with S3 while your file data continues to reside in your FSx for NetApp ONTAP file system.\n  Amazon FSx for NetApp ONTAP is the first and only complete, fully managed NetApp ONTAP file system in the cloud, allowing you to migrate on-premises applications that rely on NetApp ONTAP or other NAS appliances to AWS without having to change how you manage your data. An S3 Access Point is an endpoint that helps control and simplify how different applications or users can access data. Now, with S3 Access Points for FSx for NetApp ONTAP, you can discover new insights, innovate faster, and make even better data-driven decisions with the data you migrate to AWS. For example, you can use your data to augment generative AI applications with Amazon Bedrock, train machine learning models with Amazon SageMaker, run analysis using Amazon Glue or a wide range of AWS Data and Analytics Competency Partner solutions, and run workflows using S3-based cloud-native applications.\n  Get started with this capability by creating and attaching S3 Access Points to new FSx for NetApp ONTAP file systems using the Amazon FSx console, the AWS Command Line Interface (AWS CLI), or the AWS Software Development Kit (AWS SDK). Support for existing FSx for NetApp ONTAP file systems will come in an upcoming weekly maintenance window. This new capability is available in the select AWS Regions.\n  To get started, see the following list of resources:\n  \n \n \nAmazon FSx for NetApp ONTAP\n \n \nAmazon S3 Access Points\n \n \nAWS News Blog",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-fsx-netapp-ontap-s3-access",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "sagemaker",
        "s3",
        "glue"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova",
        "sagemaker",
        "s3",
        "glue",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-69bad9f64822",
      "title": "Amazon RDS for SQL Server launches optimize CPU with new generation instances for up to 55% lower price",
      "description": "Amazon RDS for SQL Server launches optimize CPU with support for M7i and R7i instance families, which reduce prices by up to 55% compared to equivalent previous generation instances. Optimize CPU optimizes Simultaneous Multi-threading (SMT) configuration to reduce commercial software charges. Customers can lower cost by upgrading to M7i and R7i instances from similar 6th generation instances. Furthermore, for memory or IO intensive database workloads, customers can get additional cost reduction by fine tuning optimize CPU configuration.\n  RDS for SQL Server price for database instance hours consumed is inclusive of Microsoft Windows and Microsoft SQL Server software charges. Optimize CPU disables SMT for instances with 2 or more physical CPU cores. This reduces the number of vCPUs, and the corresponding commercial software charges by 50% while providing the same number of physical CPU cores, and near equivalent performance. The most significant savings are available on 2Xlarge and higher instances, and instances that use Multi-AZ deployment, where RDS optimizes to reduce SQL Server software charges for only a single active node for most usage. For workloads that are memory or IO intensive, customers can fine tune the number of active physical CPU cores for further savings.\n  RDS for SQL Server supports M7i and R7i instances in all AWS Regions. With unbundled instance pricing, database costs are calculated with separate charges for third party licensing fees per vCPU hour, and third party licensing fees are not eligible towards your organization’s discounts with AWS. You can view Microsoft Windows and SQL Server charges associated with your usage on AWS Billing and Cost Management, and in monthly bills. For more details, visit RDS for SQL Server pricing, Amazon RDS User Guide and AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-rds-sql-server-optimized-cpu-lower-prices",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-bfb723928032",
      "title": "Amazon EC2 P6e-GB300 UltraServers accelerated by NVIDIA GB300 NVL72 are now generally available",
      "description": "Today, AWS announces the general availability of Amazon Elastic Compute Cloud (Amazon EC2) P6e-GB300 UltraServers. P6e-GB300 UltraServers, accelerated by NVIDIA GB300 NVL72, provide 1.5x GPU memory and 1.5x FP4 compute (without sparsity) compared to P6e-GB200. \n \nCustomers can optimize performance for the most powerful models in production with P6e-GB300 for applications that require higher context and implement emerging inference techniques like reasoning and Agentic AI.\n \nTo get started with P6e-GB300 UltraServers, please contact your AWS sales representative.\n \nTo learn more about P6e UltraServers and instances, visit Amazon EC2 P6 instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-p6e-gb300-ultraservers-nvidia-gb300-nvl72-generally-available",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-5ca455cce367",
      "title": "Announcing new memory-optimized Amazon EC2 X8aedz Instances",
      "description": "AWS announces Amazon EC2 X8aedz, next generation memory optimized instances, powered by 5th Gen AMD EPYC processors (formerly code named Turin). These instances offer the highest maximum CPU frequency, 5GHz in the cloud. They deliver up to 2x higher compute performance compared to previous generation X2iezn instances.\n  X8aedz instances are built using the latest sixth generation AWS Nitro Cards and are ideal for electronic design automation (EDA) workloads such as physical layout and physical verification jobs, and relational databases that benefit from high single-threaded processor performance and a large memory footprint. The combination of 5 GHz processors and local NVMe storage enables faster processing of memory-intensive backend EDA workloads such as floor planning, logic placement, clock tree synthesis (CTS), routing, and power/signal integrity analysis.\n  X8aedz instances feature a 32:1 ratio of memory to vCPU and are available in 8 sizes ranging from 2 to 96 vCPUs with 64 to 3,072 GiB of memory, including two bare metal variants, and up to 8 TB of local NVMe SSD storage.\n  X8aedz instances are now available in US West (Oregon) and Asia Pacific (Tokyo) regions. Customers can purchase X8aedz instances via Savings Plans, On-Demand instances, and Spot instances. To get started, sign in to the AWS Management Console. For more information visit the Amazon EC2 X8aedz instance page or AWS news blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/memory-optimized-amazon-ec2-x8aedz-instances/",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "now-available"
      ]
    },
    {
      "id": "aws-news-146916b0350b",
      "title": "Announcing Amazon EC2 Memory optimized X8i instances (Preview)",
      "description": "Amazon Web Services is announcing the preview of Amazon EC2 X8i, next-generation Memory optimized instances. X8i instances are powered by custom Intel Xeon 6 processors delivering the highest performance and fastest memory among comparable Intel processors in the cloud. X8i instances offer 1.5x more memory capacity (up to 6TB) , and up to 3.4x more memory bandwidth compared to previous generation X2i instances.\n  X8i instances will be SAP-certified and deliver 46% higher SAPS compared to X2i instances, for mission-critical SAP workloads. X8i instances are a great choice for memory-intensive workloads, including in-memory databases and analytics, large-scale traditional databases, and Electronic Design Automation (EDA). X8i instances offer 35% higher performance than X2i instances with even higher gains for some workloads.\n  To learn more or request access to the X8i instances preview, visit the Amazon EC2 X8i page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-x8i-instances-preview",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-72357d1afc62",
      "title": "Amazon S3 increases the maximum object size to 50 TB",
      "description": "Amazon S3 increased the maximum object size to 50 TB, a 10x increase from the previous 5 TB limit. This simplifies the processing of large objects such as high-resolution videos, seismic data files, AI training datasets and more. You can store 50 TB objects in all S3 storage classes and use them with all S3 features.\n  Optimize upload and download performance for your large objects by using the latest AWS Common Runtime (CRT) and S3 Transfer Manager in the AWS SDK. You can apply S3's storage management capabilities to these objects. For example, use S3 Lifecycle to automatically archive infrequently accessed objects to S3 Glacier storage classes, or use S3 Replication to copy objects across AWS accounts or Regions.\n  Amazon S3 supports objects up to 50 TB in all AWS Regions. To learn more about working with large objects, visit the S3 User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-s3-maximum-object-size-50-tb/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "support"
      ]
    },
    {
      "id": "aws-news-313f260093e1",
      "title": "Mistral Large 3 and Ministral 3 family now available first  on Amazon Bedrock",
      "description": "Customers can now use Mistral Large 3 and the Ministral 3 family of models available first on Amazon Bedrock as well as additional models including Voxtral Mini 1.0, Voxtral Small 1.0, and Magistral Small 1.2 on Amazon Bedrock, a platform for building generative AI applications and agents at production scale.\n \nMistral Large 3 is a state-of-the-art, open-weight, general-purpose multimodal model with a granular Mixture-of-Experts architecture featuring 41B active parameters and 675B total parameters, designed for reliability and long-context comprehension. The Ministral 3 family—consisting of 14B, 8B, and 3B models—offers competitive checkpoints across language, vision, and instruct variants, enabling developers to select the right scale for customization and deployment. Amazon Bedrock is the first platform to offer these cutting-edge models, giving customers early access to Mistral AI's latest innovations. Mistral Large 3 excels at production-grade assistants, retrieval-augmented systems, and complex enterprise workflows with support for a 256K context window and powerful agentic capabilities. The Ministral 3 family complements this with flexible deployment options: Ministral 3 14B delivers advanced multimodal capabilities for local deployment, Ministral 3 8B provides best-in-class text and vision capabilities for edge deployment and single-GPU operation, and Ministral 3 3B offers robust capabilities in a compact package for low-resource environments. Together, these models span the full spectrum from frontier intelligence to efficient edge computing.\n \nThese models are now available in Amazon Bedrock. For the full list of available AWS Regions, refer to the documentation.\n \nTo get started with these models in Amazon Bedrock, visit the Amazon Bedrock Mistral AI page",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/mistral-large-3-ministral-3-family-available-amazon-bedrock",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "lex",
        "early-access",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-4709d37d5fa2",
      "title": "Amazon S3 Batch Operations introduces performance improvements",
      "description": "Amazon S3 Batch Operations now completes jobs up to 10x faster at a scale of up to 20 billion objects in a job, helping you accelerate large-scale storage operations.\n  With S3 Batch Operations, you can perform operations at scale such as copying objects between staging and production buckets, tagging objects for S3 Lifecycle management, or computing object checksums to verify the content of stored datasets. S3 Batch Operations now pre-processes objects, executes jobs, and generates completion reports up to 10x faster for jobs processing millions of objects with no additional configuration or cost. To get started, create a job in the AWS Management Console and specify operation type as well as filters like bucket, prefix, or creation date. S3 automatically generates the object list, creates an AWS Identity and Access Management (IAM) role with permission policies as needed, then initiates the job.\n  S3 Batch Operations performance improvements are available in all AWS Regions, except for AWS China Regions and AWS GovCloud (US) Regions. For pricing information, please visit the Management & Insights tab of the Amazon S3 pricing page. To learn more about S3 Batch Operations, visit the overview page and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/s3-batch-operations-performance-improvements/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "iam",
        "improvement"
      ]
    },
    {
      "id": "aws-news-4f603af09d02",
      "title": "Introducing AWS AI Factories",
      "description": "AWS AI Factories are now available, providing rapidly deployable, high-performance AWS AI infrastructure in your own data centers. By combining the latest AWS Trainium accelerators and NVIDIA GPUs, specialized low-latency networking, high-performance storage, and AWS AI services, AI Factories accelerate your AI buildouts by months or years compared to building independently. Leveraging nearly two decades of AWS cloud leadership expertise, AWS AI Factories eliminate the complexity of procurement, setup, and optimization that typically delays AI initiatives.\n \nWith integrated AWS AI services like Amazon Bedrock and Amazon SageMaker, you gain immediate access to leading foundation models without negotiating separate contracts with individual model providers.  AWS AI Factories operate as dedicated environments built exclusively for you or your designated trusted community, ensuring complete separation and operating independence while integrating with the broader set of AWS services. This approach helps governments and enterprises meet digital sovereignty requirements while benefiting from the unparalleled security, reliability, and capabilities of the AWS Cloud. You provide the data center space and power capacity you've already acquired, while AWS deploys and manages the infrastructure. \n \nAWS AI Factories deliver advanced AI technologies to enterprises across all industries and government organizations seeking secure, isolated environments with strict data residency requirements. These dedicated environments provide access to the same advanced technologies available in public cloud Regions, allowing you to build AI-powered applications as well as train and deploy large language models using your own proprietary data. Rather than spending years building capacity independently, AWS accelerates deployment timelines so you can focus on innovation instead of infrastructure complexity. \n \nContact your AWS account team to learn more about deploying AWS AI Factories in your data center and accelerating your AI initiatives with AWS proven expertise in building and maintaining dedicated AI infrastructure at scale.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-ai-factories",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "sagemaker",
        "lex",
        "trainium",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "sagemaker",
        "lex",
        "trainium",
        "organizations",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-56b08362877c",
      "title": "Introducing AWS DevOps Agent (preview), frontier agent for operational excellence",
      "description": "We're excited to launch AWS DevOps Agent in preview, a frontier agent that resolves and proactively prevents incidents, continuously improving reliability and performance of applications in AWS, multicloud, and hybrid environments. AWS DevOps Agent investigates incidents and identifies operational improvements as an experienced DevOps engineer would: by learning your resources and their relationships, working with your observability tools, runbooks, code repositories, and CI/CD pipelines, and correlating telemetry, code, and deployment data across all of them to understand the relationships between your application resources.\n \nAWS DevOps Agent autonomously triages incidents and guides teams to rapid resolution to reduce Mean Time to Resolution (MTTR). AWS DevOps Agent begins investigating the moment an alert comes in, whether at 2 AM or during peak hours, to quickly restore your application to optimal performance. It analyzes patterns across historical incidents to provide actionable recommendations that strengthen key areas including observability, infrastructure optimization, and deployment pipeline enhancement. AWS DevOps Agent helps access the untapped insights in your operational data and tools without changing your workflows.\n \nAWS DevOps Agent is available at no additional cost during preview in the US East (N. Virginia) Region. To learn more, read the AWS News Blog and see getting started.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/devops-agent-preview-frontier-agent-operational-excellence/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "launch",
        "preview",
        "ga",
        "improvement",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-c9b4bcecc903",
      "title": "AWS Security Hub is now generally available with near real-time risk analytics",
      "description": "Amazon Web Services (AWS) announces the general availability of AWS Security Hub, a unified cloud security solution that prioritizes your critical security issues and helps you respond at scale, reduce security risks, and improve team productivity. With general availability, Security Hub now includes near real-time risk analytics, advanced trends, unified enablement and management, and streamlined pricing across multiple AWS security services. Security Hub detects critical risks by correlating and enriching security signals from Amazon GuardDuty, Amazon Inspector, and AWS Security Hub CSPM, enabling you to quickly surface and prioritize active risks in your cloud environment.\n  Security Hub now delivers near real-time risk analytics and advanced trends, transforming correlated security signals into actionable insights through enhanced visualizations and contextual enrichment. You can enable Security Hub for individual accounts or across your entire AWS Organization with centralized deployment and management. These new capabilities complement existing capabilities, including exposure findings, security-focused resource inventory, attack path visualization, and automated response workflows with ticketing system integration. This centralized management reduces the need for manual correlation across multiple consoles and enables streamlined remediation at scale while helping minimize potential operational disruptions, now with improved cost predictability through streamlined pricing that consolidates charges across multiple AWS security services. The service automatically visualizes potential attack paths by showing how adversaries could chain together threats, vulnerabilities, and misconfigurations to compromise critical resources, providing deeper risk context powered by more comprehensive analytics.\n  For more information about AWS commercial Regions where Security Hub is available, see the AWS Region table. The service integrates with existing AWS security services, providing more comprehensive security posture without additional operational overhead. To learn more about Security Hub and get started, visit the AWS Security Hub console or the AWS Security Hub product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/security-hub-near-real-time-risk-analytics/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-001f362a6859",
      "title": "Amazon RDS for Oracle and SQL Server now support up to 256 TiB storage with additional storage volumes",
      "description": "Amazon Relational Database Service (Amazon RDS) for Oracle and SQL Server now support up to 256 TiB storage size, a 4x increase in storage size per database instance. Customers can add up to three additional storage volumes in addition to the primary storage volume, each up to 64 TiB storage, to their database instance. Additional storage volumes can be added, scaled up, or removed from the database instance without application downtime, so customers have the flexibility to add and adjust storage volumes over time based on changing workload requirements.\n  With additional storage volumes, customers can continue to scale database storage beyond the maximum storage size available in the primary volume. Also, customers can temporarily add volumes when they have a short-term requirement for additional storage, such as for month-end data processing or importing data from local storage, and remove unused volumes when they are no longer required. Furthermore, customers can optimize cost performance by using a combination of high-performance Provisioned IOPS SSD (io2) volumes and General Purpose (gp3) volumes for their database instance. For example, data that requires consistent IOPS performance can be stored on an io2 volume, and infrequently accessed historical data can be stored on a gp3 volume to optimize storage cost.\n  To get started, customers can create additional storage volumes in a new or existing database instance through the AWS Management Console, AWS CLI, or SDKs. For more information, visit the RDS for Oracle User Guide and RDS for SQL Server User Guide. To learn more about how customers can benefit from additional storage volumes, visit the AWS news blog post. Additional storage volumes are available in all commercial AWS Regions and the AWS GovCloud (US) Regions.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/rds-oracle-sql-server-256-tib-storage-support/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-ff7335a08f36",
      "title": "Amazon S3 Tables now support automatic replication of Apache Iceberg tables",
      "description": "Amazon S3 Tables now support automatic replication of Apache Iceberg tables across AWS Regions and accounts. This new capability replicates your complete table structure, including all snapshots and metadata to reduce query latency and improve data accessibility for global analytics workloads.\n  S3 Tables replication automatically creates read-only replica tables in your destination table buckets, backfills them with the latest state of the source table, and continuously monitors for new updates to keep replicas in sync. Replica tables can be configured with independent snapshot retention policies and encryption keys from source tables to meet compliance and data protection requirements. You can query replica tables using Amazon SageMaker Unified Studio or any Iceberg-compatible engine including Amazon Athena, Amazon Redshift, Apache Spark, and DuckDB.\n  S3 Tables replication is now available in all AWS Regions where S3 Tables are supported. For pricing details, visit the Amazon S3 pricing page. To learn more about S3 Tables, visit the product page, documentation, and read the AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/s3-tables-automatic-replication-apache-iceberg-tables/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "athena"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "athena",
        "now-available",
        "update",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-6a76b8d73350",
      "title": "Amazon S3 Vectors is now generally available with 40 times the scale of preview",
      "description": "Amazon S3 Vectors, the first cloud object storage with native support to store and query vectors, is now generally available. S3 Vectors delivers purpose-built, cost-optimized vector storage for AI agents, inference, Retrieval Augmented Generation (RAG), and semantic search at billion-vector scale. S3 Vectors is designed to provide the same elasticity, durability, and availability as Amazon S3 and reduces the total costs to upload, store, and query vectors by up to 90%. With general availability, you can store and query up to two billion vectors per index and elastically scale to 10,000 vector indexes per vector bucket. Infrequent queries continue to return results in under one second, with more frequent queries now resulting in latencies around 100 milliseconds or less. Your application can achieve write throughput of 1,000 vectors per second when streaming single-vector updates into your indexes, retrieve up to 100 search results per query, and store up to 50 metadata keys alongside each vector for fine-grained filtering in your queries.\n \nWith S3 Vectors you get a new bucket type—a vector bucket—that is optimized for durable, low-cost vector storage. Within vector buckets, you organize your vector data with vector indexes and get a dedicated set of APIs to store, access, and query vectors without provisioning any infrastructure. By default, S3 Vectors encrypts all vector data in a vector bucket with server-side encryption using S3-managed keys (SSE-S3) or optionally, you can use AWS Key Management Service (SSE-KMS) to set a default customer-managed key to encrypt all new vector indexes in the vector bucket. You can now also set a dedicated customer-managed key per vector index, helping you build scalable multi-tenant applications and meet regulatory and governance requirements. You can also tag vector buckets and indexes for attribute-based access control (ABAC) as well as to track and organize costs using AWS Billing and Cost Management.\n \nS3 Vectors integrates with Amazon Bedrock Knowledge Bases to reduce the cost of using large vector datasets for RAG. When creating a Knowledge Base in Amazon Bedrock or Amazon SageMaker Unified Studio, you can choose an existing Amazon S3 vector index or create a new one using the Quick Create workflow. With Amazon OpenSearch Service, you can optimize costs for hybrid search workloads by configuring OpenSearch to automatically manage vector storage in S3.\n \nS3 Vectors is now generally available in 14 AWS Regions, expanding from 5 Regions in preview. To learn more, visit the product page, S3 pricing page, documentation, and AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-s3-vectors-generally-available",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "sagemaker",
        "unified studio",
        "s3 vectors",
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "unified studio",
        "s3 vectors",
        "s3",
        "opensearch",
        "opensearch service",
        "preview",
        "generally-available",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-81efd460d076",
      "title": "Amazon Bedrock AgentCore now includes Policy (preview), Evaluations (preview) and more",
      "description": "Today, Amazon Bedrock AgentCore introduces new offerings, including Policy (preview) and Evaluations (preview), to give teams the controls and quality assurance they need to confidently scale agent deployment across their organization, transforming agents from prototypes to solutions in production.\n  Policy in AgentCore integrates with AgentCore Gateway to intercept every tool call in real time, ensuring agents stay within defined boundaries without slowing down. Teams can create policies using natural language that automatically convert to Cedar—the AWS open-source policy language—helping development, compliance, and security teams set up, understand, and audit rules without writing custom code. AgentCore Evaluations helps developers test and continuously monitor agent performance based on real-world behavior to improve quality and catch issues before they cause widespread customer impact. Developers can use 13 built-in evaluators for common quality dimensions, such as helpfulness, tools selection, and accuracy, or create custom model-based scoring systems, drastically reducing the effort required to develop evaluation infrastructure. All quality metrics are accessible through a unified dashboard powered by Amazon CloudWatch. We’ve also added new features to AgentCore Memory, AgentCore Runtime, and AgentCore Identity to support more advanced agent capabilities. AgentCore Memory now includes episodic memory, enabling agents to learn and adapt from experiences, building knowledge over time to create more humanlike interactions. AgentCore Runtime supports bidirectional streaming for natural conversations where agents simultaneously listen and respond while handling interruptions and context changes mid-conversation, unlocking powerful voice agent use cases. AgentCore Identity now supports custom claims for enhanced authentication rules across multi-tenant environments while maintaining seamless integration with your chosen identity providers.\n  AgentCore Evaluations is available in preview in four AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), Europe (Frankfurt). Policy in AgentCore is available in preview in all AWS Regions where AgentCore is available.\n  Learn more about new AgentCore updates through the blog, deep dive using AgentCore resources, and get started with the AgentCore Starter Toolkit. AgentCore offers consumption-based pricing with no upfront costs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-bedrock-agentcore-policy-evaluations-preview",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "cloudwatch",
        "preview",
        "ga",
        "new-feature",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-e37cf2716a76",
      "title": "Amazon CloudWatch launches unified management and analytics for operational, security, and compliance data",
      "description": "Amazon CloudWatch now provides new data management and analytics capabilities that allow you to unify operational, security, and compliance data across your AWS environment and third-party sources. DevOps teams, security analysts, and compliance officers can now access all their data in a single place, eliminating the need to maintain multiple separate data stores and complex (extract-transform-load) ETL pipelines. CloudWatch now offers greater flexibility in where and how customers gain insights into this data, both natively in CloudWatch or with any Apache Iceberg-compatible tool.\n  With the unified data store enhancements, customers can now easily collect and aggregate logs across AWS accounts and regions aligned to geographic boundaries, business units, or persona-specific requirements. With AWS Organization-wide enablement for AWS sources such as AWS CloudTrail, Amazon VPC, and Amazon WAF, and managed collectors for third party sources such as Crowdstrike, Okta, Palo Alto Networks, CloudWatch makes it easy to bring more of your logs together. Customers can use pipelines to transform and enrich their logs to standard formats such as Open Cybersecurity Schema Framework (OCSF) for security analytics, and define facets to accelerate insights on their data. Customers can make their data available in managed Amazon S3 Tables at no additional storage charge, enabling teams to query data in Amazon SageMaker Unified Studio, Amazon Quick Suite, Amazon Athena, Amazon Redshift, or any Apache Iceberg-compatible analytics tool.\n  To get started, visit the Ingestion page in the CloudWatch console and add one or more data sources. To learn more about Amazon CloudWatch unified data store, visit the product page, pricing page, and documentation. For Regional availability, visit the AWS Builder Center.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-cloudwatch-unified-management-analytics",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "sagemaker",
        "unified studio",
        "lex",
        "s3",
        "redshift",
        "athena",
        "cloudwatch",
        "waf"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "sagemaker",
        "unified studio",
        "lex",
        "s3",
        "redshift",
        "athena",
        "cloudwatch",
        "waf",
        "launch",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-4d58f9580777",
      "title": "Announcing Amazon Nova 2 foundation models now available in Amazon Bedrock",
      "description": "Today AWS announces Amazon Nova 2, our next generation of general models that deliver reasoning capabilities with industry-leading price performance. The new models available today in Amazon Bedrock are:\n \n• Amazon Nova 2 Lite, a fast, cost-effective reasoning model for everyday workloads.\n \n• Amazon Nova 2 Pro (Preview), our most intelligent model for highly complex, multistep tasks.\n \nAmazon Nova 2 Lite and Amazon Nova 2 Pro (Preview) offer significant advancements over our previous generation models. These models support extended thinking with step-by-step reasoning and task decomposition and include three thinking intensity levels—low, medium, and high—giving developers control over the balance of speed, intelligence, and cost. The models also offer built-in tools such as code interpreter and web grounding, support remote MCP tools, and provide a one-million-token context window for richer interactions.\n \nNova 2 Lite can be used for a broad range of your everyday tasks. It offers the best combination of price, performance, and speed. Early customers are using Nova 2 Lite for customer service chatbots, document processing, and business process automation. Nova 2 Lite can be customized using supervised fine-tuning (SFT) on Amazon Bedrock and Amazon SageMaker, and full fine-tuning is available on Amazon SageMaker. Amazon Nova 2 Pro (Preview) can be used for highly complex agentic tasks such as multi-document analysis, video reasoning, and software migrations.\n \nAmazon Nova 2 Lite and Nova 2 Pro (Preview) is now available in Amazon Bedrock via global cross region inference in multiple locations. Nova 2 Pro is in preview with early access available to all Amazon Nova Forge customers. If interested, reach out to your AWS account team regarding access.\n \nLearn more at the AWS News Blog, Amazon Nova models product page, and Amazon Nova user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/nova-2-foundation-models-amazon-bedrock/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "sagemaker",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "sagemaker",
        "lex",
        "preview",
        "early-access",
        "ga",
        "now-available",
        "support",
        "new-model"
      ]
    },
    {
      "id": "aws-news-a003c3534e1a",
      "title": "Amazon OpenSearch Service adds GPU-accelerated and auto-optimized vector indexes",
      "description": "You can now build billion-scale vector databases in under an hour on Amazon OpenSearch Service with GPU-acceleration, and auto-optimize vector indexes for optimal trade-offs between search quality, speed and cost.\n  Previously, large-scale vector indexes took days to build, and optimizing them required experts to spend weeks of manual tuning. The time, cost and effort weighed down innovation velocity, and customers forwent cost and performance optimizations. You can now run serverless, auto-optimize jobs to generate optimization recommendations. You simply specify search latency and recall requirements, and these jobs will evaluate index configurations (k-NN algorithms, quantization, and engine settings) automatically. Then, you can use vector GPU-acceleration to build an optimized index up to 10X faster at a quarter of the indexing cost. Serverless GPUs dynamically activate and accelerate your domain or collection, so you’re only billed when you benefit from speed boosts—all done without you managing GPU instances.\n  These capabilities help you scale AI applications including semantic search, recommendation engines, and agentic systems more efficiently. By simplifying and accelerating the time to build large-scale, optimized vector databases, your team will be empowered to innovate faster.\n  Vector GPU-acceleration is available for vector collections and OpenSearch 3.1+ domains in US East (N. Virginia), US West (Oregon), Asia Paciﬁc (Sydney), Europe (Ireland), and Asia Pacific (Tokyo) Regions. Vector auto-optimize is available for vector collections and OpenSearch 2.17+ domains in US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Paciﬁc (Mumbai), Asia Paciﬁc (Singapore), Asia Paciﬁc (Sydney), Asia Paciﬁc (Tokyo), Europe (Frankfurt) and Europe (Ireland) Regions. Learn more.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-opensearch-service-gpu-accelerated-auto-optimized-vector-indexes",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "opensearch",
        "opensearch service",
        "eks"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "nova",
        "opensearch",
        "opensearch service",
        "eks",
        "ga"
      ]
    },
    {
      "id": "aws-news-60f93eef06f8",
      "title": "Announcing Database Savings Plans with up to 35% savings",
      "description": "Today, AWS announces Database Savings Plans, a new flexible pricing model that helps you save up to 35% in exchange for a commitment to a consistent amount of usage (measured in $/hour) over a one-year term with no upfront payment.\n  Database Savings Plans automatically apply to eligible serverless and provisioned instance usage regardless of supported engine, instance family, size, deployment option, or AWS Region. For example, with Database Savings Plans, you can change between Aurora db.r7g and db.r8g instances, shift a workload from EU (Ireland) to US (Ohio), modernize from Amazon RDS for Oracle to Amazon Aurora PostgreSQL or from RDS to Amazon DynamoDB and still benefit from discounted pricing offered by Database Savings Plans.\n  Database Savings Plans will be available starting today in all AWS Regions, except China Regions, with support for Amazon Aurora, Amazon RDS, Amazon DynamoDB, Amazon ElastiCache, Amazon DocumentDB (with MongoDB compatibility), Amazon Neptune, Amazon Keyspaces (for Apache Cassandra), Amazon Timestream, and AWS Database Migration Service (DMS).\n  You can get started with Database Savings Plans from the AWS Billing and Cost Management Console or by using the AWS CLI. To realize the largest savings, you can make a commitment to Savings Plans by using purchase recommendations provided in the console. For a more customized analysis, you can use the Savings Plans Purchase Analyzer to estimate potential cost savings for custom purchase scenarios. For more information, visit the Database Savings Plans pricing page and the AWS Savings Plans FAQs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/database-savings-plans-savings",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "dynamodb",
        "rds"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lex",
        "dynamodb",
        "rds",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-407048c12183",
      "title": "Amazon Bedrock adds 18 fully managed open weight models, the largest expansion of new models to date",
      "description": "Amazon Bedrock is a platform for building generative AI applications and agents at production scale. Amazon Bedrock provides access to a broad selection of fully managed models from leading AI companies through a unified API, enabling you to evaluate, switch, and adopt new models without rewriting applications or changing infrastructure. Today, Amazon Bedrock is adding 18 fully managed open weight models to its model offering, the largest expansion of new models to date.\n \nYou can now access the following models in Amazon Bedrock:\n  \nGoogle: Gemma 3 4B, Gemma 3 12B, Gemma 3 27B\n \nMiniMax AI: MiniMax M2\n \nMistral AI: Mistral Large 3, Ministral 3 3B, Ministral 3 8B, Ministral 3 14B, Magistral Small 1.2, Voxtral Mini 1.0, Voxtral Small 1.0\n \nMoonshot AI: Kimi K2 Thinking\n \nNVIDIA: NVIDIA Nemotron Nano 2 9B, NVIDIA Nemotron Nano 2 VL 12B\n \nOpenAI: gpt-oss-safeguard-20b, gpt-oss-safeguard-120b\n \nQwen: Qwen3-Next-80B-A3B, Qwen3-VL-235B-A22B\n \nFor the full list of available AWS Regions, refer to the documentation.\n \nTo learn more about all the models that Amazon Bedrock offers, view the Amazon Bedrock model choice page. To get started using these models in Amazon Bedrock, read the launch blog and visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-bedrock-fully-managed-open-weight-models",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "launch",
        "expansion",
        "new-model"
      ]
    },
    {
      "id": "aws-news-ef6225c704a6",
      "title": "Amazon EMR Serverless eliminates local storage provisioning for Apache Spark workloads",
      "description": "Amazon EMR Serverless now offers serverless storage that eliminates local storage provisioning for Apache Spark workloads, reducing data processing costs by up to 20% and preventing job failures from disk capacity constraints. You no longer need to configure local disk type and size for each application. EMR Serverless automatically handles intermediate data operation such as shuffle with no local storage charges. You pay only for compute and memory resources your job consumes.\n  EMR Serverless offloads intermediate data operations to a fully managed, auto-scaling serverless storage that encrypts data in transit and at rest with job-level isolation. Serverless storage decouples storage from compute, allowing Spark to release workers immediately when idle rather than keeping workers active to preserve temporary data. It eliminates job failures from insufficient disk capacity and reduces costs by avoiding idle worker charges. This is particularly valuable for jobs using dynamic resource allocation, such as recommendation engines processing millions of customer interactions, where initial stages process large datasets with high parallelism then narrow as data aggregates.\n  This feature is generally available for EMR release 7.12 and later. See Supported AWS Regions for availability. To get started, visit serverless storage for EMR Serverless documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-emr-serverless-local-storage-provisioning-apache-spark-workloads",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "emr"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "emr",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-2da9fd465b9d",
      "title": "Build agents to automate production UI workflows with Amazon Nova Act (GA)",
      "description": "We are excited to announce the general availability of Amazon Nova Act, a new AWS service for developers to build and manage fleets of highly reliable agents for automating production UI workflows. Nova Act is powered by a custom Nova 2 Lite model and provides high reliability with unmatched cost efficiency, fastest time-to-value, and ease of implementation at scale.\n  Nova Act can reliably complete repetitive UI workflows in the browser, execute APIs or tools (e.g. write to PDF), and escalate to a human supervisor when appropriate. Developers that need to automate repetitive processes across the enterprise can define workflows combining the flexibility of natural language with more deterministic Python code. Technical teams using Nova Act can start prototyping quickly on the online playground at nova.amazon.com/act, refine and debug their scripts using the Nova Act IDE extension, and deploy to AWS in just a few steps.\n  Nova Act is available today in AWS Region US East (N. Virginia).\n  Learn more about Nova Act.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/build-automate-production-ui-workflows-nova-act/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-2ad945ee365c",
      "title": "AWS previews EC2 C8ine instances",
      "description": "AWS launches the preview of Amazon EC2 C8ine instances, powered by custom sixth-generation Intel Xeon Scalable processors (Granite Rapids) and the latest AWS Nitro v6 card. These instances are designed specifically for dataplane packet processing workloads.\n  Amazon EC2 C8ine instance configurations can deliver up to 2.5 times higher packet performance per vCPU versus prior generation C6in instances. They can offer up to 2x higher network bandwidth through internet gateways and up to 3x more Elastic Network Interface (ENI) compared to existing C6in network optimized instances. They are ideal for packet processing workloads requiring high performance at small packet sizes. These workloads include security virtual appliances, firewalls, load balancers, DDoS protection systems, and Telco 5G UPF applications.\n  These instances are available for preview upon request through your AWS account team. Connect with your account representatives to signup.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-previews-ec2-c8ine-instances",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "launch",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-40c7988b6612",
      "title": "Amazon GuardDuty Extended Threat Detection now supports Amazon EC2 and Amazon ECS",
      "description": "AWS announces further enhancements to Amazon GuardDuty Extended Threat Detection with new capabilities to detect multistage attacks targeting Amazon Elastic Compute Cloud (Amazon EC2) instances and Amazon Elastic Container Service (Amazon ECS) clusters running on AWS Fargate or Amazon EC2. GuardDuty Extended Threat Detection uses artificial intelligence and machine learning algorithms trained at AWS scale to automatically correlate security signals and detect critical threats. It analyzes multiple security signals across network activity, process runtime behavior, malware execution, and AWS API activity over extended periods to detect sophisticated attack patterns that might otherwise go unnoticed.\n  With this launch, GuardDuty introduces two new critical-severity findings: AttackSequence:EC2/CompromisedInstanceGroup and AttackSequence:ECS/CompromisedCluster. These findings provide attack sequence information, allowing you to spend less time on initial analysis and more time responding to critical threats, minimizing business impact. For example, GuardDuty can identify suspicious processes followed by persistence attempts, crypto-mining activities, and reverse shell creation, representing these related events as a single, critical-severity finding. Each finding includes a detailed summary, events timeline, mapping to MITRE ATT&CK® tactics and techniques, and remediation recommendations.\n  While GuardDuty Extended Threat Detection is automatically enabled for GuardDuty customers at no additional cost, its detection comprehensiveness depends on your enabled GuardDuty protection plans. To improve attack sequence coverage and threat analysis of Amazon EC2 instances, enable Runtime Monitoring for EC2. To enable detection of compromised ECS clusters, enable Runtime Monitoring for Fargate or EC2 depending on your infrastructure type.\n  To get started, enable GuardDuty protection plans via the Console or API. New GuardDuty customers can start with a 30-day free trial, and existing customers who haven't used Runtime Monitoring can also try it free for 30 days. For additional information, visit the blog post and Amazon Guard Duty product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/guardduty-extended-threat-detection-ec2-ecs/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "ecs",
        "fargate"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "ecs",
        "fargate",
        "launch",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-0a2fabefed90",
      "title": "Announcing Amazon EC2 Trn3 UltraServers for faster, lower-cost generative AI training",
      "description": "AWS announces the general availability of Amazon Elastic Compute Cloud (Amazon EC2) Trn3 UltraServers powered by our fourth–generation AI chip Trainium3, our first 3nm AWS AI chip purpose-built to deliver the best token economics for next-generation agentic, reasoning, and video generation applications.\n  Each AWS Trainium3 chip provides 2.52 petaflops (PFLOPs) of FP8 compute, increases the memory capacity by 1.5x and bandwidth by 1.7x over Trainium2 to 144 GB of HBM3e memory, and 4.9 TB/s of memory bandwidth. Trainium3 is designed for both dense and expert-parallel workloads with advanced data types (MXFP8 and MXFP4) and improved memory-to-compute balance for real-time, multimodal, and reasoning tasks.\n  Trn3 UltraServers can scale up to 144 Trainium3 chips (362 FP8 PFLOPs total) and are available in EC2 UltraClusters 3.0 to scale to hundreds of thousands of chips. A fully configured Trn3 UltraServer delivers up to 20.7 TB of HBM3e and 706 TB/s of aggregate memory bandwidth. The next-generation Trn3 UltraServer, feature the NeuronSwitch-v1, an all-to-all fabric that doubles interchip interconnect bandwidth over Trn2 UltraServer.\n  Trn3 delivers up to 4.4x higher performance, 3.9x higher memory bandwidth and 4x better performance/watt compared to our Trn2 UltraServers, providing the best price-performance for training and serving frontier-scale models, including reinforcement learning, Mixture-of-Experts (MoE), reasoning, and long-context architectures. On Amazon Bedrock, Trainium3 is our fastest accelerator, delivering up to 3× faster performance than Trainium2 with over 5× higher output tokens per megawatt at similar latency per user.\n  New Trn3 UltraServers are built for AI researchers and powered by the AWS Neuron SDK, to unlock breakthrough performance. With native PyTorch integration, developers can train and deploy without changing a single line of model code. For AI performance engineers, we’ve enabled deeper access to Trainium3 so they can fine-tune performance, customize kernels, and push models even further. Because innovation thrives on openness, we are committed to engaging with our developers through open-source tools and resources.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-trn3-ultraservers",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "trainium",
        "trainium3",
        "neuron",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova",
        "trainium",
        "trainium3",
        "neuron",
        "ec2",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-3bcc932fc880",
      "title": "AWS Lambda announces durable functions for multi-step applications and AI workflows",
      "description": "AWS Lambda announces durable functions, enabling developers to build reliable multi-step applications and AI workflows within the Lambda developer experience. Durable functions automatically checkpoint progress, suspend execution for up to one year during long-running tasks, and recover from failures - all without requiring you to manage additional infrastructure or write custom state management and error handling code.\n  Customers use Lambda for the simplicity of its event-driven programming model and built-in integrations. While traditional Lambda functions excel at handling single, short-lived tasks, developers building complex multi-step applications, such as order processing, user onboarding, and AI-assisted workflows, previously needed to implement custom state management logic or integrate with external orchestration services. Lambda durable functions address this opportunity by extending the Lambda programming model with new operations like \"steps\" and \"waits\" that let you checkpoint progress and pause execution without incurring compute charges. The service handles state management, error recovery, and efficient pausing and resuming of long-running tasks, allowing you to focus on your core business logic.\n  Lambda durable functions are generally available in US East (Ohio) with support for Python (versions 3.13 and 3.14) and Node.js (versions 22 and 24) runtimes. For the latest region availability, visit the AWS Capabilities by Region page.\n  You can activate durable functions for new Python or Node.js based Lambda functions using the AWS Lambda API, AWS Management Console, AWS Command Line Interface (AWS CLI), AWS Cloud Formation, AWS Serverless Application Model (AWS SAM), AWS SDK, and AWS Cloud Development Kit (AWS CDK). For more information on durable functions, visit the AWS Lambda Developer Guide and launch blog post. To learn about pricing, visit AWS Lambda pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/lambda-durable-multi-step-applications-ai-workflows/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "lambda"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "lambda",
        "launch",
        "generally-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-9760f84bbfd6",
      "title": "AWS Support transformation: AI-powered operations with the human expertise you trust",
      "description": "AWS Support announces a transformation of its Support portfolio, simplified into three intelligent, experience-driven plans: Business Support+, Enterprise Support, and Unified Operations. Each plan combines the speed and precision of AI with the expertise of AWS engineers. Each higher plan builds on the previous one, adding faster response times, proactive guidance, and smarter operations. The result: reduced engineering burden, stronger reliability and resiliency, and streamlined cloud operations.\n  Business Support+ delivers 24/7 AI-powered assistance that understands your context, with direct engagement to AWS experts for critical issues within 30 minutes—twice as fast as current plans. Enterprise Support expands on this with designated Technical Account Managers (TAMs) who blend generative AI insights with human judgment to provide strategic operational guidance across resiliency, cost, and efficiency. It also includes AWS Security Incident Response at no additional cost, which customers can activate to automate security alert investigation and triage. Unified Operations, the top plan, is designed for mission-critical workloads—offering a global team of designated experts who deliver architecture reviews, guided testing, proactive optimization, and five-minute context-specific response times for critical incidents. Customers using AWS DevOps Agent (preview) can engage with AWS Support with one-click from an investigation when needed, giving AWS experts immediate context for faster resolution. AWS DevOps Agent is a frontier agent that resolves and proactively prevents incidents, continuously improving reliability and performance of applications in AWS, multicloud, and hybrid environments.\n  Business Support+, Enterprise Support, and Unified Operations are available in all commercial AWS Regions. Existing customers can continue with their current plans or explore the new offerings for enhanced performance and efficiency. To see how AWS blends AI intelligence and human expertise to transform your cloud operations, visit the AWS Support product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-support-transformation-ai-powered-operations",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "preview",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-263f470684fd",
      "title": "AWS Security Agent (Preview): AI agent for proactive app security",
      "description": "Today, AWS announces the preview of AWS Security Agent, an AI-powered agent that proactively secures your applications throughout the development lifecycle. AWS Security Agent conducts automated security reviews tailored to your organizational requirements and delivers context-aware penetration testing. By continuously validating security from design to deployment, it helps prevent vulnerabilities early in development across all your environments.\n \nSecurity teams define organizational security requirements once in the AWS Security Agent console, such as approved encryption libraries, authentication frameworks, and logging standards. AWS Security Agent then automatically validates these requirements throughout development by evaluating architectural documents and code against your defined standards, providing specific guidance when violations are detected. For deployment validation, security teams define their penetration testing scope and AWS Security Agent develops application context, executes sophisticated attack chains, and discovers and validates vulnerabilities. This delivers consistent security policy enforcement across all teams, scales security reviews to match development velocity, and transforms penetration testing from a periodic bottleneck into an on-demand capability that dramatically reduces risk exposure.\n \nAWS Security Agent (Preview) is currently available in the US East (N. Virginia) Region. All of your data remains safe and private. Your queries and data are never used to train models. AWS Security Agent logs API activity to AWS CloudTrail for auditing and compliance.\n \nTo learn more about AWS Security Agent, visit the product page and read the launch announcement. For technical details and to get started, see the AWS Security Agent documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-security-agent-preview",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds",
        "launch",
        "preview",
        "ga",
        "announcement"
      ]
    },
    {
      "id": "aws-news-cdbe838811da",
      "title": "Announcing New Compute-Optimized Amazon EC2 C8a Instances",
      "description": "AWS announces the general availability of new compute-optimized Amazon EC2 C8a instances. C8a instances are powered by 5th Gen AMD EPYC processors (formerly code named Turin) with a maximum frequency of 4.5 GHz, delivering up to 30% higher performance and up to 19% better price-performance compared to C7a instances.\n  C8a instances deliver 33% more memory bandwidth compared to C7a instances, making these instances ideal for latency sensitive workloads. Compared to Amazon EC2 C7a instances, they are up to 57% faster for GroovyJVM allowing better response times for Java-based applications. C8a instances offer 12 sizes including 2 bare metal sizes. This range of instance sizes allows customers to precisely match their workload requirements.\n  C8a instances are built on AWS Nitro System and are ideal for high performance, compute-intensive workloads such as batch processing, distributed analytics, high performance computing (HPC), ad serving, highly-scalable multiplayer gaming, and video encoding.\n  C8a instances are available in the following AWS Regions: US East (N. Virginia), US East (Ohio), and US West (Oregon) regions. To get started, sign in to the AWS Management Console. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information visit the Amazon EC2 C8a instance page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/compute-optimized-amazon-ec2-c8a-instances/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "ga"
      ]
    },
    {
      "id": "aws-news-652da7a2225a",
      "title": "Announcing Amazon EC2 M4 Max Mac instances (Preview)",
      "description": "Amazon Web Services announces preview of Amazon EC2 M4 Max Mac instances, powered by the latest Mac Studio hardware. Amazon EC2 M4 Max Mac instances are the next-generation EC2 Mac instances, that enable Apple developers to migrate their most demanding build and test workloads onto AWS. These instances are ideal for building and testing applications for Apple platforms such as iOS, macOS, iPadOS, tvOS, watchOS, visionOS, and Safari.\n  M4 Max Mac instances are powered by the AWS Nitro System, providing up to 10 Gbps network bandwidth and 8 Gbps of Amazon Elastic Block Store (Amazon EBS) storage bandwidth. These instances are built on Apple M4 Max Mac Studio computers featuring a 16-core CPU, 40-core GPU, 16-core Neural Engine, and 128GB of unified memory. Compared to EC2 M4 Pro Mac instances, M4 Max instances offer twice the GPU cores and more than 2.5x the unified memory, offering customers more choice to match instance capabilities to their specific workload requirements and further expanding the selection of Apple silicon Mac hardware on AWS.\n \nTo learn more or request access to the Amazon EC2 M4 Max Mac instances preview, visit the Amazon EC2 Mac page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-m4-max-mac-instances-preview",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "preview"
      ]
    },
    {
      "id": "aws-news-5615baf94b9d",
      "title": "Introducing Amazon Nova 2 Omni in Preview",
      "description": "We are excited to announce Amazon Nova 2 Omni, an all-in-one model for multimodal reasoning and image generation. It is the industry’s first reasoning model that supports text, images, video, and speech inputs while generating both text and image outputs. It enables multimodal understanding, image generation and editing using natural language, and speech transcription.\n  Unlike traditional approaches that often force organizations to stitch together various specialized models, each supporting different input and output types, Nova 2 Omni eliminates the complexity of managing multiple AI models. This helps to accelerate application development while reducing complexity and costs, enabling developers to tackle diverse tasks from marketing content creation and customer support call transcription to video analysis and documentation with visual aids.\n  The model supports a 1M token context window, 200+ languages for text processing and 10 languages for speech input. It can generate and edits high-quality images using natural language, enabling character consistency, text rendering within image as well as object and background modification. Nova 2 Omni delivers superior speech understanding with native reasoning to transcribe, translate and summarize multi-speaker conversations. And with flexible reasoning controls for depth and budget, developers can ensure optimal performance, accuracy, and cost management across different use cases.\n  Nova 2 Omni is in preview with early access available to all Nova Forge customers. Please reach out to your AWS account team for access. To learn more about Amazon Nova 2 Omni read the user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-nova-2-omni-preview",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "translate",
        "lex",
        "transcribe",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "translate",
        "lex",
        "transcribe",
        "organizations",
        "preview",
        "early-access",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f4dd8e1f32da",
      "title": "Amazon Nova Forge: Build your own Frontier Models using Nova",
      "description": "We are excited to announce the general availability of Nova Forge, a new service to build your own frontier models using Nova.\n  With Nova Forge, you can start your model development on SageMaker AI from early Nova checkpoints across pre-training, mid-training, or post-training phases. You can blend proprietary data with Amazon Nova-curated data to train the model. You can also take advantage of model development features available exclusively on Nova Forge, including the ability to execute Reinforcement Fine Tuning (RFT) with reward functions in your environment and to implement custom safety guardrails using the built-in responsible AI toolkit. Nova Forge allows you to build models that deeply understand your organization’s proprietary knowledge and reflects your expertise, while preserving general capabilities like reasoning and minimizing risks like catastrophic forgetting. In addition, Nova Forge customers get early access to new Nova models, including Nova 2 Pro and Nova 2 Omni.\n  Nova Forge is available today in US East (N. Virginia) AWS Region and will be available in additional regions in the coming months. Learn more about Nova Forge on the AWS News Blog, the Amazon Nova Forge product page, or the Amazon Nova Forge user guide. You can get started with Nova Forge today from the Amazon Nova Forge console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-nova-forge-frontier-models-nova/",
      "pubDate": "2025-12-02T13:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "early-access",
        "ga"
      ]
    },
    {
      "id": "aws-news-d3d4bf286e7d",
      "title": "Amazon API Gateway adds MCP proxy support",
      "description": "Amazon API Gateway now supports Model Context Protocol (MCP) proxy, allowing you to transform your existing REST APIs into MCP-compatible endpoints. This new capability enables organizations to make their APIs accessible to AI agents and MCP clients. Through integration with Amazon Bedrock AgentCore's Gateway service, you can securely convert your REST APIs into agent-compatible tools while enabling intelligent tool discovery through semantic search.\n  The MCP proxy capability, alongside Bedrock AgentCore Gateway services, delivers three key benefits. First, it enables REST APIs to communicate with AI agents and MCP clients through protocol translation, eliminating the need for application modifications or managing additional infrastructure. Second, it provides comprehensive security through dual authentication - verifying agent identities for inbound requests while managing secure connections to REST APIs for outbound calls. Finally, it enables AI agents to search and select the most relevant REST APIs that best match the prompt context.\n  To learn about pricing for this feature, please see the Amazon Bedrock AgentCore pricing page. Amazon API Gateway MCP proxy capability is available in the nine AWS Regions that Amazon Bedrock AgentCore is available in: Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Dublin), Europe (Frankfurt), US East (N. Virginia), US East (Ohio), and US West (Oregon). To get started, visit Amazon API Gateway documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/api-gateway-mcp-proxy-support/",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "api gateway",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "api gateway",
        "organizations",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-f36ad3c2df49",
      "title": "Amazon SageMaker Catalog now exports asset metadata as queryable dataset",
      "description": "Amazon SageMaker Catalog now exports asset metadata as an Apache Iceberg table through Amazon S3 Tables. This allows data teams to query catalog inventory and answer questions such as, \"How many assets were registered last month?\", \"Which assets are classified as confidential?\", or \"Which assets lack business descriptions?\" using standard SQL without building custom ETL infrastructure for reporting.\n \nThis capability automatically converts catalog asset metadata into a queryable table accessible from Amazon Athena, SageMaker Unified Studio notebooks, AI agents, and other analytics and BI tools. The exported table includes technical metadata (such as resource_id, resource_type), business metadata (such as asset_name, business_description), ownership details, and timestamps. Data is partitioned by snapshot_date for time travel queries and automatically appears in SageMaker Unified Studio under the aws-sagemaker-catalog bucket.\n \nThis capability is available in all AWS Regions where SageMaker Catalog is supported at no additional charge. You pay only for underlying services including S3 Tables storage and Amazon Athena queries. You can control storage costs by setting retention policies on the exported tables to automatically remove records older than your specified period.\n  To get started, activate dataset export using the AWS CLI, then access the asset table through S3 Tables or SageMaker Unified Studio's Data tab within 24 hours. Query using Amazon Athena, Studio notebooks, or connect external BI tools through the S3 Tables Iceberg REST Catalog endpoint. For instructions, see the Amazon SageMaker user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/sagemaker-catalog-asset-metadata-queryable-dataset/",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "rds",
        "athena"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "rds",
        "athena",
        "support"
      ]
    },
    {
      "id": "aws-news-1f46b500a6a3",
      "title": "Amazon CloudWatch GenAI observability now supports Amazon AgentCore Evaluations",
      "description": "Amazon CloudWatch now enables automated quality assessment of AI agents through AgentCore Evaluations. This new capability helps developers continuously monitor and improve agent performance based on real-world interactions, allowing teams to identify and address quality issues before they impact customers.\n  AgentCore Evaluations comes with 13 pre-built evaluators covering essential quality dimensions like helpfulness, tool selection, and response accuracy, while also supporting custom model-based scoring systems. You can access unified quality metrics and agent telemetry in CloudWatch dashboards, with end-to-end tracing capabilities to correlate evaluation metrics with prompts and logs. The feature integrates seamlessly with CloudWatch's existing capabilities including Application Signals, Alarms, Sensitive Data Protection, and Logs Insights. This capability eliminates the need for teams to build and maintain custom evaluation infrastructure, accelerating the deployment of high-quality AI agents. Developers can monitor their entire agent fleet through the AgentCore section in the CloudWatch GenAI observability console.\n \nAgentCore Evaluations is now available in US East (N. Virginia), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Sydney). To get started, visit the documentation and pricing details. Standard CloudWatch pricing applies for underlying telemetry data.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/cloudwatch-genai-observability-agentcore-evaluations/",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "agentcore",
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "agentcore",
        "rds",
        "cloudwatch",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-c5df555a7a43",
      "title": "Announcing new memory optimized Amazon EC2 X8aedz instances",
      "description": "AWS announces Amazon EC2 X8aedz, next generation memory optimized instances, powered by 5th Gen AMD EPYC processors (formerly code named Turin). These instances offer the highest maximum CPU frequency, 5GHz in the cloud. They deliver up to 2x higher compute performance compared to previous generation X2iezn instances.\n  X8aedz instances are built using the latest sixth generation AWS Nitro Cards and are ideal for electronic design automation (EDA) workloads such as physical layout and physical verification jobs, and relational databases that benefit from high single-threaded processor performance and a large memory footprint. The combination of 5 GHz processors and local NVMe storage enables faster processing of memory-intensive backend EDA workloads such as floor planning, logic placement, clock tree synthesis (CTS), routing, and power/signal integrity analysis.\n  X8aedz instances feature a 32:1 ratio of memory to vCPU and are available in 8 sizes ranging from 2 to 96 vCPUs with 64 to 3,072 GiB of memory, including two bare metal variants, and up to 8 TB of local NVMe SSD storage.\n  X8aedz instances are now available in US West (Oregon) and Asia Pacific (Tokyo) regions. Customers can purchase X8aedz instances via Savings Plans, On-Demand instances, and Spot instances. To get started, sign in to the AWS Management Console. For more information visit the Amazon EC2 X8aedz instance page or AWS news blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/new-memory-optimized-amazon-ec2-x8aedz-instances",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "now-available"
      ]
    },
    {
      "id": "aws-news-689229736e75",
      "title": "Amazon Bedrock AgentCore Runtime now supports bi-directional streaming",
      "description": "Amazon Bedrock AgentCore Runtime now supports bi-directional streaming, enabling real-time conversations where agents listen and respond simultaneously while handling interruptions and context changes mid-conversation. This feature eliminates conversational friction by enabling continuous, two-way communication where context is preserved throughout the interaction.\n  Traditional agents require users to wait for them to finish responding before providing clarification or corrections, creating stop-start interactions that break conversational flow and feel unnatural, especially in voice applications. Bi-directional streaming addresses this limitation by enabling continuous context handling, helping power voice agents that deliver natural conversational experiences where users can interrupt, clarify, or change direction mid-conversation, while also enhancing text-based interactions through improved responsiveness. Built into AgentCore Runtime, this feature eliminates months of engineering effort required to build real-time streaming capabilities, so developers can focus on building innovative agent experiences rather than managing complex streaming infrastructure.\n  This feature is available in all nine AWS Regions where Amazon Bedrock AgentCore Runtime is available: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), and Europe (Ireland).\n  To learn more about AgentCore Runtime bi-directional streaming, read the blog, visit the AgentCore documentation and get started with the AgentCore Starter Toolkit. With AgentCore Runtime's consumption-based pricing, you only pay for active resources consumed during agent execution, with no charges for idle time or upfront costs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/bedrock-agentcore-runtime-bi-directional-streaming/",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "nova",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-e19574de6969",
      "title": "Amazon SageMaker AI announces serverless MLflow capability for faster AI development",
      "description": "Amazon SageMaker AI now offers a serverless MLflow capability that dynamically scales to support AI model development tasks. With MLflow, AI developers can begin tracking, comparing, and evaluating experiments without waiting for infrastructure setup.\n  As customers across industries accelerate AI development, they require capabilities to track experiments, observe behavior, and evaluate the performance of AI models, applications and agents. However, managing MLflow infrastructure requires administrators to continuously maintain and scale tracking servers, make complex capacity planning decisions, and deploy separate instances for data isolation. This infrastructure burden diverts resources away from core AI development and creates bottlenecks that impact team productivity and cost effectiveness.\n  With this update, MLflow now scales dynamically to deliver fast performance for demanding and unpredictable model development tasks, then scales down during idle time. Administrators can also enhance productivity by setting up cross-account access via Resource Access Manager (RAM) to simplify collaboration across organizational boundaries.\n  The serverless MLflow capability on Amazon SageMaker AI is offered at no additional charge and works natively with familiar Amazon SageMaker AI model development capabilities like SageMaker AI JumpStart, SageMaker Model Registry and SageMaker Pipelines. Customers can access the latest version of MLflow on Amazon SageMaker AI with automatic version updates.\n  Amazon SageMaker AI with MLflow is now available in select AWS Regions. To learn more, see the Amazon SageMaker AI user guide and the AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/sagemaker-ai-serverless-mlflow-ai-development/",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "lex",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-c4e599974567",
      "title": "Amazon S3 Tables now offer the Intelligent-Tiering storage class",
      "description": "Amazon S3 Tables now offer the Intelligent-Tiering storage class, which optimizes costs based on access patterns, without performance impact or operational overhead. Intelligent-Tiering automatically transitions data in tables across three low-latency access tiers as access patterns change, reducing storage costs by up to 80%. Additionally, S3 Tables automated maintenance operations such as compaction, snapshot expiration, and unreferenced file removal never tier up your data. This helps you to keep your tables optimized while saving on storage costs.\n  With the Intelligent-Tiering storage class, data in tables not accessed for 30 consecutive days automatically transitions to the Infrequent Access tier (40% lower cost than the Frequent Access tier). After 90 days without access, that data transitions to the Archive Instant Access tier (68% lower cost than the Infrequent Access tier). You can now select Intelligent-Tiering as the storage class when you create a table or set it as the default for all new tables in a table bucket.\n  The Intelligent-Tiering storage class is available in all AWS Regions where S3 Tables are available. For pricing details, visit the Amazon S3 pricing page. To learn more about S3 Tables, visit the product page, documentation, and read the AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/s3-tables-intelligent-tiering-storage-class/",
      "pubDate": "2025-12-02T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3"
      ]
    },
    {
      "id": "aws-news-8cd3d5f72646",
      "title": "AWS Transform launches an AI agent for full-stack Windows modernization",
      "description": "AWS Transform is expanding its capability from the .NET modernization agent to now include the full-stack Windows modernization agent that handles both .NET applications and their associated databases. The new agent automates the transformation of .NET applications and Microsoft SQL Server databases to Amazon Aurora PostgreSQL and deploys them to containers on Amazon ECS or Amazon EC2 Linux. AWS Transform accelerates full-stack Windows modernization by 5x across application and database layers, while reducing operating costs by up to 70%.\n  With AWS Transform, customers can accelerate their full-stack modernization journey through automated discovery, transformation, and deployment. The full-stack Windows modernization agent scans Microsoft SQL Server databases in Amazon EC2 or Amazon RDS instances, and it scans .NET application code from source repositories (GitHub, GitLab, Bitbucket, or Azure Repos) to create customized, editable modernization plans. It automatically transforms SQL Server schemas to Aurora PostgreSQL and migrates databases to new or existing Aurora PostgreSQL target clusters. For .NET application transformation, the agent updates database connections in the source code and modifies database access code written in Entity Framework and ADO.NET to be compatible with Aurora PostgreSQL—all in a unified workflow with human supervision. All the transformed code is committed to a new repository branch. Finally, the transformed application along with the databases can be deployed into a new or existing environment to validate the transformed applications and databases. Customers can monitor transformation progress through worklog updates and interactive chat, and they can use the detailed transformation summaries for next steps recommendations and for easy handoff to AI code companions.\n  AWS Transform for full-stack Windows modernization is available in the US East (N. Virginia) AWS Region.\n  To learn more, visit the overview page and AWS Transform documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-transform-ai-agent-full-stack-windows-modernization",
      "pubDate": "2025-12-01T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "ecs"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ec2",
        "rds",
        "ecs",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-839280c1af5b",
      "title": "AWS Transform for mainframe now supports application reimagining",
      "description": "AWS Transform for mainframe delivers new data and activity analysis capabilities to extract comprehensive insights to drive the reimagining of mainframe applications. These insights can be combined with business logic extraction to inform decomposition of legacy applications into logical business domains. Together, these form the basis of a comprehensive specification for coding agents like Kiro to reimagine applications into cloud-native architectures.\n  The new capabilities empower organizations to reimagine legacy workloads, providing a comprehensive reverse engineering workflow that includes automated code and data structure analysis, activity analysis, technical documentation generation, business logic extraction, and intelligent code decomposition. Through in-depth data and activity analysis, AWS Transform helps identify application components with high utilization or business value, allowing teams to optimize their modernization efforts and make data-informed architectural decisions.\n  In the AI-powered chat interface, users can customize their modernization approach through flexible job plans that allow them to select predefined comprehensive workflows—full modernization, analysis focus, or business logic focus—or create their own combination of capabilities based on specific objectives.\n  The reimagine capabilities in AWS Transform for mainframe are available today in US East (N. Virginia), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London) Regions.\n  To learn more about reimagining mainframe applications with AWS Transform for mainframe, read the AWS News Blog post or visit the AWS Transform product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-mainframe-application-reimagining/",
      "pubDate": "2025-12-01T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-3bd2560befb0",
      "title": "AWS Transform adds new agentic AI capabilities for enterprise VMware migrations",
      "description": "AWS Transform adds powerful new agentic AI capabilities to automate VMware migrations to AWS. The migration agent collaborates with migration teams to understand business priorities and intelligently plan and migrate hundreds of applications spanning thousands of servers, significantly reducing manual effort, time, and complexity.\n  The agent can now discover your on-premises environment and prioritize applications for migration using the AWS Transform discovery tool, inventory data from various third-party discovery tools, and unstructured data such as documents, notes, and business rules. It analyzes infrastructure, database, and application details, maps dependencies, and generates migration plans grouped by business and technical priorities such as ownership, department, function, subnet, and operating systems. It generates networks with hub-and-spoke and isolated network configurations, provides flexible IP address management options, deploys to multiple accounts, generates network configurations for your AWS landing zones, and migrates from source environments like NSX, Palo Alto, Fortigate, and Cisco ACI. The agent migrates servers to AWS securely and iteratively in waves and provides clear progress updates throughout the deployment. It also migrates Windows and Linux x86 servers, hypervisors such as VMware, HyperV, Nutanix, and KVM, and bare-metal physical environments to multiple target accounts. Throughout your migration, you can ask the agent questions as it guides your decisions, whether that’s repeating or skipping steps, or adjusting plans. To simplify internal approvals, the agent also generates a detailed report with the migration plan and mapping of networks, servers, and applications.\n  With AWS Transform, you can accelerate time to value, lower risk, and reduce the complexity of VMware migrations. These new capabilities are available in all AWS Regions where AWS Transform is offered, with support for migrating servers and networks to 16 AWS Regions.\n  Learn more on the product page and user guide, and get started with AWS Transform.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-vmware-agentic-ai-enterprise-migration/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-c6df8d64d713",
      "title": "AWS launches AWS Transform custom to accelerate organization-wide application modernization",
      "description": "AWS Transform custom is now generally available, accelerating organization-specific code and application modernization at scale using agentic AI. AWS Transform is the first agentic AI service to accelerate the transformation of Windows, mainframe, VMware, and more—reducing technical debt and making your tech stack AI-ready. Technical debt accumulates when organizations maintain legacy systems and outdated code, requiring them to allocate 20-30% of their software development resources to repeatable, cross-codebase transformation tasks that must be performed manually. AWS Transform can automate repeatable transformations of version upgrades, runtime migrations, framework transitions, and language translations at scale, reducing execution time by over 80% in many cases while eliminating the need for specialized automation expertise.\n \nThe custom transformation agent in AWS Transform provides both pre-built and custom solutions. It includes out-of-the-box transformations for common scenarios, such as Python and Node.js runtime upgrades, Lambda function modernization, AWS SDK updates across multiple languages, and Java 8 to 17 upgrades (supporting any build system including Gradle and Maven). For organization-specific needs, teams can define custom transformations using natural language, reference documents, and code samples. Users can trigger autonomous transformations with a simple one-line CLI command, which can be scripted or embedded into any existing pipeline or workflow. Within your organization, the agent continually learns from developer feedback and execution results, improving transformation accuracy and tightly aligning the agent’s performance with your organization’s preferences. This approach enables organizations to systematically address technical debt at scale, with the agent continually improving while developers can focus on innovation and high-impact tasks.\n \nAWS Transform custom is now available in the US East (N. Virginia) AWS Region.\n \nTo learn more, visit the user guide, overview page, and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-custom-organization-wide-modernization/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lambda",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "nova",
        "lambda",
        "organizations",
        "launch",
        "generally-available",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-0b2d15aede4a",
      "title": "AWS Transform for mainframe delivers new testing automation capabilities",
      "description": "AWS Transform for mainframe now offers test planning and automation features to accelerate mainframe modernization projects. New capabilities include automated test plan generation, test data collection scripts, and test case automation scripts, alongside functional test environment tools for continuous delivery and regression testing, helping accelerate and de-risk testing and validation during mainframe modernization projects.\n  The new capabilities address key testing challenges across the modernization lifecycle, reducing the time and effort required for mainframe modernization testing, which typically consumes over 50% of project duration. Automated test plan generation helps teams reduce upfront planning efforts and align on critical functional tests needed to mitigate risk and ensure modernization success, while test data collection scripts accelerate the error-prone, complex process of capturing mainframe data. Test automation scripts then enable scalable execution of test cases by automating test environment staging, test case execution, and results validation against expected outcomes.\n  By automating complex testing tasks and reducing dependency on scarce mainframe expertise, organizations can now modernize their applications with greater confidence while improving accuracy through consistent, automated processes.\n  The new testing capabilities in AWS Transform for mainframe are available today in US East (N. Virginia), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London) Regions.\n  To learn more about automated testing in AWS Transform for mainframe, and how it can help your organization accelerate modernization, read the AWS News Blog, visit the AWS Transform for mainframe product page, or explore the AWS Transform User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-mainframe-testing-automation/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-fbcf70ff0cc1",
      "title": "AWS Transform expands .NET transformation capabilities and enhances developer experience",
      "description": "Today, AWS announces the general availability of expanded .NET transformation capabilities and an enhanced developer experience in AWS Transform. Customers can now modernize .NET Framework and .NET code to .NET 10 or .NET Standard. New transformation capabilities include UI porting of ASP.NET Web Forms to Blazor on ASP.NET Core and porting Entity Framework ORM code. The new developer experience, available with the AWS Toolkit for Visual Studio 2026 or 2022, is customizable, interactive, and iterative. It includes an editable transformation plan, estimated transformation time, real-time updates during transformation, the ability to repeat transformations with a revised plan, and next steps markdown for easy handoff to AI code companions. With these enhancements, AWS Transform provides a path to modern .NET for more project types, supports the latest releases of .NET and Visual Studio, and gives developers oversight and control of transformations.\n \nDevelopers can now streamline their .NET modernization through an enhanced IDE experience. The process begins with automated code analysis that produces a customizable transformation plan. Developers can customize the transformation plan, such as fine-tuning package updates. Throughout the transformation, they benefit from transparent progress tracking and detailed activity logs. Upon completion, developers receive a Next Steps document that outlines remaining tasks, including Linux readiness requirements, which they can address through additional AWS Transform iterations or by leveraging AI code companion tools such as Kiro.\n \nAWS Transform is available in the following AWS Regions: US East (N. Virginia), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London).\n \nTo get started with AWS Transform, refer to the AWS Transform documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-net-transformation-developer-experience/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-1ffd715165b7",
      "title": "Amazon Connect now provides native testing and simulation capabilities",
      "description": "Amazon Connect now allows you to test and simulate contact center experiences in just a few clicks, making it easy to validate workflows, self-service voice interactions, and their outcomes. For each test, you can configure the test parameters including the caller's phone number or customer profile, the reason for the call (such as \"I need to check my order status\"), the expected responses (such as \"Your request has been processed\"), and business conditions like after-hours scenarios or full call queues. After executing tests, results show success or failure based on your defined criteria, along with the path taken by the simulated interaction and detailed logs to quickly diagnose potential issues\n  With this launch, you can run multiple tests simultaneously to validate scenarios and workflows at scale, reducing testing time. Companies can view test results and identify common failure patterns across all their tests in Connect's analytics dashboards. These capabilities enable you to rapidly validate changes to your workflows and confidently deploy new experiences to adapt to your ever-changing business needs.\n  To learn more about these features, see the Amazon Connect Administrator Guide. These features are available in all AWS regions where Amazon Connect is available. To learn more about Amazon Connect, AWS’s AI-native customer experience solution, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-native-testing-simulation-capabilities",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds",
        "launch"
      ]
    },
    {
      "id": "aws-news-f196750d89bd",
      "title": "Amazon Connect launches Model Context Protocol (MCP) support",
      "description": "Amazon Connect now supports Model Context Protocol (MCP), enabling AI agents for end-customer self-service and employee assistance to use standardized tools for retrieving information and completing actions. With this launch, businesses can enhance their AI agents with extensible tool capabilities that improve issue resolution. For example, an AI agent can automatically look up order status, process refunds, and update customer records during a self-service interaction without requiring human intervention.\n  With this launch, Amazon Connect provides out-of-the-box MCP tools for common tasks such as updating contact attributes and retrieving case information. You can also use flow modules as MCP tools to reuse the same business logic across both deterministic and generative AI workflows. Additionally, you can integrate custom tools or third-party services through flow modules or the Amazon Bedrock AgentCore Gateway.\n  For region availability, please see the availability of Amazon Connect features by Region. To learn more about Connect’s AI agents please visit the website or see the help documentation. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-mcp-support",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "rds",
        "launch",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-2dbaffb3d657",
      "title": "Amazon Connect launches automated email responses using conditional keywords and phrases",
      "description": "Amazon Connect now allows you to automate email responses and agent routing logic using keyword and phrase conditions, helping organizations increase self-service, reduce manual handling time, and improve routing accuracy. For example, if a customer sends an email asking if a certain product is in stock, or is checking on their shipment status, an automated response can be sent without involving an agent.\n  To enable this feature, add the Get stored content block to your flows and use accompanying flow blocks such as Check contact attributes and Send message to configure automated email responses and routing.\n  Amazon Connect email is available in the US East (N. Virginia), US West (Oregon), Africa (Cape Town), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London) regions. To learn more and get started, please refer to the help documentation or visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-automated-email-responses/",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "organizations",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-e236ddb5007a",
      "title": "Amazon Connect now provides automated performance evaluations for self-service interactions",
      "description": "Amazon Connect now provides businesses with the ability to automatically evaluate the quality of self-service interactions and get aggregated insights to improve customer experience. Managers can define custom criteria to assess the quality of self-service interactions, that can be filled manually or automatically using insights from conversational analytics, and other Connect data. For example, you can automatically assess if the AI agent repeatedly fails to understand the customer, resulting in poor customer sentiment and transfer to a human agent. Managers can review these insights in aggregate and on individual contacts, alongside self-service interaction recordings and transcripts, to identify opportunities to improve AI agent performance.\n  Manually filled evaluations of self-service interactions are available in all regions where Amazon Connect is offered. Automated evaluations of self-service interactions are available in the following AWS regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Europe (Frankfurt). For information about Amazon Connect pricing, please visit our pricing page. To learn more, please visit our documentation and our webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-automated-performance-evaluations-self-service-interactions",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-13754dd52a44",
      "title": "Amazon Connect now supports AI agent assistance and summarization for Agentforce Service",
      "description": "Amazon Connect launches real-time AI agent assistance and contact summarization for Salesforce Contact Center with Amazon Connect (SCC-AC). It enables Connect AI agents to automatically leverage customer information and knowledge base articles from Salesforce CRM for accelerated issue resolution and consistent outcomes across voice and chat interactions.\n  When human intervention is required, the seamless integration within SCC-AC connects customers to agents who have a unified view of customer data, issue context, and interaction history within Agentforce Service and Agentforce Sales. Agents receive real-time voice transcripts and contextual recommendations, while supervisors gain enhanced call monitoring capabilities directly in Salesforce. Upon resolution, automated post-contact summarization enables agents to easily update Salesforce cases, streamlining administrative tasks. Administrators can deploy and configure this integrated contact center solution in minutes, leveraging Amazon Connect's voice, digital channels, and intelligent routing capabilities.\n  This feature is available in all AWS Regions where Amazon Connect is available. To learn more and get started, see the Salesforce Contact Center with Amazon Connect documentation. To learn more about Amazon Connect, see Amazon Connect and our strategic Salesforce partnership",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-ai-agent-assistance-summarization-agentforce-service",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-3aca50927ed4",
      "title": "Amazon Connect now provides improved analytics and monitoring for AI agents",
      "description": "Amazon Connect now provides analytics and monitoring capabilities for AI agents across self-service and agent assistance experiences. With this launch, you can measure and continuously improve AI agent performance and customer outcomes through easy to customize dashboards that provide key metrics like number of AI agent led interactions, hand-off rates, conversation turns, and average handle time. You can also compare AI agent performance across versions to identify optimal configurations and review insights to understand where AI agents are performing well and where improvements are needed. Additionally, with this launch, you can configure rules to trigger automated actions, such as sending alerts when self-service contacts are transferred to human agents with low sentiment scores. Amazon Connect also provides AI agent traces via APIs with detailed information such as request and response payloads and tool invocations, enabling you to easily understand AI agent actions and decision-making for faster troubleshooting.\n  This capabilities is available in all AWS Regions where Amazon Connect AI agents are offered. To learn more about AI agent analytics, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS contact center as a service solution on the cloud, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-improved-analytics-monitoring-ai-agents",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "launch",
        "improvement"
      ]
    },
    {
      "id": "aws-news-97b700bfdba5",
      "title": "Amazon Connect adds support for third-party speech-to-text and text-to-speech AI models for end-customer self-service",
      "description": "Amazon Connect now supports third-party speech providers for end-customer self-service, giving you greater flexibility in how you deliver voice experiences. You can integrate Deepgram for speech-to-text and ElevenLabs for text-to-speech directly within Amazon Connect, using them together with Amazon Connect's native speech capabilities, built-in orchestration, analytics, and compliance controls.\n  This feature is available with Amazon Connect unlimited AI and in all commercial AWS regions where Amazon Connect is offered. For more information, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-third-party-speech-to-text-to-speech-ai-models",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-6ac1157bb35b",
      "title": "Amazon Connect Chat now supports agent-initiated workflows",
      "description": "Amazon Connect now supports agent-initiated workflows, enabling agents to send interactive forms to collect sensitive data or share general policies and disclosures within customer chat conversations, increasing efficiency and improving customer experience. For example, when a customer needs to update their address, agents can now send a form that customers complete without leaving the chat interface.\n  Agents can trigger these workflows at any point during a chat conversation, making interactions more dynamic and responsive to customer needs. By handling everything within the ongoing chat conversation, businesses can maintain security and compliance standards while helping customers get faster solutions.\n  These new agent capabilities are now available in the following regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (London), and Africa (Cape Town). To learn more, visit the Amazon Connect documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-chat-agent-initiated-workflows",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-7b34b11c940a",
      "title": "Amazon Connect agent workspace now supports custom visual themes",
      "description": "Amazon Connect now allows you to customize the visual appearance of the agent workspace. You can apply a custom theme, including a logo, font, and color palette for light and dark modes, so the agent workspace aligns with the brand identity of your company or business unit.\n  Contact center agents spend hours each day in the Amazon Connect agent workspace, which provides them with all of the customer information, applications, and step-by-step guidance they need to deliver superior customer experiences. With today’s launch, organizations can change the default Amazon Connect theme to their own branded experience, creating a more familiar and intuitive experience for agents who use the agent workspace and other company applications. The agent workspace also has a new header bar where agents can easily access their settings, including their preference of light and dark mode, contributing to greater agent satisfaction and efficiency.\n  The Amazon Connect agent workspace is available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Africa (Cape Town), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (London), and AWS GovCloud (US-West).\n  To learn more and get started, see the administrator guide and developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-agent-workspace-custom-visual-themes",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-40738846eef5",
      "title": "Amazon Connect launches AI-powered predictive insights (Preview)",
      "description": "Today, Amazon Connect is launching AI-powered predictive insights that transform how businesses understand and serve their customers. This new feature set builds upon Connect's existing customer profiles, introducing five recommendation algorithms that leverage AI to analyze customer behavior patterns and interaction history. These AI-powered insights are available for both self-service and agent interactions, enabling businesses to transform all customer touchpoints – from suggesting complementary products during service calls to providing smart product discovery through intelligent chat experiences by leveraging their existing customer data within Connect Customer Profiles. Businesses can also leverage these AI-powered insights to build their Connect AI agent for specialized for sales.\n  The five recommendation algorithms are as follows: \"Recommended for You\" provides tailored suggestions based on individual user interactions patterns with any catalog; \"Similar Items\" uses generative AI to suggest alternative products or services; \"Frequently Paired Items\" powers cross-selling by identifying complementary product or service combinations, \"Popular Items\" surfaces top-performing product recommendations, and \"Trending Now\" captures real-time customer interest for timely engagement.\n  With Amazon Connect Customer Profiles, you only pay-as-you-go for utilized profiles. Public preview for AI-powered predictive insights is available in Europe (Frankfurt), US East (N. Virginia), Asia Pacific (Seoul), Asia Pacific (Tokyo), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central).\n  To learn more, visit our webpages for Customer Profiles.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-ai-powered-predictive-insights-preview",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "preview",
        "ga",
        "new-feature",
        "public-preview"
      ]
    },
    {
      "id": "aws-news-5e9a04ebec70",
      "title": "Amazon Connect now simplifies linking related contacts to cases using flows",
      "description": "Amazon Connect now makes it easier to link related contacts such as email replies, call transfers, persistent chats, and queued callbacks to the same case so agents can view the complete customer journey and resolve issues faster. You can use flows to link a follow-up contact to an existing case, eliminating the need for custom logic or manual linking.\n  Amazon Connect Cases is available in the following AWS regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town) AWS regions. To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-simplifies-linking-related-contacts-cases-using-flows",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-396183336a16",
      "title": "Amazon Connect enhances its agent assistance capabilities",
      "description": "Amazon Connect now provides customer service representatives with new AI agents that guide them through customer interactions by recommending actions, retrieving information, and executing tasks on their behalf. For example, an AI agent can guide a representative through processing a product return by automatically pulling order history, calculating refund amounts, and initiating the return process. These AI agents analyze conversation context and customer sentiment in real-time, actively completing tasks such as preparing documentation and handling routine processes. This enables representatives to focus on building customer relationships and handling complex situations while AI manages the background work, enhancing productivity and ensuring consistent outcomes. You can get started with out-of-the-box agents provided by Amazon Connect or easily customize AI agent behavior and actions to align with your business needs.\n  To learn more about Amazon Connect AI agents, please visit the website or see the help documentation. For region availability, please see the availability of Amazon Connect features by Region. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-enhances-agent-assistance-capabilities",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-32bed17198ba",
      "title": "Amazon Connect now provides AI-powered case summaries",
      "description": "Amazon Connect now provides AI-powered case summaries that give agents complete context into customer issues, reduce manual wrap-up work, and help resolve cases faster. With a single click, agents can generate a concise case summary even when the case spans multiple interactions, follow-up tasks, and teams, capturing key details such as issue background, actions taken, and next steps. Administrators can configure custom prompts and guardrails to ensure that summaries align with organizational style and preferences.\n  Amazon Connect Cases is available in the following AWS regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town) AWS regions. To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-ai-powered-case-summaries",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-dbcd91a33051",
      "title": "Amazon Connect now supports multiple knowledge bases and integrates with your Amazon Bedrock Knowledge Bases",
      "description": "Amazon Connect now allows you to bring your own Amazon Bedrock Knowledge Bases and supports multiple knowledge bases per AI agent, giving you greater flexibility in how you organize and access knowledge content for your AI agents. You can now connect your existing Bedrock Knowledge Bases directly to Amazon Connect AI agents in just a few clicks, with no additional setup or data duplication required. This allows you to leverage your current data sources and the Amazon Bedrock Knowledge Base connectors, including Adobe Experience Manager, Confluence, SharePoint, and OneDrive, giving you flexibility to use existing content repositories.\n  With support for multiple knowledge bases per AI agent, you can configure AI agents to query multiple sources in parallel for more comprehensive responses. For example, a financial services company can easily connect separate knowledge bases for compliance documentation, product information, and internal policies, enabling AI agents to provide complete guidance across all relevant content during customer interactions.\n  This feature is available in all AWS Regions where Amazon Connect AI agents and Amazon Bedrock Knowledge Bases are offered. To learn more about these features, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS cloud-based contact center, and Amazon Connect AI agents please visit the Amazon Connect Website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-multiple-knowledge-bases-integrates-amazon-bedrock-knowledge-bases",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f0a59fe884c8",
      "title": "Amazon Connect Outbound Campaigns now supports multi-step, multi-channel customer engagement journey builder",
      "description": "Amazon Connect Outbound Campaigns now supports visual journey builder, a new feature that lets you create multi-step, multi-channel customer engagements directly in the Amazon Connect console. You can design end-to-end engagement experiences that combine voice, SMS, email, and WhatsApp interactions to reach customers proactively and reduce inbound contact volume.\n  Outbound Campaigns help you automate personalized communication flows based on customer behavior or time-based triggers. For example, you can send an appointment reminder by SMS, follow up with a voice call if the customer does not respond, and send a confirmation email once the appointment is booked. You can also configure steps in the journey builder that offer customers the option to connect with a live agent through Amazon Connect when additional support is needed. You can use existing Amazon Connect Flow integrations, AI capabilities, and customer data from Amazon Connect Customer Profiles to tailor each interaction. This helps contact centers improve engagement rates, reduce manual effort, and deliver more consistent customer experiences.\n  This feature is available in all AWS Regions where Amazon Connect Outbound Campaigns is supported. To learn more, visit the Amazon Connect Outbound Campaigns documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/connect-outbound-multi-step-multi-channel-builder/",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize",
        "ga",
        "new-feature",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-2650c3263efd",
      "title": "Amazon Connect introduces agentic self-service with more natural, expressive, and adaptive voice interactions",
      "description": "Amazon Connect is introducing agentic self-service capabilities that enable AI agents to understand, reason, and take action across voice and messaging channels to automate routine and complex customer service tasks. Connect enables you to blend deterministic and agentic experiences, allowing you to deploy these AI agents at scale, reliably and safely. With integration with advanced speech models from Amazon Nova Sonic, voice self-service experiences now deliver more natural and adaptive interactions. Connect's self-service voice AI agents understand not only what customers say but how they say it, adapting voice responses to match customer tone and sentiment while maintaining natural conversational pace across multiple languages and accents. For example, when a customer calls about an order issue, your AI agent can greet them by name, ask clarifying questions, look up their order status, and process a refund, with voice interactions that adapt to the customer's tone and respond expressively throughout the conversation. This enables your contact center to automate complex troubleshooting, account management, and consultative interactions while maintaining the ability to escalate to a live representative at any point.\n  Nova Sonic support with Amazon Connect is available in two commercial AWS Regions: US East (N. Virginia) and US West (Oregon) and fully available in English and Spanish and in preview for French, Italian, and German. To learn more about this feature see the Amazon Connect Administrator Guide and Amazon Connect pricing page. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-agentic-self-service",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "lex",
        "preview",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-2bf695171597",
      "title": "Amazon Connect now supports creation of custom metrics for use in dashboards and APIs",
      "description": "Amazon Connect now supports creation of custom metrics, enabling contact center supervisors to analyze tailored performance measurements without requiring technical skills. This feature provides a simple, no-code interface for performing mathematical operations (e.g., addition, subtraction, sum, average) on existing Connect data to build metrics that align with your organization's specific business requirements. Custom metrics are available to use in the dashboards and APIs.\n  With custom metrics, you can track performance in ways that matter most to your business. For example, create average handle time metrics for premium versus standard customer segments, calculate total agent time on outbound calls by product line, or measure queue performance filtered by contact type such as callbacks versus incoming calls.\n This new feature is available in all AWS regions where Amazon Connect is offered. To learn more about Amazon Connect custom metrics, see the Administrator Guide. To learn more about Amazon Connect, see the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-metric-customization/",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-5eec8e966a0f",
      "title": "Amazon Connect Chat now supports in-flight data redaction and message processing",
      "description": "Amazon Connect now supports message processing that intercepts and processes chat messages before they reach any participant. This new capability enables automatic redaction of sensitive data and custom message processing, helping businesses maintain compliance and security standards while delivering personalized customer experiences.\n  The built-in sensitive data redaction can automatically detect and remove sensitive information like credit card numbers and social security numbers across multiple languages, including English, French, Portuguese, German, Italian, and Spanish variants. You can choose to redact selected or all sensitive data entities, with options to replace them with generic or entity-specific placeholders (e.g., [PII] or [NAME]). Businesses can also integrate custom processors for use cases such as language translation or profanity filtering, ensuring compliant and effective communications for their specific business needs.\n  These message processing capabilities are now available in the following regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt) Europe (London), Africa (South Africa). To learn more about Amazon Connect, visit the Amazon Connect documentation and pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-chat-in-flight-data-redaction-message-processing",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "personalize",
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "personalize",
        "rds",
        "ga",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-1b32fbad45c0",
      "title": "Amazon Connect now streams messages for AI-powered interactions",
      "description": "Amazon Connect now supports message streaming for AI-powered chat interactions. This new capability shows Connect AI agent responses as they're being generated, which reduces perceived wait times and improves the customer experience.\n  When using Amazon Connect AI agents, customers see status updates like \"One moment while I review your account\" during processing, and watch responses appear progressively. This experience gives customers confidence their request is actively being worked on while AI agents reason, invoke tools, and craft comprehensive solutions.\n  Message streaming for AI-powered interactions is now available in the following regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (London) and Africa (Cape Town). To learn more, visit the Amazon Connect documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-streams-messages-ai-powered-interactions",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "now-available",
        "update",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-dfbfc3dccf33",
      "title": "Announcing Amazon EKS Capabilities",
      "description": "Amazon Elastic Kubernetes Service (EKS) announces the general availability of EKS Capabilities, a fully-managed extensible set of Kubernetes-native platform features for workload deployment, AWS cloud resource management, and Kubernetes resource composition and orchestration. EKS Capabilities provides out-of-the-box platform features and offloads operations to AWS, improving the performance and security of your platform components.\n  EKS Capabilities streamlines building and scaling with Kubernetes, allowing you to focus on deploying applications rather than maintaining platform infrastructure. These capabilities run in AWS-owned infrastructure separate from your clusters, with AWS handling auto scaling, patching, and upgrading. Application developers get ready-to-use platform capabilities that enable faster workload deployment and scaling across the organization, while platform teams can offload operational tasks to AWS. Three capabilities are available at launch including continuous deployment with Argo CD, AWS resource management through AWS Controllers for Kubernetes (ACK), and dynamic resource orchestration using Kube Resource Orchestrator (KRO).\n  EKS Capabilities is available today in all AWS Regions, except AWS GovCloud (US) and China Regions. To get started with EKS Capabilities, use the EKS API, CLI, eksctl, AWS Console, or your favorite infrastructure as code tooling to enable it in a new or existing EKS cluster. To learn more, visit the EKS Capabilities feature webpage, user guide, pricing webpage, and AWS News Launch blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-capabilities",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-441875790df9",
      "title": "AWS expands AI Competency with new Agentic AI categories",
      "description": "AWS announces a major expansion of the AI Competency (formerly Generative AI Competency) in the largest Specialization launch to date including 60 validated partners across three new Agentic AI categories: Agentic AI Tools, Agentic AI Applications, and Agentic AI Consulting Services. These categories help customers identify and work with AWS Partners who specialize in developing and implementing autonomous AI systems that can perceive, reason, and act with minimal human oversight. To streamline the partner validation process, AWS today launched an AI agent in AWS Partner Central that provides partners with immediate feedback on their AI Specialization applications, significantly accelerating the path to competency attainment.\n  As organizations move beyond AI experimentation toward production-ready autonomous systems, they need partners with proven expertise in deploying AI agents that can orchestrate complex workflows, maintain contextual awareness, and collaborate across multiple platforms. The new Agentic AI categories validate partners who can deliver sophisticated solutions and offerings using Amazon Bedrock AgentCore, Strands Agents, Amazon SageMaker AI, and other AWS AI services while maintaining strong commitments to responsible AI development, governance, and monitoring.\n  AWS Partners in these categories undergo rigorous technical validation and must demonstrate successful customer implementations that meet AWS's high standards for security, reliability, and operational excellence. These validated partners are uniquely positioned to help customers deploy production-grade autonomous AI systems that drive real business value.\n  Apply to the AWS AI Competency on Partner Central and learn more about the AWS AI Competency through our APN Blog and explore validated partners in the new Agentic AI categories.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-ai-competency-agentic-ai-categories",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "sagemaker",
        "lex",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "sagemaker",
        "lex",
        "rds",
        "organizations",
        "launch",
        "ga",
        "expansion"
      ]
    },
    {
      "id": "aws-news-cded7962e9c6",
      "title": "AWS Partner Central is now available in the AWS Management Console",
      "description": "Today, AWS announces the availability of AWS Partner Central in the AWS Management Console, simplifying access for AWS Partners to Partner Central and the AWS Marketplace Management Portal, and introducing APIs that offer integration and process automation capabilities.\n  The integration of AWS Partner Central into the AWS Console delivers an enhanced experience and new capabilities for Partners. With an expanded set of APIs, partners can automate co-selling processes, streamline AWS Marketplace activities, and unlock AWS Partner Network benefits more seamlessly. Enhanced security and user management features, built on AWS Identity and Access Management (IAM), allow for granular permissions and single sign-on (SSO), improving operational efficiency and scalability.\n  AWS Partner Central in the console is available for AWS Partners today. This new experience is available in all AWS Regions, providing Partners with a consistent and secure way to manage their AWS business across the globe. Existing Partners can begin their migration to the new experience using the migration feature in the existing Partner Central portal, which provides step-by-step guidance for migrating to the AWS Console. To learn more about the new AWS Partner Central experience and how to get started, read the blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-partner-central-available-management-console",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "iam",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-144bd9fb3a39",
      "title": "Amazon SageMaker Catalog provides automatic data classification using AI agents",
      "description": "Amazon SageMaker Catalog now provides automated data classification that suggests business glossary terms during data publishing, reducing manual tagging effort and improving metadata consistency across organizations.\n  This capability analyzes table metadata and schema information using Amazon Bedrock's language models to recommend relevant terms from organizational business glossaries. Data producers receive AI-generated suggestions for business terms defined within their glossaries, which include both functional terms and sensitive data classifications such as PII and PHI, making it easy to tag their datasets with standardized vocabulary. Producers can accept or modify these suggestions before publishing, ensuring consistent terminology across data assets and improving data discoverability for business users.\n  Automated data classification is available in US East (N. Virginia, Ohio), US West (Oregon), Asia Pacific (Tokyo, Seoul, Singapore, Sydney, Mumbai), and Europe (Frankfurt, Ireland, London, Paris) AWS regions where Amazon\n SageMaker operates.\n  To get started, go to SageMaker Unified Studio to configure your business glossary to generate recommendations for business glossary terms. You can also use the AWS CLI or SDKs to programmatically manage glossary term suggestions.\n For more information, see the SageMaker Catalog user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-catalog-automatic-data-classification-ai-agents",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "sagemaker",
        "unified studio",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "unified studio",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-c803298e7651",
      "title": "AWS Clean Rooms supports synthetic dataset generation training custom ML training",
      "description": "AWS Clean Rooms now enables you and your partners to generate privacy-enhancing synthetic datasets from your collective data to train regression and classification machine learning (ML) models.\n \nSynthetic dataset generation allows you and your partners to create training datasets with similar statistical properties to the original data, without the training code having access to real records. This new capability de-identifies subjects—such as people or entities about whom data has been collected—in the original data, mitigating the risk that a model will memorize information about individuals in the training data. This unlocks new ML model training use cases that were previously restricted by privacy concerns, such as campaign optimization, fraud detection, and medical research. For example, an airline with a proprietary algorithm wants to collaborate with a hotel brand to offer joint promotions to high-value customers, but neither organization wants to share sensitive consumer data. Using AWS Clean Rooms ML, they can generate a synthetic version of their collective dataset to train the model without exposing raw data—enabling more accurate promotions targeting while protecting customer privacy.\n \nFor more information about the AWS Regions where AWS Clean Rooms ML is available, see the AWS Regions table. To learn more, visit AWS Clean Rooms ML.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-clean-rooms-synthetic-dataset-generation-custom-ml",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "rds",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-81bf5f175758",
      "title": "Announcing AWS Lambda Managed Instances, a capability to run functions on your Amazon EC2 instances",
      "description": "AWS Lambda Managed Instances lets you run Lambda functions on your Amazon EC2 instances while maintaining Lambda's operational simplicity. With Lambda Managed Instances, you can access specialized compute configurations and drive cost efficiency through EC2 pricing advantages, without managing infrastructure.\n  Lambda Managed Instances fully manages all infrastructure tasks, including instance lifecycle, OS and runtime patching, built-in routing, load balancing, and auto-scaling based on configurable parameters - so you can focus on writing code. This operational simplicity extends to the extensive EC2 instance catalog, giving you access to the latest-generation processors like AWS Graviton4 and high-bandwidth networking options. You can process parallel requests within each execution environment, maximizing resource utilization and improving price-performance.\n  Lambda Managed Instances is ideal for customers requiring specialized hardware configurations, as well as those with steady-state or predictable workloads seeking to optimize costs while maintaining Lambda's serverless experience. You can further improve costs by leveraging EC2 pricing models including Compute Savings Plans and Reserved Instances.\n  Getting started is straightforward - you can continue building functions with familiar development workflows, including Console and your preferred IDEs. First, create a capacity provider that defines your compute preferences, including VPC configuration, optional instance requirements and scaling policies. Then, attach your Lambda functions to the capacity provider via the AWS Lambda Console, APIs, or Infrastructure as Code tooling. Lambda Managed Instances integrates seamlessly with all Lambda event sources and tools like Amazon CloudWatch, AWS X-Ray and AWS Config. Latest versions of Java, Node.js, Python and .NET runtimes are supported.\n  Lambda Managed Instances is now available in the US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Tokyo), and Europe (Ireland) Regions. To learn more, visit the launch blog and AWS Lambda Managed Instances documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-lambda-managed-instances",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "ec2",
        "cloudwatch",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "ec2",
        "cloudwatch",
        "graviton",
        "launch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-965f83c97bb6",
      "title": "Introducing Amazon Route 53 Global Resolver for secure anycast DNS resolution (preview)",
      "description": "Today, AWS announced the preview of Amazon Route 53 Global Resolver, a new internet-reachable DNS resolver that provides easy, secure, and reliable DNS resolution from anywhere for queries made by your authorized clients.\n  With Global Resolver, authorized clients in your organization can achieve split DNS resolution by resolving public domains on the internet and private domains associated with Route 53 private hosted zones, from anywhere. Global Resolver also allows you to create rules that protects your clients from DNS-based data exfiltration attacks. Using DNS Firewall rules for Global Resolver, you can filter queries for domains based on threat categories (e.g. Malware, Spam), web-content (e.g. Adult and Mature Content, Gambling), or advanced DNS threats (DNS tunneling, Domain Generation Algorithms), and log all queries centrally for easy auditing. Global Resolver enables you to achieve high availability of DNS resolution for your clients, by allowing you to select two or more regions for anycast DNS resolution with automatic failover to the closest available region.\n  With the launch of Global Resolver, we are renaming Route 53 Resolver to Route 53 VPC Resolver, to help clarify the distinction between the two services. Route 53 VPC Resolver allows you to resolve DNS queries from AWS resources in your Amazon VPCs for public domain names, VPC-specific DNS names, and Amazon Route 53 private hosted zones, and is available by default in each VPC. You can also associate Resolver endpoints with the VPC Resolver to forward DNS queries between your on-premises and Amazon VPCs.\n  Visit the service page for Global Resolver pricing and feature details. During the preview, Global Resolver will be available at no additional cost. For more information about AWS Regions where Global Resolver is available during preview, see here. To get started with a step-by-step walkthrough, see the AWS News Blog or documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-route-53-global-resolver-secure-anycast-dns-resolution-preview",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-a2412e35ffb9",
      "title": "Amazon CloudWatch incident reports now support Five Whys analysis",
      "description": "Amazon CloudWatch launched incident report generation capabilities with an AI-powered root-cause workflow that guides customers through the \"Five Why’s\" analysis technique. The feature is modeled on the correction or errors process used by both teams within Amazon and our customers to improve their operations.\n  The incident report generation capability now supports a guided, chat-based workflow powered by Amazon Q that walks customers through identifying the “Five Why’s” behind an incident. Teams can use this process to help identify the underlying root causes behind an incident. The capability leverages both human input and AI-based analysis of incident data to recommends specific measures operators can take to prevent future occurrences and improve their operations.\n  The incident report generation feature is available at no additional cost for CloudWatch customers and is available in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), Europe (Spain), and Europe (Stockholm).\n  You can create an incident report by first creating a CloudWatch investigation and then clicking “Incident report”. To initiate the Five Whys workflow, scroll down to the “Five Why’s” section of your report and select “Guide Me”. To learn more, visit the CloudWatch incident reports documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-incident-reports-five-whys-analysis",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "cloudwatch",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-0cb204fe91c9",
      "title": "Introducing multi-product solutions in AWS Marketplace",
      "description": "AWS Marketplace now supports solution-centric procurement with multi-product solutions — a combination of products and services from one or more AWS Partners tailored to specific industries and customer use cases. Partners can now implement their vertical expertise and solution-selling strategies in AWS Marketplace. This new capability allows customers to discover and purchase complete solutions through a seamless procurement process.\n  Partners, from Independent Software Vendors (ISVs) to System Integrators, can now sell comprehensive solutions in AWS Marketplace by combining their own software and services with products they are authorized to resell from other AWS Partners. Each component maintains distinct pricing and terms, giving partners and customers flexibility in how they structure the sale. Partners can position solutions to their target audience by outlining use cases and explaining how components work together. Customers benefit from streamlined procurement with a single point of contact for negotiation, total cost assessment, and one-time approval covering all products. After purchase, customers have the flexibility to independently manage renewals and term lengths for each component, making this approach valuable for organizations addressing complex use cases that require multiple products and services.\n  This new capability is available in all AWS Regions where AWS Marketplace operates, supporting SaaS, Server, AI Agents and Tools, Machine Learning, and Professional Services product types.\n  To learn more about solution-centric procurement in AWS Marketplace, review this blog. Partners can start listing multi-product solutions through AWS Partner Central after reviewing the seller documentation. Customers can explore multi-product solutions in AWS Marketplace.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/introducing-multi-product-solutions-aws-marketplace",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-0a3b5ec43912",
      "title": "AWS Marketplace introduces agent mode and AI-enhanced search to accelerate solution discovery",
      "description": "AWS Marketplace introduces two new AI-powered capabilities, agent mode and enhanced search, to accelerate solution discovery across over 30,000 listings. These capabilities reflect the shift to solution-centric procurement in AWS Marketplace, helping you more quickly discover and evaluate solutions to your business challenges.\n  Agent mode, a conversational discovery experience that’s purpose-built for software procurement, helps you reach informed purchasing decisions fast. Describe your use case, upload business requirements documentation, and discover solutions that match your needs. Through interactive dialogue, you can ask questions and explore product insights drawn from AWS data, security and compliance records, verified vendor information, and real-time web intelligence. Agent mode accelerates your evaluation with dynamic side-by-side comparisons personalized to your requirements that can be customized with natural language. Once you’re ready to buy, you can initiate a purchase or create a downloadable detailed purchasing proposal to share with your internal stakeholders for approvals. You can also get the same tailored discovery experience on your preferred AI application through an integration with the AWS Marketplace MCP server.\n  AI-enhanced search helps you find the right the solutions fast and start evaluating your options on product pages or in agent mode. You can describe your needs and receive relevant solution results with AI-generated summaries to better understand your options and key consideration factors. New smart categories dynamically adapt to your specific search, helping you narrow down results with tailored topics. With the AWS Specializations badge added to search results, you can easily identify technically validated Partners across industries, use cases, and services.\n  To start discovering products, visit the AWS Marketplace website to use AI-enhanced search and agent mode. To learn more about Marketplace MCP, visit the MCP server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-marketplace-agent-mode-ai-enhanced-search",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "personalize",
        "rds"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize",
        "rds",
        "integration"
      ]
    },
    {
      "id": "aws-news-24cd991522e9",
      "title": "Apache Spark encryption performance improvement with Amazon EMR 7.9",
      "description": "In this post, we analyze the results from our benchmark tests comparing the Amazon EMR 7.9 optimized Spark runtime against Spark 3.5.5 without encryption optimizations. We walk through a detailed cost analysis and provide step-by-step instructions to reproduce the benchmark.",
      "link": "https://aws.amazon.com/blogs/big-data/apache-spark-encryption-performance-improvement-with-amazon-emr-7-9/",
      "pubDate": "2025-11-27T01:37:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-61dc3e3d79bd",
      "title": "Run Apache Spark and Apache Iceberg write jobs 2x faster with Amazon EMR",
      "description": "In this post, we demonstrate the write performance benefits of using the Amazon EMR 7.12 runtime for Spark and Iceberg compares to open source Spark 3.5.6 with Iceberg 1.10.0 tables on a 3TB merge workload.",
      "link": "https://aws.amazon.com/blogs/big-data/run-apache-spark-and-apache-iceberg-write-jobs-2x-faster-with-amazon-emr/",
      "pubDate": "2025-11-27T01:03:08.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-70a75d3e1cfa",
      "title": "Medidata’s journey to a modern lakehouse architecture on AWS",
      "description": "In this post, we show you how Medidata created a unified, scalable, real-time data platform that serves thousands of clinical trials worldwide with AWS services, Apache Iceberg, and a modern lakehouse architecture.",
      "link": "https://aws.amazon.com/blogs/big-data/medidatas-journey-to-a-modern-lakehouse-architecture-on-aws/",
      "pubDate": "2025-11-27T01:00:46.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": []
    },
    {
      "id": "aws-news-f3f2eea0b334",
      "title": "How Myriad Genetics achieved fast, accurate, and cost-efficient document processing using the AWS open-source Generative AI Intelligent Document Processing Accelerator",
      "description": "In this post, we explore how Myriad Genetics partnered with the AWS Generative AI Innovation Center to transform their healthcare document processing pipeline using Amazon Bedrock and Amazon Nova foundation models, achieving 98% classification accuracy while reducing costs by 77% and processing time by 80%. We detail the technical implementation using AWS's open-source GenAI Intelligent Document Processing Accelerator, the optimization strategies for document classification and key information extraction, and the measurable business impact on Myriad's prior authorization workflows.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-myriad-genetics-achieved-fast-accurate-and-cost-efficient-document-processing-using-the-aws-open-source-generative-ai-intelligent-document-processing-accelerator/",
      "pubDate": "2025-11-27T00:58:14.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-587d9a94208c",
      "title": "How CBRE powers unified property management search and digital assistant using Amazon Bedrock",
      "description": "In this post, CBRE and AWS demonstrate how they transformed property management by building a unified search and digital assistant using Amazon Bedrock, enabling professionals to access millions of documents and multiple databases through natural language queries. The solution combines Amazon Nova Pro for SQL generation and Claude Haiku for document interactions, achieving a 67% reduction in processing time while maintaining enterprise-grade security across more than eight million documents.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-cbre-powers-unified-property-management-search-and-digital-assistant-using-amazon-bedrock/",
      "pubDate": "2025-11-27T00:56:27.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-e771ae5d8453",
      "title": "Managed Tiered KV Cache and Intelligent Routing for Amazon SageMaker HyperPod",
      "description": "In this post, we introduce Managed Tiered KV Cache and Intelligent Routing for Amazon SageMaker HyperPod, new capabilities that can reduce time to first token by up to 40% and lower compute costs by up to 25% for long context prompts and multi-turn conversations. These features automatically manage distributed KV caching infrastructure and intelligent request routing, making it easier to deploy production-scale LLM inference workloads with enterprise-grade performance while significantly reducing operational overhead.",
      "link": "https://aws.amazon.com/blogs/machine-learning/managed-tiered-kv-cache-and-intelligent-routing-for-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-11-27T00:50:04.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-2bf53cc475cb",
      "title": "Apply fine-grained access control with Bedrock AgentCore Gateway interceptors",
      "description": "We are launching a new feature: gateway interceptors for Amazon Bedrock AgentCore Gateway. This powerful new capability provides fine-grained security, dynamic access control, and flexible schema management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/apply-fine-grained-access-control-with-bedrock-agentcore-gateway-interceptors/",
      "pubDate": "2025-11-26T22:28:29.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "launch",
        "ga",
        "new-feature",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-214f1f935f59",
      "title": "Achieve 2x faster data lake query performance with Apache Iceberg on Amazon Redshift",
      "description": "In 2025, Amazon Redshift delivered several performance optimizations that improved query performance over twofold for Iceberg workloads on Amazon Redshift Serverless, delivering exceptional performance and cost-effectiveness for your data lake workloads. In this post, we describe some of the optimizations that led to these performance gains.",
      "link": "https://aws.amazon.com/blogs/big-data/achieve-2x-faster-data-lake-query-performance-with-apache-iceberg-on-amazon-redshift/",
      "pubDate": "2025-11-26T22:16:15.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "redshift",
        "ga"
      ]
    },
    {
      "id": "aws-news-a9adcc780d04",
      "title": "Introducing catalog federation for Apache Iceberg tables in the AWS Glue Data Catalog",
      "description": "AWS Glue now supports catalog federation for remote Iceberg tables in the Data Catalog. With catalog federation, you can query remote Iceberg tables, stored in Amazon S3 and cataloged in remote Iceberg catalogs, using AWS analytics engines and without moving or duplicating tables. In this post, we discuss how to get started with catalog federation for Iceberg tables in the Data Catalog.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-catalog-federation-for-apache-iceberg-tables-in-the-aws-glue-data-catalog/",
      "pubDate": "2025-11-26T22:08:07.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "glue"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "glue",
        "support"
      ]
    },
    {
      "id": "aws-news-4a3aca511605",
      "title": "Accelerate data lake operations with Apache Iceberg V3 deletion vectors and row lineage",
      "description": "In this post, we walk you through the new capabilities in Iceberg V3, explain how deletion vectors and row lineage address these challenges, explore real-world use cases across industries, and provide practical guidance on implementing Iceberg V3 features across AWS analytics, catalog, and storage services.",
      "link": "https://aws.amazon.com/blogs/big-data/accelerate-data-lake-operations-with-apache-iceberg-v3-deletion-vectors-and-row-lineage/",
      "pubDate": "2025-11-26T22:05:47.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-0dbe89f3f79b",
      "title": "Orchestrating large-scale document processing with AWS Step Functions and Amazon Bedrock batch inference",
      "description": "Organizations often have large volumes of documents containing valuable information that remains locked away and unsearchable. This solution addresses the need for a \nscalable, automated text extraction and knowledge base pipeline that transforms static document collections into intelligent, searchable repositories for generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-large-scale-document-processing-with-aws-step-functions-and-amazon-bedrock-batch-inference/",
      "pubDate": "2025-11-26T21:41:51.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock",
        "step functions",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "step functions",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-0445b6b72acd",
      "title": "How Condé Nast accelerated contract processing and rights analysis with Amazon Bedrock",
      "description": "In this post, we explore how Condé Nast used Amazon Bedrock and Anthropic’s Claude to accelerate their contract processing and rights analysis workstreams. The company’s extensive portfolio, spanning multiple brands and geographies, required managing an increasingly complex web of contracts, rights, and licensing agreements.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-conde-nast-accelerated-contract-processing-and-rights-analysis-with-amazon-bedrock/",
      "pubDate": "2025-11-26T21:37:27.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex"
      ]
    },
    {
      "id": "aws-news-f2f20ca0e88d",
      "title": "Building AI-Powered Voice Applications: Amazon Nova Sonic Telephony Integration Guide",
      "description": "Available through the Amazon Bedrock bidirectional streaming API, Amazon Nova Sonic can connect to your business data and external tools and can be integrated directly with telephony systems. This post will introduce sample implementations for the most common telephony scenarios.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-ai-powered-voice-applications-amazon-nova-sonic-telephony-integration-guide/",
      "pubDate": "2025-11-26T21:21:54.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "integration"
      ]
    },
    {
      "id": "aws-news-617c09bb9eb6",
      "title": "University of California Los Angeles delivers an immersive theater experience with AWS generative AI services",
      "description": "In this post, we will walk through the performance constraints and design choices by OARC and REMAP teams at UCLA, including how AWS serverless infrastructure, AWS Managed Services, and generative AI services supported the rapid design and deployment of our solution. We will also describe our use of Amazon SageMaker AI and how it can be used reliably in immersive live experiences.",
      "link": "https://aws.amazon.com/blogs/machine-learning/university-of-california-los-angeles-delivers-an-immersive-theater-experience-with-aws-generative-ai-services/",
      "pubDate": "2025-11-26T21:20:45.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-61c6bc9ae82a",
      "title": "Optimizing Mobileye’s REM™ with AWS Graviton: A focus on ML inference and Triton integration",
      "description": "In this post, we focus on one portion of the REM™ system: the automatic identification of changes to the road structure which we will refer to as Change Detection. We will share our journey of architecting and deploying a solution for Change Detection, the core of which is a deep learning model called CDNet. We will share real-life decisions and tradeoffs when building and deploying a high-scale, highly parallelized algorithmic pipeline based on a Deep Learning (DL) model, with an emphasis on efficiency and throughput.",
      "link": "https://aws.amazon.com/blogs/machine-learning/optimizing-mobileyes-rem-with-aws-graviton-a-focus-on-ml-inference-and-triton-integration/",
      "pubDate": "2025-11-26T19:50:03.000Z",
      "source": "mlBlog",
      "services": [
        "graviton"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "graviton",
        "integration"
      ]
    },
    {
      "id": "aws-news-b38de7bae141",
      "title": "Evaluate models with the Amazon Nova evaluation container using Amazon SageMaker AI",
      "description": "This blog post introduces the new Amazon Nova model evaluation features in Amazon SageMaker AI. This release adds custom metrics support, LLM-based preference testing, log probability capture, metadata analysis, and multi-node scaling for large evaluations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/evaluate-models-with-the-amazon-nova-evaluation-container-using-amazon-sagemaker-ai/",
      "pubDate": "2025-11-26T19:39:01.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-8df2ee2ec34f",
      "title": "Getting started with Apache Iceberg write support in Amazon Redshift",
      "description": "In this post, we show how you can use Amazon Redshift to write data directly to Apache Iceberg tables stored in Amazon S3 and S3 Tables for seamless integration between your data warehouse and data lake while maintaining ACID compliance.",
      "link": "https://aws.amazon.com/blogs/big-data/getting-started-with-apache-iceberg-write-support-in-amazon-redshift/",
      "pubDate": "2025-11-26T19:34:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "s3",
        "redshift",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-01131f60b90b",
      "title": "Beyond the technology: Workforce changes for AI",
      "description": "In this post, we explore three essential strategies for successfully integrating AI into your organization: addressing organizational debt before it compounds, embracing distributed decision-making through the \"octopus organization\" model, and redefining management roles to align with AI-powered workflows. Organizations must invest in both technology and workforce preparation, focusing on streamlining processes, empowering teams with autonomous decision-making within defined parameters, and evolving each management layer from traditional oversight to mentorship, quality assurance, and strategic vision-setting.",
      "link": "https://aws.amazon.com/blogs/machine-learning/beyond-the-technology-workforce-changes-for-ai/",
      "pubDate": "2025-11-26T18:42:45.000Z",
      "source": "mlBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-5de16f9b057e",
      "title": "Enhanced performance for Amazon Bedrock Custom Model Import",
      "description": "You can now achieve significant performance improvements when using Amazon Bedrock Custom Model Import, with reduced end-to-end latency, faster time-to-first-token, and improved throughput through advanced PyTorch compilation and CUDA graph optimizations. With Amazon Bedrock Custom Model Import you can to bring your own foundation models to Amazon Bedrock for deployment and inference at scale. In this post, we introduce how to use the improvements in Amazon Bedrock Custom Model Import.",
      "link": "https://aws.amazon.com/blogs/machine-learning/enhanced-performance-for-amazon-bedrock-custom-model-import/",
      "pubDate": "2025-11-26T16:46:01.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "improvement"
      ]
    },
    {
      "id": "aws-news-1c031b337189",
      "title": "Secure Amazon Elastic VMware Service (Amazon EVS) with AWS Network Firewall",
      "description": "In this post, we demonstrate how to utilize AWS Network Firewall to secure an Amazon EVS environment, using a centralized inspection architecture across an EVS cluster, VPCs, on-premises data centers and the internet. We walk through the implementation steps to deploy this architecture using AWS Network Firewall and AWS Transit Gateway.",
      "link": "https://aws.amazon.com/blogs/architecture/secure-amazon-elastic-vmware-service-amazon-evs-with-aws-network-firewall/",
      "pubDate": "2025-11-26T16:22:03.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-7aef8bce6a76",
      "title": "Amazon SageMaker AI introduces EAGLE based adaptive speculative decoding to accelerate generative AI inference",
      "description": "Amazon SageMaker AI now supports EAGLE-based adaptive speculative decoding, a technique that accelerates large language model inference by up to 2.5x while maintaining output quality. In this post, we explain how to use EAGLE 2 and EAGLE 3 speculative decoding in Amazon SageMaker AI, covering the solution architecture, optimization workflows using your own datasets or SageMaker's built-in data, and benchmark results demonstrating significant improvements in throughput and latency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-ai-introduces-eagle-based-adaptive-speculative-decoding-to-accelerate-generative-ai-inference/",
      "pubDate": "2025-11-26T00:29:42.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-a7bab8231d01",
      "title": "Orchestrating data processing tasks with a serverless visual workflow in Amazon SageMaker Unified Studio",
      "description": "In this post, we show how to use the new visual workflow experience in SageMaker Unified Studio IAM-based domains to orchestrate an end-to-end machine learning workflow. The workflow ingests weather data, applies transformations, and generates predictions—all through a single, intuitive interface, without writing any orchestration code.",
      "link": "https://aws.amazon.com/blogs/big-data/orchestrating-data-processing-tasks-with-a-serverless-visual-workflow-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-25T23:08:05.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam"
      ]
    },
    {
      "id": "aws-news-ba4b2b5742c2",
      "title": "Train custom computer vision defect detection model using Amazon SageMaker",
      "description": "In this post, we demonstrate how to migrate computer vision workloads from Amazon Lookout for Vision to Amazon SageMaker AI by training custom defect detection models using pre-trained models available on AWS Marketplace. We provide step-by-step guidance on labeling datasets with SageMaker Ground Truth, training models with flexible hyperparameter configurations, and deploying them for real-time or batch inference—giving you greater control and flexibility for automated quality inspection use cases.",
      "link": "https://aws.amazon.com/blogs/machine-learning/train-custom-computer-vision-defect-detection-model-using-amazon-sagemaker/",
      "pubDate": "2025-11-25T22:44:22.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lookout for vision",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "lookout for vision",
        "lex"
      ]
    },
    {
      "id": "aws-news-c9da28428aee",
      "title": "Node.js 24 runtime now available in AWS Lambda",
      "description": "You can now develop AWS Lambda functions using Node.js 24, either as a managed runtime or using the container base image. Node.js 24 is in active LTS status and ready for production use. It is expected to be supported with security patches and bugfixes until April 2028. The Lambda runtime for Node.js 24 includes a new implementation of the […]",
      "link": "https://aws.amazon.com/blogs/compute/node-js-24-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-25T22:19:46.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f3d43f94fc40",
      "title": "Practical implementation considerations to close the AI value gap",
      "description": "The AWS Customer Success Center of Excellence (CS COE) helps customers get tangible value from their AWS investments. We've seen a pattern: customers who build AI strategies that address people, process, and technology together succeed more often. In this post, we share practical considerations that can help close the AI value gap.",
      "link": "https://aws.amazon.com/blogs/machine-learning/practical-implementation-considerations-to-close-the-ai-value-gap/",
      "pubDate": "2025-11-25T20:19:50.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-7cb737e81dc9",
      "title": "The attendee’s guide to hybrid cloud and edge computing at AWS re:Invent 2025",
      "description": "AWS re:Invent 2025 returns to Las Vegas, Nevada, from December 1–5, 2025. This year, we’re offering a comprehensive lineup of sessions and booth activities to help you build resilient, performant, and scalable applications wherever you need them—in the cloud, on premises, or at the edge.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-hybrid-cloud-and-edge-computing-at-aws-reinvent-2025/",
      "pubDate": "2025-11-25T19:27:19.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-e78bda25ea6d",
      "title": "Introducing bidirectional streaming for real-time inference on Amazon SageMaker AI",
      "description": "We're introducing bidirectional streaming for Amazon SageMaker AI Inference, which transforms inference from a transactional exchange into a continuous conversation. This post shows you how to build and deploy a container with bidirectional streaming capability to a SageMaker AI endpoint. We also demonstrate how you can bring your own container or use our partner Deepgram's pre-built models and containers on SageMaker AI to enable bi-directional streaming feature for real-time inference.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-bidirectional-streaming-for-real-time-inference-on-amazon-sagemaker-ai/",
      "pubDate": "2025-11-25T19:09:59.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-7612920ee216",
      "title": "Physical AI in practice: Technical foundations that fuel human-machine interactions",
      "description": "In this post, we explore the complete development lifecycle of physical AI—from data collection and model training to edge deployment—and examine how these intelligent systems learn to understand, reason, and interact with the physical world through continuous feedback loops. We illustrate this workflow through Diligent Robotics' Moxi, a mobile manipulation robot that has completed over 1.2 million deliveries in hospitals, saving nearly 600,000 hours for clinical staff while transforming healthcare logistics and returning valuable time to patient care.",
      "link": "https://aws.amazon.com/blogs/machine-learning/physical-ai-in-practice-technical-foundations-that-fuel-human-machine-interactions/",
      "pubDate": "2025-11-25T17:00:25.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": []
    },
    {
      "id": "aws-news-e6ded75f4000",
      "title": "HyperPod now supports Multi-Instance GPU to maximize GPU utilization for generative AI tasks",
      "description": "In this post, we explore how Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) technology, enabling you to partition powerful GPUs into multiple isolated instances for running concurrent workloads like inference, research, and interactive development. By maximizing GPU utilization and reducing wasted resources, MIG helps organizations optimize costs while maintaining performance isolation and predictable quality of service across diverse machine learning tasks.",
      "link": "https://aws.amazon.com/blogs/machine-learning/hyperpod-now-supports-multi-instance-gpu-to-maximize-gpu-utilization-for-generative-ai-tasks/",
      "pubDate": "2025-11-25T16:10:39.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-e5767083a6d4",
      "title": "Optimize unused capacity with Amazon EC2 interruptible capacity reservations",
      "description": "Organizations running critical workloads on Amazon Elastic Compute Cloud (Amazon EC2) reserve compute capacity using On-Demand Capacity Reservations (ODCR) to have availability when needed. However, reserved capacity can intermittently sit idle during off-peak periods, between deployments, or when workloads scale down. This unused capacity represents a missed opportunity for cost optimization and resource efficiency across the organization.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-unused-capacity-with-amazon-ec2-interruptible-capacity-reservations/",
      "pubDate": "2025-11-25T01:09:16.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-60262ac8a35f",
      "title": "Accelerate generative AI innovation in Canada with Amazon Bedrock cross-Region inference",
      "description": "We are excited to announce that customers in Canada can now access advanced foundation models including Anthropic's Claude Sonnet 4.5 and Claude Haiku 4.5 on Amazon Bedrock through cross-Region inference (CRIS). This post explores how Canadian organizations can use cross-Region inference profiles from the Canada (Central) Region to access the latest foundation models to accelerate AI initiatives. We will demonstrate how to get started with these new capabilities, provide guidance for migrating from older models, and share recommended practices for quota management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-generative-ai-innovation-in-canada-with-amazon-bedrock-cross-region-inference/",
      "pubDate": "2025-11-24T23:56:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-333d00155bd8",
      "title": "Power up your ML workflows with interactive IDEs on SageMaker HyperPod",
      "description": "Amazon SageMaker HyperPod clusters with Amazon Elastic Kubernetes Service (EKS) orchestration now support creating and managing interactive development environments such as JupyterLab and open source Visual Studio Code, streamlining the ML development lifecycle by providing managed environments for familiar tools to data scientists. This post shows how HyperPod administrators can configure Spaces for their clusters, and how data scientists can create and connect to these Spaces.",
      "link": "https://aws.amazon.com/blogs/machine-learning/power-up-your-ml-workflows-with-interactive-ides-on-sagemaker-hyperpod/",
      "pubDate": "2025-11-24T21:25:56.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-1fcfec9f0f23",
      "title": "Claude Opus 4.5 now in Amazon Bedrock",
      "description": "Anthropic's newest foundation model, Claude Opus 4.5, is now available in Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models from leading AI companies. In this post, I'll show you what makes this model different, walk through key business applications, and demonstrate how to use Opus 4.5's new tool use capabilities on Amazon Bedrock.",
      "link": "https://aws.amazon.com/blogs/machine-learning/claude-opus-4-5-now-in-amazon-bedrock/",
      "pubDate": "2025-11-24T19:22:59.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "now-available"
      ]
    },
    {
      "id": "aws-news-5403d33b1bbc",
      "title": "How potential performance upside with AWS Graviton helps reduce your costs further",
      "description": "Amazon Web Services (AWS) provides many mechanisms to optimize the price performance of workloads running on Amazon Elastic Compute Cloud (Amazon EC2), and the selection of the optimal infrastructure to run on can be one of the most impactful levers. When we started building the AWS Graviton processor, our goal was to optimize AWS Graviton […]",
      "link": "https://aws.amazon.com/blogs/compute/how-potential-performance-upside-with-aws-graviton-helps-reduce-your-costs-further/",
      "pubDate": "2025-11-24T19:11:55.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton"
      ]
    },
    {
      "id": "aws-news-7d35cf5f9ae9",
      "title": "Enhancing API security with Amazon API Gateway TLS security policies",
      "description": "In this post, you will learn how the new Amazon API Gateway’s enhanced TLS security policies help you meet standards such as PCI DSS, Open Banking, and FIPS, while strengthening how your APIs handle TLS negotiation. This new capability increases your security posture without adding operational complexity, and provides you with a single, consistent way to standardize TLS configuration across your API Gateway infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/enhancing-api-security-with-amazon-api-gateway-tls-security-policies/",
      "pubDate": "2025-11-21T21:17:52.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "rds",
        "api gateway"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "api gateway",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-9d3d32287870",
      "title": "Improving throughput of serverless streaming workloads for Kafka",
      "description": "Event-driven applications often need to process data in real-time. When you use AWS Lambda to process records from Apache Kafka topics, you frequently encounter two typical requirements: you need to process very high volumes of records in close to real-time, and you want your consumers to have the ability to scale rapidly to handle traffic spikes. Achieving both necessitates understanding how Lambda consumes Kafka streams, where the potential bottlenecks are, and how to optimize configurations for high throughput and best performance.",
      "link": "https://aws.amazon.com/blogs/compute/improving-throughput-of-serverless-streaming-workloads-for-kafka/",
      "pubDate": "2025-11-21T20:02:57.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "rds",
        "kafka"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "rds",
        "kafka"
      ]
    },
    {
      "id": "aws-news-b3a3371e0c90",
      "title": "Build scalable REST APIs using Amazon API Gateway private integration with Application Load Balancer",
      "description": "Today, we announced \nAmazon API Gateway REST API’s support for private integration with \nApplication Load Balancers (ALBs). You can use this new capability to securely expose your VPC-based applications through your REST APIs without exposing your ALBs to the public internet.",
      "link": "https://aws.amazon.com/blogs/compute/build-scalable-rest-apis-using-amazon-api-gateway-private-integration-with-application-load-balancer/",
      "pubDate": "2025-11-21T19:28:04.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "api gateway",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-12b5ed99b30f",
      "title": "Introducing Cluster Insights: Unified monitoring dashboard for Amazon OpenSearch Service clusters",
      "description": "This blog will guide you through setting up and using Cluster Insights, including key features and metrics. By the conclusion, you'll understand how to use Cluster insights to recognize and address performance and resiliency issues within your OpenSearch Service clusters.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-cluster-insights-unified-monitoring-dashboard-for-amazon-opensearch-service-clusters/",
      "pubDate": "2025-11-21T16:38:56.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-c2a79337519c",
      "title": "Enforce business glossary classification rules in Amazon SageMaker Catalog",
      "description": "Amazon SageMaker Catalog now supports metadata enforcement rules for glossary terms classification (tagging) at the asset level. With this capability, administrators can require that assets include specific business terms or classifications. Data producers must apply required glossary terms or classifications before an asset can be published. In this post, we show how to enforce business glossary classification rules in SageMaker Catalog.",
      "link": "https://aws.amazon.com/blogs/big-data/enforce-business-glossary-classification-rules-in-amazon-sagemaker-catalog/",
      "pubDate": "2025-11-20T18:39:41.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-32281bfd2f59",
      "title": "Enhanced data discovery in Amazon SageMaker Catalog with custom metadata forms and rich text documentation",
      "description": "Amazon SageMaker Catalog now supports custom metadata forms and rich text descriptions at the column level, extending existing curation capabilities for business names, descriptions, and glossary term classifications. Column-level context is essential for understanding and trusting data. This release helps organizations improve data discoverability, collaboration, and governance by letting metadata stewards document columns using structured and formatted information that aligns with internal standards. In this post, we show how to enhance data discovery in SageMaker Catalog with custom metadata forms and rich text documentation at the schema level.",
      "link": "https://aws.amazon.com/blogs/big-data/enhanced-data-discovery-in-amazon-sagemaker-catalog-with-custom-metadata-forms-and-rich-text-documentation/",
      "pubDate": "2025-11-20T18:35:07.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "rds",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-df24f6f1c182",
      "title": "Building multi-tenant SaaS applications with AWS Lambda’s new tenant isolation mode",
      "description": "Today, AWS is announcing tenant isolation for AWS Lambda, enabling you to process function invocations in separate execution environments for each end-user or tenant invoking your Lambda function. This capability simplifies building secure multi-tenant SaaS applications by managing tenant-level compute environment isolation and request routing, allowing you to focus on core business logic rather than implementing tenant-aware compute environment isolation.",
      "link": "https://aws.amazon.com/blogs/compute/building-multi-tenant-saas-applications-with-aws-lambdas-new-tenant-isolation-mode/",
      "pubDate": "2025-11-20T17:47:17.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-b04be71f4d69",
      "title": "Improve API discoverability with the new Amazon API Gateway Portal",
      "description": "In this post, we will show how you can use the new portal feature to create customizable portals with enhanced security features in minutes, with APIs from multiple accounts, without managing any infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/improve-api-discoverability-with-the-new-amazon-api-gateway-portal/",
      "pubDate": "2025-11-20T00:41:25.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-9150859a247c",
      "title": "Building an AI gateway to Amazon Bedrock with Amazon API Gateway",
      "description": "In this post, we'll explore a reference architecture that helps enterprises govern their Amazon Bedrock implementations using Amazon API Gateway. This pattern enables key capabilities like authorization controls, usage quotas, and real-time response streaming. We'll examine the architecture, provide deployment steps, and discuss potential enhancements to help you implement AI governance at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/building-an-ai-gateway-to-amazon-bedrock-with-amazon-api-gateway/",
      "pubDate": "2025-11-19T23:33:41.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "api gateway"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "api gateway",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-e3fa9789b76a",
      "title": "Getting started with Amazon S3 Tables in Amazon SageMaker Unified Studio",
      "description": "In this post, you learn how to integrate SageMaker Unified Studio with S3 Tables and query your data using Amazon Athena, Amazon Redshift, or Apache Spark in EMR and AWS Glue.",
      "link": "https://aws.amazon.com/blogs/big-data/getting-started-with-amazon-s3-tables-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-19T23:26:57.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-4934fd40d9d8",
      "title": "Architecting for AI excellence: AWS launches three Well-Architected Lenses at re:Invent 2025",
      "description": "At re:Invent 2025, we introduce one new lens and two significant updates to the AWS Well-Architected Lenses specifically focused on AI workloads: the Responsible AI Lens, the Machine Learning (ML) Lens, and the Generative AI Lens. Together, these lenses provide comprehensive guidance for organizations at different stages of their AI journey, whether you're just starting to experiment with machine learning or already deploying complex AI applications at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-for-ai-excellence-aws-launches-three-well-architected-lenses-at-reinvent-2025/",
      "pubDate": "2025-11-19T19:36:31.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-61647c9310e0",
      "title": "Announcing the updated AWS Well-Architected Generative AI Lens",
      "description": "We are delighted to announce an update to the AWS Well-Architected Generative AI Lens. This update features several new sections of the Well-Architected Generative AI Lens, including new best practices, advanced scenario guidance, and improved preambles on responsible AI, data architecture, and agentic workflows.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-generative-ai-lens/",
      "pubDate": "2025-11-19T19:36:28.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-5044b6bc98c4",
      "title": "Announcing the updated AWS Well-Architected Machine Learning Lens",
      "description": "We are excited to announce the updated AWS Well-Architected Machine Learning Lens, now enhanced with the latest capabilities and best practices for building machine learning (ML) workloads on AWS.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-machine-learning-lens/",
      "pubDate": "2025-11-19T19:36:25.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-0801d7b479dd",
      "title": "Cross-account lakehouse governance with Amazon S3 Tables and SageMaker Catalog",
      "description": "In this post, we walk you through a practical solution for secure, efficient cross-account data sharing and analysis. You’ll learn how to set up cross-account access to S3 Tables using federated catalogs in Amazon SageMaker, perform unified queries across accounts with Amazon Athena in Amazon SageMaker Unified Studio, and implement fine-grained access controls at the column level using AWS Lake Formation.",
      "link": "https://aws.amazon.com/blogs/big-data/cross-account-lakehouse-governance-with-amazon-s3-tables-and-sagemaker-catalog/",
      "pubDate": "2025-11-18T23:01:03.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "athena"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "athena"
      ]
    },
    {
      "id": "aws-news-05b9bc2e3644",
      "title": "Python 3.14 runtime now available in AWS Lambda",
      "description": "AWS Lambda now supports Python 3.14 as both a managed runtime and container base image. Python is a popular language for building serverless applications. Developers can now take advantage of new features and enhancements when creating serverless applications on Lambda.",
      "link": "https://aws.amazon.com/blogs/compute/python-3-14-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-18T21:29:50.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "new-feature",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-1c81acbb3316",
      "title": "Introducing Amazon MWAA Serverless",
      "description": "Today, AWS announced Amazon Managed Workflows for Apache Airflow (MWAA) Serverless. This is a new deployment option for MWAA that eliminates the operational overhead of managing Apache Airflow environments while optimizing costs through serverless scaling. In this post, we demonstrate how to use MWAA Serverless to build and deploy scalable workflow automation solutions.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-amazon-mwaa-serverless/",
      "pubDate": "2025-11-17T22:22:46.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-c36d51e13ef0",
      "title": "Building serverless applications with Rust on AWS Lambda",
      "description": "Today, AWS Lambda is promoting Rust support from Experimental to Generally Available. This means you can now use Rust to build business-critical serverless applications, backed by AWS Support and the Lambda availability SLA.",
      "link": "https://aws.amazon.com/blogs/compute/building-serverless-applications-with-rust-on-aws-lambda/",
      "pubDate": "2025-11-14T21:38:15.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "experimental",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-78f167df36fd",
      "title": "AWS Lambda now supports Java 25",
      "description": "You can now develop AWS Lambda functions using Java 25 either as a managed runtime or using the container base image. This blog post highlights notable Java language features, Java Lambda runtime updates, and how you can use the new Java 25 runtime in your serverless applications.",
      "link": "https://aws.amazon.com/blogs/compute/aws-lambda-now-supports-java-25/",
      "pubDate": "2025-11-14T20:51:20.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-525a7aa26225",
      "title": "Your guide to AWS Analytics at AWS re:Invent 2025",
      "description": "It’s that time of year again — AWS re:Invent is here! At re:Invent, bold ideas come to life. Get a front-row seat to hear inspiring stories from AWS experts, customers, and leaders as they explore today’s most impactful topics, from data analytics to AI. For all the data enthusiasts and professionals, we’ve curated a comprehensive […]",
      "link": "https://aws.amazon.com/blogs/big-data/your-guide-to-aws-analytics-at-aws-reinvent-2025/",
      "pubDate": "2025-11-13T20:06:19.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-d4d5eb413522",
      "title": "How Yelp modernized its data infrastructure with a streaming lakehouse on AWS",
      "description": "This is a guest post by Umesh Dangat, Senior Principal Engineer for Distributed Services and Systems at Yelp, and Toby Cole, Principle Engineer for Data Processing at Yelp, in partnership with AWS. Yelp processes massive amounts of user data daily—over 300 million business reviews, 100,000 photo uploads, and countless check-ins. Maintaining sub-minute data freshness with […]",
      "link": "https://aws.amazon.com/blogs/big-data/how-yelp-modernized-its-data-infrastructure-with-a-streaming-lakehouse-on-aws/",
      "pubDate": "2025-11-13T18:07:22.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-32e40b364aee",
      "title": "The attendee’s guide to the AWS re:Invent 2025 Compute track",
      "description": "From December 1st to December 5th, Amazon Web Services (AWS) will hold its annual premier learning event: re:Invent. There are over 2000+ learning sessions that focus on specific topics at various skill levels, and the compute team have created 76 unique sessions for you to choose. There are many sessions you can choose from, and we are here to help you choose the sessions that best fit your needs. Even if you cannot join in person, you can catch-up with many of the sessions on-demand and even watch the keynote and innovation sessions live.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-the-aws-reinvent-2025-compute-track/",
      "pubDate": "2025-11-12T20:58:36.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-a7184d7c3c1a",
      "title": "Introducing the Amazon OpenSearch Lens for the AWS Well-Architected Framework",
      "description": "In this post, we show you how to use the Amazon OpenSearch Service Lens to evaluate your OpenSearch Service workloads against architectural best practices.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-the-amazon-opensearch-lens-for-the-aws-well-architected-framework/",
      "pubDate": "2025-11-12T01:07:02.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "ga"
      ]
    },
    {
      "id": "aws-news-25fb32cc6ab1",
      "title": "AWS Lambda networking over IPv6",
      "description": "This post examines the benefits of transitioning Lambda functions to IPv6, provides practical guidance for implementing dual-stack support in your Lambda environment, and considerations for maintaining compatibility with existing systems during migration.",
      "link": "https://aws.amazon.com/blogs/compute/aws-lambda-networking-over-ipv6/",
      "pubDate": "2025-11-07T22:14:31.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "support"
      ]
    },
    {
      "id": "aws-news-360e834c997a",
      "title": "BASF Digital Farming builds a STAC-based solution on Amazon EKS",
      "description": "This post was co-written with Frederic Haase and Julian Blau with BASF Digital Farming GmbH. At xarvio – BASF Digital Farming, our mission is to empower farmers around the world with cutting-edge digital agronomic decision-making tools. Central to this mission is our crop optimization platform, xarvio FIELD MANAGER, which delivers actionable insights through a range […]",
      "link": "https://aws.amazon.com/blogs/architecture/basf-digital-farming-builds-a-stac-based-solution-on-amazon-eks/",
      "pubDate": "2025-10-22T16:21:09.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-24029d05087c",
      "title": "What’s New in the AWS Deploy Tool for .NET",
      "description": "Version 2.0 of the AWS Deploy Tool for .NET is now available. This new major version introduces several foundational upgrades to improve the deployment experience for .NET applications on AWS. The tool comes with new minimum runtime requirements. We have upgraded it to require .NET 8 because the predecessor, .NET 6, is now out of […]",
      "link": "https://aws.amazon.com/blogs/developer/whats-new-in-the-aws-deploy-tool-for-net/",
      "pubDate": "2025-10-14T13:25:42.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-2f3bd8791ed1",
      "title": "Modernization of real-time payment orchestration on AWS",
      "description": "The global real-time payments market is experiencing significant growth. According to Fortune Business Insights, the market was valued at USD 24.91 billion in 2024 and is projected to grow to USD 284.49 billion by 2032, with a CAGR of 35.4%. Similarly, Grand View Research reports that the global mobile payment market, valued at USD 88.50 […]",
      "link": "https://aws.amazon.com/blogs/architecture/modernization-of-real-time-payment-orchestration-on-aws/",
      "pubDate": "2025-10-01T23:34:00.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": []
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-4fbb29739c17",
      "title": "General Availability Release of the Migration Tool for the AWS SDK for Java 2.x",
      "description": "The AWS SDK for Java 1.x (v1) entered maintenance mode on July 31, 2024, and will reach end-of-support on December 31, 2025. We recommend that you migrate to the AWS SDK for Java 2.x (v2) to access new features, enhanced performance, and continued support from AWS. To help you migrate efficiently, we’ve created a migration […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-release-of-the-migration-tool-for-the-aws-sdk-for-java-2-x/",
      "pubDate": "2025-09-26T16:47:36.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-7e2f23dd38ac",
      "title": "Simplify multi-tenant encryption with a cost-conscious AWS KMS key strategy",
      "description": "In this post, we explore an efficient approach to managing encryption keys in a multi-tenant SaaS environment through centralization, addressing challenges like key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. We demonstrate how implementing a centralized key management strategy using a single AWS KMS key per tenant can maintain security and compliance while reducing operational overhead as organizations scale.",
      "link": "https://aws.amazon.com/blogs/architecture/simplify-multi-tenant-encryption-with-a-cost-conscious-aws-kms-key-strategy/",
      "pubDate": "2025-08-21T21:54:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-d1d1f77f887e",
      "title": "How Karrot built a feature platform on AWS, Part 1: Motivation and feature serving",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post starts by presenting our motivation, our requirements, and the solution architecture, focusing on feature serving.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-1-motivation-and-feature-serving/",
      "pubDate": "2025-08-14T15:16:29.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-40ebd26fef7f",
      "title": "How Karrot built a feature platform on AWS, Part 2: Feature ingestion",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post covers the process of collecting features in real-time and batch ingestion into an online store, and the technical approaches for stable operation.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-2-feature-ingestion/",
      "pubDate": "2025-08-14T15:16:27.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    },
    {
      "id": "aws-news-8b2281cd8002",
      "title": "Maximizing Business Value Through Strategic Cloud Optimization",
      "description": "As cloud spending continues to surge, organizations must focus on strategic cloud optimization to maximize business value. This blog post explores key insights from MIT Technology Review's publication on cloud optimization, highlighting the importance of viewing optimization as a continuous process that encompasses all six AWS Well-Architected pillars.",
      "link": "https://aws.amazon.com/blogs/architecture/maximizing-business-value-through-strategic-cloud-optimization/",
      "pubDate": "2025-08-01T15:33:28.000Z",
      "source": "architectureBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-9e63742dd9e4",
      "title": "How Zapier runs isolated tasks on AWS Lambda and upgrades functions at scale",
      "description": "In this post, you’ll learn how Zapier has built their serverless architecture focusing on three key aspects: using Lambda functions to build isolated Zaps, operating over a hundred thousand Lambda functions through Zapier's control plane infrastructure, and enhancing security posture while reducing maintenance efforts by introducing automated function upgrades and cleanup workflows into their platform architecture.",
      "link": "https://aws.amazon.com/blogs/architecture/how-zapier-runs-isolated-tasks-on-aws-lambda-and-upgrades-functions-at-scale/",
      "pubDate": "2025-07-25T13:30:06.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-11d98a88cbe1",
      "title": "Implement monitoring for Amazon EKS with managed services",
      "description": "In this post, we show you how to implement comprehensive monitoring for Amazon Elastic Kubernetes Service (Amazon EKS) workloads using AWS managed services. This solution demonstrates building an EKS platform that combines flexible compute options with enterprise-grade observability using AWS native services and OpenTelemetry.",
      "link": "https://aws.amazon.com/blogs/architecture/implement-monitoring-for-amazon-eks-with-managed-services/",
      "pubDate": "2025-07-18T15:47:13.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    },
    {
      "id": "aws-news-875544c87826",
      "title": "Preview Release of the AWS SDK Java 2.x HTTP Client built on Apache HttpClient 5.5.x",
      "description": "The AWS SDK for Java 2.x introduces the Apache 5 SDK HTTP client which is built on Apache HttpClient 5.5.x. This new SDK HTTP client is available alongside our existing SDK HTTP clients: Apache HttpClient 4.5.x, Netty, URL Connection, and AWS CRT HttpClient. To differentiate the use of Apache HttpClient 4.5.x and Apache HttpClient 5.5.x, […]",
      "link": "https://aws.amazon.com/blogs/developer/preview-release-of-theaws-sdk-java-2-x-http-client-built-on-apache-httpclient-5-5-x/",
      "pubDate": "2025-07-18T03:36:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-6606f79cd3d5",
      "title": "AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available",
      "description": "Today, we are excited to announce the general availability of the AWS .NET Distributed Cache Provider for Amazon DynamoDB. This is a seamless, serverless caching solution that enables .NET developers to efficiently manage their caching needs across distributed systems. Consistent caching is a difficult problem in distributed architectures, where maintaining data integrity and performance across […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-net-distributed-cache-provider-for-amazon-dynamodb-now-generally-available/",
      "pubDate": "2025-07-03T13:49:25.000Z",
      "source": "developersAndDevOps",
      "services": [
        "dynamodb"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "dynamodb",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-ae25b45e1a62",
      "title": "AWS Tools for PowerShell V5 now Generally Available",
      "description": "This blog was co-authored by Afroz Mohammed and Jonathan Nunn, Software Developers on the AWS PowerShell team. We’re excited to announce the general availability of the AWS Tools for PowerShell version 5, a major update that brings new features and improvements in security, along with a few breaking changes. New Features You can now cancel […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-tools-for-powershell-v5-now-generally-available/",
      "pubDate": "2025-06-23T22:59:33.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "new-feature",
        "update",
        "improvement"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-27b43a8f9a42",
      "title": "Deploy to ARM-Based Compute with AWS Deploy Tool for .NET",
      "description": "We’re excited to announce that the AWS Deploy Tool for .NET now supports deploying .NET applications to select ARM-based compute platforms on AWS! Whether you’re deploying from Visual Studio or using the .NET CLI, you can now target cost-effective ARM infrastructure like AWS Graviton with the same streamlined experience you’re used to. Why deploy to […]",
      "link": "https://aws.amazon.com/blogs/developer/deploy-to-arm-based-compute-with-aws-deploy-tool-for-net/",
      "pubDate": "2025-05-08T20:16:40.000Z",
      "source": "developersAndDevOps",
      "services": [
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "graviton",
        "support"
      ]
    },
    {
      "id": "aws-news-4d3126ea3a15",
      "title": "General Availability of AWS SDK for .NET V4.0",
      "description": "Version 4.0 of the AWS SDK for .NET has been released for general availability (GA). V4 has been in development for a little over a year in our SDK’s public GitHub repository with 13 previews being released. This new version contains performance improvements, consistency with other AWS SDKs, and bug and usability fixes that required […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-of-aws-sdk-for-net-v4-0/",
      "pubDate": "2025-04-28T20:05:16.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-49859f1bef68",
      "title": "Introducing the AWS IoT Device SDK for Swift (Developer Preview)",
      "description": "Today, AWS launches the developer preview of the AWS IoT Device SDK for Swift. The IoT Device SDK for Swift empowers Swift developers to create IoT applications for Linux and Apple macOS, iOS, and tvOS platforms using the MQTT 5 protocol. The SDK supports Swift 5.10+ and is designed to help developers easily integrate with […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-the-aws-iot-device-sdk-for-swift-developer-preview/",
      "pubDate": "2025-03-31T16:26:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-dd08a704e7e9",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 2)",
      "description": "In Part 1 of our blog posts for .NET Aspire and AWS Lambda, we showed you how .NET Aspire can be used for running and debugging .NET Lambda functions. In this part, Part 2, we’ll show you how to take advantage of the .NET Aspire programming model for best practices and for connecting dependent resources […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-2/",
      "pubDate": "2025-03-04T17:54:04.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-4185fb6b40aa",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 1)",
      "description": "In a recent post we gave some background on .NET Aspire and introduced our AWS integrations with .NET Aspire that integrate AWS into the .NET dev inner loop for building applications. The integrations included how to provision application resources with AWS CloudFormation or AWS Cloud Development Kit (AWS CDK) and using Amazon DynamoDB local for […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-1/",
      "pubDate": "2025-03-03T21:16:42.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda",
        "dynamodb",
        "cloudformation"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "dynamodb",
        "cloudformation",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-866c6557a5ec",
      "title": "Integrating AWS with .NET Aspire",
      "description": ".NET Aspire is a new way of building cloud-ready applications. In particular, it provides an orchestration for local environments in which to run, connect, and debug the components of distributed applications. Those components can be .NET projects, databases, containers, or executables. .NET Aspire is designed to have integrations with common components used in distributed applications. […]",
      "link": "https://aws.amazon.com/blogs/developer/integrating-aws-with-net-aspire/",
      "pubDate": "2025-02-11T20:39:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "integration"
      ]
    },
    {
      "id": "aws-news-9568575bd4f9",
      "title": "Updating AWS SDK defaults – AWS STS service endpoint and Retry Strategy",
      "description": "AWS announces important configuration updates coming July 31st, 2025, affecting AWS SDKs and CLIs default settings. Two key changes include switching the AWS Security Token Service (STS) endpoint to regional and updating the default retry strategy to standard. These updates aim to improve service availability and reliability by implementing regional endpoints to reduce cross-regional dependencies and introducing token-bucket throttling for standardized retry behavior. Organizations should test their applications before the release date and can opt-in early or temporarily opt-out of these changes. These updates align with AWS best practices for optimal service performance and security.",
      "link": "https://aws.amazon.com/blogs/developer/updating-aws-sdk-defaults-aws-sts-service-endpoint-and-retry-strategy/",
      "pubDate": "2025-02-11T05:37:32.000Z",
      "source": "developersAndDevOps",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga",
        "update"
      ]
    }
  ]
}