{
  "lastUpdated": "2025-12-18T06:17:40.053Z",
  "totalItems": 202,
  "sources": {
    "whatsNew": 94,
    "mlBlog": 20,
    "newsBlog": 20,
    "bigDataBlog": 16,
    "architectureBlog": 17,
    "computeBlog": 18,
    "developersAndDevOps": 17
  },
  "items": [
    {
      "id": "aws-news-4911a42f92d4",
      "title": "Power data ingestion into Splunk using Amazon Data Firehose",
      "description": "With Kinesis Data Firehose, customers can use a fully managed, reliable, and scalable data streaming solution to Splunk. In this post, we tell you a bit more about the Kinesis Data Firehose and Splunk integration. We also show you how to ingest large amounts of data into Splunk using Kinesis Data Firehose.",
      "link": "https://aws.amazon.com/blogs/big-data/power-data-ingestion-into-splunk-using-amazon-data-firehose/",
      "pubDate": "2025-12-17T18:52:29.000Z",
      "source": "bigDataBlog",
      "services": [
        "kinesis"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kinesis",
        "integration"
      ]
    },
    {
      "id": "aws-news-fab819686d72",
      "title": "Amazon WorkSpaces Applications announces additional health and performance metrics",
      "description": "Today, Amazon WorkSpaces Applications announced a new set of Amazon CloudWatch metrics for monitoring the health and performance of fleets, sessions, instances, and users. Administrators and support operations personnel can conveniently enable monitoring across fleets from the Amazon CloudWatch console. These metrics simplify troubleshooting and dynamically update to reflect the latest state of important performance metrics.\n  Users can make informed decisions on sizing and end users' streaming instances by setting performance thresholds on available metrics to meet performance and budgeting criteria. They can view instance and session performance metrics to troubleshoot end user streaming session related issues.\n  To enable this feature for your fleet instancess, you must use a WorkSpaces Applications image that uses latest agent released on or after December 06, 2025 or has been updated using Managed WorkSpaces Applications image updates released on or after December 05, 2025.\n \nThese CloudWatch metrics are available in all the AWS commercial and AWS GovCloud (US) Regions where Amazon WorkSpaces Applications is currently available. To get started or learn more, you can visit Amazon WorkSpaces Applications Metrics and Dimensions documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-workspaces-applications-health-performance-metrics",
      "pubDate": "2025-12-17T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudwatch",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-5d22d44eeb20",
      "title": "Now generally available: Amazon EC2 M8gn and M8gb instances",
      "description": "Today, AWS announces the general availability of the new Amazon Elastic Compute Cloud (Amazon EC2) M8gn and M8gb instances. These instances are powered by AWS Graviton4 processors to deliver up to 30% better compute performance than AWS Graviton3 processors. M8gn instances feature the latest 6th generation AWS Nitro Cards, and offer up to 600 Gbps network bandwidth, the highest network bandwidth among network optimized EC2 instances. M8gb offer up to 150 Gbps of EBS bandwidth to provide higher EBS performance compared to same-sized equivalent Graviton4-based instances.\n  M8gn are ideal for network-intensive workloads such as high-performance file systems, distributed web scale in-memory caches, caching fleets, real-time big data analytics, and Telco applications such as 5G User Plane Function (UPF). M8gb are ideal for workloads requiring high block storage performance such as high performance databases and NoSQL databases.\n \nM8gn instances offer instance sizes up to 48xlarge, up to 768 GiB of memory, up to 600 Gbps of networking bandwidth, and up to 60 Gbps of bandwidth to Amazon Elastic Block Store (EBS). They also support EFA networking on the 16xlarge, 24xlarge, and 48xlarge sizes.\n  M8gb instances offer sizes up to 24xlarge, up to 768 GiB of memory, up to 150 Gbps of EBS bandwidth, and up to 200 Gbps of networking bandwidth. They support Elastic Fabric Adapter (EFA) networking on the 16xlarge and 24xlarge sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n \nThe new instances are available in the following AWS Regions: US East (N. Virginia), and US West (Oregon).\n  To learn more, see Amazon EC2 M8gn and M8gb Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/generally-available-amazon-ec2-m8gn-m8gb-instances",
      "pubDate": "2025-12-17T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "rds",
        "graviton",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-ffe776e25488",
      "title": "AWS Databases are now available on the Vercel Marketplace",
      "description": "Today, AWS Databases including Amazon Aurora PostgreSQL, Amazon Aurora DSQL, and Amazon DynamoDB are generally available on the Vercel Marketplace, enabling you to create and connect to an AWS database directly from Vercel in seconds.\n  To get started, you can create a new AWS Account from Vercel that includes access to the three databases and $100 USD in credits. These credits can be used with any of these database option for up to six months. Once your account is set up, you can have a production-ready Aurora database or DynamoDB table powering your Vercel projects within seconds. You can also manage your plan, add payment information, and view usage details anytime by visiting the AWS settings portal from the Vercel dashboard. To learn more, visit the AWS landing page on the Vercel Marketplace.\n  The integration includes serverless options for Amazon Aurora PostgreSQL, Amazon Aurora DSQL, and Amazon DynamoDB to simplify your application needs and reduce costs by scaling to zero when not in use. You can create a database in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Europe (Ireland), Europe (Frankfurt), Asia Pacific (Tokyo), and Asia Pacific (Mumbai) with more Regions coming soon.\n  AWS Databases deliver security, reliability, and price performance without the operational overhead, whether you're prototyping your next big idea or running production AI and data driven applications. For more information, visit the AWS Databases webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-databases-are-available-on-the-vercel/",
      "pubDate": "2025-12-17T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "dynamodb"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "dynamodb",
        "generally-available",
        "now-available",
        "integration",
        "coming-soon"
      ]
    },
    {
      "id": "aws-news-e5980152a49f",
      "title": "Amazon Aurora now supports PostgreSQL 18.1 in the Amazon RDS Database preview environment",
      "description": "Amazon Aurora PostgreSQL-Compatible Edition now supports PostgreSQL version 18.1 in the Amazon RDS Database Preview Environment, allowing you to evaluate PostgreSQL 18.1 on Amazon Aurora PostgreSQL. PostgreSQL 18.1 was released by the PostgreSQL community on September 9, 2025. \n  PostgreSQL 18.1 includes \"skip scan\" support for multicolumn B-tree indexes and improves WHERE clause handling for OR and IN conditions. It introduces parallel GIN index builds and updates join operations. Observability improvements show buffer usage counts and index lookups during query execution, along with a per-connection I/O utilization metric. To learn more about PostgreSQL 18.1, read here.\n  \n Database instances in the RDS Database Preview Environment allow testing of a new database engine without the hassle of having to self-install, provision, and manage a preview version of the Aurora PostgreSQL database software. Clusters are retained for a maximum period of 60 days and are automatically deleted after this retention period. Amazon RDS Database Preview Environment database instances are priced the same as production Aurora instances created in the US East (Ohio) Region.\n  \n Amazon Aurora is designed for unparalleled high performance and availability at global scale with full MySQL and PostgreSQL compatibility. It provides built-in security, continuous backups, serverless compute, up to 15 read replicas, automated multi-Region replication, and integrations with other AWS services. To get started with Amazon Aurora, take a look at our getting started page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-aurora-postgresql-18-1-rds-database-preview",
      "pubDate": "2025-12-17T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "preview",
        "update",
        "improvement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-da707b0d38df",
      "title": "Tracking and managing assets used in AI development with Amazon SageMaker AI",
      "description": "In this post, we'll explore the new capabilities and core concepts that help organizations track and manage models development and deployment lifecycles. We will show you how the features are configured to train models with automatic end-to-end lineage, from dataset upload and versioning to model fine-tuning, evaluation, and seamless endpoint deployment.",
      "link": "https://aws.amazon.com/blogs/machine-learning/tracking-and-managing-assets-used-in-ai-development-with-amazon-sagemaker-ai/",
      "pubDate": "2025-12-17T16:53:30.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-13a0ca971134",
      "title": "Track machine learning experiments with MLflow on Amazon SageMaker using Snowflake integration",
      "description": "In this post, we demonstrate how to integrate Amazon SageMaker managed MLflow as a central repository to log these experiments and provide a unified system for monitoring their progress.",
      "link": "https://aws.amazon.com/blogs/machine-learning/track-machine-learning-experiments-with-mlflow-on-amazon-sagemaker-using-snowflake-integration/",
      "pubDate": "2025-12-17T16:50:57.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "integration"
      ]
    },
    {
      "id": "aws-news-567762193978",
      "title": "AWS announces enhanced custom line item controls for AWS Billing Conductor",
      "description": "Starting today, AWS Billing Conductor customers gain greater flexibility when using custom line items.\n  Customers can now create service-specific custom line items scoped at either one AWS service or to a set of selected AWS service and can choose how these line items are presented in the pro forma billing artifacts, such as Bills Page, Cost Explorer and Cost and Usage Records.\n  These enhancements enable customers to create more precise and tailored charge-back and re-billing strategies that better reflect their pricing structures and improve the traceability experience for pro forma users. Customers can use this functionality to apply percentage discounts on Saving Plans fees or allocate shared flat support charges under AWS Support service. Service specific custom line items are available for standard billing group regardless of the type of pricing plan selected, and for billing-transfer billing groups exclusively when customer-managed pricing plans are selected.\n  To start, use AWS Billing Conductor console or APIs, create a custom line item and specify the cost reference value (one or multiple AWS services) and the display setting options (itemized or consolidated under your service of choice). To learn more about custom line items visit AWS Billing Conductor documentation.\n  This feature is available now in all AWS commercial Regions, excluding AWS China (Beijing) Region, operated by Sinnet, and AWS China (Ningxia) Region, operated by NWCD.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/enhanced-custom-line-item-controls-aws-billing-conductor",
      "pubDate": "2025-12-17T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-c8e1d411e6b8",
      "title": "Amazon EC2 C8g, M8g, R8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8g and M8g instances are available in AWS GovCloud (US-West) and R8g and M8g instances are available in AWS GovCloud (US-East) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. They are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon C8g, M8g and R8g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. C8g and R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 C8g Instances, Amazon EC2 M8g Instances, and Amazon EC2 R8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS GovCloud (US) Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-c8g-m8g-r8g-instances-additional-regions",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-c5ac4749b0cf",
      "title": "Amazon ECR Public now supports PrivateLink for US East (N. Virginia) SDK Endpoint",
      "description": "Amazon Elastic Container Registry (ECR) Public now supports PrivateLink for the US East (N. Virginia) SDK endpoint, providing enhanced network security and private connectivity for customers. This update allows customers to access this ECR Public SDK endpoint through a private network connection, reducing exposure to the public internet.\n  With this enhancement, customers can now establish a private connection from their Amazon Virtual Private Cloud (VPC) to their ECR Public SDK endpoint while creating and maintaining their ECR Public repositories. This means organizations can maintain network privacy and security, reduce exposure of sensitive network traffic, comply with stricter network security requirements, and simplify network architecture for accessing ECR Public resources.\n  Get started today with the US East (N. Virginia) ECR Public SDK endpoint.\n \nTo learn more, visit ECR documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ecr-public-privatelink-us-east-n-virginia-sdk-endpoint",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga",
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-e1e4b4a072a5",
      "title": "EC2 Auto Scaling now offers a synchronous API to launch instances inside an Auto Scaling group",
      "description": "Today, EC2 Auto Scaling is launching a new API, LaunchInstances, which gives customers more control and flexibility over how EC2 Auto Scaling provisions instances while providing instant feedback on capacity availability.\n  Customers use EC2 Auto Scaling for automated fleet management. With scaling policies, EC2 Auto Scaling can automatically add instances when demand spikes and remove them when traffic drops, ensuring customers' applications always have the right amount of compute. EC2 Auto Scaling also offers the ability to monitor and replace unhealthy instances. In certain use cases, customers may want to specify exactly where EC2 Auto Scaling should launch additional instances and need immediate feedback on capacity availability. The new LaunchInstances API allows customers to precisely control where instances are launched by specifying an override for any Availability Zone and/or subnet in an Auto Scaling group, while providing immediate feedback on capacity availability. This synchronous operation gives customers real-time insight into scaling operations, enabling them to quickly implement alternative strategies if needed. For additional flexibility, the API includes optional asynchronous retries to help reach the desired capacity.\n  This feature is now available in all AWS Regions and AWS GovCloud (US) Regions, at no additional cost beyond standard EC2 and EBS usage. To get started, visit the AWS Command Line Interface (CLI) and the AWS SDKs. To learn more about this feature, visit the AWS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-auto-scaling-synchronous-api-launch-instances-auto-scaling-group",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-e1072d090a34",
      "title": "Amazon EC2 C8g instances now available in Europe (Zurich)",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8g instances are available in AWS Europe (Zurich) region. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 C8g instances are built for compute-intensive workloads, such as high performance computing (HPC), batch processing, gaming, video encoding, scientific modeling, distributed analytics, CPU-based machine learning (ML) inference, and ad serving. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon C7g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. C8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 C8g Instances. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-c8g-instances-europe-zurich",
      "pubDate": "2025-12-17T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-41d288f2de9f",
      "title": "Amazon OpenSearch Service announces new OI2 instances",
      "description": "Amazon OpenSearch Service introduces OI2 instances, expanding the OpenSearch Optimized Instance family. The new OI2 instances delivers up to 9% higher indexing throughput compared to OR2 instances and up to 33% over I8g instances in our internal benchmarks.\n \nThe new OI2 OpenSearch Optimized instances use the same architecture as the OR2 instances, leveraging best-in-class cloud technologies like Amazon S3, to provide high durability, and improved price-performance for higher indexing throughput better for indexing heavy workload. Each OpenSearch Optimized instance is provisioned with compute, 3rd generation AWS Nitro SSDs for caching, and remote Amazon S3-based managed storage. OI2 offers pay-as-you-go pricing and reserved instances, with a simple hourly rate for the instance including the NVMe storage, as well as managed storage provisioned. OI2 instances come in sizes ‘large’ through ‘24xlarge’, and offer compute, memory, and up to 22.5 TB storage. Please refer to the Amazon OpenSearch Service pricing page for pricing details.\n  OI2 instance family is now available on Amazon OpenSearch Service across 12 regions globally: US East (N. Virginia, Ohio), US West (Oregon), Canada (Central), Asia Pacific (Mumbai, Singapore, Sydney, Tokyo), Europe (Frankfurt, Ireland, London, Spain).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-opensearch-service-oi2-instances/",
      "pubDate": "2025-12-17T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-d42bdd7e063f",
      "title": "AWS Payment Cryptography is now available in Asia Pacific(Hyderabad) and Europe(Paris)",
      "description": "AWS Payment Cryptography has expanded its global presence with availability in two new regions - Asia Pacific(Hyderabad) and Europe(Paris). This expansion enables customers with latency-sensitive payment applications to build, deploy or migrate into additional AWS Regions without depending on cross-region support. These Region offers offers additional options for multi-region high availability for Europe and India.\n  AWS Payment Cryptography is a fully managed service that simplifies payment-specific cryptographic operations and key management for cloud-hosted payment applications. The service scales elastically with your business needs and is assessed as compliant with PCI PIN and PCI P2PE requirements, eliminating the need to maintain dedicated payment HSM instances. Organizations performing payment functions - including acquirers, payment facilitators, networks, switches, processors, and banks can now position their payment cryptographic operations closer to their applications while reducing dependencies on auxiliary data centers with dedicated payment HSMs.\n  AWS Payment Cryptography is available in the following AWS Regions: Canada(Montreal), US East (Ohio, N. Virginia), US West (Oregon), Europe (Ireland, Frankfurt, London,Paris), Africa(Cape Town) and Asia Pacific (Singapore, Tokyo, Osaka, Mumbai,Hyderabad).\n  To start using the service, please download the latest AWS CLI/SDK and see the AWS Payment Cryptography user guide for more information.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-payment-cryptography-available-in-hyderabad-paris/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga",
        "now-available",
        "support",
        "new-region",
        "expansion"
      ]
    },
    {
      "id": "aws-news-f9c302bcebc4",
      "title": "AWS Marketplace now supports mandatory purchase orders and custom messaging",
      "description": "AWS Marketplace now supports mandatory purchase order requirements and custom messaging at the time of purchase, allowing organizations to strengthen their procurement governance. These capabilities help procurement, software asset management, and cloud governance teams enforce compliance policies while maintaining purchasing agility.\n  Administrators can now enforce their mandatory purchase order policy by requiring buyers to provide purchase orders when subscribing to products through AWS Marketplace. These requirements can be applied to purchases through a private and public offer across various pricing types. Additionally, administrators can add a custom message on the procurement page, providing guidance on policy requirements and support contacts. Organizations can implement purchase order requirements without custom messaging, use custom messaging to guide buyers through the procurement process, or combine both features for more comprehensive governance. These capabilities can also be used with Private Marketplace, which allows customers to create a curated catalog of approved products for specific users and groups within an AWS organization. This flexibility helps finance and procurement teams enforce compliance at the time of purchase, improve cost allocation accuracy, and streamline procurement-to-pay cycles.\n  These capabilities are available today in all AWS Regions where AWS Marketplace is supported.\n  For information on configuring purchase order requirements and custom messaging, refer to the AWS Marketplace Buyer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-marketplace-mandatory-purchase-orders-custom-messaging",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-a4d885726005",
      "title": "Amazon EC2 M8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) M8g instances are available in Asia Pacific (Thailand, Jakarta, Melbourne), and AWS Middle East (UAE) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 M8g instances are built for general-purpose workloads, such as application servers, microservices, gaming servers, midsize data stores, and caching fleets. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon M7g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. M8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 M8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-m8g-additional-regions/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-3d31af0ecae0",
      "title": "Amazon EC2 R8g instances now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8g instances are available in AWS Europe (Paris), and Asia Pacific (Hyderabad) regions. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 R8g instances are ideal for memory-intensive workloads such as databases, in-memory caches, and real-time big data analytics. These instances are built on the AWS Nitro System, which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.\n  AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. AWS Graviton4-based R8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 1.5TB) than Graviton3-based R7g instances. These instances are up to 30% faster for web applications, 40% faster for databases, and 45% faster for large Java applications compared to AWS Graviton3-based R7g instances. R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS).\n  To learn more, see Amazon EC2 R8g Instances. To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-r8g-instances-additional-regions/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a159bd5150c4",
      "title": "Amazon OpenSearch Service now offers a new multi-tier storage",
      "description": "Amazon OpenSearch Service now offers a new multi-tier storage option powered by OpenSearch Optimized Instances. This new architecture combines Amazon S3 cloud technology with local instance storage to deliver improved durability and performance. The new multi-tier architecture features two tiers: hot and warm. The hot tier handles frequently accessed data, while the warm tier leverages Amazon S3 for cost-effective storage of less frequently accessed data. \n  Until now, Amazon OpenSearch Service supported a warm tier through UltraWarm, which provided cost-effective storage for read-only data. The new warm tier powered by OpenSearch Optimized instances supports write operations, providing greater flexibility for data management. You can automate rotating data from hot to warm as it ages using Index State Management feature.\n \nFor warm tier deployments, customers can use OpenSearch Optimized (OI2) instances (size ‘large’ to ‘8xlarge’), with addressable warm of up to five times the local cache size. tandard Managed Storage charges apply for warm data. The new Multi-tier experience is available on OpenSearch 3.3 and above. For more information please refer to the documentation.\n  New Multi-Tier experience on OI2 instance family is now available on Amazon OpenSearch Service across 12 regions globally: US East (N. Virginia, Ohio), US West (Oregon), Canada (Central), Asia Pacific (Mumbai, Singapore, Sydney, Tokyo), Europe (Frankfurt, Ireland, London, Spain).  Please refer to the Amazon OpenSearch Service pricing page for pricing details",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/writeable-warm-tier-opensearch-optimized-instances/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-adc986ca71dc",
      "title": "AWS Security Incident Response is now available in ten additional AWS Regions",
      "description": "AWS Security Incident Response is now available to customers in ten additional opt-in AWS Regions: Africa (Cape Town), Asia Pacific (Hong Kong, Hyderabad, Jakarta, Melbourne), Europe (Zurich, Milan, Spain), Middle East (UAE, Bahrain). You can now use these additional regions to prepare for, respond to, and recover from security events faster and more effectively.\n  AWS Security Incident Response streamlines every step of the security incident response lifecycle through automated security finding monitoring and triage, AI-powered investigation, and containment capabilities. When specialized expertise is required, Security Incident Response gives you direct 24/7 access to a dedicated group of AWS security experts who respond to your request within minutes. This powerful combination of automation and expertise enables you to confidently scale your security operations, so you can focus on innovation and growth.\n  For more information, please visit the AWS Security Incident Response page and documentation for more information. See the Supported Configurations page for regional and language support.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/security-incident-response-ten-regions/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f8f0c1cb093c",
      "title": "AWS IAM Identity Center is now available in the Asia Pacific (Taipei) AWS Region",
      "description": "You can now deploy AWS IAM Identity Center in 37 AWS Regions, including Asia Pacific (Taipei).\n  IAM Identity Center is the recommended service for managing workforce access to AWS applications. It enables you to connect your existing source of workforce identities to AWS once and offer your users single sign on experience across AWS. It powers the personalized experiences offered by AWS applications, such as Amazon Q, and the ability to define and audit user-aware access to data in AWS services, such as Amazon Redshift. It can also help you manage access to multiple AWS accounts from a central place. IAM Identity Center is available at no additional cost in these AWS Regions.\n  To learn more about IAM Identity Center, visit the product detail page. To get started, see the IAM Identity Center user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-iam-identity-center-asia-pacific-taipei-region/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "redshift",
        "iam",
        "iam identity center",
        "now-available"
      ]
    },
    {
      "id": "aws-news-746dbc3dd116",
      "title": "Amazon EC2 C8i and C8i-flex instances are now available in the Asia Pacific (Singapore) Region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8i and C8i-flex instances are available in the Asia Pacific (Singapore) region. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. These C8i and C8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver up to 20% higher performance than C7i and C7i-flex instances, with even higher gains for specific workloads. The C8i and C8i-flex are up to 60% faster for NGINX web applications, up to 40% faster for AI deep learning recommendation models, and 35% faster for Memcached stores compared to C7i and C7i-flex.\n  C8i-flex are the easiest way to get price performance benefits for a majority of compute intensive workloads like web and application servers, databases, caches, Apache Kafka, Elasticsearch, and enterprise applications. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  C8i instances are a great choice for all memory-intensive workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. C8i instances offer 13 sizes including 2 bare metal sizes and the new 96xlarge size for the largest applications.\n  To get started, sign in to the AWS Management Console. Customers can purchase these instances via Savings Plans, On-Demand instances, and Spot instances. For more information about the new C8i and C8i-flex instances visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-c8i-c8i-flex-instances-singapore-region/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "kafka"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "kafka",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-92fff5b85f8f",
      "title": "Amazon Redshift Serverless announces the general availability of dual-stack mode supporting IPV6",
      "description": "Amazon Redshift Serverless announces the general availability of dual-stack mode that supports Internet Protocol version 6 (IPv6). This enhancement enables you to modernize your network infrastructure and meet the growing demands of internet connectivity.\n  Redshift Serverless supports configuring your Redshift workgroups with both IPv4 and IPv6 addresses (dual-stack) or IPv4-only configurations within your AWS Virtual Private Clouds (VPCs). You can enable IPv6 support when creating new Redshift Serverless workgroups or modify existing workgroups to support IPv6 addressing. With this capability, you can deploy Redshift warehouses in IPv6-enabled VPC subnets and configure network settings to support the expanding address space requirements of your applications. Your applications can now communicate with Redshift warehouses using either IPv4 or IPv6 protocols, ensuring compatibility with both existing and future network architectures.\n \nThis feature is available in all AWS commercial regions where Redshift Serverless is available. To get started, read the documentation and blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-redshift-serverless-announces-dual-stack-mode-ipv6/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "redshift"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "redshift",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-ab6f94cc5659",
      "title": "AWS Payment Cryptography is now available in Sydney with AS2805 support",
      "description": "Today, AWS Payment Cryptography has expanded to Australia (Sydney) Region, and now supports AS2805 functionality. This expansion represents the service's thirteenth AWS Region worldwide. With AS2805 capabilities customers can migrate more payment workloads to AWS while maintaining operability with other companies utilizing this standard.\n  Australia, New Zealand and several other countries rely on Australia Standards 2805 (AS2805) as a consistent approach for managing cryptography between organizations for card payments. Historically, these companies required Hardware Security Modules (HSM) to perform these operations in a compliant, compatible manner. AWS Payment Cryptography now provides equivalent functionality for node-to-node use cases in an elastic, scalable service, eliminating the operational burden of procuring and managing standalone hardware. Customers can leverage the service’s use of PCI-certified HSMs as part of their overall compliance programs while using APIs that integrate with AWS IAM and AWS CloudTrail.\n  AWS Payment Cryptography is available in the following AWS Regions: Canada (Montreal), US East (Ohio, N. Virginia), US West (Oregon), Europe (Ireland, Frankfurt, London), Africa (Cape Town), Asia Pacific (Singapore, Tokyo, Osaka, Mumbai) and Australia New Zealand (Sydney).\n  To start using the service, please download the latest AWS CLI/SDK and see the AWS Payment Cryptography user guide for more information including further compliance details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-payment-cryptography-in-sydney/",
      "pubDate": "2025-12-17T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "iam",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "iam",
        "organizations",
        "ga",
        "now-available",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-ea7c0f3a27c5",
      "title": "Reference guide for building a self-service analytics solution with Amazon SageMaker",
      "description": "In this post, we show how to use Amazon SageMaker Catalog to publish data from multiple sources, including Amazon S3, Amazon Redshift, and Snowflake. This approach enables self-service access while ensuring robust data governance and metadata management.",
      "link": "https://aws.amazon.com/blogs/big-data/reference-guide-for-building-a-self-service-analytics-solution-with-amazon-sagemaker/",
      "pubDate": "2025-12-16T21:47:23.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "s3",
        "redshift"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "redshift"
      ]
    },
    {
      "id": "aws-news-3721792acb1c",
      "title": "Governance by design: The essential guide for successful AI scaling",
      "description": "Picture this: Your enterprise has just deployed its first generative AI application. The initial results are promising, but as you plan to scale across departments, critical questions emerge. How will you enforce consistent security, prevent model bias, and maintain control as AI applications multiply?",
      "link": "https://aws.amazon.com/blogs/machine-learning/governance-by-design-the-essential-guide-for-successful-ai-scaling/",
      "pubDate": "2025-12-16T21:18:54.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-ee18d02e7e8f",
      "title": "How Tata Power CoE built a scalable AI-powered solar panel inspection solution with Amazon SageMaker AI and Amazon Bedrock",
      "description": "In this post, we explore how Tata Power CoE and Oneture Technologies use AWS services to automate the inspection process end-to-end.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-tata-power-coe-built-a-scalable-ai-powered-solar-panel-inspection-solution-with-amazon-sagemaker-ai-and-amazon-bedrock/",
      "pubDate": "2025-12-16T18:55:36.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-2ac0bf78247e",
      "title": "Unlocking video understanding with TwelveLabs Marengo on Amazon Bedrock",
      "description": "In this post, we'll show how the TwelveLabs Marengo embedding model, available on Amazon Bedrock, enhances video understanding through multimodal AI. We'll build a video semantic search and analysis solution using embeddings from the Marengo model with Amazon OpenSearch Serverless as the vector database, for semantic search capabilities that go beyond simple metadata matching to deliver intelligent content discovery.",
      "link": "https://aws.amazon.com/blogs/machine-learning/unlocking-video-understanding-with-twelvelabs-marengo-on-amazon-bedrock/",
      "pubDate": "2025-12-16T18:51:10.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "opensearch"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "opensearch"
      ]
    },
    {
      "id": "aws-news-ecb79e398964",
      "title": "Amazon Connect launches additional details within real-time metric alerts",
      "description": "Amazon Connect alerts on real-time metrics now provide the specific agents, queues, flows, or routing profiles that exceeded thresholds and triggered the alert. This enables managers to respond faster to customer experience and operational issues by eliminating the need to manually investigate the root cause of the alert. For example, alerts on elevated queue wait times now include the exact queues affected, so managers can reassign agents to those queues. These detailed alerts can be sent through email, tasks, and Amazon EventBridge.\n  This feature is available in all regions where Amazon Connect is offered. To learn more, please visit our documentation and our webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-connect-additional-details-real-time-metric-alerts/",
      "pubDate": "2025-12-16T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eventbridge"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eventbridge",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-06b34c0d447a",
      "title": "AWS Artifact enables access to previous versions of compliance reports",
      "description": "AWS Artifact now enables direct access to previous versions of AWS compliance reports, eliminating the need to contact AWS Support or account representatives. This self-service capability helps customers efficiently manage their compliance documentation requirements, particularly during audits and vendor assessments that require historical compliance evidence.\n  To access previous report versions, you need the \"artifact:ListReportVersions\" IAM permission, which is included in the AWS managed policy \"AWSArtifactReportsReadOnlyAccess\". If you're unable to view previous versions of reports in the AWS Artifact console, please contact your AWS account administrator to request this permission.\n  Once authorized, you can access previous versions of compliance reports (such as SOC, ISO, and C5) directly through the AWS Artifact console. Simply navigate to the reports page and select any report to view its available versions. The availability of previous report versions varies by compliance program, with some reports offering versions from multiple prior years while others may have more limited historical coverage.\n  This feature is now generally available in US East (N. Virginia) and AWS GovCloud (US-West) Regions.\n  To learn more about accessing previous versions of compliance reports, visit the AWS Artifact documentation. For general information about AWS Artifact, see the AWS Artifact product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-artifact-access-previous-versions-compliance-reports",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "iam",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f12f19beadac",
      "title": "AWS Security Incident Response introduces integration with Slack",
      "description": "AWS Security Incident Response now offers integration with the cloud-based team collaboration platform Slack, enabling you to prepare for, respond to, and recover from security events faster and more effectively while maintaining your existing notification and communication workflows. With the bidirectional integration, you can create and update cases in both the Security Incident Response console and Slack with automatic data replication. Each Security Incident Response case is represented as a dedicated Slack channel, while comments and attachments sync instantly. This gives responders immediate access to critical case information and enables more efficient collaboration regardless of tool preference.\n  The integration helps security teams engage faster and accelerate response times by automatically adding Security Incident Response watchers to the corresponding Slack channel. This integration is available as an open-source solution on GitHub, providing customers and partners the opportunity to customize and extend the functionality. The integration leverages EventBridge which allows customers to continue using their existing security incident management and notification tooling, while leveraging AWS Security Incident Response capabilities. The solution features a modular architecture, and includes guidance on how to use Amazon Q Developer, Kiro, or similar AI assistants that help make it easy to add new integration targets beyond Slack.\n  To get started with the AWS Security Incident Response Slack integration, visit our GitHub repository. Visit our technical documentation for Slack for implementation details. Learn more about AWS Security Incident Response in the service’s User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-security-incident-response-integration-slack",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "eventbridge"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "eventbridge",
        "ga",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-d6f1e4f1ae67",
      "title": "Amazon EC2 M8i instances are now available in additional Regions",
      "description": "Starting today, Amazon EC2 M8i instances are now available in Asia Pacific (Seoul), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Singapore), and Canada (Central) Regions. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. The M8i offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver up to 20% better performance than M7i instances, with even higher gains for specific workloads. The M8i instances are up to 30% faster for PostgreSQL databases, up to 60% faster for NGINX web applications, and up to 40% faster for AI deep learning recommendation models compared to M7i instances.\n  M8i instances are a great choice for all general purpose workloads, especially for workloads that need the largest instance sizes or continuous high CPU usage. The SAP-certified M8i instances offer 13 sizes including 2 bare metal sizes and the new 96xlarge size for the largest applications.\n  To get started, sign in to the AWS Management Console. For more information about the new instances, visit the M8i instance page or visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-m8i-instances-additional-regions",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-8d6172a91323",
      "title": "AWS reduces publishing time for Carbon Footprint Data to 21 days or Less",
      "description": "AWS is now publishing your carbon footprint data in 21 days or less. Previously, the carbon footprint data was published with up to a three month data lag. Now, you have access to your carbon footprint data with estimates published between the 15th and the 21st of the month following your usage.\n  With carbon footprint data available sooner, you have the insights needed to make more timely decisions about how and where your applications are running and identify opportunities to reduce emissions and costs through improved resource efficiency. Also, the CCFT dashboard maintains 38 months of data so you can view your carbon usage trends over time.\n  To view your carbon footprint data, navigate to your carbon emissions data through the AWS Billing and Cost Management console. For more information about CCFT visit the CCFT capabilities and features page, review the CCFT user guides, and learn more by visiting the CCFT webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-reduces-publishing-time-carbon-footprint-data",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-eea5558b8e2f",
      "title": "Amazon SageMaker AI is now available in Asia Pacific (New Zealand)",
      "description": "Starting today, you can build, train, and deploy machine learning (ML) models in Asia Pacific (New Zealand).\n  Amazon SageMaker AI is a fully managed platform that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker AI removes the heavy lifting from each step of the machine learning process to make it easier to develop high quality models.\n \nTo learn more and get started, see SageMaker AI documentation and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-ai-asia-pacific-new-zealand",
      "pubDate": "2025-12-16T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "now-available"
      ]
    },
    {
      "id": "aws-news-5ba02da780e9",
      "title": "Amazon Quick Suite now supports memory for chat agents",
      "description": "We are announcing memory for chat agents in Amazon Quick Suite – a feature that allows users to get personalized responses based on their previous conversations. With this feature, Quick Suite remembers the preferences users specify in chat and generate responses that are tailored to them. Users can also view their inferred preferences and remove any memory they don’t want Quick chat agents to use.\n  Previously, chat users needed to repeat their preferences around response format, acronyms, dashboards, and integrations in every conversation. They also had to clarify ambiguous topics and entities in chat, increasing the tedious back and forth needed to get accurate and insightful responses. Memory addresses this pain point by remembering facts and details about users in a way that ensures responses provided to users continuously learn and improve. Users also control what Quick Suite remembers about them – all the memories are viewable and removable by users, and users have the choice to start chat in Private Mode in which conversations are not used to infer memories.\n  Memory in Quick Suite chat agents is available in US East (N. Virginia) and US West (Oregon). To learn more, visit the Amazon Quick Suite User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-quick-suite-memory-chat-agents/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "rds",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-0b94c99ea07b",
      "title": "Amazon EC2 M8i-flex instances are now available in Asia Pacific (Sydney) Region",
      "description": "Starting today, Amazon EC2 M8i-flex instances are now available in Asia Pacific (Sydney) Region. These instances are powered by custom Intel Xeon 6 processors, available only on AWS, delivering the highest performance and fastest memory bandwidth among comparable Intel processors in the cloud. The M8i-flex instances offer up to 15% better price-performance, and 2.5x more memory bandwidth compared to previous generation Intel-based instances. They deliver up to 20% better performance than M7i-flex instances, with even higher gains for specific workloads. The M8i-flex instances are up to 30% faster for PostgreSQL databases, up to 60% faster for NGINX web applications, and up to 40% faster for AI deep learning recommendation models compared to M7i-flex instances.\n  M8i-flex instances are the easiest way to get price performance benefits for a majority of general-purpose workloads like web and application servers, microservices, small and medium data stores, virtual desktops, and enterprise applications. They offer the most common sizes, from large to 16xlarge, and are a great first choice for applications that don't fully utilize all compute resources.\n  To get started, sign in to the AWS Management Console. For more information about the new instances, visit the M8i-flex instance page or visit the AWS News blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-m8i-flex-instances-sydney-region/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-143d7e18abbc",
      "title": "Amazon Quick Suite browser extension now supports Quick Flows",
      "description": "Amazon Quick Suite browser extension now supports Amazon Quick Flows, enabling you to run workflows directly within your web browser, eliminating the need to manually extract information from each web page. You can invoke workflows that you've created or that have been shared with you, and pass web page content as input—all without leaving your browser.\n  This capability is great for completing routine tasks such as analyzing contract documents to extract key terms, or generating weekly reports from project dashboards that automatically notify stakeholders.\n  Quick Flows in browser extension is available now in US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland). There are no additional charges for using the browser extension beyond standard Quick Flows usage.\n  To get started, visit your Chrome, Firefox or Edge store page to install browser extension and sign in with your Quick Suite account. Once you sign in, look for the Flows icon below the chat box to invoke your flows. To learn more about invoking Quick Flows in browser extension, please visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/quick-suite-browser-extension-quick-flows/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-a0896a92b827",
      "title": "AWS Clean Rooms publishes events for member invitations and table readiness to EventBridge",
      "description": "AWS Clean Rooms now publishes events to Amazon EventBridge for new member invitations and table readiness, delivering real-time insights and increasing transparency to collaboration members. Invited members to a collaboration now receive an EventBridge notification when invited to a Clean Rooms collaboration, making it easier for members to review new invitations and join collaborations. Collaboration members are also notified when AWS Entity Resolution resources are associated to a collaboration, such as ID mapping tables and ID namespaces, enabling you to automatically start analysis that uses related records across collaborators’ datasets. For example, when a publisher invites an advertiser to a collaboration, the publisher can automatically run their media planning analyses as soon as the advertiser has created their ID mapping table in the collaboration, reducing time-to-action from hours to minutes and increasing transparency between collaboration members.\n  With AWS Clean Rooms, customers can create a secure data clean room in minutes and collaborate with any company on AWS or Snowflake to generate unique insights about advertising campaigns, investment decisions, and research and development. For more information about the AWS Regions where AWS Clean Rooms is available, see the AWS Regions table. To learn more about collaborating with AWS Clean Rooms, visit AWS Clean Rooms or AWS Entity Resolution.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/clean-rooms-events-member-invitations-table-readiness/",
      "pubDate": "2025-12-16T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "eventbridge"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "eventbridge"
      ]
    },
    {
      "id": "aws-news-b77817f9e138",
      "title": "Introducing the Apache Spark troubleshooting agent for Amazon EMR and AWS Glue",
      "description": "In this post, we show you how the Apache Spark troubleshooting agent helps analyze Apache Spark issues by providing detailed root causes and actionable recommendations. You’ll learn how to streamline your troubleshooting workflow by integrating this agent with your existing monitoring solutions across Amazon EMR and AWS Glue.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-the-apache-spark-troubleshooting-agent-for-amazon-emr-and-aws-glue/",
      "pubDate": "2025-12-16T02:02:46.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr",
        "glue"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "emr",
        "glue"
      ]
    },
    {
      "id": "aws-news-45a9cad1a252",
      "title": "Introducing Apache Spark upgrade agent for Amazon EMR",
      "description": "In this post, you learn how to assess your existing Amazon EMR Spark applications, use the Spark upgrade agent directly from the Kiro IDE, upgrade a sample e-commerce order analytics Spark application project (including build configs, source code, tests, and data quality validation), and review code changes before rolling them out through your CI/CD pipeline.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-apache-spark-upgrade-agent-for-amazon-emr/",
      "pubDate": "2025-12-16T01:04:59.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-c96efd75c6aa",
      "title": "Accelerate Apache Hive read and write on Amazon EMR using enhanced S3A",
      "description": "In this post, we demonstrate how Apache Hive on Amazon EMR 7.10 delivers significant performance improvements for both read and write operations on Amazon S3.",
      "link": "https://aws.amazon.com/blogs/big-data/accelerate-apache-hive-read-and-write-on-amazon-emr-using-enhanced-s3a/",
      "pubDate": "2025-12-15T21:55:33.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "s3",
        "emr",
        "improvement"
      ]
    },
    {
      "id": "aws-news-95cd816fd5ef",
      "title": "Amazon EMR HBase on Amazon S3 transitioning to EMR S3A with comparable EMRFS performance",
      "description": "Starting with version 7.10, Amazon EMR is transitioning from EMR File System (EMRFS) to EMR S3A as the default file system connector for Amazon S3 access. This transition brings HBase on Amazon S3 to a new level, offering performance parity with EMRFS while delivering substantial improvements, including better standardization, improved portability, stronger community support, improved performance through non-blocking I/O, asynchronous clients, and better credential management with AWS SDK V2 integration. In this post, we discuss this transition and its benefits.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-emr-hbase-on-amazon-s3-transitioning-to-emr-s3a-with-comparable-emrfs-performance/",
      "pubDate": "2025-12-15T21:20:04.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "s3",
        "emr",
        "improvement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-f91bea5e9dd1",
      "title": "Checkpointless training on Amazon SageMaker HyperPod: Production-scale training with faster fault recovery",
      "description": "In this post, we introduce checkpointless training on Amazon SageMaker HyperPod, a paradigm shift in model training that reduces the need for traditional checkpointing by enabling peer-to-peer state recovery. Results from production-scale validation show 80–93% reduction in recovery time (from 15–30 minutes or more to under 2 minutes) and enables up to 95% training goodput on cluster sizes with thousands of AI accelerators.",
      "link": "https://aws.amazon.com/blogs/machine-learning/checkpointless-training-on-amazon-sagemaker-hyperpod-production-scale-training-with-faster-fault-recovery/",
      "pubDate": "2025-12-15T19:45:50.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-b436aaca5181",
      "title": "How Socure achieved 50% cost reduction by migrating from self-managed Spark to Amazon EMR Serverless",
      "description": "Socure is one of the leading providers of digital identity verification and fraud solutions. Socure’s data science environment includes a streaming pipeline called Transaction ETL (TETL), built on OSS Apache Spark running on Amazon EKS. TETL ingests and processes data volumes ranging from small to large datasets while maintaining high-throughput performance. In this post, we show how Socure was able to achieve 50% cost reduction by migrating the TETL streaming pipeline from self-managed spark to Amazon EMR serverless.",
      "link": "https://aws.amazon.com/blogs/big-data/how-socure-achieved-50-cost-reduction-by-migrating-from-self-managed-spark-to-amazon-emr-serverless/",
      "pubDate": "2025-12-15T19:23:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr",
        "eks"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr",
        "eks"
      ]
    },
    {
      "id": "aws-news-42a927cd723a",
      "title": "Adaptive infrastructure for foundation model training with elastic training on SageMaker HyperPod",
      "description": "Amazon SageMaker HyperPod now supports elastic training, enabling your machine learning (ML) workloads to automatically scale based on resource availability. In this post, we demonstrate how elastic training helps you maximize GPU utilization, reduce costs, and accelerate model development through dynamic resource adaptation, while maintain training quality and minimizing manual intervention.",
      "link": "https://aws.amazon.com/blogs/machine-learning/adaptive-infrastructure-for-foundation-model-training-with-elastic-training-on-sagemaker-hyperpod/",
      "pubDate": "2025-12-15T18:12:22.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "support"
      ]
    },
    {
      "id": "aws-news-d57b77f74852",
      "title": "Amazon Elastic VMware Service (Amazon EVS) is now available in additional Regions",
      "description": "Today, we're announcing that Amazon Elastic VMware Service (Amazon EVS) is now available in all availability zones in the US West (N. California), Asia Pacific (Hyderabad), Asia Pacific (Malaysia), Canada West (Calgary), Europe (Milan), Mexico (Central), and South America (São Paulo) Regions. This expansion provides more options to leverage the scale and flexibility of AWS for running your VMware workloads in the cloud.\n  Amazon EVS lets you run VMware Cloud Foundation (VCF) directly within your Amazon Virtual Private Cloud (VPC) on EC2 bare-metal instances, powered by AWS Nitro. Using either our step-by-step configuration workflow or the AWS Command Line Interface (CLI) with automated deployment capabilities, you can set up a complete VCF environment in just a few hours. This rapid deployment enables faster workload migration to AWS, helping you eliminate aging infrastructure, reduce operational risks, and meet critical timelines for exiting your data center.\n  The added availability in these Regions gives your VMware workloads lower latency through closer proximity to your end users, compliance with data residency or sovereignty requirements, and additional high availability and resiliency options for your enhanced redundancy strategy.\n  To get started, visit the Amazon EVS product detail page and user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-evs-available-in-additional-regions/",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ec2",
        "ga",
        "now-available",
        "expansion"
      ]
    },
    {
      "id": "aws-news-563e37119679",
      "title": "Amazon Managed Service for Apache Flink is now available in AWS Asia Pacific (Auckland) Region",
      "description": "Starting today, customers can use Amazon Managed Service for Apache Flink in Asia Pacific (Auckland) Region to build real-time stream processing applications.\n  Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon Simple Storage Service (Amazon S3), custom integrations, and more using built-in connectors.\n  You can learn more about Amazon Managed Service for Apache Flink here. For Amazon Managed Service for Apache Flink region availability, refer to the AWS Region Table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-managed-service-apache-flink-aws-asia-pacific-auckland-region/",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-29dfac7f5a0b",
      "title": "Announcing cost allocation using users’ attributes",
      "description": "AWS announces a new cost allocation feature that uses existing workforce user attributes like cost center, division, organization, and department to track and analyze AWS application usage and cost. This new capability enables customers to allocate per-user monthly subscription and on-demand fees of AWS applications, such as Amazon Q Business, Amazon Q Developer, and Amazon QuickSight, to respective internal business units.\n  Customers should import their workforce users’ attributes to IAM Identity Center, the recommended service for managing workforce access to AWS applications. After importing the attributes, customers can enable one or more of these attributes as cost allocation tags from the AWS Billing and Cost Management console. When users access AWS applications, their usage and cost are automatically recorded with selected attributes. Cloud Financial Operations (FinOps) professionals can view and analyze costs in AWS Cost Explorer and AWS CUR 2.0, gaining visibility into how different teams drive AWS usage and costs.\n  Support for cost allocation using user attributes is generally available in all AWS Regions, excluding GovCloud (US) Regions and China (Beijing) and China (Ningxia) Regions.\n  To learn more, see organizing and tracking cost using AWS cost allocation tags.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/cost-allocation-using-users-attributes",
      "pubDate": "2025-12-15T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "q business",
        "iam",
        "iam identity center",
        "quicksight"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "q business",
        "iam",
        "iam identity center",
        "quicksight",
        "generally-available",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-91e426ea990a",
      "title": "Customize agent workflows with advanced orchestration techniques using Strands Agents",
      "description": "In this post, we explore two powerful orchestration patterns implemented with Strands Agents. Using a common set of travel planning tools, we demonstrate how different orchestration strategies can solve the same problem through distinct reasoning approaches,",
      "link": "https://aws.amazon.com/blogs/machine-learning/customize-agent-workflows-with-advanced-orchestration-techniques-using-strands-agents/",
      "pubDate": "2025-12-15T17:35:47.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-9eb3e2112316",
      "title": "Operationalize generative AI workloads and scale to hundreds of use cases with Amazon Bedrock – Part 1: GenAIOps",
      "description": "In this first part of our two-part series, you'll learn how to evolve your existing DevOps architecture for generative AI workloads and implement GenAIOps practices. We'll showcase practical implementation strategies for different generative AI adoption levels, focusing on consuming foundation models.",
      "link": "https://aws.amazon.com/blogs/machine-learning/operationalize-generative-ai-workloads-and-scale-to-hundreds-of-use-cases-with-amazon-bedrock-part-1-genaiops/",
      "pubDate": "2025-12-15T17:31:53.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-1ddf08efc0c4",
      "title": "Applying data loading best practices for ML training with Amazon S3 clients",
      "description": "In this post, we present practical techniques and recommendations for optimizing throughput in ML training workloads that read data directly from Amazon S3 general purpose buckets.",
      "link": "https://aws.amazon.com/blogs/machine-learning/applying-data-loading-best-practices-for-ml-training-with-amazon-s3-clients/",
      "pubDate": "2025-12-15T17:29:31.000Z",
      "source": "mlBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "s3"
      ]
    },
    {
      "id": "aws-news-93e908d04930",
      "title": "AWS Weekly Roundup: Amazon ECS, Amazon CloudWatch, Amazon Cognito and more (December 15, 2025)",
      "description": "Can you believe it? We’re nearly at the end of 2025. And what a year it’s been! From re:Invent recap events, to AWS Summits, AWS Innovate, AWS re:Inforce, Community Days, and DevDays and, recently, adding that cherry on the cake, re:Invent 2025, we have lived through a year filled with exciting moments and technology advancements […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ecs-amazon-cloudwatch-amazon-cognito-and-more-december-15-2025/",
      "pubDate": "2025-12-15T16:42:05.000Z",
      "source": "newsBlog",
      "services": [
        "nova",
        "ecs",
        "cloudwatch"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "nova",
        "ecs",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-7790bd8307b4",
      "title": "Amazon EKS introduces enhanced network security policies",
      "description": "Today, we’re announcing enhanced network policy capabilities in Amazon Elastic Kubernetes Service (EKS), allowing customers to improve the network security posture for their Kubernetes workloads and their integrations with cluster-external destinations. This enhancement builds on network segmentation features previously supported in EKS. Now you can centrally enforce network access filters across the entire cluster, as well as leverage Domain Name System (DNS) based policies to secure egress traffic from your cluster’s environment.\n  As customers continue to scale their application environments using EKS, network traffic isolation is increasingly fundamental for preventing unauthorized access to resources inside and outside the cluster. To address this, EKS introduced support for Kubernetes NetworkPolicies in the Amazon VPC Container Network Interface (VPC CNI) plugin, allowing you to segment pod-to-pod communication at a namespace level. Now you can further strengthen the defensive posture for your Kubernetes network environment by centrally managing network filters for the whole cluster. Also, cluster admins now have a more stable and predictable approach for preventing unauthorized access to cluster-external resources in the cloud or on-prem using egress rules that filter traffic to external endpoints based on their Fully Qualified Domain Name (FQDN).\n  These new network security features are available in all commercial AWS Regions for new EKS clusters running Kubernetes version 1.29 or later, with support for existing clusters to follow in the coming weeks. ClusterNetworkPolicy is available in all EKS cluster launch modes using VPC CNI v1.21.0 or later. DNS-based policies are only supported in EKS Auto Mode-launched EC2 instances. To learn more, visit the Amazon EKS documentation or read the launch blog post here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-eks-enhanced-network-security-policies",
      "pubDate": "2025-12-15T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "eks",
        "launch",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-fb913b7afc1a",
      "title": "AWS Billing and Cost Management now supports PDF export and CSV data download for Dashboards",
      "description": "Today, AWS announces PDF export and CSV data download capabilities for AWS Billing and Cost Management Dashboards. These new features enable you to export your customized dashboards as PDF files for offline analysis and sharing, and download individual widget data in CSV format for detailed examination in spreadsheet applications. With these capabilities, you now have more ways to distribute AWS cost insights across your organization, in addition to sharing dashboards with can-view or can-edit access.\n  Billing and Cost Management Dashboards allows you to export entire dashboards or individual widgets as PDF files directly from the console, eliminating the need for screenshots or manual formatting. The PDF export feature provides formatted reports that maintain consistent appearance and preserve dashboard layouts, making them ideal for sharing with stakeholders during board meetings, reviews, or strategic planning sessions. For detailed data analysis needs, you can export individual widget data in CSV format, enabling analysts to perform granular examination of specific cost metrics in their preferred spreadsheet tools.\n  AWS Billing and Cost Management Dashboards PDF and CSV export features are available at no additional cost in all AWS commercial Regions, excluding AWS China Regions.\n  To get started, visit the AWS Billing and Cost Management console and select \"Dashboards\" from the left navigation menu. For more information, see the AWS Billing and Cost Management Dashboards export user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-billing-cost-management-pdf-export-csv-data-download-dashboards",
      "pubDate": "2025-12-15T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-71196cd1c0ae",
      "title": "ACM now supports automated certificate management for Kubernetes",
      "description": "AWS Certificate Manager (ACM) now automates certificate provisioning and distribution for Kubernetes workloads through AWS Controllers for Kubernetes (ACK). Previously, ACM automated certificate management for AWS-integrated services like Application Load Balancers and CloudFront. However, using ACM certificates with applications terminating TLS in Kubernetes required manual steps: exporting certificates and private keys via API, creating Kubernetes Secrets, and updating them at renewal. This integration extends ACM's automation to any Kubernetes workload for both public and private certificates, enabling you to manage certificates using native Kubernetes APIs.\n  With ACK, you define certificates as Kubernetes resources, and the ACK controller automates the complete certificate lifecycle: requesting certificates from ACM, exporting them after validation, updating Kubernetes Secrets with the certificate and private key, and automatically updating those Secrets at renewal. This enables you to use ACM exportable public certificates (launched in June 2025) for internet-facing workloads or AWS Private CA private certificates for internal services in Amazon EKS or other Kubernetes environments. Use cases include terminating TLS in application pods (NGINX, custom applications), securing service mesh communication (Istio, Linkerd), and managing certificates for third-party ingress controllers (NGINX Ingress, Traefik). You can also distribute certificates to hybrid and edge Kubernetes environments.\n  This feature is available in all commercial, AWS GovCloud (US), and AWS China regions where ACM is available.\n To learn more, visit the GitHub link or read our documentation and our pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/acm-automated-certificate-management-kubernetes/",
      "pubDate": "2025-12-15T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "cloudfront"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks",
        "cloudfront",
        "launch",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-26be0fdf4fa3",
      "title": "Amazon EC2 M7a instances are now available in the Europe (London) Region",
      "description": "Starting today, the general-purpose Amazon EC2 M7a instances are now available in AWS Europe (London) Region. M7a instances, powered by 4th Gen AMD EPYC processors (code-named Genoa) with a maximum frequency of 3.7 GHz, deliver up to 50% higher performance compared to M6a instances.\n \nWith this additional region, M7a instances are available in the following AWS Regions: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney, Tokyo), and Europe (Frankfurt, Ireland, Spain, Stockholm, London). These instances can be purchased as Savings Plans, Reserved, On-Demand, and Spot instances. To get started, visit the AWS Management Console, AWS Command Line Interface (CLI), and AWS SDKs. To learn more, visit the M7a instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-m7a-instances-europe-london-region/",
      "pubDate": "2025-12-15T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "now-available"
      ]
    },
    {
      "id": "aws-news-145bc0082f15",
      "title": "How Bayer transforms Pharma R&D with a cloud-based data science ecosystem using Amazon SageMaker",
      "description": "In this post, we discuss how Bayer AG used the next generation of Amazon SageMaker to build a cloud-based Pharma R&D Data Science Ecosystem (DSE) that unified data ingestion, storage, analytics, and AI/ML workflows.",
      "link": "https://aws.amazon.com/blogs/big-data/how-bayer-transforms-pharma-rd-with-a-cloud-based-data-science-ecosystem-using-amazon-sagemaker/",
      "pubDate": "2025-12-12T23:06:25.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-36722fddcb63",
      "title": "Building zero trust generative AI applications in healthcare with AWS Nitro Enclaves",
      "description": "In healthcare, generative AI is transforming how \nmedical professionals analyze data, \nsummarize clinical notes, and \ngenerate insights to improve patient outcomes. From \nautomating medical documentation to assisting in \ndiagnostic reasoning, large language models (LLMs) have the potential to augment clinical workflows and accelerate research. However, these innovations also introduce significant privacy, security, and intellectual property challenges.",
      "link": "https://aws.amazon.com/blogs/compute/building-zero-trust-generative-ai-applications-in-healthcare-with-aws-nitro-enclaves/",
      "pubDate": "2025-12-12T19:06:03.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-27b9a3890ec7",
      "title": "Building a voice-driven AWS assistant with Amazon Nova Sonic",
      "description": "In this post, we explore how to build a sophisticated voice-powered AWS operations assistant using Amazon Nova Sonic for speech processing and Strands Agents for multi-agent orchestration. This solution demonstrates how natural language voice interactions can transform cloud operations, making AWS services more accessible and operations more efficient.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-a-voice-driven-aws-assistant-with-amazon-nova-sonic/",
      "pubDate": "2025-12-12T18:07:57.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-bf9d1270943d",
      "title": "AWS DataSync increases scalability and performance for on-premises file transfers",
      "description": "AWS DataSync Enhanced mode now supports data transfers between on-premises file servers and Amazon S3, enabling customers to transfer datasets that scale to virtually unlimited numbers of files at higher levels of performance than DataSync Basic mode.\n  AWS DataSync is a secure, high-speed file transfer service that optimizes data movement over a network. Enhanced mode uses parallel processing to deliver higher performance and scalability for datasets of any size, while removing file count limitations and providing detailed transfer metrics for better monitoring and management. Previously, Enhanced mode was available for data transfers between Amazon S3 locations and for multicloud transfers. This launch extends the capabilities of Enhanced mode to support transfers between on-premises NFS or SMB file servers, and Amazon S3. Using Enhanced mode, customers can accelerate generative AI workloads by rapidly moving training datasets to AWS, power data lake analytics by synchronizing on-premises data with cloud-based pipelines, and drive large-scale migrations for archival and cloud modernization.\n  This new capability is available in all AWS Regions where AWS DataSync is offered. To get started, visit the AWS DataSync console. For more information, see the AWS DataSync documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-datasync-scalability-performance-on-premises-file-transfers",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "launch",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-e86106073841",
      "title": "AWS Shield network security director now supports multi-account analysis",
      "description": "Today, AWS Shield announces multi-account network security management and automated network analysis for network security director, which is currently in preview. AWS Shield network security director provides visibility into the AWS resources in your AWS organization, identifies missing or misconfigured network security services, and recommends remediation steps.\n  With network security director, you can specify a delegated administrator account from which you can start continuous network analysis for multiple accounts or organizational units in your AWS Organization. You can then centrally view each account’s network topology, network security findings, and recommended remediations for missing or misconfigured network security services. You can also easily summarize and report on the network security misconfigurations identified by AWS Shield network security director from within Amazon Q Developer in the AWS Management Console and chat applications.\n  AWS Shield network security director is also now available in five additional AWS regions: Europe (Ireland), Europe (Frankfurt), Asia Pacific (Hong Kong), Asia Pacific (Singapore), and Australia (Sydney).\n  To learn more, visit the overview page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-shield-network-security-director-multi-account-analysis",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "preview",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-a6f6576e96fe",
      "title": "Amazon MSK Replicator is now available in ten additional AWS Regions",
      "description": "You can now use Amazon MSK Replicator to replicate streaming data across Amazon Managed Streaming for Apache Kafka (Amazon MSK) clusters in ten additional AWS Regions: Middle East (Bahrain), Middle East (UAE), Asia Pacific (Jakarta), Asia Pacific (Hong Kong), Asia Pacific (Osaka), Asia Pacific (Melbourne), Africa (Cape Town), Europe (Milan), Europe (Zurich) and Israel (Tel Aviv). \n  MSK Replicator is a feature of Amazon MSK that enables you to reliably replicate data across Amazon MSK clusters in different or the same AWS Region(s) in a few clicks. With MSK Replicator, you can easily build regionally resilient streaming applications for increased availability and business continuity. MSK Replicator provides automatic asynchronous replication across MSK clusters, eliminating the need to write custom code, manage infrastructure, or setup cross-region networking. MSK Replicator automatically scales the underlying resources so that you can replicate data on-demand without having to monitor or scale capacity. MSK Replicator also replicates the necessary Kafka metadata including topic configurations, Access Control Lists (ACLs), and consumer group offsets. If an unexpected event occurs in a region, you can failover to the other AWS Region and seamlessly resume processing.\n  You can get started with MSK Replicator from the Amazon MSK console or the Amazon CLI. With this launch, MSK Replicator is now available in thirty five AWS Regions. To learn more, visit the MSK Replicator documentation, product page, and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-msk-replicator-additional-aws-regions",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "kafka",
        "msk",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a3b184f0ddfd",
      "title": "Amazon EMR Managed Scaling is now available in 7 additional AWS regions",
      "description": "We are excited to announce that Amazon EMR Managed Scaling is now available for EMR on EC2 customers in the Asia Pacific (Malaysia, Melbourne, New Zealand, Taipei, Thailand), Canada West (Calgary), and Mexico (Central) AWS Regions. Amazon EMR Managed Scaling automatically resizes the EC2 instances in your EMR cluster for the best performance at the lowest possible cost.\n  With Amazon EMR Managed Scaling, you simply specify the minimum and maximum compute limits for your clusters, and Amazon EMR on EC2 automatically resizes your cluster for optimal performance and resource utilization. Amazon EMR Managed Scaling constantly monitors key workload-related metrics and uses an algorithm that optimizes the cluster size for the best resource utilization. Using this algorithm, Amazon EMR can scale the EC2 cluster up during peaks and scale it down during idle periods, reducing your costs and optimizing cluster capacity for the best performance. Amazon EMR Managed Scaling can also be used with Amazon EC2 Spot Instances, that lets you take advantage of unused EC2 capacity for a discount when compared to on-demand prices.\n  Amazon EMR Managed Scaling is now available in all AWS commercial regions.\n  Amazon EMR Managed Scaling is supported for Apache Spark, Apache Hive and YARN-based workloads on Amazon EMR on EC2 versions 6.14 and above. To learn more and to get started, visit the Amazon EMR Managed Scaling user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-emr-managed-scaling-additional-regions",
      "pubDate": "2025-12-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "emr"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "emr",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-55630eadf2b3",
      "title": "Validate best practice compliance for SAP ABAP applications with AWS Systems Manager",
      "description": "AWS Systems Manager (AWS SSM) Configuration Manager now allows you to automatically test SAP ABAP based applications on AWS against best practices defined in the AWS Well-Architected Framework SAP Lens.\n  Keeping SAP applications optimally configured requires SAP administrators to stay current with best practices from multiple sources including AWS, SAP, and operating system vendors and manually check their configurations to validate adherence. AWS SSM Configuration Manager automatically assesses SAP applications running on AWS against these standards, proactively identifying misconfigurations and recommending specific remediation steps, allowing you to make the necessary changes before potential impacts to business operations. With this launch, configuration checks can be scheduled or run on-demand for SAP HANA and ABAP applications.\n  SSM for SAP Configuration Manager is available in AWS Regions where SSMSAP is available.\n  To learn more, read the launch blog, or refer to the AWS Systems Manager for SAP documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/compliance-sap-abap-systems-manager/",
      "pubDate": "2025-12-12T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-38954b7fb804",
      "title": "Amazon EC2 X2iedn instances now available in AWS Europe (Zurich)  region",
      "description": "Starting today, memory-optimized Amazon Compute Cloud (Amazon EC2) X2iedn instances are available in AWS Europe (Zurich) region. These instances, powered by 3rd generation Intel Xeon Scalable Processors and built with AWS Nitro System, are designed for memory-intensive workloads. They deliver improvements in performance, price performance, and cost per GiB of memory compared to previous generation X1e instances. These instances are SAP-certified for running Business Suite on HANA, SAP S/4HANA, Data Mart Solutions on HANA, Business Warehouse on HANA, SAP BW/4HANA, and SAP NetWeaver workloads on any database.\n  To learn more, visit the EC2 X2i Instances Page, or connect with your AWS Support contacts.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-x2iedn-instances-zurich-region/",
      "pubDate": "2025-12-12T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "now-available",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-f9d2d3e1e71b",
      "title": "AWS DataSync introduces Terraform support for Enhanced mode",
      "description": "The AWS DataSync Terraform module now supports Enhanced mode for transfers between S3 locations, making it easier for you to set up high-performance data transfers at scale.\n  AWS DataSync is a secure, high-speed file transfer service that optimizes data movement over a network. Enhanced mode uses parallel processing to deliver higher performance and scalability for datasets of any size, while removing file count limitations and providing detailed transfer metrics for better monitoring and management. You can now use Terraform to automatically provision DataSync tasks configured for Enhanced mode. This eliminates manual configuration steps that can be time-consuming and error-prone, while giving you a consistent, repeatable, version-controlled deployment process that can scale across your organization.\n  You can access the AWS DataSync Terraform module on GitHub or through the Terraform Registry.\n  To learn more about DataSync, see the AWS DataSync documentation. To see all Regions where DataSync is available, visit the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/datasync-terraform-enhanced-mode/",
      "pubDate": "2025-12-12T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-b15681b1f2c8",
      "title": "Amazon EC2 X2iedn instances now available in AWS Asia Pacific (Thailand) region",
      "description": "Starting today, memory-optimized Amazon Compute Cloud (Amazon EC2) X2iedn instances are available in AWS Asia Pacific (Thailand) region. These instances, powered by 3rd generation Intel Xeon Scalable Processors and built with AWS Nitro System, are designed for memory-intensive workloads. They deliver improvements in performance, price performance, and cost per GiB of memory compared to previous generation X1e instances. These instances are SAP-certified for running Business Suite on HANA, SAP S/4HANA, Data Mart Solutions on HANA, Business Warehouse on HANA, SAP BW/4HANA, and SAP NetWeaver workloads on any database.\n \nTo learn more, visit the EC2 X2i Instances Page, or connect with your AWS Support contacts.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-x2iedn-instances-thailand-region/",
      "pubDate": "2025-12-12T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "now-available",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-6fe4eb3af4c2",
      "title": "AWS Elastic Beanstalk is now available in additional regions",
      "description": "We are excited to announce the general availability of AWS Elastic Beanstalk in Asia Pacific (New Zealand) (Melbourne), (Malaysia), (Hyderabad), Canada West (Calgary), and Europe (Zurich).\n  AWS Elastic Beanstalk is a service that simplifies application deployment and management on AWS. The service automatically handles deployment, capacity provisioning, load balancing, auto-scaling, and application health monitoring, allowing developers to focus on writing code.\n  For a complete list of regions and service offerings, see AWS Regions.\n  To get started on AWS Elastic Beanstalk, see the AWS Elastic Beanstalk Developer Guide. To learn more about Elastic Beanstalk, visit the Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-beanstalk-additional-regions/",
      "pubDate": "2025-12-12T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-c6a98dee6bf6",
      "title": "Amazon Aurora DSQL now supports cluster creation in seconds",
      "description": "Amazon Aurora DSQL now supports faster cluster creation, reducing setup time from minutes to seconds.\n  With cluster creation now in seconds, developers can instantly provision Aurora DSQL databases to rapidly prototype new ideas. Developers can use the integrated query editor in the AWS console to immediately start building without needing to configure external clients or connect through the Aurora DSQL Model Context Protocol (MCP) server to enable AI-powered development tools. Whether prototyping or running production workloads, Aurora DSQL delivers virtually unlimited scalability, active-active high availability, zero infrastructure management, and pay-for-what-you-use pricing, ensuring your database effortlessly scales alongside your application needs.\n  This enhancement is available in all Regions where Aurora DSQL is offered. Get started with Aurora DSQL for free with the AWS Free Tier. To learn more, visit the Aurora DSQL webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-aurora-dsql-cluster-creation-in-seconds",
      "pubDate": "2025-12-11T21:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-7b9f7a2bf518",
      "title": "How Harmonic Security improved their data-leakage detection system with low-latency fine-tuned models using Amazon SageMaker, Amazon Bedrock, and Amazon Nova Pro",
      "description": "This post walks through how Harmonic Security used Amazon SageMaker AI, Amazon Bedrock, and Amazon Nova Pro to fine-tune a ModernBERT model, achieving low-latency, accurate, and scalable data leakage detection.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-harmonic-security-improved-their-data-leakage-detection-system-with-low-latency-fine-tuned-models-using-amazon-sagemaker-amazon-bedrock-and-amazon-nova-pro/",
      "pubDate": "2025-12-11T18:28:15.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-4d26edbf5c94",
      "title": "How Swisscom builds enterprise agentic AI for customer support and sales using Amazon Bedrock AgentCore",
      "description": "In this post, we'll show how Swisscom implemented Amazon Bedrock AgentCore to build and scale their enterprise AI agents for customer support and sales operations. As an early adopter of Amazon Bedrock in the AWS Europe Region (Zurich), Swisscom leads in enterprise AI implementation with their Chatbot Builder system and various AI initiatives. Their successful deployments include Conversational AI powered by Rasa and fine-tuned LLMs on Amazon SageMaker, and the Swisscom Swisscom myAI assistant, built to meet Swiss data protection standards.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-swisscom-builds-enterprise-agentic-ai-for-customer-support-and-sales-using-amazon-bedrock-agentcore/",
      "pubDate": "2025-12-11T18:24:13.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "sagemaker",
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "sagemaker",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-fe825be28e53",
      "title": "Scaling MLflow for enterprise AI: What’s New in SageMaker AI with MLflow",
      "description": "Today we’re announcing Amazon SageMaker AI with MLflow, now including a serverless capability that dynamically manages infrastructure provisioning, scaling, and operations for artificial intelligence and machine learning (AI/ML) development tasks. In this post, we explore how these new capabilities help you run large MLflow workloads—from generative AI agents to large language model (LLM) experimentation—with improved performance, automation, and security using SageMaker AI with MLflow.",
      "link": "https://aws.amazon.com/blogs/machine-learning/scaling-mlflow-for-enterprise-ai-whats-new-in-sagemaker-ai-with-mlflow/",
      "pubDate": "2025-12-11T18:16:19.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-a1e0e42d9e9a",
      "title": "Amazon Bedrock AgentCore Observability with Langfuse",
      "description": "In this post, we explain how to integrate Langfuse observability with Amazon Bedrock AgentCore to gain deep visibility into an AI agent's performance, debug issues faster, and optimize costs. We walk through a complete implementation using Strands agents deployed on AgentCore Runtime followed by step-by-step code examples.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-observability-with-langfuse/",
      "pubDate": "2025-12-11T18:12:48.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "ga"
      ]
    },
    {
      "id": "aws-news-fed58c801712",
      "title": "Amazon WorkSpaces Secure Browser introduces Web Content Filtering",
      "description": "Amazon WorkSpaces Secure Browser now includes Web Content Filtering, a comprehensive security and compliance feature that enables organizations to control and monitor web content access. This new capability allows administrators to define granular access policies, block specific URLs or entire domain categories using 25+ predefined categories, and seamlessly integrate with Session Logger for enhanced monitoring and compliance reporting.\n  While existing Chrome policies for domain control remain supported, Web Content Filtering provides a more comprehensive way to control web access through category-based filtering and improved logging capabilities. Organizations can better manage their remote work security and compliance requirements through centralized policy management that scales across the enterprise. IT security teams can implement default-deny policies for high-security environments, while compliance officers benefit from detailed logging and monitoring capabilities. The feature maintains flexibility by allowing customized policies and exceptions based on specific business needs.\n  This feature is available at no additional cost in 10 AWS Regions, including US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt, London, Ireland), and Asia Pacific (Tokyo, Mumbai, Sydney, Singapore). WorkSpaces Secure Browser offers pay-as-you go pricing.\n  To get started with WorkSpaces Secure Browser, see Getting Started with Amazon WorkSpaces Secure Browser. You can enable this feature in your AWS console and automatically migrate any browser policies for URL Blocklists or URL Allowlists. To learn more about the feature, please refer to the feature documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-workspaces-secure-browser-web-content-filtering/",
      "pubDate": "2025-12-11T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-b56aaf668b93",
      "title": "Architecting conversational observability for cloud applications",
      "description": "In this post, we walk through building a generative AI–powered troubleshooting assistant for Kubernetes. The goal is to give engineers a faster, self-service way to diagnose and resolve cluster issues, cut down Mean Time to Recovery (MTTR), and reduce the cycles experts spend finding the root cause of issues in complex distributed systems.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-conversational-observability-for-cloud-applications/",
      "pubDate": "2025-12-11T15:59:39.000Z",
      "source": "architectureBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-cabf93d91266",
      "title": "Amazon Cognito identity pools now support private connectivity with AWS PrivateLink",
      "description": "Amazon Cognito identity pools now support AWS PrivateLink, enabling you to securely exchange federated identities for AWS credentials through private connectivity between your virtual private cloud (VPC) and Cognito. This eliminates the need to route authentication traffic over the public internet, providing enhanced security for your workloads. Identity pools map authenticated and guest identities to your AWS Identity and Access Management (IAM) roles and provide temporary AWS credentials, with this new feature, through a secure and private connection.\n  You can use PrivateLink connections in all AWS Regions where Amazon Cognito identity pools are available, except AWS China (Beijing) Region, operated by Sinnet, and AWS GovCloud (US) Regions. Creating VPC endpoints on AWS PrivateLink will incur additional charges; refer to AWS PrivateLink pricing page for details. You can get started by creating an AWS PrivateLink VPC interface endpoint for Amazon Cognito identity pools using the AWS Management Console, AWS Command Line Interface (CLI), AWS Software Development Kits (SDKs), AWS Cloud Development Kit (CDK), or AWS CloudFormation. To learn more, refer to the documentation on creating a VPC interface endpoint and Amazon Cognito’s developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-cognito-identity-pools-private-connectivity-aws-privatelink",
      "pubDate": "2025-12-11T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudformation",
        "iam",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-f5227466de55",
      "title": "Amazon Aurora PostgreSQL now supports integration with Kiro powers",
      "description": "Today, AWS announces Amazon Aurora PostgreSQL-Compatible Edition integration with Kiro powers, enabling developers to build Aurora PostgreSQL backed applications faster with AI agent-assisted development using Kiro. Kiro powers is a repository of curated and pre-packaged Model Context Protocol (MCP) servers, steering files, and hooks validated by Kiro partners to accelerate specialized software development and deployment use cases. Kiro power for Aurora PostgreSQL packages the MCP server with targeted database development guidance, giving the Kiro agent instant expertise in Aurora PostgreSQL operations and schema design.\n  Kiro power for Aurora PostgreSQL bundles direct database connectivity through the Aurora PostgreSQL MCP server for data plane operations (queries, table creation, schema management), and control plane operations (cluster creation) and the steering file with Aurora PostgreSQL–specific best practices. When developers work on database tasks, the power dynamically loads relevant guidance – whether creating new Aurora clusters, designing schemas, or optimizing queries – so AI agents receive only the context needed for the specific task at hand.\n  Aurora PostgreSQL power is available within Kiro IDE and Kiro powers webpage for one-click installation and can create and manage Aurora PostgreSQL clusters in all AWS Regions. For more information about development use cases, read this blog post. To learn more about Aurora PostgreSQL MCP server, visit our documentation.\n  Amazon Aurora is designed for unparalleled high performance and availability at global scale with full PostgreSQL compatibility. It provides built-in security, continuous backups, serverless compute, up to 15 read replicas, and automated multi-Region replication. To get started with Amazon Aurora, visit our getting started page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-aurora-postgresql-integration-kiro-powers",
      "pubDate": "2025-12-11T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-e072615bad94",
      "title": "Amazon CloudWatch SDK supports optimized JSON, CBOR protocols",
      "description": "Amazon CloudWatch announces support for both the JSON and Concise Binary Object Representation (CBOR) protocols in the CloudWatch SDK, enabling lower latency and improved performance for CloudWatch customers. The SDK will automatically use JSON or CBOR as its new default communication protocol, offering customers a lower end-to-end processing latency as well as reduced payload sizes, application client side CPU, and memory usage.\n  Customers use the CloudWatch SDK either directly or through Infrastructure as Code solutions to manage their monitoring resources. Reducing control plane operations latency and payload size helps customer optimize their operational maintenance and resources usage and costs. JSON and the CBOR data formats are standards designed to enable better performance over the traditional AWS Query protocol.\n  The CloudWatch SDK for JSON and CBOR protocols support is available in all AWS Regions where Amazon CloudWatch is available and for all generally available AWS SDK language variants.\n  To leverage the performance improvements, customers can install the latest SDK version here. To learn more about the AWS SDK, see Amazon Developer tools.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-cloudwatch-sdk-json-cbor-protocols",
      "pubDate": "2025-12-11T12:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "cloudwatch",
        "generally-available",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-a7f6df5e7855",
      "title": "AWS Application Migration Service supports IPv6",
      "description": "AWS Application Migration Service (MGN) now supports Internet Protocol version 6 (IPv6) for both service communication and application migrations. Organizations can migrate applications that use IPv6 addressing, enabling transitions to modern network infrastructures.\n \nYou can connect to AWS MGN using new dual-stack service endpoints that support both IPv4 and IPv6 communications. When migrating applications, you can transfer replication data using IPv4 or IPv6 while maintaining network connections and security. Then, during testing and cutover phases, you can use your chosen network configuration (IPv4, IPv6, or dual-stack) to launch servers in your target environment.\n  This feature is available in every AWS Region that supports AWS MGN and Amazon Elastic Compute Cloud (Amazon EC2) dual-stack endpoints. For supported regions, see the AWS MGN Supported AWS Regions and Amazon EC2 Endpoints documentation.\n  To learn more about AWS MGN, visit our product page or documentation. To get started, sign in to the AWS Application Migration Service Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/application-migration-service-ipv6/",
      "pubDate": "2025-12-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-64a8f75f76c1",
      "title": "Amazon EC2 High Memory U7i instances now available in additional regions",
      "description": "Amazon EC2 High Memory U7i instances with 24TB of memory (u7in-24tb.224xlarge) are now available in AWS Europe (Frankfurt), U7i instances with 16TB of memory (u7in-16tb.224xlarge) are now available in AWS Asia Pacific (Mumbai), and U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in the AWS Europe (Paris) region. U7i instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7in-24tb instances offer 24TiB of DDR5 memory, U7in-16tb instances offer 16TiB of DDR5 memory, and U7i-6tb instances offer 6TiB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n \nU7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7in-16tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 200Gbps of network bandwidth, and support ENA Express. U7in-24tb instances offer 896 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 200Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n \nTo learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-high-memory-u7i-instances-additional-regions/",
      "pubDate": "2025-12-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-b09d90c01400",
      "title": "Amazon EC2 I7i instances now available in additional AWS regions",
      "description": "Amazon Web Services (AWS) announces the availability of high performance Storage Optimized Amazon EC2 I7i instances in AWS Asia Pacific (Singapore, Jakarta), Europe (Stockholm) regions. Powered by 5th generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.2 GHz, these instances deliver up to 23% better compute performance and more than 10% better price performance over previous generation I4i instances. Powered by 3rd generation AWS Nitro SSDs, I7i instances offer up to 45TB of NVMe storage with up to 50% better real-time storage performance, up to 50% lower storage I/O latency, and up to 60% lower storage I/O latency variability compared to I4i instances.\n  I7i instances are ideal for I/O intensive and latency-sensitive workloads that demand very high random IOPS performance with real-time latency to access small to medium size datasets (multi-TBs). I7i instances support torn write prevention feature with up to 16KB block sizes, enabling customers to eliminate database performance bottlenecks.\n  I7i instances are available in eleven sizes - nine virtual sizes up to 48xlarge and two bare metal sizes - delivering up to 100Gbps of network bandwidth and 60Gbps of Amazon Elastic Block Store (EBS) bandwidth.\n To learn more, visit the I7i instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-i7i-instances-additional-regions/",
      "pubDate": "2025-12-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-8169660124b1",
      "title": "Amazon EC2 C7i instances are now available in the Asia Pacific (Hyderabad) Region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C7i instances powered by custom 4th Gen Intel Xeon Scalable processors (code-named Sapphire Rapids) are available in the Asia Pacific (Hyderabad) Region. C7i instances are supported by custom Intel processors, available only on AWS.\n  C7i instances deliver up to 15% better price-performance versus C6i instances and are a great choice for all compute-intensive workloads, such as batch processing, distributed analytics, ad-serving, and video encoding. C7i instances offer larger instance sizes, up to 48xlarge, and two bare metal sizes (metal-24xl, metal-48xl). These bare-metal sizes support built-in Intel accelerators: Data Streaming Accelerator, In-Memory Analytics Accelerator, and QuickAssist Technology that are used to facilitate efficient offload and acceleration of data operations and optimize performance for workloads.\n  C7i instances support new Intel Advanced Matrix Extensions (AMX) that accelerate matrix multiplication operations for applications such as CPU-based ML. Customers can attach up to 128 EBS volumes to a C7i instance vs. up to 28 EBS volumes to a C6i instance. This allows processing of larger amounts of data, scale workloads, and improved performance over C6i instances.\n  To learn more, visit Amazon EC2 C7i Instances. To get started, see the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-c7i-instances-asia-pacific-hyderabad-region/",
      "pubDate": "2025-12-11T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-2dc96b0ea892",
      "title": "Amazon ECS now supports custom container stop signals on AWS Fargate",
      "description": "Amazon Elastic Container Service (Amazon ECS) now supports custom container stop signals for Linux tasks running on AWS Fargate, honoring the stop signal configured in Open Container Initiative (OCI) images when tasks are stopped. The enhancement improves graceful shutdown behavior by aligning Fargate task termination with each container’s preferred termination signal.\n  Previously, when an Amazon ECS task running on AWS Fargate was stopped, each Linux container always received SIGTERM followed by SIGKILL after the configured timeout. With the new behavior, the Amazon ECS container agent reads the stop signal from the container image configuration and sends that signal when stopping the task. Containers that rely on signals such as SIGQUIT or SIGINT for graceful shutdown can now run on Fargate with their intended termination semantics. If no STOPSIGNAL is configured, Amazon ECS continues to send SIGTERM by default.\n  Customers can use custom stop signals on Amazon ECS with AWS Fargate by adding a STOPSIGNAL instruction (for example, STOPSIGNAL SIGQUIT) to their OCI‑compliant container images. Support for container‑defined stop signals is available in all AWS Regions. To learn more, refer to the ECS Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ecs-custom-container-stop-signals-fargate/",
      "pubDate": "2025-12-10T20:48:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "fargate"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ecs",
        "fargate",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-8104f30c91af",
      "title": "Implement automated smoke testing using Amazon Nova Act headless mode",
      "description": "This post shows how to implement automated smoke testing using Amazon Nova Act headless mode in CI/CD pipelines. We use SauceDemo, a sample ecommerce application, as our target for demonstration. We demonstrate setting up Amazon Nova Act for headless browser automation in CI/CD environments and creating smoke tests that validate key user workflows. We then show how to implement parallel execution to maximize testing efficiency, configure GitLab CI/CD for automatic test execution on every deployment, and apply best practices for maintainable and scalable test automation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/implement-automated-smoke-testing-using-amazon-nova-act-headless-mode/",
      "pubDate": "2025-12-10T19:04:24.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-8b2e20dd7213",
      "title": "Now generally available: Amazon EC2 C8gb instances",
      "description": "Today, AWS announces the general availability of the new Amazon Elastic Block Storage (Amazon EBS) optimized Amazon Elastic Compute Cloud (Amazon EC2) C8gb instances. These instances are powered by AWS Graviton4 processors to deliver up to 30% better compute performance than AWS Graviton3 processors. At up to 150 Gbps of EBS bandwidth, these instances offer higher EBS performance compared to same-sized equivalent Graviton4-based instances. Take advantage of the higher block storage performance offered by these new EBS optimized EC2 instances to scale the performance and throughput of workloads such as high-performance file systems, while optimizing the cost of running your workloads.\n \nFor increased scalability, these instances offer instance sizes up to 24xlarge, including a metal-24xl size, up to 192 GiB of memory, up to 150 Gbps of EBS bandwidth, up to 200 Gbps of networking bandwidth. These instances support Elastic Fabric Adapter (EFA) networking on the 16xlarge, 24xlarge, metal-24xl sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n \nThe new C8gb instances are available in US East (N. Virginia) and US West (Oregon) regions. Metal sizes are only available in US East (N. Virginia) region.\n \nTo learn more, see Amazon EC2 C8gb Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/generally-available-amazon-ec2-c8gb-instances",
      "pubDate": "2025-12-10T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "graviton",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-30581ecb3d79",
      "title": "How BASF’s Agriculture Solutions drives traceability and climate action by tokenizing cotton value chains using Amazon Managed Blockchain",
      "description": "BASF Agricultural Solutions combines innovative products and digital tools with practical farmer knowledge. This post explores how Amazon Managed Blockchain can drive a positive change in the agricultural industry by tokenizing food and cotton value chains for traceability, climate action, and circularity.",
      "link": "https://aws.amazon.com/blogs/architecture/how-basfs-agriculture-solutions-drives-traceability-and-climate-action-by-tokenizing-cotton-value-chains-using-amazon-managed-blockchain/",
      "pubDate": "2025-12-10T17:41:52.000Z",
      "source": "architectureBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-5b4eef6d6997",
      "title": "Amazon EC2 X8g instances now available in Asia Pacific (Sydney) region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) X8g instances are available in Asia Pacific (Sydney) region. These instances are powered by AWS Graviton4 processors and deliver up to 60% better performance than AWS Graviton2-based Amazon EC2 X2gd instances. X8g instances offer up to 3 TiB of total memory and increased memory per vCPU compared to other Graviton4-based instance. They have the best price performance among EC2 X-series instances, and are ideal for memory-intensive workloads such as electronic design automation (EDA) workloads, in-memory databases (Redis, Memcached), relational databases (MySQL, PostgreSQL), real-time big data analytics, real-time caching servers, and memory-intensive containerized applications.\n  X8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 3TiB) than Graviton2-based X2gd instances. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS). Elastic Fabric Adapter (EFA) networking support is offered on 24xlarge, 48xlarge, and bare metal sizes, and Elastic Network Adapter (ENA) Express support is available on instance sizes larger than 12xlarge.\n  To learn more, see Amazon EC2 X8g Instances. To quickly migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program. To get started, see the AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-x8g-instances-asia-pacific-sydney/",
      "pubDate": "2025-12-10T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-3871c2986a1d",
      "title": "Amazon Braket now supports Qiskit 2.0",
      "description": "Amazon Braket now supports Qiskit 2.0, enabling quantum developers to use the latest version of the most popular quantum software framework with native primitives and client-side compilation capabilities.\n  With this release, Braket provides native implementations of Qiskit's Sampler and Estimator primitives that leverage Braket's program sets for optimized batching, reducing execution time and costs compared to generic wrapper approaches. The native primitives handle parameter sweeps and observable measurements service-side, eliminating the need for customers to implement this logic manually. Additionally, the bidirectional circuit conversion capability enables customers to use Qiskit's extensive compilation framework for client-side transpilation before submitting to Braket devices, providing the control and reproducibility that enterprise users and researchers require for device characterization experiments and custom compilation passes.\n  Qiskit 2.0 support is available in all AWS Regions where Amazon Braket is available. To get started, see the Qiskit-Braket provider documentation and the Amazon Braket Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-braket-qiskit-2-0/",
      "pubDate": "2025-12-10T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-20fcf921c10f",
      "title": "AWS Support Center Console now supports  screen sharing for troubleshooting support cases",
      "description": "Today, AWS announces that AWS Support Center Console now support screen sharing for troubleshooting support cases. With this new feature, you can request a virtual meeting while in an active chat or call, join support calls with one click through a meeting bridge link. With the new virtual meetings, you will be able to share your screen during the meeting and maintain seamless access to case details for efficient troubleshooting. This enhancement simplifies your support experience by keeping all support interactions within the AWS Support Center console.\n \nTo learn more visit the AWS Support page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/support-center-console-screen-sharing/",
      "pubDate": "2025-12-10T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-e820691af9bb",
      "title": "Introducing Apache Iceberg materialized views in AWS Glue Data Catalog",
      "description": "Hundreds of thousands of customers build artificial intelligence and machine learning (AI/ML) and analytics applications on AWS, frequently transforming data through multiple stages for improved query performance—from raw data to processed datasets to final analytical tables. Data engineers must solve complex problems, including detecting what data has changed in base tables, writing and maintaining transformation […]",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-apache-iceberg-materialized-views-in-aws-glue-data-catalog/",
      "pubDate": "2025-12-09T21:36:51.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex",
        "glue"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "glue"
      ]
    },
    {
      "id": "aws-news-d8a86205a454",
      "title": "Real-world reasoning: How Amazon Nova 2 Lite handles complex customer support scenarios",
      "description": "This post evaluates the reasoning capabilities of our latest offering in the Nova family, Amazon Nova 2 Lite, using practical scenarios that test these critical dimensions. We compare its performance against other models in the Nova family—Lite 1.0, Micro, Pro 1.0, and Premier—to elucidate how the latest version advances reasoning quality and consistency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/real-world-reasoning-how-amazon-nova-lite-2-0-handles-complex-customer-support-scenarios/",
      "pubDate": "2025-12-09T20:50:42.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-7c4719968fc9",
      "title": "Amazon EC2 C8gn instances are now available in additional regions",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8gn instances, powered by the latest-generation AWS Graviton4 processors, are available in the AWS US East (Ohio) and Middle East (UAE) Regions. The new instances provide up to 30% better compute performance than Graviton3-based Amazon EC2 C7gn instances. Amazon EC2 C8gn instances feature the latest 6th generation AWS Nitro Cards, and offer up to 600 Gbps network bandwidth, the highest network bandwidth among network optimized EC2 instances.\n  Take advantage of the enhanced networking capabilities of C8gn to scale performance and throughput, while optimizing the cost of running network-intensive workloads such as network virtual appliances, data analytics, CPU-based artificial intelligence and machine learning (AI/ML) inference.\n  For increased scalability, C8gn instances offer instance sizes up to 48xlarge, up to 384 GiB of memory, and up to 60 Gbps of bandwidth to Amazon Elastic Block Store (EBS). C8gn instances support Elastic Fabric Adapter (EFA) networking on the 16xlarge, 24xlarge, 48xlarge, metal-24xl, and metal-48xl sizes, which enables lower latency and improved cluster performance for workloads deployed on tightly coupled clusters.\n  C8gn instances are available in the following AWS Regions: US East (N. Virginia, Ohio), US West (Oregon, N.California), Europe (Frankfurt, Stockholm), Asia Pacific (Singapore, Malaysia, Sydney, Thailand), Middle East (UAE)\n  To learn more, see Amazon C8gn Instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page. To get started, see AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-c8gn-instances-additional-regions",
      "pubDate": "2025-12-09T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "rds",
        "graviton",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-2847b88fac95",
      "title": "Create AI-powered chat assistants for your enterprise with Amazon Quick Suite",
      "description": "In this post, we show how to build chat agents in Amazon Quick Suite. We walk through a three-layer framework—identity, instructions, and knowledge—that transforms Quick Suite chat agents into intelligent enterprise AI assistants. In our example, we demonstrate how our chat agent guides feature discovery, use enterprise data to inform recommendations, and tailors solutions based on potential to impact and your team’s adoption readiness.",
      "link": "https://aws.amazon.com/blogs/machine-learning/create-ai-powered-chat-assistants-for-your-enterprise-with-amazon-quick-suite/",
      "pubDate": "2025-12-09T17:07:22.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q"
      ]
    },
    {
      "id": "aws-news-884043325b80",
      "title": "Amazon EC2 X8g instances now available in Europe (Stockholm) region",
      "description": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) X8g instances are available in Europe (Stockholm) region. These instances are powered by AWS Graviton4 processors, and they offer up to 3 TiB of total memory and increased memory per vCPU compared to other Graviton4-based instances. X8g instances are ideal for memory-intensive workloads, such as electronic design automation (EDA) workloads, in-memory databases (Redis, Memcached), relational databases (MySQL, PostgreSQL), real-time big data analytics, real-time caching servers, and memory-intensive containerized applications.\n \nX8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 3TiB) than Graviton2-based X2gd instances. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS). Elastic Fabric Adapter (EFA) networking support is offered on 24xlarge, 48xlarge, and bare metal sizes, and Elastic Network Adapter (ENA) Express support is available on instance sizes larger than 12xlarge.\n \nX8g instances are currently available in the following AWS Regions: US East (N. Virginia, Ohio), US West (Oregon), and Europe (Frankfurt, Stockholm).\n \nTo learn more, see Amazon EC2 X8g Instances. To quickly migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program. To get started, see the AWS Management Console, AWS Command Line Interface (AWS CLI), and AWS SDKs.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-x8g-instances-europe-stockholm/",
      "pubDate": "2025-12-09T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-cd68753eba87",
      "title": "AWS Partner Central now includes opportunity deal sizing",
      "description": "Today, AWS announces deal sizing capability in AWS Partner Central. This new feature, available within the APN Customer Engagements (ACE) Opportunities, uses AI to provide deal size estimates and AWS service recommendations. Deal Sizing capability allows Partners to save time on deal management by simplifying the process of estimating AWS monthly recurring revenue (MMR) when creating or updating opportunities.\n  Partners can optionally import AWS Pricing Calculator URLs to automatically populate AWS service selections and corresponding spend estimates into their opportunities, reducing the need for manual re-entry. When a Pricing Calculator URL is provided, deal sizing delivers enhanced insights including pricing strategy optimization recommendations, potential cost savings analysis, Migration Acceleration Program (MAP) eligibility indicators, and modernization pathway analysis. These enhanced insights help Partners refine their technical approach and strengthen funding applications, accelerating the funding approval process.\n  Deal sizing is now available in AWS Partner Central worldwide. The feature is accessible through both AWS Partner Central and the AWS Partner Central API for Selling, which is available in the US East (N. Virginia) Region.\n  To get started, log in to AWS Partner Central in the console to create or update opportunities and view deal sizing insights. For API integration with your CRM system, see the AWS Partner Central API Documentation. To learn more about deal sizing, visit the Partner Central Sales Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-partner-central-opportunity-deal-sizing",
      "pubDate": "2025-12-09T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ga",
        "now-available",
        "new-feature",
        "update",
        "integration"
      ]
    },
    {
      "id": "aws-news-7443b569a108",
      "title": "Amazon RDS and Aurora now support resource tagging for Automated Backups",
      "description": "Amazon RDS and Aurora now support resource tagging for automated backups and cluster automated backups. You can now tag your automated backups separately from the parent DB instance or DB cluster, enabling Attribute-Based Access Control (ABAC) and simplifying resource management and cost tracking.\n \nWith this launch, you can tag automated backups in the same way as other RDS resources using the AWS Management Console, API, or SDK. Use these tags with IAM policies to control access and permissions to automated backups. Additionally, these tags can help you categorize your resources by application, project, department, environment, and more, as well as manage, organize, and track costs of your automated backups. For example, create application specific tags to control permissions for describing, deleting, or restoring automated backups and to organize and track backup costs of the application.\n \nThis capability is available in all AWS Regions, including the AWS GovCloud (US) Regions where Aurora and RDS are available.\n \nTo learn more about tagging Aurora and RDS automated backups, see the Amazon documentation on Tagging Amazon Aurora resources, Tagging Amazon RDS resources, and Using tags for attribute-based access control.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/rds-aurora-resource-tagging-automated-backups/",
      "pubDate": "2025-12-09T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "iam"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "iam",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f90bc2468fce",
      "title": "Amazon GameLift Servers enhances AWS Console for game developers with AI powered assistance",
      "description": "Today, Amazon GameLift Servers is launching AI-powered assistance in the AWS Console, leveraging Amazon Q Developer to provide tailored guidance for game developers. This new feature integrates specialized GameLift Servers knowledge to help customers navigate complex workflows, troubleshoot issues, and optimize their game server deployments more efficiently.\n  Developers can now access AI-assisted recommendations for game server integration, fleet configuration, and performance optimization directly within the AWS Console via Amazon GameLift Servers. This enhancement aims to streamline decision making processes, reduce troubleshooting time, and improve overall resource utilization, leading to cost savings and better player experiences.\n  AI-powered assistance is now available in all Amazon GameLift Servers supported regions, except AWS China. To learn more about this new feature, visit the Amazon GameLift Servers documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/gamelift-servers-console-developers-ai-powered/",
      "pubDate": "2025-12-09T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "lex",
        "launch",
        "ga",
        "now-available",
        "new-feature",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-f4552e03b140",
      "title": "Auto-optimize your Amazon OpenSearch Service vector database",
      "description": "AWS recently announced the general availability of auto-optimize for the Amazon OpenSearch Service vector engine. This feature streamlines vector index optimization by automatically evaluating configuration trade-offs across search quality, speed, and cost savings. You can then run a vector ingestion pipeline to build an optimized index on your desired collection or domain. Previously, optimizing index […]",
      "link": "https://aws.amazon.com/blogs/big-data/auto-optimize-your-amazon-opensearch-service-vector-database/",
      "pubDate": "2025-12-08T23:58:24.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-262fa5942e1b",
      "title": "Build billion-scale vector databases in under an hour with GPU acceleration on Amazon OpenSearch Service",
      "description": "AWS recently announced the general availability of GPU-accelerated vector (k-NN) indexing on Amazon OpenSearch Service. You can now build billion-scale vector databases in under an hour and index vectors up to 10 times faster at a quarter of the cost. This feature dynamically attaches serverless GPUs to boost domains and collections running CPU-based instances. With […]",
      "link": "https://aws.amazon.com/blogs/big-data/build-billion-scale-vector-databases-in-under-an-hour-with-gpu-acceleration-on-amazon-opensearch-service/",
      "pubDate": "2025-12-08T23:57:19.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-aa5650a9d9d2",
      "title": "SAP data ingestion and replication with AWS Glue zero-ETL",
      "description": "AWS Glue zero-ETL with SAP now supports data ingestion and replication from SAP data sources such as Operational Data Provisioning (ODP) managed SAP Business Warehouse (BW) extractors, Advanced Business Application Programming (ABAP), Core Data Services (CDS) views, and other non-ODP data sources. Zero-ETL data replication and schema synchronization writes extracted data to AWS services like Amazon Redshift, Amazon SageMaker lakehouse, and Amazon S3 Tables, alleviating the need for manual pipeline development. In this post, we show how to create and monitor a zero-ETL integration with various ODP and non-ODP SAP sources.",
      "link": "https://aws.amazon.com/blogs/big-data/sap-data-ingestion-and-replication-with-aws-glue-zero-etl/",
      "pubDate": "2025-12-08T23:11:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "s3",
        "redshift",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "redshift",
        "glue",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-c8a3488015cc",
      "title": "AWS SDK for JavaScript aligns with Node.js release schedule",
      "description": "This post is about AWS SDK for JavaScript v3 announcing end of support for Node.js versions based on Node.js release schedule, and it is not about AWS Lambda. For the latter, refer to the Lambda runtime deprecation policy. In the second week of January 2026, the AWS SDK for JavaScript v3 (JS SDK) will start […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-javascript-aligns-with-node-js-release-schedule/",
      "pubDate": "2025-12-08T17:32:10.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "support"
      ]
    },
    {
      "id": "aws-news-709f8862deee",
      "title": "How AWS delivers generative AI to the public sector in weeks, not years",
      "description": "Experts at the Generative AI Innovation Center share several strategies to help organizations excel with generative AI.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-aws-delivers-generative-ai-to-the-public-sector-in-weeks-not-years/",
      "pubDate": "2025-12-08T17:23:32.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "eks",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "nova",
        "eks",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-632e1959900f",
      "title": "AWS Weekly Roundup: AWS re:Invent keynote recap, on-demand videos, and more (December 8, 2025)",
      "description": "The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our top announcements of AWS re:Invent 2025 that you can […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinvent-keynote-recap-on-demand-videos-and-more-december-8-2025/",
      "pubDate": "2025-12-08T17:05:29.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "announcement"
      ]
    },
    {
      "id": "aws-news-1f771f0e37b4",
      "title": "S&P Global Data integration expands Amazon Quick Research capabilities",
      "description": "Today, we are pleased to announce a new integration between Amazon Quick Research and S&P Global. This integration brings both S&P Global Energy news, research, and insights and S&P Global Market Intelligence data to Quick Research customers in one deep research agent. In this post, we explore S&P Global’s data sets and the solution architecture of the integration with Quick Research.",
      "link": "https://aws.amazon.com/blogs/machine-learning/sp-global-data-integration-expands-amazon-quick-research-capabilities/",
      "pubDate": "2025-12-08T16:47:17.000Z",
      "source": "mlBlog",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "integration"
      ]
    },
    {
      "id": "aws-news-f8633d530b1e",
      "title": "She architects: Bringing unique perspectives to innovative solutions at AWS",
      "description": "Have you ever wondered what it is really like to be a woman in tech at one of the world's leading cloud companies? Or maybe you are curious about how diverse perspectives drive innovation beyond the buzzwords? Today, we are providing an insider's perspective on the role of a solutions architect (SA) at Amazon Web Services (AWS). However, this is not a typical corporate success story. We are three women who have navigated challenges, celebrated wins, and found our unique paths in the world of cloud architecture, and we want to share our real stories with you.",
      "link": "https://aws.amazon.com/blogs/architecture/she-architects-bringing-unique-perspectives-to-innovative-solutions-at-aws/",
      "pubDate": "2025-12-08T16:37:15.000Z",
      "source": "architectureBlog",
      "services": [
        "nova",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "nova",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-9d9ba6695109",
      "title": "Amazon Quick Suite integrates Quick Research with Quick Flows for report automation",
      "description": "Amazon Quick Suite now includes Quick Research as a step within Quick Flows. This integration enables teams to generate comprehensive research reports as part of automated, multi-step workflows, transforming research projects into reusable workflows that can be shared across their organization.\n  Quick Suite is Amazon's new AI-powered workspace that helps organizations get answers from their business data and move quickly from insights to action. With this integration, teams can trigger research automatically within their flows rather than conducting separate analysis. This addresses a critical productivity challenge by enabling teams to capture and scale proven research methods across hundreds of automated use cases. The integration also allows users to automate research workflows through scheduled triggers so users can set up flows that automatically generate research at specific times. Common use cases include automated account plan creation, standardizing product compliance analysis, and scheduled industry reports.\n  Users benefit from pre-configured flows that generate research based on flow creator instructions and optional user inputs. The generated research report can be used further to automatically trigger downstream actions like updating a Salesforce opportunity for an account team to follow up on, posting on a Jira ticket for a compliance team to review, or creating an Asana task for a patent lawyer to approve. This unlocks \"set and forget\" workflows that deliver consistent analysis without manual heavy lifting. Now operating within these automated workflows, Quick Research maintains its core strength of streamlining analysis across diverse enterprise data sources while delivering verified, source-traced insights. For existing Flow users, this provides access to more comprehensive analysis.\n  Quick Research with Flows integration is available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland). To learn more about automating your research needs, read the Quick Suite user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-quick-suite-research-flows-report-automation",
      "pubDate": "2025-12-08T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "amazon q",
        "organizations",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-92a461f07465",
      "title": "Announcing Spatial Data Management on AWS to accelerate spatial-data insights",
      "description": "Today, AWS is announcing Spatial Data Management on AWS (SDMA), a solution that enables customers to store, enrich, and connect spatial data at scale. SDMA enables customers to store their multimodal spatial data representing their physical assets (3D, geospatial, behavioral, temporal data) in a secure, centralized cloud environment. SDMA serves as a collaborative hub enabling connectivity between customer’s spatial data, their ISV SaaS applications, and AWS Services. In addition, customers can use SDMA’s collection rules to define how their spatial data is organized and enriched, helping maintain consistency and governance. Customers can use SDMA’s APIs, desktop application, and web interface to efficiently manage spatial data to accelerate insights and informed decision making around physical operations.\n \nSDMA centralizes customer’s spatial data in a secure and highly available cloud repository to enhance data transparency and accessibility across workflows. Leveraging SDMA's automated metadata extraction for spatial data file formats, starting with: .LAZ, .E57, .GLB, and .GLTF, customers can improve data discoverability and relationships. SDMA’s REST APIs and customizable connectors simplify integrations with external applications — eliminating manual file handling and enhancing cloud and on-premises interoperability. SDMA's intuitive web and desktop interfaces enable users across technical skill levels to manage spatial data efficiently. Auto-generated file previews are designed to improve workflow speed and data accuracy, they allow users to view and validate data without downloading large files.\n \nSDMA is available in the following AWS regions: Asia Pacific (Tokyo, Singapore, Sydney), Europe (Frankfurt, Ireland, London), US East (N. Virginia, Ohio), US West (Oregon).\n \nTo learn more, visit the SDMA Product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/spatial-data-management-spatial-data-insights/",
      "pubDate": "2025-12-08T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "preview",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-8273e71b1636",
      "title": "Amazon OpenSearch Service now supports automatic semantic enrichment",
      "description": "Amazon OpenSearch Service now brings automatic semantic enrichment to managed clusters, matching the capability we launched for OpenSearch Serverless earlier this year. This feature allows you to leverage the power of semantic search with minimal configuration effort.\n  Traditional lexical search only matches exact phrases, often missing relevant content. Automatic semantic enrichment understands context and meaning, delivering more relevant results. For example, a search for \"eco-friendly transportation options\" finds matches about \"electric vehicles\" or \"public transportation\"—even when these exact terms aren't present. This new capability handles all semantic processing automatically, eliminating the need to manage machine learning models. It supports both English-only and multi-lingual variants, covering 15 languages including Arabic, French, Hindi, Japanese, Korean, and more. You pay only for actual usage during data ingestion, billed as OpenSearch Compute Unit (OCU) - Semantic Search. View the pricing page for cost details and a pricing example.\n  This feature is now available for Amazon OpenSearch Service domains running OpenSearch version 2.19 or later. Currently, this feature supports non-VPC domains in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm).\n  Get started with our documentation on automatic semantic enrichment.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/opensearch-service-automatic-semantic-enrichment/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service",
        "launch",
        "ga",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-7756d1765b26",
      "title": "TwelveLabs’ Pegasus 1.2 model now in 23 new AWS regions via Global cross-region inference",
      "description": "Amazon Bedrock introduces Global cross-Region inference for TwelveLabs' Pegasus 1.2, expanding model availability to 23 new regions in addition to the seven regions where the model was already available. You can now also access the model in all EU regions in Amazon Bedrock using Geographic cross-Region inference. Geographic cross-Region inference is ideal for workloads with data residency or compliance requirements within a specific geographic boundary, while Global cross-Region inference is recommended for applications that prioritize availability and performance across multiple geographies.\n  Pegasus 1.2 is a powerful video-first language model that can generate text based on the visual, audio, and textual content within videos. Specifically designed for long-form video, it excels at video-to-text generation and temporal understanding. With Pegasus 1.2's availability in these additional regions, you can now build video-intelligence applications closer to your data and end users, reducing latency and simplifying your architecture.\n  For a complete list of supported inference profiles and regions for Pegasus 1.2, refer to the Cross-Region Inference documentation. To get started with Pegasus 1.2, visit the Amazon Bedrock console. To learn more, read the product page and Amazon Bedrock documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/twelvelabs-pegasus-available-with-global-cross-region-inference/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-c46520142038",
      "title": "SES Mail Manager is now available in 10 additional AWS Regions, 27 total",
      "description": "Amazon SES announces that the SES Mail Manager product is now available in 10 additional commercial AWS Regions. This expands coverage from the current 17 commercial AWS Regions where Mail Manager is launched, meaning that Mail Manager is now offered in all commercial Regions where SES offers its core Outbound service.\n  SES Mail Manager allows customers to configure email routing and delivery mechanisms for their domains, and to have a single view of email governance, risk, and compliance solutions for all email workloads. Organizations commonly deploy Mail Manager to replace legacy hosted mail relays or simplify integration with third-party mailbox providers and email security solutions. Mail Manager also supports onward delivery to WorkMail mailboxes, built-in archiving with search and export capabilities, and integration with third-party security add-ons directly within the console.\n  The 10 new Mail Manager Regions include Middle East (Bahrain), Asia Pacific (Jakarta), Africa (Cape Town), Middle East (UAE), Asia Pacific (Hyderabad), Asia Pacific (Malaysia), Europe (Milan), Israel (Tel Aviv), Canada West (Calgary), and Europe (Zurich). The full list of Mail Manager Region availability is here. \n  To learn more, see the Amazon SES Mail Manager product page and the SES Mail Manager documentation. You can start using Mail Manager in these new Regions through the Amazon SES console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ses-mail-manager-10-regions/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "launch",
        "ga",
        "now-available",
        "integration",
        "support",
        "new-region"
      ]
    },
    {
      "id": "aws-news-01ad74db6ed9",
      "title": "Amazon SES adds VPC support for API endpoints",
      "description": "Today, Amazon Simple Email Service (SES) added support for accessing SES API endpoints through Virtual Private Cloud (VPC) endpoints. Customers use VPC endpoints to enable access to SES APIs for sending emails and managing their SES resource configuration. This release helps customers increase security in their VPCs.\n  Previously, customers who ran their workloads in a VPC could access SES APIs by configuring an internet gateway resource in their VPC. This enabled traffic from the VPC to flow into the internet, and reach SES public API endpoints. Now, customers can use the VPC endpoints to access SES APIs without the need for an internet gateway, reducing the chances for activity in the VPC to be exposed to the internet..\n  SES supports VPC for SES API endpoints in all AWS Regions where SES is available.\n  For more information, see the documentation for information about setting up VPC endpoints with Amazon SES.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ses-vpc-api-endpoints/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-ad34366e53a8",
      "title": "Amazon Connect launches WhatsApp channel for Outbound Campaigns",
      "description": "Amazon Connect Outbound Campaigns now supports WhatsApp, expanding on the WhatsApp Business messaging capabilities that already allow customers to contact your agents. You can now engage customers through proactive, automated campaigns on their preferred messaging platform, delivering timely communications such as appointment reminders, payment notifications, order updates, and product recommendations directly through WhatsApp. Setting up WhatsApp campaigns uses the same familiar Amazon Connect interface, where you can define your target audience, choose personalized message templates, schedule delivery times, and apply compliance guardrails, just as you do for SMS, voice, and email campaigns.\n  Previously, Outbound Campaigns supported SMS, email, and voice channels, while WhatsApp was available only for customers to initiate conversations with your agents. With WhatsApp support in Outbound Campaigns, you can now proactively reach customers through an additional messaging platform while maintaining a unified campaign management experience. You can personalize WhatsApp messages using real-time customer data, track delivery and engagement metrics, and manage communication frequency and timing to ensure compliance. This expansion provides greater flexibility to connect with customers on their preferred platforms while streamlining your omnichannel outreach strategy.\n  This feature is available in all AWS Regions where Amazon Connect Outbound Campaigns is supported. To learn more, visit the Amazon Connect Outbound Campaigns documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/connect-whatsapp-channel-outbound-campaigns/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "personalize"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "personalize",
        "launch",
        "ga",
        "update",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-4d9478a7f155",
      "title": "Amazon SageMaker now supports self-service migration of Notebook instances to latest platform versions",
      "description": "Amazon SageMaker Notebook instance now supports self-service migration, allowing you to update your notebook instance platform identifier through the UpdateNotebookInstance API. This enables you to seamlessly transition from unsupported platform identifiers (notebook-al1-v1, notebook-al2-v1, notebook-al2-v2) to supported versions (notebook-al2-v3, notebook-al2023-v1).\n  With the new PlatformIdentifier parameter in the UpdateNotebookInstance API, you can update to newer versions of the Notebook instance platform while preserving your existing data and configurations. The platform identifier determines which Operating System and JupyterLab version combination your notebook instance runs. This self-service capability simplifies the migration process and helps you keep your notebook instances current.\n  This feature is supported through AWS CLI (version 2.31.27 or newer) and SDK, and is available in all AWS Regions where Amazon SageMaker Notebook instances are supported. To learn more, see Update a Notebook Instance in the Amazon SageMaker Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-self-service-migration-notebook-instances",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-0424929cc700",
      "title": "AWS Elastic Beanstalk now supports Node.js 24 on Amazon Linux 2023",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Node.js 24 applications on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest features and improvements in Node.js while taking advantage of the enhanced security and performance of AL2023.\n \nAWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Node.js 24 on AL2023 delivers updates to the V8 JavaScript engine, npm 11, and security and performance improvements. Developers can create Elastic Beanstalk environments running Node.js 24 on AL2023 through the Elastic Beanstalk Console, CLI, or API.\n \nThis platform is available in all commercial AWS Regions where Elastic Beanstalk is available, including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n \nTo learn more about Node.js 24 on Amazon Linux 2023, see the AWS Elastic Beanstalk Developer guide. For additional information, visit the AWS Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-beanstalk-node-js-24-linux-2023/",
      "pubDate": "2025-12-05T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-99629c57268b",
      "title": "Amazon Connect Customer Profiles launches new segmentation capabilities (Beta)",
      "description": "Amazon Connect Customer Profiles now offers new segmentation capabilities powered by Spark SQL (Beta), enabling you to build sophisticated customer segments using your complete Customer Profiles data with AI assistance.\n  You can:\n  \n \n \nAccess complete profile data: Use both custom objects and standard objects for segmentation\n \n \nLeverage SQL capabilities: Join objects, filter with statistical functions like percentiles, and standardize date fields for complex analysis\n \n \nBuild segments with AI assistance: Use natural language prompts with the Segment AI assistant to automatically generate segment definitions in Spark SQL, or write SQL directly\n \n \nValidate before deployment: Review AI-generated SQL, view natural language explanations, and get automatic segment estimates\n \n \nFor example, you can create segments like \"customers who called customer services more than 3 times in the past month about new purchases they made\" or \"high-value customers in the 90th percentile of lifetime spend\" to enable precise targeting for outbound campaigns and personalized customer experiences.\n  These new segmentation capabilities are offered alongside existing segmentation features. Both integrate seamlessly with segment membership calls, Flow blocks, and Outbound Campaigns, allowing you to choose the approach that best fits your use case.\n  Getting started: Enable Data store from the Customer Profiles page to use the new segmentation capabilities\n  Availability: Available in all AWS regions where Amazon Connect Customer Profiles is offered.\n  For more information, see Build customer segments in Amazon Connect in the Amazon Connect Administrator Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-connect-customer-profiles/",
      "pubDate": "2025-12-05T15:04:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "personalize"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "personalize",
        "launch",
        "beta"
      ]
    },
    {
      "id": "aws-news-5a5afa48e9ee",
      "title": "Amazon Q now can analyze SES email sending",
      "description": "Today, Amazon Q (Q) added support for analyzing email sending in Amazon Simple Email Service (SES). Now customers can ask Q questions about their SES resource setup and usage patterns, and Q will help them optimize their configuration and troubleshoot deliverability problems. This makes it easier to manage SES operational activities with less technical knowledge.\n  Previously, customers could use SES features such as Virtual Deliverability Manager to manage and explore their SES resource configuration and usage. SES provided convenient dashboard views and query tools to help customers find information, however customers needed deep understanding of email sending concepts to interact with the service. Now, customers can ask Q for help in optimizing resource configuration and troubleshooting deliverability challenges. Q will evaluate customer’s usage patterns and SES resource configuration, find the answers customers need, and help them understand the context without requiring pre-knowledge or manual exploration.\n  Q supports SES resource analysis in all AWS Regions where SES and Q are available.\n  For more information, see the Q documentation for information about interacting with SES through Q.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-q-analyze-ses-email-sending/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "support"
      ]
    },
    {
      "id": "aws-news-39665ab10ff1",
      "title": "AWS launches simplified enablement of AWS CloudTrail events in Amazon CloudWatch",
      "description": "Today, AWS launches simplified enablement of AWS CloudTrail events in Amazon CloudWatch, a monitoring and logging service that helps you collect, monitor, and analyze log data from your AWS resources and applications. With this launch, you can now centrally configure collection of CloudTrail events in CloudWatch alongside other popular AWS log sources such as Amazon VPC flow logs and Amazon EKS Control Plane Logs. CloudWatch's ingestion experience provides a consolidated view that simplifies collecting telemetry from different sources for accounts in your AWS Organization thus ensuring comprehensive monitoring and data collection across your AWS environment.\n  This new integration leverages service-linked channels (SLCs) to receive events from CloudTrail without requiring trails, and also provides additional benefits such as safety-checks and termination protection. You incur both CloudTrail event delivery charges and CloudWatch Logs ingestion fees based on custom logs pricing.\n  To learn more about enablement of CloudTrail events in CloudWatch and supported AWS regions, visit the Amazon CloudWatch documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/key-enhancements-cloudtrail-events-cloudwatch/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "cloudwatch",
        "launch",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-116745600502",
      "title": "AWS Elastic Beanstalk now supports Python 3.14 on Amazon Linux 2023",
      "description": "AWS Elastic Beanstalk now enables customers to build and deploy Python 3.14 applications on Amazon Linux 2023 (AL2023) platform. This latest platform support allows developers to leverage the newest features and improvements in Python while taking advantage of the enhanced security and performance of AL2023.\n \nAWS Elastic Beanstalk is a service that provides the ability to deploy and manage applications in AWS without worrying about the infrastructure that runs those applications. Python 3.14 on AL2023 delivers enhanced interactive interpreter capabilities, improved error messages, important security and API improvements. Developers can create Elastic Beanstalk environments running Python 3.14 on AL2023 through the Elastic Beanstalk Console, CLI, or API.\n \nThis platform is available in all commercial AWS Regions where Elastic Beanstalk is available, including the AWS GovCloud (US) Regions. For a complete list of regions and service offerings, see AWS Regions.\n \nTo learn more about Python 3.14 on Amazon Linux 2023, see the AWS Elastic Beanstalk Developer guide. For additional information, visit the AWS Elastic Beanstalk product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-beanstalk-python-314-linux-2023/",
      "pubDate": "2025-12-05T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-1e689ae3b3ff",
      "title": "AWS Directory Service for Microsoft AD and AD Connector available in Asia Pacific (New Zealand) Region",
      "description": "AWS Directory Service for Microsoft Active Directory, also known as AWS Managed Microsoft AD, and AD Connector are now available in the Asia Pacific (New Zealand) Region.\n \n\n Built on actual Microsoft Active Directory (AD), AWS Managed Microsoft AD enables you to migrate AD-aware applications while reducing the work of managing AD infrastructure in the AWS Cloud. You can use your Microsoft AD credentials to domain join EC2 instances, and also manage containers and Kubernetes clusters. You can keep your identities in your existing Microsoft AD or create and manage identities in your AWS managed directory.\n  AD Connector is a proxy that enables AWS applications to use your existing on-premises AD identities without requiring AD infrastructure in the AWS Cloud. You can also use AD Connector to join Amazon EC2 instances to your on-premises AD domain and manage these instances using your existing group policies.\n  Please see all AWS Regions where AWS Managed Microsoft AD and AD Connector are available. To learn more, see AWS Directory Service.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-directory-service-microsoft-ad-ad-connector-new-zealand-region/",
      "pubDate": "2025-12-05T05:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "directory service"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "directory service",
        "now-available"
      ]
    },
    {
      "id": "aws-news-6e0869a825a5",
      "title": "Amazon Bedrock now supports Responses API from OpenAI",
      "description": "Amazon Bedrock now supports Responses API on new OpenAI API-compatible service endpoints. Responses API enables developers to achieve asynchronous inference for long-running inference workloads, simplifies tool use integration for agentic workflows, and also supports stateful conversation management. Instead of requiring developers to pass the entire conversation history with each request, Responses API enables them to automatically rebuild context without manual history management. These new service endpoints support both streaming and non-streaming modes, enable reasoning effort support within Chat Completions API, and require only a base URL change for developers to integrate within existing codebases with OpenAI SDK compatibility.\n  \n Chat Completions with reasoning effort support is available for all Amazon Bedrock models powered by Project Mantle, a new distributed inference engine for large-scale machine learning model serving on Amazon Bedrock. Project Mantle simplifies and expedites onboarding of new models onto Amazon Bedrock, provides highly performant and reliable serverless inference with sophisticated quality of service controls, unlocks higher default customer quotas with automated capacity management and unified pools, and provides out-of-the-box compatibility with OpenAI API specifications. Responses API support is available today starting with OpenAI's GPT OSS 20B/120B models, with support for other models coming soon.\n To get started, visit the service documentation here",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-bedrock-responses-api-from-openai/",
      "pubDate": "2025-12-04T12:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "integration",
        "support",
        "coming-soon",
        "new-model"
      ]
    },
    {
      "id": "aws-news-509a6eaf3b64",
      "title": "Announcing new Amazon EC2 M9g instances powered by AWS Graviton5 processors (Preview)",
      "description": "Starting today, new general purpose Amazon Elastic Compute Cloud (Amazon EC2) M9g instances, powered by AWS Graviton5 processors, are available in preview. AWS Graviton5 is the latest in the Graviton family of processors that are custom designed by AWS to provide the best price performance for workloads in Amazon EC2. These instances offer up to 25% better compute performance, and higher networking and Amazon Elastic Block Store (Amazon EBS) bandwidth than AWS Graviton4-based M8g instances. They are up to 30% faster for databases, up to 35% faster web applications, and up to 35% faster for machine learning workloads compared to M8g.\n  M9g instances are built on the AWS Nitro System, a collection of hardware and software innovations designed by AWS. The AWS Nitro System enables the delivery of efficient, flexible, and secure cloud services with isolated multitenancy, private networking, and fast local storage. Amazon EC2 M9g instances are ideal for workloads such as application servers, microservices, gaming servers, midsize data stores, and caching fleets.\n  To learn more or request access to the M9g preview, see Amazon EC2 M9g instances. To begin your Graviton journey, visit the Level up your compute with AWS Graviton page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/ec2-m9g-instances-graviton5-processors-preview/",
      "pubDate": "2025-12-04T09:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex",
        "ec2",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "lex",
        "ec2",
        "graviton",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-ad98b700a350",
      "title": "Amazon Bedrock adds reinforcement ﬁne-tuning simplifying how developers build smarter, more accurate AI models",
      "description": "Amazon Bedrock now supports reinforcement fine-tuning delivering 66% accuracy gains on average over base models.",
      "link": "https://aws.amazon.com/blogs/aws/improve-model-accuracy-with-reinforcement-fine-tuning-in-amazon-bedrock/",
      "pubDate": "2025-12-03T16:08:14.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f27f0877e40c",
      "title": "New serverless customization in Amazon SageMaker AI accelerates model fine-tuning",
      "description": "Accelerate AI model development with new training features that enable rapid recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/new-serverless-customization-in-amazon-sagemaker-ai-accelerates-model-fine-tuning/",
      "pubDate": "2025-12-03T16:08:03.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-20b1f9fc07df",
      "title": "Introducing checkpointless and elastic training on Amazon SageMaker HyperPod",
      "description": "Accelerate AI model development with new training features that enable instant recovery from failures and automatic scaling based on resource availability.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-checkpointless-and-elastic-training-on-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-12-03T16:07:52.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-54eab717f389",
      "title": "Amazon SageMaker HyperPod now supports checkpointless training",
      "description": "Amazon SageMaker HyperPod now supports checkpointless training, a new foundational model training capability that mitigates the need for a checkpoint-based job-level restart for fault recovery. Checkpointless training maintains forward training momentum despite failures, reducing recovery time from hours to minutes. This represents a fundamental shift from traditional checkpoint-based recovery, where failures require pausing the entire training cluster, diagnosing issues manually, and restoring from saved checkpoints, a process that can leave expensive AI accelerators idle for hours, costing your organization wasted compute.\n \nCheckpointless training transforms this paradigm by preserving the model training state across the distributed cluster, automatically swapping out faulty training nodes on the fly and using peer-to-peer state transfer from healthy accelerators for failure recovery. By mitigating checkpoint dependencies during recovery, checkpointless training can help your organization save on idle AI accelerator costs and accelerate time. Even at larger scales, checkpointless training on Amazon SageMaker HyperPod enables upwards of 95% training goodput on cluster sizes with thousands of AI accelerators.\n \nCheckpointless training on SageMaker HyperPod is available in all AWS Regions where Amazon SageMaker HyperPod is currently available. You can enable checkpointless training with zero code changes using HyperPod recipes for popular publicly available models such as Llama and GPT OSS. For custom model architectures, you can integrate checkpointless training components with minimal modifications for PyTorch-based workflows, making it accessible to your teams regardless of their distributed training expertise.\n \nTo get started, visit the Amazon SageMaker HyperPod product page and see the checkpointless training GitHub page for implementation guidance.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-sagemaker-hyperpod-checkpointless-training",
      "pubDate": "2025-12-03T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "rds"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "rds",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-15dab4dd881e",
      "title": "New serverless model customization capability in Amazon SageMaker AI",
      "description": "Amazon Web Services (AWS) announces a new serverless model customization capability that empowers AI developers to quickly customize popular models with supervised fine-tuning and the latest techniques like reinforcement learning. Amazon SageMaker AI is a fully managed service that brings together a broad set of tools to enable high-performance, low-cost AI model development for any use case. \n \nMany AI developers seek to customize models with proprietary data for improved accuracy, but this often requires lengthy iteration cycles. For example, AI developers must define a use case and prepare data, select a model and customization technique, train the model, then evaluate the model for deployment. Now AI developers can simplify the end-to-end model customization workflow, from data preparation to evaluation and deployment, and accelerate the process. With an easy-to-use interface, AI developers can quickly get started and customize popular models, including Amazon Nova, Llama, Qwen, DeepSeek, and GPT-OSS, with their own data. They can use supervised fine-tuning and the latest customization techniques such as reinforcement learning and direct preference optimization. In addition, AI developers can use the AI agent-guided workflow (in preview), and use natural language to generate synthetic data, analyze data quality, and handle model training and evaluation—all entirely serverless. \n \nYou can use this easy-to-use interface in the following AWS Regions: Europe (Ireland), US East (N. Virginia), Asia Pacific (Tokyo), and US West (Oregon). To join the waitlist to access the AI agent-guided workflow, visit the sign-up page. \n \nTo learn more, visit the SageMaker AI model customization page and blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/new-serverless-model-customization-capability-amazon-sagemaker-ai",
      "pubDate": "2025-12-03T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "preview"
      ]
    },
    {
      "id": "aws-news-a465d0dd13ac",
      "title": "Announcing TypeScript support in Strands Agents (preview) and more",
      "description": "In May, we open sourced the Strands Agents SDK, an open source python framework that takes a model-driven approach to building and running AI agents in just a few lines of code. Today, we’re announcing that TypeScript support is available in preview. Now, developers can choose between Python and TypeScript for building Strands Agents.\n  TypeScript support in Strands has been designed to provide an idiomatic TypeScript experience with full type safety, async/await support, and modern JavaScript/TypeScript patterns. Strands can be easily run in client applications, in browsers, and server-side applications in runtimes like AWS Lambda and Bedrock AgentCore. Developers can also build their entire stack in Typescript using the AWS CDK.\n  We’re also announcing three additional updates for the Strands SDK. First, edge device support for Strands Agents is generally available, extending the SDK with bidirectional streaming and additional local model providers like llama.cpp that let you run agents on small-scale devices using local models. Second, Strands steering is now available as an experimental feature, giving developers a modular prompting mechanism that provides feedback to the agent at the right moment in its lifecycle, steering agents toward a desired outcome without rigid workflows. Finally, Strands evaluations is available in preview. Evaluations gives developers the ability to systematically validate agent behavior, measure improvements, and deploy with confidence during development cycles.\n  Head to the Strands Agents GitHub to get started building.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/typescript-strands-agents-preview",
      "pubDate": "2025-12-03T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "lambda"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lambda",
        "preview",
        "experimental",
        "generally-available",
        "now-available",
        "update",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-ef3aea785303",
      "title": "Introducing elastic training on Amazon SageMaker HyperPod",
      "description": "Amazon SageMaker HyperPod now supports elastic training, enabling organizations to accelerate foundation model training by automatically scaling training workloads based on resource availability and workload priorities. This represents a fundamental shift from training with a fixed set of resources, as it saves hours of engineering time spent reconfiguring training jobs based on compute availability.\n \nAny change in compute availability previously required manually halting training, reconfiguring training parameters, and restarting jobs—a process that requires distributed training expertise and leaves expensive AI accelerators sitting idle during training job reconfiguration. Elastic training automatically expands training jobs to absorb idle AI accelerators and seamlessly contracting when higher-priority workloads need resources—all without halting training entirely.\n \nBy eliminating manual reconfiguration overhead and ensuring continuous utilization of available compute, elastic training can help save time previously spent on infrastructure management, reduce costs by maximizing cluster utilization, and accelerate time-to-market. Training can start immediately with minimal resources and grow opportunistically as capacity becomes available.\n \nSageMaker HyperPod is available in all regions where Amazon SageMaker HyperPod is currently available. Organizations can enable elastic training with zero code changes using HyperPod recipes for publicly available models including Llama and GPT OSS. For custom model architectures, customers can integrate elastic training capabilities through lightweight configuration updates and minimal code modifications, making it accessible to teams without requiring distributed systems expertise.\n \nTo get started, visit the Amazon SageMaker HyperPod product page and see the elastic training documentation for implementation guidance.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/elastic-training-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-12-03T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "organizations",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-06f56a16182f",
      "title": "Amazon Bedrock now supports reinforcement fine-tuning delivering 66% accuracy gains on average over base models",
      "description": "Amazon Bedrock now supports reinforcement fine-tuning, helping you improve model accuracy without needing deep machine learning expertise or large sums of labeled data. Amazon Bedrock automates the reinforcement fine-tuning workflow, making this advanced model customization technique accessible to everyday developers. Models learn to align with your specific requirements using a small set of prompts rather than the large sums of data needed for traditional fine-tuning methods, enabling teams to get started quickly. This capability teaches models through feedback on multiple possible responses to the same prompt, improving their judgement of what makes a good response. Reinforcement fine-tuning in Amazon Bedrock delivers 66% accuracy gains on average over base models so you can use smaller, faster, and more cost-effective model variants while maintaining high quality.\n \nOrganizations struggle to adapt AI models to their unique business needs, forcing them to choose between generic models with average performance or expensive, complex customization that requires specialized talent, infrastructure, and risky data movement. Reinforcement fine-tuning in Amazon Bedrock removes this complexity by making advanced model customization fast, automated, and secure. You can train models by uploading training data directly from your computer or choose from datasets already stored in Amazon S3, eliminating the need for any labeled datasets. You can define reward functions using verifiable rule-based graders or AI-based judges along with built-in templates to optimize your models for both objective tasks such as code generation or math reasoning, and subjective tasks such as instruction following or chatbot interactions. Your proprietary data never leaves AWS's secure, governed environment during the entire customization process, mitigating security and compliance concerns.\n \nYou can get started with reinforcement fine-tuning in Amazon Bedrock through the Amazon Bedrock console and via the Amazon Bedrock APIs. At launch, you can use reinforcement fine-tuning with Amazon Nova 2 Lite with support for additional models coming soon. To learn more about reinforcement fine-tuning in Amazon Bedrock, read the launch blog, pricing page, and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/bedrock-reinforcement-fine-tuning-66-base-models/",
      "pubDate": "2025-12-03T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "lex",
        "s3",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "lex",
        "s3",
        "organizations",
        "launch",
        "ga",
        "support",
        "coming-soon"
      ]
    },
    {
      "id": "aws-news-4139ea9a5e0b",
      "title": "Announcing replication support and Intelligent-Tiering for Amazon S3 Tables",
      "description": "New features enable automatic cost optimization through intelligent storage tiering and simplified table replication across AWS Regions and accounts.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-replication-support-and-intelligent-tiering-for-amazon-s3-tables/",
      "pubDate": "2025-12-02T16:19:14.000Z",
      "source": "newsBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-64738829059d",
      "title": "Amazon S3 Storage Lens adds performance metrics, support for billions of prefixes, and export to S3 Tables",
      "description": "New capabilities help optimize application performance, analyze unlimited prefixes, and simplify metrics analysis through S3 Tables integration.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-s3-storage-lens-adds-performance-metrics-support-for-billions-of-prefixes-and-export-to-s3-tables/",
      "pubDate": "2025-12-02T16:15:12.000Z",
      "source": "newsBlog",
      "services": [
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-17e673125d4d",
      "title": "Amazon Bedrock AgentCore adds quality evaluations and policy controls for deploying trusted AI agents",
      "description": "Deploy AI agents with confidence using new quality evaluations and policy controls—enabling precise boundaries on agent actions, continuous quality monitoring, and experience-based learning while maintaining natural conversation flows.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-bedrock-agentcore-adds-quality-evaluations-and-policy-controls-for-deploying-trusted-ai-agents/",
      "pubDate": "2025-12-02T16:14:36.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-c6bdf0af2db1",
      "title": "Build multi-step applications and AI workflows with AWS Lambda durable functions",
      "description": "New Lambda capability lets you build applications that coordinate multiple steps reliably over extended periods—from seconds to up to one year—without paying for idle compute time when waiting for external events or human decisions.",
      "link": "https://aws.amazon.com/blogs/aws/build-multi-step-applications-and-ai-workflows-with-aws-lambda-durable-functions/",
      "pubDate": "2025-12-02T16:12:19.000Z",
      "source": "newsBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-61eba6194632",
      "title": "New capabilities to optimize costs and improve scalability on Amazon RDS for SQL Server and Oracle",
      "description": "Manage development, testing, and production database workloads more efficiently with new features including Developer Edition support for SQL Server, M7i/R7i instance support with optimize CPU, and expanded storage options up to 256 TiB.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-rds-for-oracle-and-rds-for-sql-server-add-new-capabilities-to-enhance-performance-and-optimize-costs/",
      "pubDate": "2025-12-02T16:09:29.000Z",
      "source": "newsBlog",
      "services": [
        "rds"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "rds",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-0da1e0b931e3",
      "title": "Introducing Database Savings Plans for AWS Databases",
      "description": "New pricing model helps maintain cost efficiency while providing flexibility with database services and deployment options.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-database-savings-plans-for-aws-databases/",
      "pubDate": "2025-12-02T16:09:26.000Z",
      "source": "newsBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-013962572343",
      "title": "Amazon CloudWatch introduces unified data management and analytics for operations, security, and compliance",
      "description": "Reduce data management complexity and costs with automatic normalization across sources, native analytics integration, and built-in support for industry-standard formats like OCSF and Apache Iceberg.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-cloudwatch-introduces-unified-data-management-and-analytics-for-operations-security-and-compliance/",
      "pubDate": "2025-12-02T16:07:11.000Z",
      "source": "newsBlog",
      "services": [
        "lex",
        "cloudwatch"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex",
        "cloudwatch",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-c1b325cf4a05",
      "title": "New and enhanced AWS Support plans add AI capabilities to expert guidance",
      "description": "Prevent cloud infrastructure issues before they impact your business with AWS Support plans that combine AI-powered insights with expert guidance, offering faster response times and proactive monitoring across performance, security, and cost dimensions.",
      "link": "https://aws.amazon.com/blogs/aws/new-and-enhanced-aws-support-plans-add-ai-capabilities-to-expert-guidance/",
      "pubDate": "2025-12-02T16:07:03.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-9a0b50c6aecc",
      "title": "Amazon OpenSearch Service improves vector database performance and cost with GPU acceleration and auto-optimization",
      "description": "Build and optimize large-scale vector databases up to 10 times faster and at a quarter of the cost with new GPU acceleration and auto-optimization capabilities that automatically balance search quality, speed, and resource usage.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-opensearch-service-improves-vector-database-performance-and-cost-with-gpu-acceleration-and-auto-optimization/",
      "pubDate": "2025-12-02T16:06:41.000Z",
      "source": "newsBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-b8ed46f35335",
      "title": "Amazon S3 Vectors now generally available with increased scale and performance",
      "description": "Scale vector storage and querying to new heights with S3 Vectors' general availability—now supporting up to 1 billion vectors per index, 100ms query latencies, and expanded regional availability, while reducing costs up to 90% compared to specialized databases.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-s3-vectors-now-generally-available-with-increased-scale-and-performance/",
      "pubDate": "2025-12-02T16:06:11.000Z",
      "source": "newsBlog",
      "services": [
        "s3 vectors",
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3 vectors",
        "s3",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-46fcd3d2ef15",
      "title": "Amazon Bedrock adds 18 fully managed open weight models, including the new Mistral Large 3 and Ministral 3 models",
      "description": "Access fully managed foundation models from leading providers like Google, Kimi AI, MiniMax AI, Mistral AI, NVIDIA, OpenAI, and Qwen, including the new Mistral Large 3 and Ministral 3 3B, 8B, and 14B models through Amazon Bedrock.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-bedrock-adds-fully-managed-open-weight-models/",
      "pubDate": "2025-12-02T16:05:57.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-f26b55b865f0",
      "title": "Introducing Amazon EC2 X8aedz instances powered by 5th Gen AMD EPYC processors for memory-intensive workloads",
      "description": "New memory-optimized instances deliver up to 5 GHz processor speeds and 3 TiB of memory—ideal for electronic design automation workloads and memory-intensive databases requiring high single-threaded performance.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-amazon-ec2-x8aedz-instances-powered-by-5th-gen-amd-epyc-processors-for-memory-intensive-workloads/",
      "pubDate": "2025-12-02T16:05:44.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-5919cd15a7c0",
      "title": "AWS DevOps Agent helps you accelerate incident response and improve system reliability (preview)",
      "description": "New service acts as an always-on DevOps engineer, helping you respond to incidents, identify root causes, and prevent future issues through systematic analysis of incidents and operational patterns.",
      "link": "https://aws.amazon.com/blogs/aws/aws-devops-agent-helps-you-accelerate-incident-response-and-improve-system-reliability-preview/",
      "pubDate": "2025-12-02T16:05:42.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-36085772e181",
      "title": "Accelerate AI development using Amazon SageMaker AI with serverless MLflow",
      "description": "Simplify AI experimentation with zero-infrastructure MLflow that launches in minutes, scales automatically, and seamlessly integrates with SageMaker's model customization and pipeline capabilities.",
      "link": "https://aws.amazon.com/blogs/aws/accelerate-ai-development-using-amazon-sagemaker-ai-with-serverless-mlflow/",
      "pubDate": "2025-12-02T16:02:56.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "launch"
      ]
    },
    {
      "id": "aws-news-fec165d010fd",
      "title": "Announcing Amazon EC2 General purpose M8azn instances (Preview)",
      "description": "Starting today, new general purpose high-frequency high-network Amazon Elastic Compute Cloud (Amazon EC2) M8azn instances are available for preview. These instances are powered by fifth generation AMD EPYC (formerly code named Turin) processors, offering the highest maximum CPU frequency, 5GHz in the cloud. The M8azn instances offer up to 2x compute performance versus previous generation M5zn instances. These instances also deliver 24% higher performance than M8a instances.\n  M8azn instances are built on the AWS Nitro System, a collection of hardware and software innovations designed by AWS. The AWS Nitro System enables the delivery of efficient, flexible, and secure cloud services with isolated multitenancy, private networking, and fast local storage. These instances are ideal for applications such as gaming, high-performance computing, high-frequency trading (HFT), CI/CD, and simulation modeling for the automotive, aerospace, energy, and telecommunication industries.\n  To learn more or request access to the M8azn instances preview, visit the Amazon EC2 M8a page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-amazon-ec2-m8azn-preview",
      "pubDate": "2025-12-02T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex",
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova",
        "lex",
        "ec2",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-6329b7ab5837",
      "title": "Amazon FSx for NetApp ONTAP now integrates with Amazon S3 for seamless data access",
      "description": "Access FSx for NetApp ONTAP file data through S3 to enable AI/ML workloads and analytics—letting you use enterprise file data with Bedrock, SageMaker, and analytics services while it remains in your file system.",
      "link": "https://aws.amazon.com/blogs/aws/amazon-fsx-for-netapp-ontap-now-integrates-with-amazon-s3-for-seamless-data-access/",
      "pubDate": "2025-12-02T15:59:54.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "sagemaker",
        "s3"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "s3"
      ]
    },
    {
      "id": "aws-news-11d5bd89eb5c",
      "title": "Announcing Amazon Nova 2 Sonic for real-time conversational AI",
      "description": "Today, Amazon announces the availability of Amazon Nova 2 Sonic, our speech-to-speech model for natural, real-time conversational AI.  It offers best-in-class streaming speech understanding with robustness to background noise and users’ speaking styles, efficient dialog handling, and speech generation with expressive voices that can speak natively in multiple languages (Polyglot voices). It has superior reasoning, instruction following, and tool invocation accuracy over the previous model.\n \nNova 2 Sonic builds on the capabilities introduced in the original Nova Sonic model with new features including expanded language support (Portuguese and Hindi), polyglot voices that enable the model to speak different languages with native expressivity using the same voice, and turn-taking controllability to allow developers to set low, medium, or high pause sensitivity. The model also adds cross-modal interaction, allowing users to seamlessly switch between voice and text in the same session, asynchronous tool calling to support multi-step tasks without interrupting conversation flow, and a one-million token context window for sustained interactions.\n \nDevelopers can integrate Nova Sonic 2 directly into real-time voice systems using Amazon Bedrock’s bidirectional streaming API. Nova Sonic 2 now also seamlessly integrates with Amazon Connect and other leading telephony providers, including Vonage, Twilio, and AudioCodes, as well as open source frameworks such as LiveKit and Pipecat.\n \nAmazon Nova 2 Sonic is available in Amazon Bedrock in the following AWS Regions: US East (N. Virginia), US West (Oregon), and Asia Pacific (Tokyo). To learn more, read the AWS News Blog and the Amazon Nova Sonic User Guide. To get started with Nova Sonic 2 in Amazon Bedrock, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-nova-2-sonic-real-time-conversational-ai/",
      "pubDate": "2025-12-02T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-32f783e29c54",
      "title": "Announcing the Apache Spark upgrade agent for Amazon EMR",
      "description": "AWS announces the Apache Spark upgrade agent, a new capability that accelerates Apache Spark version upgrades for Amazon EMR on EC2 and EMR Serverless. The agent converts complex upgrade processes that typically take months into projects spanning weeks through automated code analysis and transformation. Organizations invest substantial engineering resources analyzing API changes, resolving conflicts, and validating applications during Spark upgrades. The agent introduces conversational interfaces where engineers express upgrade requirements in natural language, while maintaining full control over code modifications.\n  The Apache Spark upgrade agent automatically identifies API changes and behavioral modifications across PySpark and Scala applications. Engineers can initiate upgrades directly from SageMaker Unified Studio, Kiro CLI or IDE of their choice with the help of MCP (Model Context Protocol) compatibility. During the upgrade process, the agent analyzes existing code and suggests specific changes, and engineers can review and approve before implementation. The agent validates functional correctness through data quality validations. The agent currently supports upgrades from Spark 2.4 to 3.5 and maintains data processing accuracy throughout the upgrade process.\n  The Apache Spark upgrade agent is now available in all AWS Regions where SageMaker Unified Studio is available. To start using the agent, visit SageMaker Unified Studio and select IDE Spaces or install the Kiro CLI. For detailed implementation guidance, reference documentation, and migration examples, visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/apache-spark-upgrade-agent-amazon-emr",
      "pubDate": "2025-12-02T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "lex",
        "ec2",
        "emr",
        "eks",
        "organizations",
        "ga",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-b0ecbb4e838e",
      "title": "Amazon RDS for SQL Server now supports Developer Edition",
      "description": "Amazon Relational Database Service (Amazon RDS) for SQL Server now offers Microsoft SQL Server 2022 Developer Edition. SQL Server Developer Edition is a free edition of SQL Server that contains all the features of Enterprise Edition and can be used in any non-production environment. This enables customers to build, test, and demonstrate applications using SQL Server while reducing costs and maintaining consistency with their production database configurations.\n  Previously, customers that created Amazon RDS for SQL Server instances for development and test environments had to use SQL Server Standard Edition or SQL Server Enterprise Edition, which resulted in additional database licensing costs for non-production usage. Now, customers can lower the cost of their Amazon RDS development and testing instances by using SQL Server Developer Edition. Furthermore, Amazon RDS for SQL Server features such as automated backups, automated software updates, monitoring, and encryption for development and testing purposes will work on Developer Edition.\n  The license for Microsoft SQL Server Developer Edition strictly limits its use to development and testing purposes. It cannot be used in a production environment, or for any commercial purposes that directly serve end-users. For more information, refer to the Amazon RDS for SQL Server User Guide. See Amazon RDS for SQL Server Pricing for pricing details and regional availability.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-rds-sql-server-supports-developer-edition/",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-0af7d0f0d0e9",
      "title": "Amazon FSx for NetApp ONTAP now supports Amazon S3 access",
      "description": "You can now attach Amazon S3 Access Points to your Amazon FSx for NetApp ONTAP file systems so that you can access your file data as if it were in S3. With this new capability, your file data in FSx for NetApp ONTAP is effortlessly accessible for use with the broad range of artificial intelligence, machine learning, and analytics services and applications that work with S3 while your file data continues to reside in your FSx for NetApp ONTAP file system.\n  Amazon FSx for NetApp ONTAP is the first and only complete, fully managed NetApp ONTAP file system in the cloud, allowing you to migrate on-premises applications that rely on NetApp ONTAP or other NAS appliances to AWS without having to change how you manage your data. An S3 Access Point is an endpoint that helps control and simplify how different applications or users can access data. Now, with S3 Access Points for FSx for NetApp ONTAP, you can discover new insights, innovate faster, and make even better data-driven decisions with the data you migrate to AWS. For example, you can use your data to augment generative AI applications with Amazon Bedrock, train machine learning models with Amazon SageMaker, run analysis using Amazon Glue or a wide range of AWS Data and Analytics Competency Partner solutions, and run workflows using S3-based cloud-native applications.\n  Get started with this capability by creating and attaching S3 Access Points to new FSx for NetApp ONTAP file systems using the Amazon FSx console, the AWS Command Line Interface (AWS CLI), or the AWS Software Development Kit (AWS SDK). Support for existing FSx for NetApp ONTAP file systems will come in an upcoming weekly maintenance window. This new capability is available in the select AWS Regions.\n  To get started, see the following list of resources:\n  \n \n \nAmazon FSx for NetApp ONTAP\n \n \nAmazon S3 Access Points\n \n \nAWS News Blog",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-fsx-netapp-ontap-s3-access",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "sagemaker",
        "s3",
        "glue"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "nova",
        "sagemaker",
        "s3",
        "glue",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-69bad9f64822",
      "title": "Amazon RDS for SQL Server launches optimize CPU with new generation instances for up to 55% lower price",
      "description": "Amazon RDS for SQL Server launches optimize CPU with support for M7i and R7i instance families, which reduce prices by up to 55% compared to equivalent previous generation instances. Optimize CPU optimizes Simultaneous Multi-threading (SMT) configuration to reduce commercial software charges. Customers can lower cost by upgrading to M7i and R7i instances from similar 6th generation instances. Furthermore, for memory or IO intensive database workloads, customers can get additional cost reduction by fine tuning optimize CPU configuration.\n  RDS for SQL Server price for database instance hours consumed is inclusive of Microsoft Windows and Microsoft SQL Server software charges. Optimize CPU disables SMT for instances with 2 or more physical CPU cores. This reduces the number of vCPUs, and the corresponding commercial software charges by 50% while providing the same number of physical CPU cores, and near equivalent performance. The most significant savings are available on 2Xlarge and higher instances, and instances that use Multi-AZ deployment, where RDS optimizes to reduce SQL Server software charges for only a single active node for most usage. For workloads that are memory or IO intensive, customers can fine tune the number of active physical CPU cores for further savings.\n  RDS for SQL Server supports M7i and R7i instances in all AWS Regions. With unbundled instance pricing, database costs are calculated with separate charges for third party licensing fees per vCPU hour, and third party licensing fees are not eligible towards your organization’s discounts with AWS. You can view Microsoft Windows and SQL Server charges associated with your usage on AWS Billing and Cost Management, and in monthly bills. For more details, visit RDS for SQL Server pricing, Amazon RDS User Guide and AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-rds-sql-server-optimized-cpu-lower-prices",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-a835beefc96f",
      "title": "Amazon S3 Storage Lens adds performance metrics, support for billions of prefixes, and export to S3 Tables",
      "description": "Amazon S3 Storage Lens provides organization-wide visibility into your storage usage and activity to help optimize costs, improve performance, and strengthen data protection. Today, we are adding three new capabilities to S3 Storage Lens that give you deeper insights into your S3 storage usage and application performance: performance metrics that provide insights into how your applications interact with S3 data, analytics for billions of prefixes in your buckets, and metrics export directly to S3 Tables for easier querying and analysis.\n  We are adding three specific types of performance metrics. Access pattern metrics identify inefficient requests, including those that are too small and create unnecessary network overhead. Request origin metrics, such as cross-Region request counts, show when applications access data across regions, impacting latency and costs. Object access count metrics reveal when applications frequently read a small subset of objects that could be optimized through caching or moving to high-performance storage.\n  We are expanding the prefix analytics in S3 Storage Lens to enable analyzing billions of prefixes per bucket, whereas previously metrics were limited to the largest prefixes that met minimum size and depth thresholds. This gives you visibility into storage usage and activity across all your prefixes. Finally, we are making it possible to export metrics directly to managed S3 Tables, making them immediately available for querying with AWS analytics services like Amazon QuickSight and enabling you to join this data with other AWS service data for deeper insights.\n  To get started, enable performance metrics or expanded prefixes in your S3 Storage Lens advanced metrics dashboard configuration. These capabilities are available in all AWS Regions, except for AWS China Regions and AWS GovCloud (US) Regions. You can enable metrics export to managed S3 Tables in both free and advanced dashboard configurations in AWS Regions where S3 Tables are available. To learn more, visit the S3 Storage Lens overview page, documentation, S3 pricing page, and read the AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-s3-storage-lens-performance-metrics-prefixes-export-tables",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "s3",
        "quicksight"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "amazon q",
        "s3",
        "quicksight",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-bfb723928032",
      "title": "Amazon EC2 P6e-GB300 UltraServers accelerated by NVIDIA GB300 NVL72 are now generally available",
      "description": "Today, AWS announces the general availability of Amazon Elastic Compute Cloud (Amazon EC2) P6e-GB300 UltraServers. P6e-GB300 UltraServers, accelerated by NVIDIA GB300 NVL72, provide 1.5x GPU memory and 1.5x FP4 compute (without sparsity) compared to P6e-GB200. \n \nCustomers can optimize performance for the most powerful models in production with P6e-GB300 for applications that require higher context and implement emerging inference techniques like reasoning and Agentic AI.\n \nTo get started with P6e-GB300 UltraServers, please contact your AWS sales representative.\n \nTo learn more about P6e UltraServers and instances, visit Amazon EC2 P6 instances.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-p6e-gb300-ultraservers-nvidia-gb300-nvl72-generally-available",
      "pubDate": "2025-12-02T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-24cd991522e9",
      "title": "Apache Spark encryption performance improvement with Amazon EMR 7.9",
      "description": "In this post, we analyze the results from our benchmark tests comparing the Amazon EMR 7.9 optimized Spark runtime against Spark 3.5.5 without encryption optimizations. We walk through a detailed cost analysis and provide step-by-step instructions to reproduce the benchmark.",
      "link": "https://aws.amazon.com/blogs/big-data/apache-spark-encryption-performance-improvement-with-amazon-emr-7-9/",
      "pubDate": "2025-11-27T01:37:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-61dc3e3d79bd",
      "title": "Run Apache Spark and Apache Iceberg write jobs 2x faster with Amazon EMR",
      "description": "In this post, we demonstrate the write performance benefits of using the Amazon EMR 7.12 runtime for Spark and Iceberg compares to open source Spark 3.5.6 with Iceberg 1.10.0 tables on a 3TB merge workload.",
      "link": "https://aws.amazon.com/blogs/big-data/run-apache-spark-and-apache-iceberg-write-jobs-2x-faster-with-amazon-emr/",
      "pubDate": "2025-11-27T01:03:08.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-70a75d3e1cfa",
      "title": "Medidata’s journey to a modern lakehouse architecture on AWS",
      "description": "In this post, we show you how Medidata created a unified, scalable, real-time data platform that serves thousands of clinical trials worldwide with AWS services, Apache Iceberg, and a modern lakehouse architecture.",
      "link": "https://aws.amazon.com/blogs/big-data/medidatas-journey-to-a-modern-lakehouse-architecture-on-aws/",
      "pubDate": "2025-11-27T01:00:46.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": []
    },
    {
      "id": "aws-news-214f1f935f59",
      "title": "Achieve 2x faster data lake query performance with Apache Iceberg on Amazon Redshift",
      "description": "In 2025, Amazon Redshift delivered several performance optimizations that improved query performance over twofold for Iceberg workloads on Amazon Redshift Serverless, delivering exceptional performance and cost-effectiveness for your data lake workloads. In this post, we describe some of the optimizations that led to these performance gains.",
      "link": "https://aws.amazon.com/blogs/big-data/achieve-2x-faster-data-lake-query-performance-with-apache-iceberg-on-amazon-redshift/",
      "pubDate": "2025-11-26T22:16:15.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "redshift",
        "ga"
      ]
    },
    {
      "id": "aws-news-0dbe89f3f79b",
      "title": "Orchestrating large-scale document processing with AWS Step Functions and Amazon Bedrock batch inference",
      "description": "Organizations often have large volumes of documents containing valuable information that remains locked away and unsearchable. This solution addresses the need for a \nscalable, automated text extraction and knowledge base pipeline that transforms static document collections into intelligent, searchable repositories for generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-large-scale-document-processing-with-aws-step-functions-and-amazon-bedrock-batch-inference/",
      "pubDate": "2025-11-26T21:41:51.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock",
        "step functions",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "step functions",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-1c031b337189",
      "title": "Secure Amazon Elastic VMware Service (Amazon EVS) with AWS Network Firewall",
      "description": "In this post, we demonstrate how to utilize AWS Network Firewall to secure an Amazon EVS environment, using a centralized inspection architecture across an EVS cluster, VPCs, on-premises data centers and the internet. We walk through the implementation steps to deploy this architecture using AWS Network Firewall and AWS Transit Gateway.",
      "link": "https://aws.amazon.com/blogs/architecture/secure-amazon-elastic-vmware-service-amazon-evs-with-aws-network-firewall/",
      "pubDate": "2025-11-26T16:22:03.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-c9da28428aee",
      "title": "Node.js 24 runtime now available in AWS Lambda",
      "description": "You can now develop AWS Lambda functions using Node.js 24, either as a managed runtime or using the container base image. Node.js 24 is in active LTS status and ready for production use. It is expected to be supported with security patches and bugfixes until April 2028. The Lambda runtime for Node.js 24 includes a new implementation of the […]",
      "link": "https://aws.amazon.com/blogs/compute/node-js-24-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-25T22:19:46.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-7cb737e81dc9",
      "title": "The attendee’s guide to hybrid cloud and edge computing at AWS re:Invent 2025",
      "description": "AWS re:Invent 2025 returns to Las Vegas, Nevada, from December 1–5, 2025. This year, we’re offering a comprehensive lineup of sessions and booth activities to help you build resilient, performant, and scalable applications wherever you need them—in the cloud, on premises, or at the edge.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-hybrid-cloud-and-edge-computing-at-aws-reinvent-2025/",
      "pubDate": "2025-11-25T19:27:19.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-e5767083a6d4",
      "title": "Optimize unused capacity with Amazon EC2 interruptible capacity reservations",
      "description": "Organizations running critical workloads on Amazon Elastic Compute Cloud (Amazon EC2) reserve compute capacity using On-Demand Capacity Reservations (ODCR) to have availability when needed. However, reserved capacity can intermittently sit idle during off-peak periods, between deployments, or when workloads scale down. This unused capacity represents a missed opportunity for cost optimization and resource efficiency across the organization.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-unused-capacity-with-amazon-ec2-interruptible-capacity-reservations/",
      "pubDate": "2025-11-25T01:09:16.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-5403d33b1bbc",
      "title": "How potential performance upside with AWS Graviton helps reduce your costs further",
      "description": "Amazon Web Services (AWS) provides many mechanisms to optimize the price performance of workloads running on Amazon Elastic Compute Cloud (Amazon EC2), and the selection of the optimal infrastructure to run on can be one of the most impactful levers. When we started building the AWS Graviton processor, our goal was to optimize AWS Graviton […]",
      "link": "https://aws.amazon.com/blogs/compute/how-potential-performance-upside-with-aws-graviton-helps-reduce-your-costs-further/",
      "pubDate": "2025-11-24T19:11:55.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton"
      ]
    },
    {
      "id": "aws-news-7d35cf5f9ae9",
      "title": "Enhancing API security with Amazon API Gateway TLS security policies",
      "description": "In this post, you will learn how the new Amazon API Gateway’s enhanced TLS security policies help you meet standards such as PCI DSS, Open Banking, and FIPS, while strengthening how your APIs handle TLS negotiation. This new capability increases your security posture without adding operational complexity, and provides you with a single, consistent way to standardize TLS configuration across your API Gateway infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/enhancing-api-security-with-amazon-api-gateway-tls-security-policies/",
      "pubDate": "2025-11-21T21:17:52.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "rds",
        "api gateway"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "api gateway",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-9d3d32287870",
      "title": "Improving throughput of serverless streaming workloads for Kafka",
      "description": "Event-driven applications often need to process data in real-time. When you use AWS Lambda to process records from Apache Kafka topics, you frequently encounter two typical requirements: you need to process very high volumes of records in close to real-time, and you want your consumers to have the ability to scale rapidly to handle traffic spikes. Achieving both necessitates understanding how Lambda consumes Kafka streams, where the potential bottlenecks are, and how to optimize configurations for high throughput and best performance.",
      "link": "https://aws.amazon.com/blogs/compute/improving-throughput-of-serverless-streaming-workloads-for-kafka/",
      "pubDate": "2025-11-21T20:02:57.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "rds",
        "kafka"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "rds",
        "kafka"
      ]
    },
    {
      "id": "aws-news-b3a3371e0c90",
      "title": "Build scalable REST APIs using Amazon API Gateway private integration with Application Load Balancer",
      "description": "Today, we announced \nAmazon API Gateway REST API’s support for private integration with \nApplication Load Balancers (ALBs). You can use this new capability to securely expose your VPC-based applications through your REST APIs without exposing your ALBs to the public internet.",
      "link": "https://aws.amazon.com/blogs/compute/build-scalable-rest-apis-using-amazon-api-gateway-private-integration-with-application-load-balancer/",
      "pubDate": "2025-11-21T19:28:04.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "api gateway",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-df24f6f1c182",
      "title": "Building multi-tenant SaaS applications with AWS Lambda’s new tenant isolation mode",
      "description": "Today, AWS is announcing tenant isolation for AWS Lambda, enabling you to process function invocations in separate execution environments for each end-user or tenant invoking your Lambda function. This capability simplifies building secure multi-tenant SaaS applications by managing tenant-level compute environment isolation and request routing, allowing you to focus on core business logic rather than implementing tenant-aware compute environment isolation.",
      "link": "https://aws.amazon.com/blogs/compute/building-multi-tenant-saas-applications-with-aws-lambdas-new-tenant-isolation-mode/",
      "pubDate": "2025-11-20T17:47:17.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-b04be71f4d69",
      "title": "Improve API discoverability with the new Amazon API Gateway Portal",
      "description": "In this post, we will show how you can use the new portal feature to create customizable portals with enhanced security features in minutes, with APIs from multiple accounts, without managing any infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/improve-api-discoverability-with-the-new-amazon-api-gateway-portal/",
      "pubDate": "2025-11-20T00:41:25.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-9150859a247c",
      "title": "Building an AI gateway to Amazon Bedrock with Amazon API Gateway",
      "description": "In this post, we'll explore a reference architecture that helps enterprises govern their Amazon Bedrock implementations using Amazon API Gateway. This pattern enables key capabilities like authorization controls, usage quotas, and real-time response streaming. We'll examine the architecture, provide deployment steps, and discuss potential enhancements to help you implement AI governance at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/building-an-ai-gateway-to-amazon-bedrock-with-amazon-api-gateway/",
      "pubDate": "2025-11-19T23:33:41.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "api gateway"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "api gateway",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-4934fd40d9d8",
      "title": "Architecting for AI excellence: AWS launches three Well-Architected Lenses at re:Invent 2025",
      "description": "At re:Invent 2025, we introduce one new lens and two significant updates to the AWS Well-Architected Lenses specifically focused on AI workloads: the Responsible AI Lens, the Machine Learning (ML) Lens, and the Generative AI Lens. Together, these lenses provide comprehensive guidance for organizations at different stages of their AI journey, whether you're just starting to experiment with machine learning or already deploying complex AI applications at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-for-ai-excellence-aws-launches-three-well-architected-lenses-at-reinvent-2025/",
      "pubDate": "2025-11-19T19:36:31.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-61647c9310e0",
      "title": "Announcing the updated AWS Well-Architected Generative AI Lens",
      "description": "We are delighted to announce an update to the AWS Well-Architected Generative AI Lens. This update features several new sections of the Well-Architected Generative AI Lens, including new best practices, advanced scenario guidance, and improved preambles on responsible AI, data architecture, and agentic workflows.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-generative-ai-lens/",
      "pubDate": "2025-11-19T19:36:28.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-5044b6bc98c4",
      "title": "Announcing the updated AWS Well-Architected Machine Learning Lens",
      "description": "We are excited to announce the updated AWS Well-Architected Machine Learning Lens, now enhanced with the latest capabilities and best practices for building machine learning (ML) workloads on AWS.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-machine-learning-lens/",
      "pubDate": "2025-11-19T19:36:25.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-05b9bc2e3644",
      "title": "Python 3.14 runtime now available in AWS Lambda",
      "description": "AWS Lambda now supports Python 3.14 as both a managed runtime and container base image. Python is a popular language for building serverless applications. Developers can now take advantage of new features and enhancements when creating serverless applications on Lambda.",
      "link": "https://aws.amazon.com/blogs/compute/python-3-14-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-18T21:29:50.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "new-feature",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-c36d51e13ef0",
      "title": "Building serverless applications with Rust on AWS Lambda",
      "description": "Today, AWS Lambda is promoting Rust support from Experimental to Generally Available. This means you can now use Rust to build business-critical serverless applications, backed by AWS Support and the Lambda availability SLA.",
      "link": "https://aws.amazon.com/blogs/compute/building-serverless-applications-with-rust-on-aws-lambda/",
      "pubDate": "2025-11-14T21:38:15.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "experimental",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-78f167df36fd",
      "title": "AWS Lambda now supports Java 25",
      "description": "You can now develop AWS Lambda functions using Java 25 either as a managed runtime or using the container base image. This blog post highlights notable Java language features, Java Lambda runtime updates, and how you can use the new Java 25 runtime in your serverless applications.",
      "link": "https://aws.amazon.com/blogs/compute/aws-lambda-now-supports-java-25/",
      "pubDate": "2025-11-14T20:51:20.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-32e40b364aee",
      "title": "The attendee’s guide to the AWS re:Invent 2025 Compute track",
      "description": "From December 1st to December 5th, Amazon Web Services (AWS) will hold its annual premier learning event: re:Invent. There are over 2000+ learning sessions that focus on specific topics at various skill levels, and the compute team have created 76 unique sessions for you to choose. There are many sessions you can choose from, and we are here to help you choose the sessions that best fit your needs. Even if you cannot join in person, you can catch-up with many of the sessions on-demand and even watch the keynote and innovation sessions live.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-the-aws-reinvent-2025-compute-track/",
      "pubDate": "2025-11-12T20:58:36.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-360e834c997a",
      "title": "BASF Digital Farming builds a STAC-based solution on Amazon EKS",
      "description": "This post was co-written with Frederic Haase and Julian Blau with BASF Digital Farming GmbH. At xarvio – BASF Digital Farming, our mission is to empower farmers around the world with cutting-edge digital agronomic decision-making tools. Central to this mission is our crop optimization platform, xarvio FIELD MANAGER, which delivers actionable insights through a range […]",
      "link": "https://aws.amazon.com/blogs/architecture/basf-digital-farming-builds-a-stac-based-solution-on-amazon-eks/",
      "pubDate": "2025-10-22T16:21:09.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-24029d05087c",
      "title": "What’s New in the AWS Deploy Tool for .NET",
      "description": "Version 2.0 of the AWS Deploy Tool for .NET is now available. This new major version introduces several foundational upgrades to improve the deployment experience for .NET applications on AWS. The tool comes with new minimum runtime requirements. We have upgraded it to require .NET 8 because the predecessor, .NET 6, is now out of […]",
      "link": "https://aws.amazon.com/blogs/developer/whats-new-in-the-aws-deploy-tool-for-net/",
      "pubDate": "2025-10-14T13:25:42.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-2f3bd8791ed1",
      "title": "Modernization of real-time payment orchestration on AWS",
      "description": "The global real-time payments market is experiencing significant growth. According to Fortune Business Insights, the market was valued at USD 24.91 billion in 2024 and is projected to grow to USD 284.49 billion by 2032, with a CAGR of 35.4%. Similarly, Grand View Research reports that the global mobile payment market, valued at USD 88.50 […]",
      "link": "https://aws.amazon.com/blogs/architecture/modernization-of-real-time-payment-orchestration-on-aws/",
      "pubDate": "2025-10-01T23:34:00.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": []
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-4fbb29739c17",
      "title": "General Availability Release of the Migration Tool for the AWS SDK for Java 2.x",
      "description": "The AWS SDK for Java 1.x (v1) entered maintenance mode on July 31, 2024, and will reach end-of-support on December 31, 2025. We recommend that you migrate to the AWS SDK for Java 2.x (v2) to access new features, enhanced performance, and continued support from AWS. To help you migrate efficiently, we’ve created a migration […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-release-of-the-migration-tool-for-the-aws-sdk-for-java-2-x/",
      "pubDate": "2025-09-26T16:47:36.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-7e2f23dd38ac",
      "title": "Simplify multi-tenant encryption with a cost-conscious AWS KMS key strategy",
      "description": "In this post, we explore an efficient approach to managing encryption keys in a multi-tenant SaaS environment through centralization, addressing challenges like key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. We demonstrate how implementing a centralized key management strategy using a single AWS KMS key per tenant can maintain security and compliance while reducing operational overhead as organizations scale.",
      "link": "https://aws.amazon.com/blogs/architecture/simplify-multi-tenant-encryption-with-a-cost-conscious-aws-kms-key-strategy/",
      "pubDate": "2025-08-21T21:54:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-d1d1f77f887e",
      "title": "How Karrot built a feature platform on AWS, Part 1: Motivation and feature serving",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post starts by presenting our motivation, our requirements, and the solution architecture, focusing on feature serving.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-1-motivation-and-feature-serving/",
      "pubDate": "2025-08-14T15:16:29.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-40ebd26fef7f",
      "title": "How Karrot built a feature platform on AWS, Part 2: Feature ingestion",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post covers the process of collecting features in real-time and batch ingestion into an online store, and the technical approaches for stable operation.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-2-feature-ingestion/",
      "pubDate": "2025-08-14T15:16:27.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    },
    {
      "id": "aws-news-8b2281cd8002",
      "title": "Maximizing Business Value Through Strategic Cloud Optimization",
      "description": "As cloud spending continues to surge, organizations must focus on strategic cloud optimization to maximize business value. This blog post explores key insights from MIT Technology Review's publication on cloud optimization, highlighting the importance of viewing optimization as a continuous process that encompasses all six AWS Well-Architected pillars.",
      "link": "https://aws.amazon.com/blogs/architecture/maximizing-business-value-through-strategic-cloud-optimization/",
      "pubDate": "2025-08-01T15:33:28.000Z",
      "source": "architectureBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-875544c87826",
      "title": "Preview Release of the AWS SDK Java 2.x HTTP Client built on Apache HttpClient 5.5.x",
      "description": "The AWS SDK for Java 2.x introduces the Apache 5 SDK HTTP client which is built on Apache HttpClient 5.5.x. This new SDK HTTP client is available alongside our existing SDK HTTP clients: Apache HttpClient 4.5.x, Netty, URL Connection, and AWS CRT HttpClient. To differentiate the use of Apache HttpClient 4.5.x and Apache HttpClient 5.5.x, […]",
      "link": "https://aws.amazon.com/blogs/developer/preview-release-of-theaws-sdk-java-2-x-http-client-built-on-apache-httpclient-5-5-x/",
      "pubDate": "2025-07-18T03:36:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-6606f79cd3d5",
      "title": "AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available",
      "description": "Today, we are excited to announce the general availability of the AWS .NET Distributed Cache Provider for Amazon DynamoDB. This is a seamless, serverless caching solution that enables .NET developers to efficiently manage their caching needs across distributed systems. Consistent caching is a difficult problem in distributed architectures, where maintaining data integrity and performance across […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-net-distributed-cache-provider-for-amazon-dynamodb-now-generally-available/",
      "pubDate": "2025-07-03T13:49:25.000Z",
      "source": "developersAndDevOps",
      "services": [
        "dynamodb"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "dynamodb",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-ae25b45e1a62",
      "title": "AWS Tools for PowerShell V5 now Generally Available",
      "description": "This blog was co-authored by Afroz Mohammed and Jonathan Nunn, Software Developers on the AWS PowerShell team. We’re excited to announce the general availability of the AWS Tools for PowerShell version 5, a major update that brings new features and improvements in security, along with a few breaking changes. New Features You can now cancel […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-tools-for-powershell-v5-now-generally-available/",
      "pubDate": "2025-06-23T22:59:33.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "new-feature",
        "update",
        "improvement"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-27b43a8f9a42",
      "title": "Deploy to ARM-Based Compute with AWS Deploy Tool for .NET",
      "description": "We’re excited to announce that the AWS Deploy Tool for .NET now supports deploying .NET applications to select ARM-based compute platforms on AWS! Whether you’re deploying from Visual Studio or using the .NET CLI, you can now target cost-effective ARM infrastructure like AWS Graviton with the same streamlined experience you’re used to. Why deploy to […]",
      "link": "https://aws.amazon.com/blogs/developer/deploy-to-arm-based-compute-with-aws-deploy-tool-for-net/",
      "pubDate": "2025-05-08T20:16:40.000Z",
      "source": "developersAndDevOps",
      "services": [
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "graviton",
        "support"
      ]
    },
    {
      "id": "aws-news-4d3126ea3a15",
      "title": "General Availability of AWS SDK for .NET V4.0",
      "description": "Version 4.0 of the AWS SDK for .NET has been released for general availability (GA). V4 has been in development for a little over a year in our SDK’s public GitHub repository with 13 previews being released. This new version contains performance improvements, consistency with other AWS SDKs, and bug and usability fixes that required […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-of-aws-sdk-for-net-v4-0/",
      "pubDate": "2025-04-28T20:05:16.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-49859f1bef68",
      "title": "Introducing the AWS IoT Device SDK for Swift (Developer Preview)",
      "description": "Today, AWS launches the developer preview of the AWS IoT Device SDK for Swift. The IoT Device SDK for Swift empowers Swift developers to create IoT applications for Linux and Apple macOS, iOS, and tvOS platforms using the MQTT 5 protocol. The SDK supports Swift 5.10+ and is designed to help developers easily integrate with […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-the-aws-iot-device-sdk-for-swift-developer-preview/",
      "pubDate": "2025-03-31T16:26:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-dd08a704e7e9",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 2)",
      "description": "In Part 1 of our blog posts for .NET Aspire and AWS Lambda, we showed you how .NET Aspire can be used for running and debugging .NET Lambda functions. In this part, Part 2, we’ll show you how to take advantage of the .NET Aspire programming model for best practices and for connecting dependent resources […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-2/",
      "pubDate": "2025-03-04T17:54:04.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-4185fb6b40aa",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 1)",
      "description": "In a recent post we gave some background on .NET Aspire and introduced our AWS integrations with .NET Aspire that integrate AWS into the .NET dev inner loop for building applications. The integrations included how to provision application resources with AWS CloudFormation or AWS Cloud Development Kit (AWS CDK) and using Amazon DynamoDB local for […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-1/",
      "pubDate": "2025-03-03T21:16:42.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda",
        "dynamodb",
        "cloudformation"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "dynamodb",
        "cloudformation",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-866c6557a5ec",
      "title": "Integrating AWS with .NET Aspire",
      "description": ".NET Aspire is a new way of building cloud-ready applications. In particular, it provides an orchestration for local environments in which to run, connect, and debug the components of distributed applications. Those components can be .NET projects, databases, containers, or executables. .NET Aspire is designed to have integrations with common components used in distributed applications. […]",
      "link": "https://aws.amazon.com/blogs/developer/integrating-aws-with-net-aspire/",
      "pubDate": "2025-02-11T20:39:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "integration"
      ]
    },
    {
      "id": "aws-news-9568575bd4f9",
      "title": "Updating AWS SDK defaults – AWS STS service endpoint and Retry Strategy",
      "description": "AWS announces important configuration updates coming July 31st, 2025, affecting AWS SDKs and CLIs default settings. Two key changes include switching the AWS Security Token Service (STS) endpoint to regional and updating the default retry strategy to standard. These updates aim to improve service availability and reliability by implementing regional endpoints to reduce cross-regional dependencies and introducing token-bucket throttling for standardized retry behavior. Organizations should test their applications before the release date and can opt-in early or temporarily opt-out of these changes. These updates align with AWS best practices for optimal service performance and security.",
      "link": "https://aws.amazon.com/blogs/developer/updating-aws-sdk-defaults-aws-sts-service-endpoint-and-retry-strategy/",
      "pubDate": "2025-02-11T05:37:32.000Z",
      "source": "developersAndDevOps",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga",
        "update"
      ]
    }
  ]
}