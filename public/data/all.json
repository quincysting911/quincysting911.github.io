{
  "lastUpdated": "2025-12-02T06:17:11.704Z",
  "totalItems": 198,
  "sources": {
    "whatsNew": 95,
    "mlBlog": 20,
    "newsBlog": 16,
    "bigDataBlog": 17,
    "architectureBlog": 16,
    "computeBlog": 18,
    "developersAndDevOps": 16
  },
  "items": [
    {
      "id": "aws-news-17e1be7414f4",
      "title": "AWS Transform for mainframe introduces Reimagine capabilities and automated testing functionality",
      "description": "New AI-powered capabilities help transform legacy mainframe applications into cloud-native architectures while automating complex testing processes—reducing modernization timelines from years to months through intelligent analysis and automated test generation.",
      "link": "https://aws.amazon.com/blogs/aws/aws-transform-for-mainframe-introduces-reimagine-capabilities-and-automated-testing-functionality/",
      "pubDate": "2025-12-01T19:02:02.000Z",
      "source": "newsBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-ebf4a30e1e94",
      "title": "Introducing AWS Transform custom: Crush tech debt with AI-powered code modernization",
      "description": "Modernize applications at scale with this new AI-powered service that learns your organization's patterns, automates transformations across repositories, and cuts execution time by up to 80% through both pre-built and custom capabilities.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-aws-transform-custom-crush-tech-debt-with-ai-powered-code-modernization/",
      "pubDate": "2025-12-01T19:00:29.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-8cd3d5f72646",
      "title": "AWS Transform launches an AI agent for full-stack Windows modernization",
      "description": "AWS Transform is expanding its capability from the .NET modernization agent to now include the full-stack Windows modernization agent that handles both .NET applications and their associated databases. The new agent automates the transformation of .NET applications and Microsoft SQL Server databases to Amazon Aurora PostgreSQL and deploys them to containers on Amazon ECS or Amazon EC2 Linux. AWS Transform accelerates full-stack Windows modernization by 5x across application and database layers, while reducing operating costs by up to 70%.\n  With AWS Transform, customers can accelerate their full-stack modernization journey through automated discovery, transformation, and deployment. The full-stack Windows modernization agent scans Microsoft SQL Server databases in Amazon EC2 or Amazon RDS instances, and it scans .NET application code from source repositories (GitHub, GitLab, Bitbucket, or Azure Repos) to create customized, editable modernization plans. It automatically transforms SQL Server schemas to Aurora PostgreSQL and migrates databases to new or existing Aurora PostgreSQL target clusters. For .NET application transformation, the agent updates database connections in the source code and modifies database access code written in Entity Framework and ADO.NET to be compatible with Aurora PostgreSQL—all in a unified workflow with human supervision. All the transformed code is committed to a new repository branch. Finally, the transformed application along with the databases can be deployed into a new or existing environment to validate the transformed applications and databases. Customers can monitor transformation progress through worklog updates and interactive chat, and they can use the detailed transformation summaries for next steps recommendations and for easy handoff to AI code companions.\n  AWS Transform for full-stack Windows modernization is available in the US East (N. Virginia) AWS Region.\n  To learn more, visit the overview page and AWS Transform documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/aws-transform-ai-agent-full-stack-windows-modernization",
      "pubDate": "2025-12-01T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "ecs"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ec2",
        "rds",
        "ecs",
        "launch",
        "update"
      ]
    },
    {
      "id": "aws-news-839280c1af5b",
      "title": "AWS Transform for mainframe now supports application reimagining",
      "description": "AWS Transform for mainframe delivers new data and activity analysis capabilities to extract comprehensive insights to drive the reimagining of mainframe applications. These insights can be combined with business logic extraction to inform decomposition of legacy applications into logical business domains. Together, these form the basis of a comprehensive specification for coding agents like Kiro to reimagine applications into cloud-native architectures.\n  The new capabilities empower organizations to reimagine legacy workloads, providing a comprehensive reverse engineering workflow that includes automated code and data structure analysis, activity analysis, technical documentation generation, business logic extraction, and intelligent code decomposition. Through in-depth data and activity analysis, AWS Transform helps identify application components with high utilization or business value, allowing teams to optimize their modernization efforts and make data-informed architectural decisions.\n  In the AI-powered chat interface, users can customize their modernization approach through flexible job plans that allow them to select predefined comprehensive workflows—full modernization, analysis focus, or business logic focus—or create their own combination of capabilities based on specific objectives.\n  The reimagine capabilities in AWS Transform for mainframe are available today in US East (N. Virginia), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London) Regions.\n  To learn more about reimagining mainframe applications with AWS Transform for mainframe, read the AWS News Blog post or visit the AWS Transform product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-mainframe-application-reimagining/",
      "pubDate": "2025-12-01T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-3bd2560befb0",
      "title": "AWS Transform adds new agentic AI capabilities for enterprise VMware migrations",
      "description": "AWS Transform adds powerful new agentic AI capabilities to automate VMware migrations to AWS. The migration agent collaborates with migration teams to understand business priorities and intelligently plan and migrate hundreds of applications spanning thousands of servers, significantly reducing manual effort, time, and complexity.\n  The agent can now discover your on-premises environment and prioritize applications for migration using the AWS Transform discovery tool, inventory data from various third-party discovery tools, and unstructured data such as documents, notes, and business rules. It analyzes infrastructure, database, and application details, maps dependencies, and generates migration plans grouped by business and technical priorities such as ownership, department, function, subnet, and operating systems. It generates networks with hub-and-spoke and isolated network configurations, provides flexible IP address management options, deploys to multiple accounts, generates network configurations for your AWS landing zones, and migrates from source environments like NSX, Palo Alto, Fortigate, and Cisco ACI. The agent migrates servers to AWS securely and iteratively in waves and provides clear progress updates throughout the deployment. It also migrates Windows and Linux x86 servers, hypervisors such as VMware, HyperV, Nutanix, and KVM, and bare-metal physical environments to multiple target accounts. Throughout your migration, you can ask the agent questions as it guides your decisions, whether that’s repeating or skipping steps, or adjusting plans. To simplify internal approvals, the agent also generates a detailed report with the migration plan and mapping of networks, servers, and applications.\n  With AWS Transform, you can accelerate time to value, lower risk, and reduce the complexity of VMware migrations. These new capabilities are available in all AWS Regions where AWS Transform is offered, with support for migrating servers and networks to 16 AWS Regions.\n  Learn more on the product page and user guide, and get started with AWS Transform.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-vmware-agentic-ai-enterprise-migration/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-c6df8d64d713",
      "title": "AWS launches AWS Transform custom to accelerate organization-wide application modernization",
      "description": "AWS Transform custom is now generally available, accelerating organization-specific code and application modernization at scale using agentic AI. AWS Transform is the first agentic AI service to accelerate the transformation of Windows, mainframe, VMware, and more—reducing technical debt and making your tech stack AI-ready. Technical debt accumulates when organizations maintain legacy systems and outdated code, requiring them to allocate 20-30% of their software development resources to repeatable, cross-codebase transformation tasks that must be performed manually. AWS Transform can automate repeatable transformations of version upgrades, runtime migrations, framework transitions, and language translations at scale, reducing execution time by over 80% in many cases while eliminating the need for specialized automation expertise.\n \nThe custom transformation agent in AWS Transform provides both pre-built and custom solutions. It includes out-of-the-box transformations for common scenarios, such as Python and Node.js runtime upgrades, Lambda function modernization, AWS SDK updates across multiple languages, and Java 8 to 17 upgrades (supporting any build system including Gradle and Maven). For organization-specific needs, teams can define custom transformations using natural language, reference documents, and code samples. Users can trigger autonomous transformations with a simple one-line CLI command, which can be scripted or embedded into any existing pipeline or workflow. Within your organization, the agent continually learns from developer feedback and execution results, improving transformation accuracy and tightly aligning the agent’s performance with your organization’s preferences. This approach enables organizations to systematically address technical debt at scale, with the agent continually improving while developers can focus on innovation and high-impact tasks.\n \nAWS Transform custom is now available in the US East (N. Virginia) AWS Region.\n \nTo learn more, visit the user guide, overview page, and pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-custom-organization-wide-modernization/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lambda",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "nova",
        "lambda",
        "organizations",
        "launch",
        "generally-available",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-0b2d15aede4a",
      "title": "AWS Transform for mainframe delivers new testing automation capabilities",
      "description": "AWS Transform for mainframe now offers test planning and automation features to accelerate mainframe modernization projects. New capabilities include automated test plan generation, test data collection scripts, and test case automation scripts, alongside functional test environment tools for continuous delivery and regression testing, helping accelerate and de-risk testing and validation during mainframe modernization projects.\n  The new capabilities address key testing challenges across the modernization lifecycle, reducing the time and effort required for mainframe modernization testing, which typically consumes over 50% of project duration. Automated test plan generation helps teams reduce upfront planning efforts and align on critical functional tests needed to mitigate risk and ensure modernization success, while test data collection scripts accelerate the error-prone, complex process of capturing mainframe data. Test automation scripts then enable scalable execution of test cases by automating test environment staging, test case execution, and results validation against expected outcomes.\n  By automating complex testing tasks and reducing dependency on scarce mainframe expertise, organizations can now modernize their applications with greater confidence while improving accuracy through consistent, automated processes.\n  The new testing capabilities in AWS Transform for mainframe are available today in US East (N. Virginia), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London) Regions.\n  To learn more about automated testing in AWS Transform for mainframe, and how it can help your organization accelerate modernization, read the AWS News Blog, visit the AWS Transform for mainframe product page, or explore the AWS Transform User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-mainframe-testing-automation/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-fbcf70ff0cc1",
      "title": "AWS Transform expands .NET transformation capabilities and enhances developer experience",
      "description": "Today, AWS announces the general availability of expanded .NET transformation capabilities and an enhanced developer experience in AWS Transform. Customers can now modernize .NET Framework and .NET code to .NET 10 or .NET Standard. New transformation capabilities include UI porting of ASP.NET Web Forms to Blazor on ASP.NET Core and porting Entity Framework ORM code. The new developer experience, available with the AWS Toolkit for Visual Studio 2026 or 2022, is customizable, interactive, and iterative. It includes an editable transformation plan, estimated transformation time, real-time updates during transformation, the ability to repeat transformations with a revised plan, and next steps markdown for easy handoff to AI code companions. With these enhancements, AWS Transform provides a path to modern .NET for more project types, supports the latest releases of .NET and Visual Studio, and gives developers oversight and control of transformations.\n \nDevelopers can now streamline their .NET modernization through an enhanced IDE experience. The process begins with automated code analysis that produces a customizable transformation plan. Developers can customize the transformation plan, such as fine-tuning package updates. Throughout the transformation, they benefit from transparent progress tracking and detailed activity logs. Upon completion, developers receive a Next Steps document that outlines remaining tasks, including Linux readiness requirements, which they can address through additional AWS Transform iterations or by leveraging AI code companion tools such as Kiro.\n \nAWS Transform is available in the following AWS Regions: US East (N. Virginia), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London).\n \nTo get started with AWS Transform, refer to the AWS Transform documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/12/transform-net-transformation-developer-experience/",
      "pubDate": "2025-12-01T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-2107fa127a12",
      "title": "Top announcements of AWS re:Invent 2025",
      "description": "Discover our most impactful innovations across analytics, AI, compute, containers, security, and more throughout the conference week.",
      "link": "https://aws.amazon.com/blogs/aws/top-announcements-of-aws-reinvent-2025/",
      "pubDate": "2025-12-01T02:17:13.000Z",
      "source": "newsBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "nova",
        "announcement"
      ]
    },
    {
      "id": "aws-news-087705e65c34",
      "title": "Introducing Amazon Route 53 Global Resolver for secure anycast DNS resolution (preview)",
      "description": "Simplify hybrid DNS management with a unified service that resolves public and private domains globally through secure, anycast-based resolution while reducing operational overhead and maintaining consistent security controls.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-amazon-route-53-global-resolver-for-secure-anycast-dns-resolution-preview/",
      "pubDate": "2025-12-01T01:56:16.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-b5afae663e23",
      "title": "AWS Clean Rooms launches privacy-enhancing synthetic dataset generation for ML model training",
      "description": "Train ML models on sensitive collaborative data by generating synthetic datasets that preserve statistical patterns while protecting individual privacy through configurable noise levels and protection against re-identification.",
      "link": "https://aws.amazon.com/blogs/aws/aws-clean-rooms-launches-privacy-enhancing-synthetic-dataset-generation-for-ml-model-training/",
      "pubDate": "2025-12-01T01:55:54.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-bd40027aca42",
      "title": "AWS Partner Central now available in AWS Management Console",
      "description": "Access Partner Central directly through the AWS Console to streamline your journey from customer to Partner—manage solutions, opportunities, and marketplace listings in one unified interface with enterprise-grade security.",
      "link": "https://aws.amazon.com/blogs/aws/aws-partner-central-now-available-in-aws-management-console/",
      "pubDate": "2025-12-01T01:55:48.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-ca158dfedea7",
      "title": "Introducing AWS Lambda Managed Instances: Serverless simplicity with EC2 flexibility",
      "description": "Run Lambda functions on EC2 compute while maintaining serverless simplicity—enabling access to specialized hardware and cost optimizations through EC2 pricing models, with AWS handling all infrastructure management.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-aws-lambda-managed-instances-serverless-simplicity-with-ec2-flexibility/",
      "pubDate": "2025-12-01T01:55:39.000Z",
      "source": "newsBlog",
      "services": [
        "lex",
        "lambda",
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex",
        "lambda",
        "ec2"
      ]
    },
    {
      "id": "aws-news-602a7a019ade",
      "title": "Simplify IAM policy creation with IAM Policy Autopilot, a new open source MCP server for builders",
      "description": "Speed up AWS development with an open source tool that analyzes your code to generate valid IAM policies, providing AI coding assistants with up-to-date AWS service knowledge and reliable permission recommendations.",
      "link": "https://aws.amazon.com/blogs/aws/simplify-iam-policy-creation-with-iam-policy-autopilot-a-new-open-source-mcp-server-for-builders/",
      "pubDate": "2025-12-01T01:55:28.000Z",
      "source": "newsBlog",
      "services": [
        "iam"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "iam"
      ]
    },
    {
      "id": "aws-news-00b4e13a3e9a",
      "title": "Announcing Amazon EKS Capabilities for workload orchestration and cloud resource management",
      "description": "Streamline Kubernetes development with fully managed platform capabilities that handle workload orchestration and cloud resource management, eliminating infrastructure maintenance while providing enterprise-grade reliability and security.",
      "link": "https://aws.amazon.com/blogs/aws/announcing-amazon-eks-capabilities-for-workload-orchestration-and-cloud-resource-management/",
      "pubDate": "2025-12-01T01:55:10.000Z",
      "source": "newsBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-1ffd715165b7",
      "title": "Amazon Connect now provides native testing and simulation capabilities",
      "description": "Amazon Connect now allows you to test and simulate contact center experiences in just a few clicks, making it easy to validate workflows, self-service voice interactions, and their outcomes. For each test, you can configure the test parameters including the caller's phone number or customer profile, the reason for the call (such as \"I need to check my order status\"), the expected responses (such as \"Your request has been processed\"), and business conditions like after-hours scenarios or full call queues. After executing tests, results show success or failure based on your defined criteria, along with the path taken by the simulated interaction and detailed logs to quickly diagnose potential issues\n  With this launch, you can run multiple tests simultaneously to validate scenarios and workflows at scale, reducing testing time. Companies can view test results and identify common failure patterns across all their tests in Connect's analytics dashboards. These capabilities enable you to rapidly validate changes to your workflows and confidently deploy new experiences to adapt to your ever-changing business needs.\n  To learn more about these features, see the Amazon Connect Administrator Guide. These features are available in all AWS regions where Amazon Connect is available. To learn more about Amazon Connect, AWS’s AI-native customer experience solution, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-native-testing-simulation-capabilities",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds",
        "launch"
      ]
    },
    {
      "id": "aws-news-f196750d89bd",
      "title": "Amazon Connect launches Model Context Protocol (MCP) support",
      "description": "Amazon Connect now supports Model Context Protocol (MCP), enabling AI agents for end-customer self-service and employee assistance to use standardized tools for retrieving information and completing actions. With this launch, businesses can enhance their AI agents with extensible tool capabilities that improve issue resolution. For example, an AI agent can automatically look up order status, process refunds, and update customer records during a self-service interaction without requiring human intervention.\n  With this launch, Amazon Connect provides out-of-the-box MCP tools for common tasks such as updating contact attributes and retrieving case information. You can also use flow modules as MCP tools to reuse the same business logic across both deterministic and generative AI workflows. Additionally, you can integrate custom tools or third-party services through flow modules or the Amazon Bedrock AgentCore Gateway.\n  For region availability, please see the availability of Amazon Connect features by Region. To learn more about Connect’s AI agents please visit the website or see the help documentation. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-mcp-support",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "rds",
        "launch",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-2dbaffb3d657",
      "title": "Amazon Connect launches automated email responses using conditional keywords and phrases",
      "description": "Amazon Connect now allows you to automate email responses and agent routing logic using keyword and phrase conditions, helping organizations increase self-service, reduce manual handling time, and improve routing accuracy. For example, if a customer sends an email asking if a certain product is in stock, or is checking on their shipment status, an automated response can be sent without involving an agent.\n  To enable this feature, add the Get stored content block to your flows and use accompanying flow blocks such as Check contact attributes and Send message to configure automated email responses and routing.\n  Amazon Connect email is available in the US East (N. Virginia), US West (Oregon), Africa (Cape Town), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London) regions. To learn more and get started, please refer to the help documentation or visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-automated-email-responses/",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "organizations",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-6ac1157bb35b",
      "title": "Amazon Connect Chat now supports agent-initiated workflows",
      "description": "Amazon Connect now supports agent-initiated workflows, enabling agents to send interactive forms to collect sensitive data or share general policies and disclosures within customer chat conversations, increasing efficiency and improving customer experience. For example, when a customer needs to update their address, agents can now send a form that customers complete without leaving the chat interface.\n  Agents can trigger these workflows at any point during a chat conversation, making interactions more dynamic and responsive to customer needs. By handling everything within the ongoing chat conversation, businesses can maintain security and compliance standards while helping customers get faster solutions.\n  These new agent capabilities are now available in the following regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (London), and Africa (Cape Town). To learn more, visit the Amazon Connect documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-chat-agent-initiated-workflows",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "ga",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-e236ddb5007a",
      "title": "Amazon Connect now provides automated performance evaluations for self-service interactions",
      "description": "Amazon Connect now provides businesses with the ability to automatically evaluate the quality of self-service interactions and get aggregated insights to improve customer experience. Managers can define custom criteria to assess the quality of self-service interactions, that can be filled manually or automatically using insights from conversational analytics, and other Connect data. For example, you can automatically assess if the AI agent repeatedly fails to understand the customer, resulting in poor customer sentiment and transfer to a human agent. Managers can review these insights in aggregate and on individual contacts, alongside self-service interaction recordings and transcripts, to identify opportunities to improve AI agent performance.\n  Manually filled evaluations of self-service interactions are available in all regions where Amazon Connect is offered. Automated evaluations of self-service interactions are available in the following AWS regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Europe (Frankfurt). For information about Amazon Connect pricing, please visit our pricing page. To learn more, please visit our documentation and our webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-automated-performance-evaluations-self-service-interactions",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-13754dd52a44",
      "title": "Amazon Connect now supports AI agent assistance and summarization for Agentforce Service",
      "description": "Amazon Connect launches real-time AI agent assistance and contact summarization for Salesforce Contact Center with Amazon Connect (SCC-AC). It enables Connect AI agents to automatically leverage customer information and knowledge base articles from Salesforce CRM for accelerated issue resolution and consistent outcomes across voice and chat interactions.\n  When human intervention is required, the seamless integration within SCC-AC connects customers to agents who have a unified view of customer data, issue context, and interaction history within Agentforce Service and Agentforce Sales. Agents receive real-time voice transcripts and contextual recommendations, while supervisors gain enhanced call monitoring capabilities directly in Salesforce. Upon resolution, automated post-contact summarization enables agents to easily update Salesforce cases, streamlining administrative tasks. Administrators can deploy and configure this integrated contact center solution in minutes, leveraging Amazon Connect's voice, digital channels, and intelligent routing capabilities.\n  This feature is available in all AWS Regions where Amazon Connect is available. To learn more and get started, see the Salesforce Contact Center with Amazon Connect documentation. To learn more about Amazon Connect, see Amazon Connect and our strategic Salesforce partnership",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-ai-agent-assistance-summarization-agentforce-service",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-3aca50927ed4",
      "title": "Amazon Connect now provides improved analytics and monitoring for AI agents",
      "description": "Amazon Connect now provides analytics and monitoring capabilities for AI agents across self-service and agent assistance experiences. With this launch, you can measure and continuously improve AI agent performance and customer outcomes through easy to customize dashboards that provide key metrics like number of AI agent led interactions, hand-off rates, conversation turns, and average handle time. You can also compare AI agent performance across versions to identify optimal configurations and review insights to understand where AI agents are performing well and where improvements are needed. Additionally, with this launch, you can configure rules to trigger automated actions, such as sending alerts when self-service contacts are transferred to human agents with low sentiment scores. Amazon Connect also provides AI agent traces via APIs with detailed information such as request and response payloads and tool invocations, enabling you to easily understand AI agent actions and decision-making for faster troubleshooting.\n  This capabilities is available in all AWS Regions where Amazon Connect AI agents are offered. To learn more about AI agent analytics, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS contact center as a service solution on the cloud, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-improved-analytics-monitoring-ai-agents",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "launch",
        "improvement"
      ]
    },
    {
      "id": "aws-news-97b700bfdba5",
      "title": "Amazon Connect adds support for third-party speech-to-text and text-to-speech AI models for end-customer self-service",
      "description": "Amazon Connect now supports third-party speech providers for end-customer self-service, giving you greater flexibility in how you deliver voice experiences. You can integrate Deepgram for speech-to-text and ElevenLabs for text-to-speech directly within Amazon Connect, using them together with Amazon Connect's native speech capabilities, built-in orchestration, analytics, and compliance controls.\n  This feature is available with Amazon Connect unlimited AI and in all commercial AWS regions where Amazon Connect is offered. For more information, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-third-party-speech-to-text-to-speech-ai-models",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-1b32fbad45c0",
      "title": "Amazon Connect now streams messages for AI-powered interactions",
      "description": "Amazon Connect now supports message streaming for AI-powered chat interactions. This new capability shows Connect AI agent responses as they're being generated, which reduces perceived wait times and improves the customer experience.\n  When using Amazon Connect AI agents, customers see status updates like \"One moment while I review your account\" during processing, and watch responses appear progressively. This experience gives customers confidence their request is actively being worked on while AI agents reason, invoke tools, and craft comprehensive solutions.\n  Message streaming for AI-powered interactions is now available in the following regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (London) and Africa (Cape Town). To learn more, visit the Amazon Connect documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-streams-messages-ai-powered-interactions",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "now-available",
        "update",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-7b34b11c940a",
      "title": "Amazon Connect agent workspace now supports custom visual themes",
      "description": "Amazon Connect now allows you to customize the visual appearance of the agent workspace. You can apply a custom theme, including a logo, font, and color palette for light and dark modes, so the agent workspace aligns with the brand identity of your company or business unit.\n  Contact center agents spend hours each day in the Amazon Connect agent workspace, which provides them with all of the customer information, applications, and step-by-step guidance they need to deliver superior customer experiences. With today’s launch, organizations can change the default Amazon Connect theme to their own branded experience, creating a more familiar and intuitive experience for agents who use the agent workspace and other company applications. The agent workspace also has a new header bar where agents can easily access their settings, including their preference of light and dark mode, contributing to greater agent satisfaction and efficiency.\n  The Amazon Connect agent workspace is available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Africa (Cape Town), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (London), and AWS GovCloud (US-West).\n  To learn more and get started, see the administrator guide and developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-agent-workspace-custom-visual-themes",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-40738846eef5",
      "title": "Amazon Connect launches AI-powered predictive insights (Preview)",
      "description": "Today, Amazon Connect is launching AI-powered predictive insights that transform how businesses understand and serve their customers. This new feature set builds upon Connect's existing customer profiles, introducing five recommendation algorithms that leverage AI to analyze customer behavior patterns and interaction history. These AI-powered insights are available for both self-service and agent interactions, enabling businesses to transform all customer touchpoints – from suggesting complementary products during service calls to providing smart product discovery through intelligent chat experiences by leveraging their existing customer data within Connect Customer Profiles. Businesses can also leverage these AI-powered insights to build their Connect AI agent for specialized for sales.\n  The five recommendation algorithms are as follows: \"Recommended for You\" provides tailored suggestions based on individual user interactions patterns with any catalog; \"Similar Items\" uses generative AI to suggest alternative products or services; \"Frequently Paired Items\" powers cross-selling by identifying complementary product or service combinations, \"Popular Items\" surfaces top-performing product recommendations, and \"Trending Now\" captures real-time customer interest for timely engagement.\n  With Amazon Connect Customer Profiles, you only pay-as-you-go for utilized profiles. Public preview for AI-powered predictive insights is available in Europe (Frankfurt), US East (N. Virginia), Asia Pacific (Seoul), Asia Pacific (Tokyo), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central).\n  To learn more, visit our webpages for Customer Profiles.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-ai-powered-predictive-insights-preview",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "launch",
        "preview",
        "ga",
        "new-feature",
        "public-preview"
      ]
    },
    {
      "id": "aws-news-5e9a04ebec70",
      "title": "Amazon Connect now simplifies linking related contacts to cases using flows",
      "description": "Amazon Connect now makes it easier to link related contacts such as email replies, call transfers, persistent chats, and queued callbacks to the same case so agents can view the complete customer journey and resolve issues faster. You can use flows to link a follow-up contact to an existing case, eliminating the need for custom logic or manual linking.\n  Amazon Connect Cases is available in the following AWS regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town) AWS regions. To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-simplifies-linking-related-contacts-cases-using-flows",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-5eec8e966a0f",
      "title": "Amazon Connect Chat now supports in-flight data redaction and message processing",
      "description": "Amazon Connect now supports message processing that intercepts and processes chat messages before they reach any participant. This new capability enables automatic redaction of sensitive data and custom message processing, helping businesses maintain compliance and security standards while delivering personalized customer experiences.\n  The built-in sensitive data redaction can automatically detect and remove sensitive information like credit card numbers and social security numbers across multiple languages, including English, French, Portuguese, German, Italian, and Spanish variants. You can choose to redact selected or all sensitive data entities, with options to replace them with generic or entity-specific placeholders (e.g., [PII] or [NAME]). Businesses can also integrate custom processors for use cases such as language translation or profanity filtering, ensuring compliant and effective communications for their specific business needs.\n  These message processing capabilities are now available in the following regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt) Europe (London), Africa (South Africa). To learn more about Amazon Connect, visit the Amazon Connect documentation and pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-chat-in-flight-data-redaction-message-processing",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "personalize",
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "personalize",
        "rds",
        "ga",
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-dbcd91a33051",
      "title": "Amazon Connect now supports multiple knowledge bases and integrates with your Amazon Bedrock Knowledge Bases",
      "description": "Amazon Connect now allows you to bring your own Amazon Bedrock Knowledge Bases and supports multiple knowledge bases per AI agent, giving you greater flexibility in how you organize and access knowledge content for your AI agents. You can now connect your existing Bedrock Knowledge Bases directly to Amazon Connect AI agents in just a few clicks, with no additional setup or data duplication required. This allows you to leverage your current data sources and the Amazon Bedrock Knowledge Base connectors, including Adobe Experience Manager, Confluence, SharePoint, and OneDrive, giving you flexibility to use existing content repositories.\n  With support for multiple knowledge bases per AI agent, you can configure AI agents to query multiple sources in parallel for more comprehensive responses. For example, a financial services company can easily connect separate knowledge bases for compliance documentation, product information, and internal policies, enabling AI agents to provide complete guidance across all relevant content during customer interactions.\n  This feature is available in all AWS Regions where Amazon Connect AI agents and Amazon Bedrock Knowledge Bases are offered. To learn more about these features, see the Amazon Connect Administrator Guide. To learn more about Amazon Connect, the AWS cloud-based contact center, and Amazon Connect AI agents please visit the Amazon Connect Website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-multiple-knowledge-bases-integrates-amazon-bedrock-knowledge-bases",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f0a59fe884c8",
      "title": "Amazon Connect Outbound Campaigns now supports multi-step, multi-channel customer engagement journey builder",
      "description": "Amazon Connect Outbound Campaigns now supports visual journey builder, a new feature that lets you create multi-step, multi-channel customer engagements directly in the Amazon Connect console. You can design end-to-end engagement experiences that combine voice, SMS, email, and WhatsApp interactions to reach customers proactively and reduce inbound contact volume.\n  Outbound Campaigns help you automate personalized communication flows based on customer behavior or time-based triggers. For example, you can send an appointment reminder by SMS, follow up with a voice call if the customer does not respond, and send a confirmation email once the appointment is booked. You can also configure steps in the journey builder that offer customers the option to connect with a live agent through Amazon Connect when additional support is needed. You can use existing Amazon Connect Flow integrations, AI capabilities, and customer data from Amazon Connect Customer Profiles to tailor each interaction. This helps contact centers improve engagement rates, reduce manual effort, and deliver more consistent customer experiences.\n  This feature is available in all AWS Regions where Amazon Connect Outbound Campaigns is supported. To learn more, visit the Amazon Connect Outbound Campaigns documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/connect-outbound-multi-step-multi-channel-builder/",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize",
        "ga",
        "new-feature",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-2bf695171597",
      "title": "Amazon Connect now supports creation of custom metrics for use in dashboards and APIs",
      "description": "Amazon Connect now supports creation of custom metrics, enabling contact center supervisors to analyze tailored performance measurements without requiring technical skills. This feature provides a simple, no-code interface for performing mathematical operations (e.g., addition, subtraction, sum, average) on existing Connect data to build metrics that align with your organization's specific business requirements. Custom metrics are available to use in the dashboards and APIs.\n  With custom metrics, you can track performance in ways that matter most to your business. For example, create average handle time metrics for premium versus standard customer segments, calculate total agent time on outbound calls by product line, or measure queue performance filtered by contact type such as callbacks versus incoming calls.\n This new feature is available in all AWS regions where Amazon Connect is offered. To learn more about Amazon Connect custom metrics, see the Administrator Guide. To learn more about Amazon Connect, see the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-metric-customization/",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds",
        "ga",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-396183336a16",
      "title": "Amazon Connect enhances its agent assistance capabilities",
      "description": "Amazon Connect now provides customer service representatives with new AI agents that guide them through customer interactions by recommending actions, retrieving information, and executing tasks on their behalf. For example, an AI agent can guide a representative through processing a product return by automatically pulling order history, calculating refund amounts, and initiating the return process. These AI agents analyze conversation context and customer sentiment in real-time, actively completing tasks such as preparing documentation and handling routine processes. This enables representatives to focus on building customer relationships and handling complex situations while AI manages the background work, enhancing productivity and ensuring consistent outcomes. You can get started with out-of-the-box agents provided by Amazon Connect or easily customize AI agent behavior and actions to align with your business needs.\n  To learn more about Amazon Connect AI agents, please visit the website or see the help documentation. For region availability, please see the availability of Amazon Connect features by Region. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-enhances-agent-assistance-capabilities",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex"
      ]
    },
    {
      "id": "aws-news-32bed17198ba",
      "title": "Amazon Connect now provides AI-powered case summaries",
      "description": "Amazon Connect now provides AI-powered case summaries that give agents complete context into customer issues, reduce manual wrap-up work, and help resolve cases faster. With a single click, agents can generate a concise case summary even when the case spans multiple interactions, follow-up tasks, and teams, capturing key details such as issue background, actions taken, and next steps. Administrators can configure custom prompts and guardrails to ensure that summaries align with organizational style and preferences.\n  Amazon Connect Cases is available in the following AWS regions: US East (N. Virginia), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Africa (Cape Town) AWS regions. To learn more and get started, visit the Amazon Connect Cases webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-ai-powered-case-summaries",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-2650c3263efd",
      "title": "Amazon Connect introduces agentic self-service with more natural, expressive, and adaptive voice interactions",
      "description": "Amazon Connect is introducing agentic self-service capabilities that enable AI agents to understand, reason, and take action across voice and messaging channels to automate routine and complex customer service tasks. Connect enables you to blend deterministic and agentic experiences, allowing you to deploy these AI agents at scale, reliably and safely. With integration with advanced speech models from Amazon Nova Sonic, voice self-service experiences now deliver more natural and adaptive interactions. Connect's self-service voice AI agents understand not only what customers say but how they say it, adapting voice responses to match customer tone and sentiment while maintaining natural conversational pace across multiple languages and accents. For example, when a customer calls about an order issue, your AI agent can greet them by name, ask clarifying questions, look up their order status, and process a refund, with voice interactions that adapt to the customer's tone and respond expressively throughout the conversation. This enables your contact center to automate complex troubleshooting, account management, and consultative interactions while maintaining the ability to escalate to a live representative at any point.\n  Nova Sonic support with Amazon Connect is available in two commercial AWS Regions: US East (N. Virginia) and US West (Oregon) and fully available in English and Spanish and in preview for French, Italian, and German. To learn more about this feature see the Amazon Connect Administrator Guide and Amazon Connect pricing page. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-agentic-self-service",
      "pubDate": "2025-11-30T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "lex",
        "preview",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-dfbfc3dccf33",
      "title": "Announcing Amazon EKS Capabilities",
      "description": "Amazon Elastic Kubernetes Service (EKS) announces the general availability of EKS Capabilities, a fully-managed extensible set of Kubernetes-native platform features for workload deployment, AWS cloud resource management, and Kubernetes resource composition and orchestration. EKS Capabilities provides out-of-the-box platform features and offloads operations to AWS, improving the performance and security of your platform components.\n  EKS Capabilities streamlines building and scaling with Kubernetes, allowing you to focus on deploying applications rather than maintaining platform infrastructure. These capabilities run in AWS-owned infrastructure separate from your clusters, with AWS handling auto scaling, patching, and upgrading. Application developers get ready-to-use platform capabilities that enable faster workload deployment and scaling across the organization, while platform teams can offload operational tasks to AWS. Three capabilities are available at launch including continuous deployment with Argo CD, AWS resource management through AWS Controllers for Kubernetes (ACK), and dynamic resource orchestration using Kube Resource Orchestrator (KRO).\n  EKS Capabilities is available today in all AWS Regions, except AWS GovCloud (US) and China Regions. To get started with EKS Capabilities, use the EKS API, CLI, eksctl, AWS Console, or your favorite infrastructure as code tooling to enable it in a new or existing EKS cluster. To learn more, visit the EKS Capabilities feature webpage, user guide, pricing webpage, and AWS News Launch blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-capabilities",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-441875790df9",
      "title": "AWS expands AI Competency with new Agentic AI categories",
      "description": "AWS announces a major expansion of the AI Competency (formerly Generative AI Competency) in the largest Specialization launch to date including 60 validated partners across three new Agentic AI categories: Agentic AI Tools, Agentic AI Applications, and Agentic AI Consulting Services. These categories help customers identify and work with AWS Partners who specialize in developing and implementing autonomous AI systems that can perceive, reason, and act with minimal human oversight. To streamline the partner validation process, AWS today launched an AI agent in AWS Partner Central that provides partners with immediate feedback on their AI Specialization applications, significantly accelerating the path to competency attainment.\n  As organizations move beyond AI experimentation toward production-ready autonomous systems, they need partners with proven expertise in deploying AI agents that can orchestrate complex workflows, maintain contextual awareness, and collaborate across multiple platforms. The new Agentic AI categories validate partners who can deliver sophisticated solutions and offerings using Amazon Bedrock AgentCore, Strands Agents, Amazon SageMaker AI, and other AWS AI services while maintaining strong commitments to responsible AI development, governance, and monitoring.\n  AWS Partners in these categories undergo rigorous technical validation and must demonstrate successful customer implementations that meet AWS's high standards for security, reliability, and operational excellence. These validated partners are uniquely positioned to help customers deploy production-grade autonomous AI systems that drive real business value.\n  Apply to the AWS AI Competency on Partner Central and learn more about the AWS AI Competency through our APN Blog and explore validated partners in the new Agentic AI categories.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-ai-competency-agentic-ai-categories",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "sagemaker",
        "lex",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "sagemaker",
        "lex",
        "rds",
        "organizations",
        "launch",
        "ga",
        "expansion"
      ]
    },
    {
      "id": "aws-news-cded7962e9c6",
      "title": "AWS Partner Central is now available in the AWS Management Console",
      "description": "Today, AWS announces the availability of AWS Partner Central in the AWS Management Console, simplifying access for AWS Partners to Partner Central and the AWS Marketplace Management Portal, and introducing APIs that offer integration and process automation capabilities.\n  The integration of AWS Partner Central into the AWS Console delivers an enhanced experience and new capabilities for Partners. With an expanded set of APIs, partners can automate co-selling processes, streamline AWS Marketplace activities, and unlock AWS Partner Network benefits more seamlessly. Enhanced security and user management features, built on AWS Identity and Access Management (IAM), allow for granular permissions and single sign-on (SSO), improving operational efficiency and scalability.\n  AWS Partner Central in the console is available for AWS Partners today. This new experience is available in all AWS Regions, providing Partners with a consistent and secure way to manage their AWS business across the globe. Existing Partners can begin their migration to the new experience using the migration feature in the existing Partner Central portal, which provides step-by-step guidance for migrating to the AWS Console. To learn more about the new AWS Partner Central experience and how to get started, read the blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-partner-central-available-management-console",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "iam",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-144bd9fb3a39",
      "title": "Amazon SageMaker Catalog provides automatic data classification using AI agents",
      "description": "Amazon SageMaker Catalog now provides automated data classification that suggests business glossary terms during data publishing, reducing manual tagging effort and improving metadata consistency across organizations.\n  This capability analyzes table metadata and schema information using Amazon Bedrock's language models to recommend relevant terms from organizational business glossaries. Data producers receive AI-generated suggestions for business terms defined within their glossaries, which include both functional terms and sensitive data classifications such as PII and PHI, making it easy to tag their datasets with standardized vocabulary. Producers can accept or modify these suggestions before publishing, ensuring consistent terminology across data assets and improving data discoverability for business users.\n  Automated data classification is available in US East (N. Virginia, Ohio), US West (Oregon), Asia Pacific (Tokyo, Seoul, Singapore, Sydney, Mumbai), and Europe (Frankfurt, Ireland, London, Paris) AWS regions where Amazon\n SageMaker operates.\n  To get started, go to SageMaker Unified Studio to configure your business glossary to generate recommendations for business glossary terms. You can also use the AWS CLI or SDKs to programmatically manage glossary term suggestions.\n For more information, see the SageMaker Catalog user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-catalog-automatic-data-classification-ai-agents",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "sagemaker",
        "unified studio",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "unified studio",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-c803298e7651",
      "title": "AWS Clean Rooms supports synthetic dataset generation training custom ML training",
      "description": "AWS Clean Rooms now enables you and your partners to generate privacy-enhancing synthetic datasets from your collective data to train regression and classification machine learning (ML) models.\n \nSynthetic dataset generation allows you and your partners to create training datasets with similar statistical properties to the original data, without the training code having access to real records. This new capability de-identifies subjects—such as people or entities about whom data has been collected—in the original data, mitigating the risk that a model will memorize information about individuals in the training data. This unlocks new ML model training use cases that were previously restricted by privacy concerns, such as campaign optimization, fraud detection, and medical research. For example, an airline with a proprietary algorithm wants to collaborate with a hotel brand to offer joint promotions to high-value customers, but neither organization wants to share sensitive consumer data. Using AWS Clean Rooms ML, they can generate a synthetic version of their collective dataset to train the model without exposing raw data—enabling more accurate promotions targeting while protecting customer privacy.\n \nFor more information about the AWS Regions where AWS Clean Rooms ML is available, see the AWS Regions table. To learn more, visit AWS Clean Rooms ML.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-clean-rooms-synthetic-dataset-generation-custom-ml",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "rds",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-81bf5f175758",
      "title": "Announcing AWS Lambda Managed Instances, a capability to run functions on your Amazon EC2 instances",
      "description": "AWS Lambda Managed Instances lets you run Lambda functions on your Amazon EC2 instances while maintaining Lambda's operational simplicity. With Lambda Managed Instances, you can access specialized compute configurations and drive cost efficiency through EC2 pricing advantages, without managing infrastructure.\n  Lambda Managed Instances fully manages all infrastructure tasks, including instance lifecycle, OS and runtime patching, built-in routing, load balancing, and auto-scaling based on configurable parameters - so you can focus on writing code. This operational simplicity extends to the extensive EC2 instance catalog, giving you access to the latest-generation processors like AWS Graviton4 and high-bandwidth networking options. You can process parallel requests within each execution environment, maximizing resource utilization and improving price-performance.\n  Lambda Managed Instances is ideal for customers requiring specialized hardware configurations, as well as those with steady-state or predictable workloads seeking to optimize costs while maintaining Lambda's serverless experience. You can further improve costs by leveraging EC2 pricing models including Compute Savings Plans and Reserved Instances.\n  Getting started is straightforward - you can continue building functions with familiar development workflows, including Console and your preferred IDEs. First, create a capacity provider that defines your compute preferences, including VPC configuration, optional instance requirements and scaling policies. Then, attach your Lambda functions to the capacity provider via the AWS Lambda Console, APIs, or Infrastructure as Code tooling. Lambda Managed Instances integrates seamlessly with all Lambda event sources and tools like Amazon CloudWatch, AWS X-Ray and AWS Config. Latest versions of Java, Node.js, Python and .NET runtimes are supported.\n  Lambda Managed Instances is now available in the US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Tokyo), and Europe (Ireland) Regions. To learn more, visit the launch blog and AWS Lambda Managed Instances documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-lambda-managed-instances",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "ec2",
        "cloudwatch",
        "graviton"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "ec2",
        "cloudwatch",
        "graviton",
        "launch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-965f83c97bb6",
      "title": "Introducing Amazon Route 53 Global Resolver for secure anycast DNS resolution (preview)",
      "description": "Today, AWS announced the preview of Amazon Route 53 Global Resolver, a new internet-reachable DNS resolver that provides easy, secure, and reliable DNS resolution from anywhere for queries made by your authorized clients.\n  With Global Resolver, authorized clients in your organization can achieve split DNS resolution by resolving public domains on the internet and private domains associated with Route 53 private hosted zones, from anywhere. Global Resolver also allows you to create rules that protects your clients from DNS-based data exfiltration attacks. Using DNS Firewall rules for Global Resolver, you can filter queries for domains based on threat categories (e.g. Malware, Spam), web-content (e.g. Adult and Mature Content, Gambling), or advanced DNS threats (DNS tunneling, Domain Generation Algorithms), and log all queries centrally for easy auditing. Global Resolver enables you to achieve high availability of DNS resolution for your clients, by allowing you to select two or more regions for anycast DNS resolution with automatic failover to the closest available region.\n  With the launch of Global Resolver, we are renaming Route 53 Resolver to Route 53 VPC Resolver, to help clarify the distinction between the two services. Route 53 VPC Resolver allows you to resolve DNS queries from AWS resources in your Amazon VPCs for public domain names, VPC-specific DNS names, and Amazon Route 53 private hosted zones, and is available by default in each VPC. You can also associate Resolver endpoints with the VPC Resolver to forward DNS queries between your on-premises and Amazon VPCs.\n  Visit the service page for Global Resolver pricing and feature details. During the preview, Global Resolver will be available at no additional cost. For more information about AWS Regions where Global Resolver is available during preview, see here. To get started with a step-by-step walkthrough, see the AWS News Blog or documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-route-53-global-resolver-secure-anycast-dns-resolution-preview",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-a2412e35ffb9",
      "title": "Amazon CloudWatch incident reports now support Five Whys analysis",
      "description": "Amazon CloudWatch launched incident report generation capabilities with an AI-powered root-cause workflow that guides customers through the \"Five Why’s\" analysis technique. The feature is modeled on the correction or errors process used by both teams within Amazon and our customers to improve their operations.\n  The incident report generation capability now supports a guided, chat-based workflow powered by Amazon Q that walks customers through identifying the “Five Why’s” behind an incident. Teams can use this process to help identify the underlying root causes behind an incident. The capability leverages both human input and AI-based analysis of incident data to recommends specific measures operators can take to prevent future occurrences and improve their operations.\n  The incident report generation feature is available at no additional cost for CloudWatch customers and is available in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), Europe (Spain), and Europe (Stockholm).\n  You can create an incident report by first creating a CloudWatch investigation and then clicking “Incident report”. To initiate the Five Whys workflow, scroll down to the “Five Why’s” section of your report and select “Guide Me”. To learn more, visit the CloudWatch incident reports documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-incident-reports-five-whys-analysis",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "cloudwatch",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-e81021595cbc",
      "title": "AWS Glue now supports Apache Iceberg based materialized views",
      "description": "AWS Glue now supports materialized views, a new capability that makes it easier for data teams to transform data and accelerate query performance. Materialized views are managed tables in the AWS Glue Data Catalog that store precomputed query results in Apache Iceberg format and automatically keep them up to date as source data changes. This feature is designed to make it easy for data engineers and analytics teams to transform data through multiple stages, from raw data to final analytical tables while reducing engineering effort and operational overhead.\n  Customers can now create materialized views using standard Spark SQL syntax with a data refresh schedule. The service automatically handles the refresh schedule, change detection, incremental updates, and compute infrastructure management. Spark engines across Amazon Athena, Amazon EMR, and AWS Glue intelligently rewrite queries to use these materialized views, accelerating performance by up to 8x while reducing compute costs. You can use SQL query engines like Athena and Redshift to access the materialized views as Iceberg tables from SQL editors and Amazon SageMaker notebooks.\n  Materialized views in AWS Glue are available in Europe (Stockholm), Asia Pacific (Thailand), Asia Pacific (Mumbai), Europe (Paris), US East (Ohio),Europe (Ireland), Europe (Frankfurt), South America (Sao Paulo), Asia Pacific (Hong Kong), US East (N. Virginia), Asia Pacific (Seoul), Asia Pacific (Malaysia), Europe (London), Asia Pacific (Tokyo), US West (Oregon), US West (N. California), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central), and Europe (Spain). To learn more, visit Working with Materialized Views in the AWS Glue developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-apache-iceberg-based-materialized-views",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "emr",
        "redshift",
        "glue",
        "athena",
        "ga",
        "update",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-0cb204fe91c9",
      "title": "Introducing multi-product solutions in AWS Marketplace",
      "description": "AWS Marketplace now supports solution-centric procurement with multi-product solutions — a combination of products and services from one or more AWS Partners tailored to specific industries and customer use cases. Partners can now implement their vertical expertise and solution-selling strategies in AWS Marketplace. This new capability allows customers to discover and purchase complete solutions through a seamless procurement process.\n  Partners, from Independent Software Vendors (ISVs) to System Integrators, can now sell comprehensive solutions in AWS Marketplace by combining their own software and services with products they are authorized to resell from other AWS Partners. Each component maintains distinct pricing and terms, giving partners and customers flexibility in how they structure the sale. Partners can position solutions to their target audience by outlining use cases and explaining how components work together. Customers benefit from streamlined procurement with a single point of contact for negotiation, total cost assessment, and one-time approval covering all products. After purchase, customers have the flexibility to independently manage renewals and term lengths for each component, making this approach valuable for organizations addressing complex use cases that require multiple products and services.\n  This new capability is available in all AWS Regions where AWS Marketplace operates, supporting SaaS, Server, AI Agents and Tools, Machine Learning, and Professional Services product types.\n  To learn more about solution-centric procurement in AWS Marketplace, review this blog. Partners can start listing multi-product solutions through AWS Partner Central after reviewing the seller documentation. Customers can explore multi-product solutions in AWS Marketplace.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/introducing-multi-product-solutions-aws-marketplace",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-0a3b5ec43912",
      "title": "AWS Marketplace introduces agent mode and AI-enhanced search to accelerate solution discovery",
      "description": "AWS Marketplace introduces two new AI-powered capabilities, agent mode and enhanced search, to accelerate solution discovery across over 30,000 listings. These capabilities reflect the shift to solution-centric procurement in AWS Marketplace, helping you more quickly discover and evaluate solutions to your business challenges.\n  Agent mode, a conversational discovery experience that’s purpose-built for software procurement, helps you reach informed purchasing decisions fast. Describe your use case, upload business requirements documentation, and discover solutions that match your needs. Through interactive dialogue, you can ask questions and explore product insights drawn from AWS data, security and compliance records, verified vendor information, and real-time web intelligence. Agent mode accelerates your evaluation with dynamic side-by-side comparisons personalized to your requirements that can be customized with natural language. Once you’re ready to buy, you can initiate a purchase or create a downloadable detailed purchasing proposal to share with your internal stakeholders for approvals. You can also get the same tailored discovery experience on your preferred AI application through an integration with the AWS Marketplace MCP server.\n  AI-enhanced search helps you find the right the solutions fast and start evaluating your options on product pages or in agent mode. You can describe your needs and receive relevant solution results with AI-generated summaries to better understand your options and key consideration factors. New smart categories dynamically adapt to your specific search, helping you narrow down results with tailored topics. With the AWS Specializations badge added to search results, you can easily identify technically validated Partners across industries, use cases, and services.\n  To start discovering products, visit the AWS Marketplace website to use AI-enhanced search and agent mode. To learn more about Marketplace MCP, visit the MCP server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-marketplace-agent-mode-ai-enhanced-search",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "personalize",
        "rds"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize",
        "rds",
        "integration"
      ]
    },
    {
      "id": "aws-news-776bc573e779",
      "title": "AWS Marketplace introduces express private offers for fast personalized pricing",
      "description": "AWS Marketplace customers can now receive private offers for third-party products in minutes through express private offers. This capability enables customers to access personalized pricing and terms which previously required lengthy sales discussions, thereby accelerating software procurement and reducing customer time-to-value.\n  Previously, obtaining personalized pricing required customers to initiate contact with sales teams, engage in discussions to negotiate terms, and navigate multiple review cycles before receiving a customized offer. Now, customers can use express private offers to get an offer within minutes by responding to a few questions. Customers are invited to use the new AI-powered experience on participating products, where they specify their purchase requirements and contract duration. AWS generates a private offer by automatically evaluating these requirements against a seller’s pre-configured pricing rules. For more customized solutions that fall outside these parameters, customers can be connected to sales representatives for additional assistance. This streamlines access to personalized pricing while ensuring customers receive offers tailored to their needs.\n  This capability is available today in all AWS Regions where the AWS Marketplace website is supported.\n  To learn more about requesting express private offers, visit the AWS Marketplace Buyer Guide. For sellers interested in enabling this feature on their listing page, visit the AWS Marketplace Seller Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-marketplace-express-private-offers",
      "pubDate": "2025-11-30T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "personalize",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-75e400c9e536",
      "title": "Multimodal retrieval for Bedrock Knowledge Bases now generally available",
      "description": "Today, AWS announces the general availability of multimodal retrieval in Bedrock Knowledge Bases. Amazon Bedrock Knowledge Bases offers managed, end-to-end Retrieval Augmented Generation (RAG) workflows to create accurate, low latency, and custom Generative AI applications by incorporating contextual information from your company's data sources. Supporting multimodal retrieval in Knowlesdge Bases enables developers to build AI-powered search and question-answering applications that work across text, images, audio, and video files. For example, a user could ask their assistant \"show me Q1 projections for Amazon Bedrock\" and Bedrock Knowledge Bases will retrieve relevant text from documents, graphs, video snippets, and audio related to revenue projections for Bedrock, allowing the assistant to generate richer and more complete answers for the end user. Previously, customers could only search through text documents and images. Now they can unlock insights from all their enterprise data formats through one unified, fully managed workflow.\n \nOrganizations struggle to extract insights from their growing multimedia data—videos, audio recordings, images, and documents— because building AI applications that can search across these different modalities is complex. As a result, valuable information trapped in terabytes of meeting recordings, training videos, and visual documentation remains inaccessible, preventing organizations from making data-driven decisions quickly and accurately. With multimodal retrieval for Knowledge Bases, developers can ingest multimodal content with full control of the parsing, chunking, embedding (e.g. Amazon Nova multimodal), and vector storage options. From there, they can then send a text query or an image as input and get relevant text, image, audio, and video segments back in order to generate a response in their generative AI applications using their choice of LLM.\n \nFor more information about creating multimodal Knowledge Bases in Bedrock, please refer to the documentation. Region availability is dependent on the features selected for multimodal support, please refer to the documentation for details.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/multimodal-retrieval-bedrock-knowledge-bases/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "nova",
        "lex",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "lex",
        "organizations",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-67724c7a4dbb",
      "title": "AWS announces IAM Policy Autopilot to help builders generate IAM policies from code",
      "description": "AWS Identity and Access Management (IAM) announces IAM Policy Autopilot, an open source Model Context Protocol (MCP) server and command-line tool that helps your AI coding assistants quickly create baseline IAM policies that you can refine as your application evolves, so you can build faster. IAM Policy Autopilot analyzes your application code locally to create identity-based policies to control access for application roles, reducing the time you spend on writing IAM policies and troubleshooting access issues. \n  IAM Policy Autopilot integrates with AI coding assistants like Kiro, Claude Code, and Cursor, and supports Python, TypeScript, and Go applications. It stays up to date with the latest AWS services and features so that builders and coding assistants have access to the latest AWS IAM permissions knowledge.\n  IAM Policy Autopilot is available at no additional cost and can be used from your own machine. To start using IAM Policy Autopilot, visit the GitHub repository and follow the setup instructions for MCP server. You can also learn more about IAM Policy Autopilot by visiting AWS News Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/iam-policy-autopilot-generate-iam-policies-code/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "iam",
        "support"
      ]
    },
    {
      "id": "aws-news-77ee953dc42d",
      "title": "AWS Marketplace now supports variable payments for professional services",
      "description": "Today, AWS Marketplace announces the general availability of variable payments, a new billing option that allows professional services sellers to bill customers as work is delivered. This capability allows sellers to set contract caps and create payment requests throughout project delivery, rather than requiring upfront payment or fixed installment schedules.\n \nProfessional services engagements often involve complexity and uncertainty, making it challenging to accurately scope and price deliverables before work begins. Variable payments supports a flexible engagement approach, while providing transparency and control for buyers. AWS Marketplace Sellers can create private offers for professional services and utilize variable payments to bill up to a predetermined contract maximum. This allows sellers to bill in AWS Marketplace based on outcomes, as milestones are completed, or as time and materials are consumed. Throughout the engagement, sellers create payment requests that describe deliverables and specify milestones or time and materials. Customers receive email notifications and can review and approve each request manually, or enable auto-approval for streamlined processing.\n \nTo learn more, visit the variable payments documentation, or access the AWS Marketplace Management Portal to create a professional services private offer with variable payment.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/marketplace-variable-payments-professional-services/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-647095c77582",
      "title": "AWS announces preview of AWS Interconnect - multicloud",
      "description": "AWS announces preview of AWS Interconnect - multicloud, providing simple, resilient, high-speed private connections to other cloud service providers (CSPs), starting in preview with Google Cloud as the first launch partner and then with Microsoft Azure later in 2026.\n  Customers have been adopting multicloud strategies while migrating more applications to the cloud. They do so for many reasons including interoperability requirements, the freedom to choose technology that best suits their needs, and the ability to build and deploy applications on any environment with greater ease and speed. Previously, when interconnecting workloads across multiple cloud providers, customers had to go the route of a ‘do-it-yourself’ multicloud approach, leading to complexities of managing global multi-layered networks at scale. AWS Interconnect - multicloud is the first purpose-built product of its kind and a new way of how clouds connect and talk to each other. It enables customers to quickly establish private, secure, high-speed network connections with dedicated bandwidth and built-in resiliency between their Amazon VPCs and other cloud environments. Interconnect - multicloud makes it easy to connect AWS networking services such as AWS Transit Gateway, AWS Cloud WAN, and Amazon VPC to other Cloud Service Providers (CSPs) quickly, instead of weeks or months.\n  Interconnect - multicloud is available in preview in five AWS Regions. You can enable this capability using the AWS Management Console. CSPs can also easily adopt via a published open API package on GitHub. For more information, see the AWS Interconnect - multicloud documentation pages.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/preview-aws-interconnect-multicloud/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "eks",
        "launch",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-2d932c791873",
      "title": "Announcing AWS AI League 2026 Championship",
      "description": "Today, AWS announces the AWS AI League 2026 Championship, expanding its flagship AI tournament with new challenges and doubling the prize pool to $50,000 for builders to compete and innovate. AI League transforms how builders use AWS AI services through gamified competition centered on solving real world business challenges.\n  The program provides participants with a quick orientation, then focuses on tournaments with two challenge tracks: the Model Customization challenge using Amazon SageMaker AI to fine-tune foundation models for specific domains, and the Agentic AI challenge using Amazon Bedrock AgentCore to build intelligent agents that can reason, plan, and execute complex tasks. Enterprises can apply to host internal tournaments and receive AWS credits, creating environments where teams collaborate and compete while building AI solutions relevant to their specific business needs. Individual developers can participate at AWS Summits, testing their abilities against peers while working directly with AWS AI services. \n  For more information about the AWS AI League and how to participate, please visit the AWS AI League page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/ai-league-2026-championship/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "nova",
        "sagemaker",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "nova",
        "sagemaker",
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-f2d713a3e108",
      "title": "AWS announces gated preview of AWS Interconnect - last mile",
      "description": "AWS launches AWS Interconnect - last mile, a fully managed connectivity offering that allows customers to connect their branch offices, data centers, and remote locations to AWS with just a few clicks, eliminating the friction of discovering partners and the complexity of network setup. As a milestone collaboration between AWS and Lumen, AWS Interconnect - last mile combines AWS cloud innovation with Lumen’s extensive network footprint to redefine how businesses connect to the cloud.\n  Customers can now instantly establish private, high-speed connections to AWS by simply entering their location, selecting bandwidth, and choosing their AWS Region. The launch simplifies the connectivity experience by automating complex network configuration including BGP peering, VLAN configuration, and ASN assignment. Customers can dynamically scale bandwidth from 1 Gbps to 100 Gbps through the AWS console and benefit from zero down-time maintenance. The service is architected for high availability and backed by SLAs. MACsec encryption is enabled by default for enhanced security between AWS Direct Connect and partner devices.\n  AWS Interconnect - last mile is available as a gated preview through Lumen, our launch partner, for customers in US starting today. Request access here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/gated-preview-interconnect-last-mile/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "nova",
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "nova",
        "lex",
        "launch",
        "preview",
        "ga"
      ]
    },
    {
      "id": "aws-news-5da4eac1b0d7",
      "title": "AWS Launches Resilience Software Competency to help customers build highly available applications",
      "description": "Today, AWS announced the expansion of its AWS Resilience Competency program to include Technology Partners, helping customers identify and implement software solutions that enhance the availability and resilience of their critical cloud workloads. This new offering addresses the growing demand for \"always on, always available\" applications and services.\n  The AWS Resilience Software Competency validates partner solutions across three essential categories: Design (high availability solutions including proxy and load balancing), Recovery (disaster recovery and data replication), and Operate (continuous resilience through observability and chaos engineering). All participating partners undergo rigorous technical validation by AWS experts to ensure they meet strict performance and operational requirements.\n  As Werner Vogels, CTO of Amazon, explains: \"Everything fails, all the time. With validated and curated solutions from AWS Resilience Partners, customers can achieve in AWS, with a fraction of the cost, a higher system availability they could ever experience if still running critical workloads on-premises.\" This program follows AWS's shared responsibility model, where AWS manages cloud infrastructure resilience while providing customers with trusted tools and partners to ensure workload resilience.\n  To get started with the AWS Resilience Software Competency program and browse qualified partners, visit the AWS Resilience Competency page. Solutions are available through AWS Marketplace for streamlined procurement.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/resilience-software-competency-build-applications/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "expansion"
      ]
    },
    {
      "id": "aws-news-eebe047053ee",
      "title": "New automated integration for CrowdStrike Falcon Next-Gen SIEM in AWS Marketplace",
      "description": "Today, AWS and CrowdStrike are making it easier to unify cloud-native security monitoring with a new automated integration experience for CrowdStrike Falcon Next-Gen Security Information and Event Management (SIEM), available in AWS Marketplace. CrowdStrike Falcon Next-Gen SIEM unifies threat detection, investigation, and response capabilities by correlating data from AWS services including AWS Security Hub, Amazon GuardDuty, and AWS CloudTrail. This new streamlined experience accelerates the configuration and integration process, eliminating manual setup across multiple AWS service consoles.\n  The guided wizard interface automates AWS service connector setup, provisioning AWS IAM roles with least privilege access, Amazon SQS queues, Amazon EventBridge rules, and Amazon SNS topics. Security teams can immediately begin leveraging agentic AI-assisted investigation capabilities, advanced correlation, and automated response features to detect and stop breaches in real-time across their AWS Organization.\n  CrowdStrike now offers pay-as-you-go pricing in AWS Marketplace, allowing customers to quickly subscribe without long-term commitments. To get started, visit the AWS Marketplace listing for CrowdStrike.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/automated-integration-crowdstrike-falcon-next-gen/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "iam",
        "eventbridge",
        "sns",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "iam",
        "eventbridge",
        "sns",
        "sqs",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-5f8201859c9d",
      "title": "AWS announces a preview of the AWS MCP Server",
      "description": "Today, AWS announces the AWS MCP Server, a managed remote Model Context Protocol (MCP) server that helps AI agents and AI-native IDEs perform real-world, multi-step tasks across one or more AWS services. The AWS MCP Server consolidates capabilities from the existing AWS API MCP and AWS Knowledge servers into a unified interface, providing access to AWS documentation, generating and executing calls to over 15,000 AWS APIs including those for newly released services, and following pre-built workflows called Agent standard operating procedures (SOPs) that guide AI agents through common tasks on AWS.\n  With the AWS MCP Server, you can ask AI assistants to perform tasks like hosting static websites on S3, provisioning EC2 instances, troubleshooting Lambda issues, and configuring CloudWatch alarms using Agent SOPs to provide step-by-step guidance. The server handles authentication and authorization through AWS Identity and Access Management (IAM) and provides audit logging through AWS CloudTrail, giving you full control over resources and permissions while enabling AI agents to execute tasks across multiple AWS services helping you complete real-world tasks faster.\n  The AWS MCP Server is available at no additional cost in the US East (N. Virginia) Region. You pay only for AWS resources you create and applicable data transfer costs. To learn more, see the AWS MCP Server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-mcp-server/",
      "pubDate": "2025-11-30T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "s3",
        "ec2",
        "iam",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "s3",
        "ec2",
        "iam",
        "cloudwatch",
        "preview"
      ]
    },
    {
      "id": "aws-news-24cd991522e9",
      "title": "Apache Spark encryption performance improvement with Amazon EMR 7.9",
      "description": "In this post, we analyze the results from our benchmark tests comparing the Amazon EMR 7.9 optimized Spark runtime against Spark 3.5.5 without encryption optimizations. We walk through a detailed cost analysis and provide step-by-step instructions to reproduce the benchmark.",
      "link": "https://aws.amazon.com/blogs/big-data/apache-spark-encryption-performance-improvement-with-amazon-emr-7-9/",
      "pubDate": "2025-11-27T01:37:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-61dc3e3d79bd",
      "title": "Run Apache Spark and Apache Iceberg write jobs 2x faster with Amazon EMR",
      "description": "In this post, we demonstrate the write performance benefits of using the Amazon EMR 7.12 runtime for Spark and Iceberg compares to open source Spark 3.5.6 with Iceberg 1.10.0 tables on a 3TB merge workload.",
      "link": "https://aws.amazon.com/blogs/big-data/run-apache-spark-and-apache-iceberg-write-jobs-2x-faster-with-amazon-emr/",
      "pubDate": "2025-11-27T01:03:08.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "emr"
      ]
    },
    {
      "id": "aws-news-70a75d3e1cfa",
      "title": "Medidata’s journey to a modern lakehouse architecture on AWS",
      "description": "In this post, we show you how Medidata created a unified, scalable, real-time data platform that serves thousands of clinical trials worldwide with AWS services, Apache Iceberg, and a modern lakehouse architecture.",
      "link": "https://aws.amazon.com/blogs/big-data/medidatas-journey-to-a-modern-lakehouse-architecture-on-aws/",
      "pubDate": "2025-11-27T01:00:46.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": []
    },
    {
      "id": "aws-news-f3f2eea0b334",
      "title": "How Myriad Genetics achieved fast, accurate, and cost-efficient document processing using the AWS open-source Generative AI Intelligent Document Processing Accelerator",
      "description": "In this post, we explore how Myriad Genetics partnered with the AWS Generative AI Innovation Center to transform their healthcare document processing pipeline using Amazon Bedrock and Amazon Nova foundation models, achieving 98% classification accuracy while reducing costs by 77% and processing time by 80%. We detail the technical implementation using AWS's open-source GenAI Intelligent Document Processing Accelerator, the optimization strategies for document classification and key information extraction, and the measurable business impact on Myriad's prior authorization workflows.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-myriad-genetics-achieved-fast-accurate-and-cost-efficient-document-processing-using-the-aws-open-source-generative-ai-intelligent-document-processing-accelerator/",
      "pubDate": "2025-11-27T00:58:14.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-587d9a94208c",
      "title": "How CBRE powers unified property management search and digital assistant using Amazon Bedrock",
      "description": "In this post, CBRE and AWS demonstrate how they transformed property management by building a unified search and digital assistant using Amazon Bedrock, enabling professionals to access millions of documents and multiple databases through natural language queries. The solution combines Amazon Nova Pro for SQL generation and Claude Haiku for document interactions, achieving a 67% reduction in processing time while maintaining enterprise-grade security across more than eight million documents.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-cbre-powers-unified-property-management-search-and-digital-assistant-using-amazon-bedrock/",
      "pubDate": "2025-11-27T00:56:27.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova"
      ]
    },
    {
      "id": "aws-news-e771ae5d8453",
      "title": "Managed Tiered KV Cache and Intelligent Routing for Amazon SageMaker HyperPod",
      "description": "In this post, we introduce Managed Tiered KV Cache and Intelligent Routing for Amazon SageMaker HyperPod, new capabilities that can reduce time to first token by up to 40% and lower compute costs by up to 25% for long context prompts and multi-turn conversations. These features automatically manage distributed KV caching infrastructure and intelligent request routing, making it easier to deploy production-scale LLM inference workloads with enterprise-grade performance while significantly reducing operational overhead.",
      "link": "https://aws.amazon.com/blogs/machine-learning/managed-tiered-kv-cache-and-intelligent-routing-for-amazon-sagemaker-hyperpod/",
      "pubDate": "2025-11-27T00:50:04.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod"
      ]
    },
    {
      "id": "aws-news-2bf53cc475cb",
      "title": "Apply fine-grained access control with Bedrock AgentCore Gateway interceptors",
      "description": "We are launching a new feature: gateway interceptors for Amazon Bedrock AgentCore Gateway. This powerful new capability provides fine-grained security, dynamic access control, and flexible schema management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/apply-fine-grained-access-control-with-bedrock-agentcore-gateway-interceptors/",
      "pubDate": "2025-11-26T22:28:29.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore",
        "lex"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "lex",
        "launch",
        "ga",
        "new-feature",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-214f1f935f59",
      "title": "Achieve 2x faster data lake query performance with Apache Iceberg on Amazon Redshift",
      "description": "In 2025, Amazon Redshift delivered several performance optimizations that improved query performance over twofold for Iceberg workloads on Amazon Redshift Serverless, delivering exceptional performance and cost-effectiveness for your data lake workloads. In this post, we describe some of the optimizations that led to these performance gains.",
      "link": "https://aws.amazon.com/blogs/big-data/achieve-2x-faster-data-lake-query-performance-with-apache-iceberg-on-amazon-redshift/",
      "pubDate": "2025-11-26T22:16:15.000Z",
      "source": "bigDataBlog",
      "services": [
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "redshift",
        "ga"
      ]
    },
    {
      "id": "aws-news-a9adcc780d04",
      "title": "Introducing catalog federation for Apache Iceberg tables in the AWS Glue Data Catalog",
      "description": "AWS Glue now supports catalog federation for remote Iceberg tables in the Data Catalog. With catalog federation, you can query remote Iceberg tables, stored in Amazon S3 and cataloged in remote Iceberg catalogs, using AWS analytics engines and without moving or duplicating tables. In this post, we discuss how to get started with catalog federation for Iceberg tables in the Data Catalog.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-catalog-federation-for-apache-iceberg-tables-in-the-aws-glue-data-catalog/",
      "pubDate": "2025-11-26T22:08:07.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "glue"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "glue",
        "support"
      ]
    },
    {
      "id": "aws-news-4a3aca511605",
      "title": "Accelerate data lake operations with Apache Iceberg V3 deletion vectors and row lineage",
      "description": "In this post, we walk you through the new capabilities in Iceberg V3, explain how deletion vectors and row lineage address these challenges, explore real-world use cases across industries, and provide practical guidance on implementing Iceberg V3 features across AWS analytics, catalog, and storage services.",
      "link": "https://aws.amazon.com/blogs/big-data/accelerate-data-lake-operations-with-apache-iceberg-v3-deletion-vectors-and-row-lineage/",
      "pubDate": "2025-11-26T22:05:47.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-0dbe89f3f79b",
      "title": "Orchestrating large-scale document processing with AWS Step Functions and Amazon Bedrock batch inference",
      "description": "Organizations often have large volumes of documents containing valuable information that remains locked away and unsearchable. This solution addresses the need for a \nscalable, automated text extraction and knowledge base pipeline that transforms static document collections into intelligent, searchable repositories for generative AI applications.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-large-scale-document-processing-with-aws-step-functions-and-amazon-bedrock-batch-inference/",
      "pubDate": "2025-11-26T21:41:51.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock",
        "step functions",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "step functions",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-0445b6b72acd",
      "title": "How Condé Nast accelerated contract processing and rights analysis with Amazon Bedrock",
      "description": "In this post, we explore how Condé Nast used Amazon Bedrock and Anthropic’s Claude to accelerate their contract processing and rights analysis workstreams. The company’s extensive portfolio, spanning multiple brands and geographies, required managing an increasingly complex web of contracts, rights, and licensing agreements.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-conde-nast-accelerated-contract-processing-and-rights-analysis-with-amazon-bedrock/",
      "pubDate": "2025-11-26T21:37:27.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex"
      ]
    },
    {
      "id": "aws-news-f2f20ca0e88d",
      "title": "Building AI-Powered Voice Applications: Amazon Nova Sonic Telephony Integration Guide",
      "description": "Available through the Amazon Bedrock bidirectional streaming API, Amazon Nova Sonic can connect to your business data and external tools and can be integrated directly with telephony systems. This post will introduce sample implementations for the most common telephony scenarios.",
      "link": "https://aws.amazon.com/blogs/machine-learning/building-ai-powered-voice-applications-amazon-nova-sonic-telephony-integration-guide/",
      "pubDate": "2025-11-26T21:21:54.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "integration"
      ]
    },
    {
      "id": "aws-news-617c09bb9eb6",
      "title": "University of California Los Angeles delivers an immersive theater experience with AWS generative AI services",
      "description": "In this post, we will walk through the performance constraints and design choices by OARC and REMAP teams at UCLA, including how AWS serverless infrastructure, AWS Managed Services, and generative AI services supported the rapid design and deployment of our solution. We will also describe our use of Amazon SageMaker AI and how it can be used reliably in immersive live experiences.",
      "link": "https://aws.amazon.com/blogs/machine-learning/university-of-california-los-angeles-delivers-an-immersive-theater-experience-with-aws-generative-ai-services/",
      "pubDate": "2025-11-26T21:20:45.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-61c6bc9ae82a",
      "title": "Optimizing Mobileye’s REM™ with AWS Graviton: A focus on ML inference and Triton integration",
      "description": "In this post, we focus on one portion of the REM™ system: the automatic identification of changes to the road structure which we will refer to as Change Detection. We will share our journey of architecting and deploying a solution for Change Detection, the core of which is a deep learning model called CDNet. We will share real-life decisions and tradeoffs when building and deploying a high-scale, highly parallelized algorithmic pipeline based on a Deep Learning (DL) model, with an emphasis on efficiency and throughput.",
      "link": "https://aws.amazon.com/blogs/machine-learning/optimizing-mobileyes-rem-with-aws-graviton-a-focus-on-ml-inference-and-triton-integration/",
      "pubDate": "2025-11-26T19:50:03.000Z",
      "source": "mlBlog",
      "services": [
        "graviton"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "graviton",
        "integration"
      ]
    },
    {
      "id": "aws-news-b38de7bae141",
      "title": "Evaluate models with the Amazon Nova evaluation container using Amazon SageMaker AI",
      "description": "This blog post introduces the new Amazon Nova model evaluation features in Amazon SageMaker AI. This release adds custom metrics support, LLM-based preference testing, log probability capture, metadata analysis, and multi-node scaling for large evaluations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/evaluate-models-with-the-amazon-nova-evaluation-container-using-amazon-sagemaker-ai/",
      "pubDate": "2025-11-26T19:39:01.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "sagemaker"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-8df2ee2ec34f",
      "title": "Getting started with Apache Iceberg write support in Amazon Redshift",
      "description": "In this post, we show how you can use Amazon Redshift to write data directly to Apache Iceberg tables stored in Amazon S3 and S3 Tables for seamless integration between your data warehouse and data lake while maintaining ACID compliance.",
      "link": "https://aws.amazon.com/blogs/big-data/getting-started-with-apache-iceberg-write-support-in-amazon-redshift/",
      "pubDate": "2025-11-26T19:34:55.000Z",
      "source": "bigDataBlog",
      "services": [
        "s3",
        "redshift"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "s3",
        "redshift",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-c44887ef4ac8",
      "title": "SageMaker HyperPod now supports Managed tiered KV cache and intelligent routing",
      "description": "Amazon SageMaker HyperPod now supports Managed Tiered KV Cache and Intelligent Routing for large language model (LLM) inference, enabling customers to optimize inference performance for long-context prompts and multi-turn conversations. Customers deploying production LLM applications need fast response times while processing lengthy documents or maintaining conversation context, but traditional inference approaches require recalculating attention mechanisms for all previous tokens with each new token generation, creating computational overhead and escalating costs. Managed Tiered KV Cache addresses this challenge by intelligently caching and reusing computed values, while Intelligent Routing directs requests to optimal instances.\n  These capabilities deliver up to 40% latency reduction, 25% throughput improvement, and 25% cost savings compared to baseline configurations. The Managed Tiered KV Cache feature uses a two-tier architecture combining local CPU memory (L1) with disaggregated cluster-wide storage (L2). AWS-native disaggregated tiered storage is the recommended backend, providing scalable terabyte-scale capacity and automatic tiering from CPU memory to local SSD for optimal memory and storage utilization. We also offer Redis as an alternative L2 cache option. The architecture enables efficient reuse of previously computed key-value pairs across requests. The newly introduced Intelligent Routing maximizes cache utilization through three configurable strategies: prefix-aware routing for common prompt patterns, KV-aware routing for maximum cache efficiency with real-time cache tracking, and round-robin for stateless workloads. These features work seamlessly together. Intelligent routing directs requests to instances with relevant cached data, reducing time to first token in document analysis and maintaining natural conversation flow in multi-turn dialogues. Built-in observability integration with Amazon Managed Grafana provides metrics for monitoring performance. You can enable these features through InferenceEndpointConfig or SageMaker JumpStart when deploying models via the HyperPod Inference Operator on EKS-orchestrated clusters.\n  These features are available in all regions where SageMaker HyperPod is available. To learn more, see the user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-hyperpod-managed-tiered-kv-cache/",
      "pubDate": "2025-11-26T18:58:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "jumpstart",
        "hyperpod",
        "eks",
        "grafana"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "jumpstart",
        "hyperpod",
        "eks",
        "grafana",
        "ga",
        "improvement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-3bab677a86c4",
      "title": "Amazon SageMaker HyperPod now supports custom Kubernetes labels and taints",
      "description": "Amazon SageMaker HyperPod now supports custom Kubernetes labels and taints, enabling customers to control pod scheduling and integrate seamlessly with existing Kubernetes infrastructure. Customers deploying AI workloads on HyperPod clusters orcehstrated with EKS need precise control over workload placement to prevent expensive GPU resources from being consumed by system pods and non-AI workloads, while ensuring compatibility with custom device plugins such as EFA and NVIDIA GPU operators. Previously, customers had to manually apply labels and taints using kubectl and reapply them after every node replacement, scaling, or patching operation, creating significant operational overhead.\n  This capability allows you to configure labels and taints at the instance group level through the CreateCluster and UpdateCluster APIs, providing a managed approach to defining and maintaining scheduling policies across the entire node lifecycle. Using the new KubernetesConfig parameter, you can specify up to 50 labels and 50 taints per instance group. Labels enable resource organization and pod targeting through node selectors, while taints repel pods without matching tolerations to protect specialized nodes. For example, you can apply NoSchedule taints to GPU instance groups to ensure only AI training jobs with explicit tolerations consume high-cost compute resources, or add custom labels that enable device plugin pods to schedule correctly. HyperPod automatically applies these configurations during node creation and maintains them across replacement, scaling, and patching operations, eliminating manual intervention and reducing operational overhead.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is available. To learn more about custom labels and taints, see the user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-hyperpod-kubernetes/",
      "pubDate": "2025-11-26T18:45:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-01131f60b90b",
      "title": "Beyond the technology: Workforce changes for AI",
      "description": "In this post, we explore three essential strategies for successfully integrating AI into your organization: addressing organizational debt before it compounds, embracing distributed decision-making through the \"octopus organization\" model, and redefining management roles to align with AI-powered workflows. Organizations must invest in both technology and workforce preparation, focusing on streamlining processes, empowering teams with autonomous decision-making within defined parameters, and evolving each management layer from traditional oversight to mentorship, quality assurance, and strategic vision-setting.",
      "link": "https://aws.amazon.com/blogs/machine-learning/beyond-the-technology-workforce-changes-for-ai/",
      "pubDate": "2025-11-26T18:42:45.000Z",
      "source": "mlBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-b78f2495bc3d",
      "title": "Amazon Kinesis Video Streams now supports a new cost effective warm storage tier",
      "description": "AWS announces a new warm storage tier for Amazon Kinesis Video Streams (Amazon KVS), delivering cost-effective storage for extended media retention. The standard Amazon KVS storage tier, now designated as the hot tier, remains optimized for real-time data access and short-term storage. The new warm tier enables long-term media retention with sub-second access latency at reduced storage costs.\n  The warm storage tier enables developers of home security and enterprise video monitoring solutions to cost-effectively stream data from devices, cameras, and mobile phones while maintaining extended retention periods for video analytics and regulatory compliance. Moreover, developers now have the flexibility to configure fragment sizes based on their specific requirements — selecting smaller fragments for lower latency use cases or larger fragments to reduce ingestion costs. Both hot and warm storage tiers integrate seamlessly with Amazon Rekognition Video and Amazon SageMaker, enabling continuous data processing to support the creation of computer vision and video analytics applications.\n  Amazon Kinesis Video Streams with the new warm storage tier is available in all regions where Amazon Kinesis Video Streams is available, except the AWS GovCloud (US) Regions.\n  To learn more, refer to the getting started guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-kinesis-video-streams-warm-storage-tier/",
      "pubDate": "2025-11-26T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "rekognition",
        "lex",
        "kinesis"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "rekognition",
        "lex",
        "kinesis",
        "support"
      ]
    },
    {
      "id": "aws-news-5de16f9b057e",
      "title": "Enhanced performance for Amazon Bedrock Custom Model Import",
      "description": "You can now achieve significant performance improvements when using Amazon Bedrock Custom Model Import, with reduced end-to-end latency, faster time-to-first-token, and improved throughput through advanced PyTorch compilation and CUDA graph optimizations. With Amazon Bedrock Custom Model Import you can to bring your own foundation models to Amazon Bedrock for deployment and inference at scale. In this post, we introduce how to use the improvements in Amazon Bedrock Custom Model Import.",
      "link": "https://aws.amazon.com/blogs/machine-learning/enhanced-performance-for-amazon-bedrock-custom-model-import/",
      "pubDate": "2025-11-26T16:46:01.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "improvement"
      ]
    },
    {
      "id": "aws-news-1c031b337189",
      "title": "Secure Amazon Elastic VMware Service (Amazon EVS) with AWS Network Firewall",
      "description": "In this post, we demonstrate how to utilize AWS Network Firewall to secure an Amazon EVS environment, using a centralized inspection architecture across an EVS cluster, VPCs, on-premises data centers and the internet. We walk through the implementation steps to deploy this architecture using AWS Network Firewall and AWS Transit Gateway.",
      "link": "https://aws.amazon.com/blogs/architecture/secure-amazon-elastic-vmware-service-amazon-evs-with-aws-network-firewall/",
      "pubDate": "2025-11-26T16:22:03.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-d834d9c22356",
      "title": "Improved AWS Health event triage",
      "description": "AWS Health now includes two new properties in its event schema - actionability and persona - enabling customers to identify the most relevant events. These properties allow organizations to programmatically identify events requiring customer action and direct them to relevant teams. The enhanced event schema is accessible through both the AWS Health API and Health EventBridge communication channels, improving operational efficiency and team coordination.\n  AWS customers receive various operational notifications and scheduled changes, including Planned Lifecycle Events. With the new actionability property, teams can quickly distinguish between events requiring action and those shared for awareness. The persona property streamlines event routing and visibility to specific teams like security and billing, ensuring critical information reaches appropriate stakeholders. These structured properties streamline integration with existing operational tools, allowing teams to effectively identify and remediate affected resources while maintaining appropriate visibility across the organization.\n  This enhancement is available across all AWS Commercial and AWS GovCloud (US) Regions. To learn more about implementing these new properties, see the AWS Health User Guide and the API and EventBridge schema documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/improved-aws-health-event-triage",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eventbridge",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "eventbridge",
        "organizations",
        "ga",
        "enhancement",
        "integration"
      ]
    },
    {
      "id": "aws-news-8cc472a5e924",
      "title": "Amazon CloudWatch now supports deletion protection for logs",
      "description": "Amazon CloudWatch now offers configuring deletion protection on your CloudWatch log groups, helping customers safeguard their critical logging data from accidental or unintended deletion. This feature provides an additional layer of protection for logs maintaining audit trails, compliance records, and operational logs that must be preserved.\n  With deletion protection enabled, administrators can prevent unintended deletions of their most important log groups. Once enabled, log groups cannot be deleted until the protection is explicitly turned off, helping safeguard critical operational, security, and compliance data. This protection is particularly valuable for preserving audit logs and production application logs needed for troubleshooting and analysis.\n  Log group deletion protection is available in all AWS commercial Regions.\n  You can enable deletion protection during log group creation or on existing log groups using the Amazon CloudWatch console, AWS Command Line Interface (AWS CLI), AWS Cloud Development Kit (AWS CDK), and AWS SDKs. For more information, visit the Amazon CloudWatch Logs User Guide..",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-deletion-protection-logs",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "cloudwatch",
        "support"
      ]
    },
    {
      "id": "aws-news-838cda64c2a9",
      "title": "Amazon SageMaker HyperPod now supports programmatic node reboot and replacement",
      "description": "Today, Amazon SageMaker HyperPod announces the general availability of new APIs that enable programmatic rebooting and replacement of SageMaker HyperPod cluster nodes. SageMaker HyperPod helps you provision resilient clusters for running machine learning (ML) workloads and developing state-of-the-art models such as large language models (LLMs), diffusion models, and foundation models (FMs). The new BatchRebootClusterNodes and BatchReplaceClusterNodes APIs enable customers to programmatically reboot or replace unresponsive or degraded cluster nodes, providing a consistent, orchestrator agnostic approach to node recovery operations.\n  The new APIs enhance node management capabilities for both Slurm and EKS orchestrated clusters complementing existing node reboot and replacement workflows. Existing orchestrator-specific methods, such as Kubernetes labels for EKS clusters and Slurm commands for Slurm clusters, remain available alongside the newly introduced programmatic capabilities for reboot and replace operations through these purpose-built APIs. When cluster nodes become unresponsive due to issues such as memory overruns or hardware degradation, recovery operations such as node reboots and replacements maybe be necessary and can be initiated through these new APIs. These capabilities are particularly valuable when running time-sensitive workloads. For instance, when a Slurm controller, login or compute node becomes unresponsive, administrators can trigger a reboot operation using the API and monitor its progress to get nodes back to operational status. Similarly, EKS cluster administrators can replace degraded worker nodes programmatically. Each API supports batch operations of up to 25 instances, enabling efficient management of large-scale recovery scenarios.\n  The reboot and replace APIs are currently supported in three AWS regions where SageMaker HyperPod is available: US East (Ohio), Asia Pacific (Mumbai), and Asia Pacific (Tokyo).The APIs can be accessed through the AWS CLI, SDK, or API calls. For more information, see the Amazon SageMaker HyperPod documentation for BatchRebootClusterNodes and BatchReplaceClusterNodes.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-hyperpod-programmatic-node-reboot-replacement",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-6e3f657a552f",
      "title": "AWS Compute Optimizer now supports unused NAT Gateway recommendations",
      "description": "Today, AWS announces that AWS Compute Optimizer now supports idle resource recommendations for NAT Gateways. With this new recommendation type, you will be able to identify NAT Gateways that are unused, resulting in cost savings.\n  With the new unused NAT Gateway recommendation, you will be able to identify NAT Gateways that show no traffic activity over a 32-day analysis period. Compute Optimizer analyzes CloudWatch metrics including active connection count, incoming packets from source, and incoming packets from destination to validate if NAT Gateways are truly unused. To avoid recommending critical backup resources, Compute Optimizer also examines if the NAT Gateway resource is associated in any AWS Route Tables. You can view the total savings potential of these unused NAT Gateways and access detailed utilization metrics to verify unused conditions before taking action.\n  This new feature is available in all AWS Regions where AWS Compute Optimizer is available except the AWS GovCloud (US) and the China Regions. To learn more about the new feature updates, please visit Compute Optimizer’s product page and user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-compute-optimizer-unused-nat-gateway-recommendations",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudwatch"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "cloudwatch",
        "ga",
        "new-feature",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-da32accf300b",
      "title": "The AWS API MCP Server is now available on AWS Marketplace",
      "description": "AWS announces the availability of the AWS API MCP Server on AWS Marketplace, enabling customers to deploy the Model Context Protocol (MCP) server to Amazon Bedrock AgentCore. The marketplace entry includes step-by-step configuration and deployment instructions for deploying the AWS API MCP Server as a managed service with built-in authentication and session isolation to Bedrock Agent Core Runtime.\n  The AWS Marketplace deployment simplifies container management while providing enterprise-grade security, scalability, and session isolation through Amazon Bedrock AgentCore Runtime. Customers can deploy the AWS\n API MCP Server with configurable authentication methods (SigV4 or JWT), implement least-privilege IAM policies, and leverage AgentCore's built-in logging and monitoring capabilities. The deployment lets customers configure IAM roles, authentication methods, and network settings according to their security requirements.\n  The AWS API MCP Server can now be deployed from AWS Marketplace in all AWS Regions where Amazon Bedrock AgentCore is supported.\n  Get started by visiting the AWS API MCP Server listing on AWS Marketplace or explore the deployment guide on AWS Labs GitHub repository. Learn more about Amazon Bedrock AgentCore in the AWS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/the-aws-api-mcp-server-aws-marketplace",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "agentcore",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore",
        "iam",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-5f2db1e3d3fc",
      "title": "Amazon S3 Block Public Access now supports organization-level enforcement",
      "description": "Amazon S3 Block Public Access (BPA) now allows organization-level control through AWS Organizations, allowing you to standardize and enforce S3 public access settings across all accounts in your AWS organization through a single policy configuration.\n  S3 Block Public Access at the organization level uses a single configuration that controls all public access settings across accounts within your organization. When you attach the policy at the root or Organizational Unit (OU)-level of your organization, it propagates to all sub-accounts within that scope, and new member accounts automatically inherit the policy. Alternatively, you can choose to apply the policy to specific accounts for more granular control. To get started, navigate to the AWS Organizations console and use the \"Block all public access\" checkbox or JSON editor. Additionally, you can use AWS CloudTrail to audit or keep track of policy attachment as well as enforcement for member accounts.\n  This feature is available in the AWS Organizations console as well as AWS CLI/SDK, in all AWS Regions where AWS Organizations and Amazon S3 are supported, with no additional charges. For more information, visit the AWS Organizations User Guide and Amazon S3 Block Public Access documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-s3-block-public-access-organization-level-enforcement",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "s3",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-72a635483fb7",
      "title": "AWS announces support for Apache Iceberg V3 deletion vectors and row lineage",
      "description": "AWS now supports deletion vectors and row lineage as defined in the Apache Iceberg Version 3 (V3) specification. These new features are available with Apache Spark on Amazon EMR 7.12, AWS Glue, Amazon SageMaker notebooks, Amazon S3 Tables, and the AWS Glue Data Catalog.\n  These Iceberg V3 capabilities help customers build petabyte-scale data lakes with improved performance for data modifications and functionality to easily track changed records. Deletion vectors write optimized delete files that speed up data pipelines and reduce data compaction costs. Row lineage provides metadata fields on each record to track changes with a simple SQL query, eliminating the computational expense of finding small changes in large tables.\n  Get started creating V3 tables by setting the table property to 'format-version = 3' in the CREATE TABLE command in Spark or a SageMaker notebook. To upgrade existing tables, simply update the table property in metadata with the new format version. When you do this, AWS query engines that support V3 will automatically begin to use deletion vectors and row lineage.\n  Iceberg V3 deletion vectors and row lineage are now available in all AWS Regions where each respective service/feature—Amazon EMR, AWS Glue, SageMaker notebooks, S3 Tables, and AWS Glue Data Catalog—is supported. To learn more about AWS support for Iceberg V3, visit Apache Iceberg V3 on AWS, and read the blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-apache-iceberg-v3-deletion-vectors-row-lineage",
      "pubDate": "2025-11-26T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "s3",
        "emr",
        "rds",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "emr",
        "rds",
        "glue",
        "now-available",
        "new-feature",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-5f762343bc19",
      "title": "Amazon Route 53 announces accelerated recovery for managing public DNS records",
      "description": "Amazon Route 53 is excited to release the accelerated recovery option for managing DNS records in public hosted zones. Accelerated recovery targets a 60-minute recovery time objective (RTO) for regaining the ability to make DNS changes to your DNS records in Route 53 public hosted zones, if AWS services in US East (N. Virginia) become temporarily unavailable.\n  The Route 53 public DNS service API is used by customers today for making changes to DNS records in order to facilitate software deployments, run infrastructure operations, and onboard new users. Customers in banking, financial technology (FinTech), and software-as-a-service (SaaS) in particular need a predictable and short RTO for meeting business continuity and disaster recovery objectives. In the past, if AWS services in US East (N. Virginia) became unavailable, customers would not be able to modify or recreate DNS records to point users and internal services to updated endpoints. Now, when you enable the accelerated recovery option on your Route 53 public hosted zone, you can make changes to Route 53 public DNS records (Resource Record Sets) in that hosted zone soon after such an interruption, most often in less than one hour.\n  Accelerated recovery for managing public DNS records is available globally, except in AWS GovCloud and Amazon Web Services in China. There is no additional charge for using this feature. To learn more about the accelerated recovery option, visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-route-53-accelerated-recovery-managing-public-dns-records",
      "pubDate": "2025-11-26T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "rds",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-4cade888fc95",
      "title": "Amazon Lex now supports LLMs as the primary option for natural language understanding",
      "description": "Amazon Lex now allows you to use Large Language Models (LLMs) as the primary option to understand customer intent across voice and chat interactions. With this capability, your voice and chat bots can better understand customer requests, handle complex utterances, maintain accuracy despite spelling errors, and extract key information from verbose inputs. When customer intent is unclear, bots can intelligently ask follow-up questions to fulfill requests accurately. For example, when a customer says “I need help with my flight,” the LLM automatically clarifies whether the customer wants to check their flight status, upgrade their flight, or change their flight.\n  This feature is available in all AWS commercial regions where Amazon Connect and Lex operate. To learn more, visit the Amazon Lex documentation or explore the Amazon Connect website to learn how Amazon Connect and Amazon Lex deliver seamless end-customer self-service experiences.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/lex-llms-primary-natural-language-understanding/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-bd7a59a25d49",
      "title": "Amazon S3 Metadata expands to 22 additional AWS Regions",
      "description": "Amazon S3 Metadata is now available in twenty-two additional AWS Regions: Africa (Cape Town), Asia Pacific (Hong Kong), Asia Pacific (Jakarta), Asia Pacific (Melbourne), Asia Pacific (Mumbai), Asia Pacific (Osaka), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central), Canada West (Calgary), Europe (London), Europe (Milan), Europe (Paris), Europe (Spain), Europe (Stockholm), Europe (Zurich), Israel (Tel Aviv), Middle East (Bahrain), Middle East (UAE), South America (Sao Paulo), and US West (N. California).\n  Amazon S3 Metadata is the easiest and fastest way to help you instantly discover and understand your S3 data with automated, easily-queried metadata that updates in near real-time. This helps you to curate, identify, and use your S3 data for business analytics, real-time inference applications, and more. S3 Metadata supports object metadata, which includes system-defined details like size and source of the object, and custom metadata, which allows you to use tags to annotate your objects with information like product SKU, transaction ID, or content rating. S3 Metadata automatically populates metadata for both new and existing objects, providing you with a comprehensive, queryable view of your data.\n  With this expansion, S3 Metadata is now generally available in twenty-eight AWS Regions. For pricing details, visit the S3 pricing page. To learn more, visit the product page, documentation, and AWS Storage Blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-s3-metadata-expands-22-regions/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "generally-available",
        "ga",
        "now-available",
        "update",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-053ac740488c",
      "title": "Amazon SageMaker AI now supports Flexible Training Plans capacity for Inference",
      "description": "Amazon SageMaker AI’s Flexible Training Plans (FTP) now support inference endpoints, giving customers guaranteed GPU capacity for planned evaluations and production peaks. Now, customers can reserve the exact instance types they need and rely on SageMaker AI to bring up the inference endpoint automatically, without doing any infrastructure management themselves.\n \nAs customers plan their ML development cycles, they need confidence that the GPUs required for model evaluation and pre-production testing will be available on the exact dates they need them. FTP makes it easy for customers to access GPU capacity to run ML workloads. With FTP support for inference endpoints, you choose your preferred instance types, compute requirements, reservation length, and start date for your inference workload. When creating the endpoint, you simply reference the reservation ARN and SageMaker AI automatically provisions and runs the endpoint on that guaranteed capacity for the entire plan duration. This removes weeks of infrastructure management and scheduling effort, letting you run inference predictably while focusing your time on improving model performance.\n \nFlexible Training Plans support for SageMaker AI Inference is available in following regions: US East (N. Virginia), US West (Oregon), US East (Ohio).\n \nTo learn more about using FTP reservations for inference endpoints, visit the SageMaker AI Inference API reference here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-ai-flexible-training-plans-inference/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "lex",
        "eks"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "lex",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-352e788815d3",
      "title": "Amazon Bedrock introduces Reserved Service tier",
      "description": "Today, Amazon Bedrock introduces a new Reserved service tier designed for workloads requiring predictable performance and guaranteed tokens-per-minute capacity. The Reserved tier provides the ability to reserve prioritized compute capacity, keeping service levels predictable for your mission critical applications. It also includes the flexibility to allocate different input and output tokens-per-minute capacities to match the exact requirements of your workload and control cost. This is particularly valuable because many workloads have asymmetric token usage patterns. For instance, summarization tasks consume many input tokens but generate fewer output tokens, while content generation applications require less input and more output capacity. When your application needs more tokens-per-minute capacity than what you reserved , the service automatically overflows to the pay-as-you-go Standard tier, ensuring uninterrupted operations. The Reserved tier targets 99.5% uptime for model response and is available today for Anthropic Claude Sonnet 4.5. Customers can reserve capacity for 1 month or 3 month duration. Customers pay a fixed price per 1K tokens-per-minute and are billed monthly.\n  With the Reserved service tier, Amazon Bedrock continues to provide more choice to customers, helping them develop, scale, and deploy applications and agents that improve productivity and customer experiences while balancing performance and cost requirements.\n  For more information about the AWS Regions where Amazon Bedrock Reserved is available, refer to the Documentation. To get access to the Reserved tier, please contact your AWS account team.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-bedrock-reserved-service-tier/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex"
      ]
    },
    {
      "id": "aws-news-7a1d603f4977",
      "title": "Amazon EMR and AWS Glue now support write operations with AWS Lake Formation fine-grained access controls",
      "description": "Amazon EMR and AWS Glue now enable you to enforce fine-grained access control (FGAC) on both read and write operations for AWS Lake Formation registered tables in your Apache Spark jobs. Previously, you could only apply Lake Formation's table, column, and row-level permissions for read operations (SELECT, DESCRIBE). This simplifies data workflows by allowing both read and write tasks in a single Spark job, eliminating the need for separate clusters or applications. Organizations can now execute end-to-end data workflows with consistent security controls, streamlining operations and reducing infrastructure costs.\n  With this launch, administrators can control who is authorized to insert new data, update specific records, or merge changes through DML operations (CREATE, ALTER, INSERT, UPDATE, DELETE, MERGE INTO, DROP), ensuring that all data modifications adhere to specified security policies to mitigate the risk of unauthorized data modification, or misuse. This launch simplifies data governance and security frameworks by providing a single point for defining access rules in AWS Lake Formation and enforcing these rules in Spark for both read and write operations.\n  This feature is available in all AWS Regions where Amazon EMR (EC2, EKS and Serverless), AWS Glue and AWS Lake Formation are available. To learn more, visit the open table format support documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-emr-aws-glue-write-operations-aws-lake-formation/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "emr",
        "rds",
        "eks",
        "glue",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "emr",
        "rds",
        "eks",
        "glue",
        "organizations",
        "launch",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-5f0418687644",
      "title": "Amazon EMR and AWS Glue now support audit context support with Lake Formation",
      "description": "Amazon EMR and AWS Glue now provide comprehensive audit context support for AWS Lake Formation credential vending APIs and AWS Glue Data Catalog GetTable and GetTables API calls. This auditing capability helps you maintain compliance with regulatory frameworks, including the Digital Markets Act (DMA) and data protection regulations. The feature is enabled by default, offering seamless integration into existing workflows while strengthening security and compliance monitoring across your data lake infrastructure.\n  You can view this audit context information in AWS CloudTrail logs, enabling enhanced security auditing, regulatory compliance, and improved troubleshooting for EMR for Apache Spark native fine-grained access control (FGAC) and full table access jobs. The audit logging feature automatically records the platform type (EMR-EC2, EMR on EKS, EMR Serverless, or AWS Glue) and its corresponding identifiers like such as Cluster ID, Step ID, Job Run ID, and Virtual Cluster ID. This enables security teams to track and correlate API calls from individual Spark jobs, streamline compliance reporting, and analyze historical data access patterns. Additionally, data engineers can quickly troubleshoot access-related issues by connecting them to specific job executions, resolve FGAC permission challenges, and monitor access patterns across different compute platforms.\n  This feature is available in all AWS Regions that support Amazon EMR, AWS Glue, and AWS Lake Formation, requiring EMR version 7.12+ or AWS Glue version 5.1+.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-emr-aws-glue-audit-context-lake-formation/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "emr",
        "rds",
        "eks",
        "glue"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "emr",
        "rds",
        "eks",
        "glue",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-3df6a4025b74",
      "title": "AWS Knowledge MCP Server now supports topic-based search",
      "description": "Today, AWS announces enhanced search capabilities for the AWS Knowledge MCP Server, which now supports topic-based search across specialized AWS documentation domains. The AWS Knowledge MCP Server is a Model Context Protocol (MCP) server that provides AI agents and developers with programmatic access to AWS documentation and knowledge resources. This enhancement enables more precise and relevant search results by allowing MCP clients and agentic frameworks to query specific documentation domains such as Troubleshooting, AWS Amplify, AWS CDK, CDK Constructs, and AWS CloudFormation, reducing noise and improving response accuracy for domain-specific queries.\n  These topic-based searches complement existing capabilities for searching API references, What's New announcements, and general AWS documentation. Developers building AI agents can now retrieve targeted information for specific use cases—for example, searching Troubleshooting documentation for error resolution, Amplify documentation for frontend development guidance, or CDK Constructs for production-ready architectural patterns. This focused approach accelerates development workflows and improves the quality of AI-generated responses for AWS-specific queries.\n  The enhanced search capabilities are available immediately at no additional cost through the AWS Knowledge MCP Server. Usage remains subject to standard rate limits. To learn more and get started, see the AWS Knowledge MCP Server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-knowledge-mcp-server-topic-based-search/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudformation",
        "enhancement",
        "support",
        "announcement"
      ]
    },
    {
      "id": "aws-news-4f8be3c8b60b",
      "title": "Introducing AWS Glue 5.1",
      "description": "AWS Glue 5.1 is now generally available, delivering improved performance, security updates, expanded Apache Iceberg capabilities, and AWS Lake Formation write support for data integration workloads.\n \nAWS Glue is a serverless, scalable data integration service that simplifies discovering, preparing, moving, and integrating data from multiple sources. This release upgrades core engines to Apache Spark 3.5.6, Python 3.11, and Scala 2.12.18, bringing performance and security enhancements. It also updates support for open table format libraries, including Apache Hudi 1.0.2, Apache Iceberg 1.10.0, and Delta Lake 3.3.2. \n \nAWS Glue 5.1 introduces support for Apache Iceberg format version 3.0, adding default column values, deletion vectors for merge-on-read tables, multi-argument transforms, and row lineage tracking. This release also extends AWS Lake Formation fine-grained access control to write operations (both DML and DDL) for Spark DataFrames and Spark SQL. Previously, this capability was limited to read operations only. AWS Glue 5.1 also adds full-table access control in Apache Spark for Apache Hudi and Delta Lake tables, providing more comprehensive security options for your data.\n \nAWS Glue 5.1 is available in US East (N. Virginia), US East (Ohio), US West (Oregon), Europe (Ireland), Europe (Stockholm), Europe (Frankfurt), Europe (Spain), Asia Pacific (Hong Kong), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Malaysia), Asia Pacific (Thailand), Asia Pacific (Mumbai), and South America (São Paulo). Visit the AWS Glue documentation for more information.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-5-1",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "glue"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "glue",
        "generally-available",
        "ga",
        "update",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-1f4f199f9723",
      "title": "Amazon Quick Research now includes trusted third-party industry intelligence",
      "description": "Amazon Quick Suite, the AI-powered workspace helping organizations get answers from their enterprise data and move swiftly from insights to action, enhances Quick Research with access to specialized third-party datasets.\n  Quick Research transforms how business professionals tackle complex business problems by completing weeks of data discovery, analysis, and insight generation in minutes. Today, Quick Research launches its partner ecosystem with industry intelligence providers S&P Global, FactSet, and IDC, with more to come. Users with existing subscriptions can combine these authoritative datasets with all of their business data and real-time web search, accelerating their path to deeper insights and strategic decision-making. Additionally, all users have access to decades of US Patent and Trademark Office data along with millions of PubMed citations and abstracts in biomedical and life sciences literature.\n  Business professionals from any industry can now access and analyze multiple data sources in one unified workspace, eliminating the need to switch between platforms. For example, a financial analyst can evaluate investment opportunities using FactSet's financial data alongside real-time web search and internal market reports, while energy teams can optimize trading strategies using S&P Global's commodity data combined with insights from their strategy teams. Similarly, sales and product teams can spot emerging trends faster by leveraging IDC's industry intelligence with their customer data. By bringing critical data sources together in one place, organizations can move from insight to action with greater speed and confidence.\n  Quick Research's third-party data integration is available in the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland). To learn more, read our User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-research-third-party-industry-intelligence/",
      "pubDate": "2025-11-26T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "lex",
        "eks",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "amazon q",
        "lex",
        "eks",
        "organizations",
        "launch",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-7aef8bce6a76",
      "title": "Amazon SageMaker AI introduces EAGLE based adaptive speculative decoding to accelerate generative AI inference",
      "description": "Amazon SageMaker AI now supports EAGLE-based adaptive speculative decoding, a technique that accelerates large language model inference by up to 2.5x while maintaining output quality. In this post, we explain how to use EAGLE 2 and EAGLE 3 speculative decoding in Amazon SageMaker AI, covering the solution architecture, optimization workflows using your own datasets or SageMaker's built-in data, and benchmark results demonstrating significant improvements in throughput and latency.",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-ai-introduces-eagle-based-adaptive-speculative-decoding-to-accelerate-generative-ai-inference/",
      "pubDate": "2025-11-26T00:29:42.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-a7bab8231d01",
      "title": "Orchestrating data processing tasks with a serverless visual workflow in Amazon SageMaker Unified Studio",
      "description": "In this post, we show how to use the new visual workflow experience in SageMaker Unified Studio IAM-based domains to orchestrate an end-to-end machine learning workflow. The workflow ingests weather data, applies transformations, and generates predictions—all through a single, intuitive interface, without writing any orchestration code.",
      "link": "https://aws.amazon.com/blogs/big-data/orchestrating-data-processing-tasks-with-a-serverless-visual-workflow-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-25T23:08:05.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam"
      ]
    },
    {
      "id": "aws-news-ba4b2b5742c2",
      "title": "Train custom computer vision defect detection model using Amazon SageMaker",
      "description": "In this post, we demonstrate how to migrate computer vision workloads from Amazon Lookout for Vision to Amazon SageMaker AI by training custom defect detection models using pre-trained models available on AWS Marketplace. We provide step-by-step guidance on labeling datasets with SageMaker Ground Truth, training models with flexible hyperparameter configurations, and deploying them for real-time or batch inference—giving you greater control and flexibility for automated quality inspection use cases.",
      "link": "https://aws.amazon.com/blogs/machine-learning/train-custom-computer-vision-defect-detection-model-using-amazon-sagemaker/",
      "pubDate": "2025-11-25T22:44:22.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lookout for vision",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "lookout for vision",
        "lex"
      ]
    },
    {
      "id": "aws-news-c9da28428aee",
      "title": "Node.js 24 runtime now available in AWS Lambda",
      "description": "You can now develop AWS Lambda functions using Node.js 24, either as a managed runtime or using the container base image. Node.js 24 is in active LTS status and ready for production use. It is expected to be supported with security patches and bugfixes until April 2028. The Lambda runtime for Node.js 24 includes a new implementation of the […]",
      "link": "https://aws.amazon.com/blogs/compute/node-js-24-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-25T22:19:46.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f3d43f94fc40",
      "title": "Practical implementation considerations to close the AI value gap",
      "description": "The AWS Customer Success Center of Excellence (CS COE) helps customers get tangible value from their AWS investments. We've seen a pattern: customers who build AI strategies that address people, process, and technology together succeed more often. In this post, we share practical considerations that can help close the AI value gap.",
      "link": "https://aws.amazon.com/blogs/machine-learning/practical-implementation-considerations-to-close-the-ai-value-gap/",
      "pubDate": "2025-11-25T20:19:50.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-7cb737e81dc9",
      "title": "The attendee’s guide to hybrid cloud and edge computing at AWS re:Invent 2025",
      "description": "AWS re:Invent 2025 returns to Las Vegas, Nevada, from December 1–5, 2025. This year, we’re offering a comprehensive lineup of sessions and booth activities to help you build resilient, performant, and scalable applications wherever you need them—in the cloud, on premises, or at the edge.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-hybrid-cloud-and-edge-computing-at-aws-reinvent-2025/",
      "pubDate": "2025-11-25T19:27:19.000Z",
      "source": "computeBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-e78bda25ea6d",
      "title": "Introducing bidirectional streaming for real-time inference on Amazon SageMaker AI",
      "description": "We're introducing bidirectional streaming for Amazon SageMaker AI Inference, which transforms inference from a transactional exchange into a continuous conversation. This post shows you how to build and deploy a container with bidirectional streaming capability to a SageMaker AI endpoint. We also demonstrate how you can bring your own container or use our partner Deepgram's pre-built models and containers on SageMaker AI to enable bi-directional streaming feature for real-time inference.",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-bidirectional-streaming-for-real-time-inference-on-amazon-sagemaker-ai/",
      "pubDate": "2025-11-25T19:09:59.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-391eb4738cdc",
      "title": "Manage Amazon SageMaker HyperPod clusters with the new Amazon SageMaker AI MCP Server",
      "description": "The Amazon SageMaker AI MCP Server now supports tools that help you setup and manage HyperPod clusters. Amazon SageMaker HyperPod removes the undifferentiated heavy lifting involved in building generative AI models by quickly scaling model development tasks such as training, fine-tuning, or deployment across a cluster of AI accelerators. The SageMaker AI MCP Server now empowers AI coding assistants to provision and operate AI/ML clusters for model training and deployment.\n  MCP servers in AWS provide a standard interface to enhance AI-assisted application development by equipping AI code assistants with real-time, contextual understanding of various AWS services. The SageMaker AI MCP server comes with tools that streamline end-to-end AI/ML cluster operations using the AI assistant of your choice—from initial setup through ongoing management. It enables AI agents to reliably setup HyperPod clusters orchestrated by Amazon EKS or Slurm complete with pre-requisites, powered by CloudFormation templates that optimize networking, storage, and compute resources. Clusters created via this MCP server are fully optimized for high-performance distributed training and inference workloads, leveraging best practice architectures to maximize throughput and minimize latency at scale. Additionally, it provides comprehensive tools for cluster and node management—including scaling operations, applying software patches, and performing various maintenance tasks. When used in conjunction with AWS API MCP Server, AWS Knowledge MCP Server, and Amazon EKS MCP Server you gain complete coverage for all SageMaker HyperPod APIs and you can effectively troubleshoot common issues, such as diagnosing why a cluster node became inaccessible. For cluster administrators, these tools streamline daily operations. For data scientists, they enable you to set up AI/ML clusters at scale without requiring infrastructure expertise, allowing you to focus on what matters most—training and deploying models.\n  You can manage your AI/ML clusters through the SageMaker AI MCP server in all regions where SageMaker HyperPod is available. To get started, visit the AWS MCP Servers documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/manage-amazon-sagemaker-hyperpod-clusters-mcp-server/",
      "pubDate": "2025-11-25T19:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "cloudformation",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-851370e8641e",
      "title": "Introducing AWS Network Firewall Proxy in preview",
      "description": "AWS introduces Network Firewall Proxy in public preview. You can use it to exert centralized controls against data exfiltration and malware injection. You can set up your Network Firewall Proxy in explicit mode in just a few clicks and filter the traffic going out from your applications and the response that these applications receive.\n  Network Firewall Proxy enables customers to efficiently manage and secure web and inter-network traffic. It protects your organization against atempts to spoof the domain name or the server name index (SNI) and offers flexibility to set fine-grained access controls. You can use Network Firewall Proxy to restrict access from your applications to trusted domains or IP addresses, or block unintended response from external servers. You can also turn on TLS inspection and set granular filtering controls on HTTP header attributes. Your Network Firewall Proxy offers comprehensive logs for monitoring your applications. You can enable them and send to Amazon S3 and AWS CloudWatch for detailed analyses and audit.\n  Try out AWS Network Firewall Proxy in your test environment today in US East (Ohio) region. Proxy is available for free during public preview. For more information check AWS Network Firewall proxy documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-network-firewall-proxy-preview",
      "pubDate": "2025-11-25T19:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "cloudwatch"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "s3",
        "cloudwatch",
        "preview",
        "ga",
        "public-preview"
      ]
    },
    {
      "id": "aws-news-309e6475f8de",
      "title": "Warner Bros. Discovery achieves 60% cost savings and faster ML inference with AWS Graviton",
      "description": "Warner Bros. Discovery (WBD) is a leading global media and entertainment company that creates and distributes the world’s most differentiated and complete portfolio of content and brands across television, film and streaming. In this post, we describe the scale of our offerings, artificial intelligence (AI)/machine learning (ML) inference infrastructure requirements for our real time recommender systems, and how we used AWS Graviton-based Amazon SageMaker AI instances for our ML inference workloads and achieved 60% cost savings and 7% to 60% latency improvements across different models.",
      "link": "https://aws.amazon.com/blogs/machine-learning/warner-bros-discovery-achieves-60-cost-savings-and-faster-ml-inference-with-aws-graviton/",
      "pubDate": "2025-11-25T17:26:48.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "graviton"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "graviton",
        "improvement"
      ]
    },
    {
      "id": "aws-news-7612920ee216",
      "title": "Physical AI in practice: Technical foundations that fuel human-machine interactions",
      "description": "In this post, we explore the complete development lifecycle of physical AI—from data collection and model training to edge deployment—and examine how these intelligent systems learn to understand, reason, and interact with the physical world through continuous feedback loops. We illustrate this workflow through Diligent Robotics' Moxi, a mobile manipulation robot that has completed over 1.2 million deliveries in hospitals, saving nearly 600,000 hours for clinical staff while transforming healthcare logistics and returning valuable time to patient care.",
      "link": "https://aws.amazon.com/blogs/machine-learning/physical-ai-in-practice-technical-foundations-that-fuel-human-machine-interactions/",
      "pubDate": "2025-11-25T17:00:25.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": []
    },
    {
      "id": "aws-news-e6ded75f4000",
      "title": "HyperPod now supports Multi-Instance GPU to maximize GPU utilization for generative AI tasks",
      "description": "In this post, we explore how Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) technology, enabling you to partition powerful GPUs into multiple isolated instances for running concurrent workloads like inference, research, and interactive development. By maximizing GPU utilization and reducing wasted resources, MIG helps organizations optimize costs while maintaining performance isolation and predictable quality of service across diverse machine learning tasks.",
      "link": "https://aws.amazon.com/blogs/machine-learning/hyperpod-now-supports-multi-instance-gpu-to-maximize-gpu-utilization-for-generative-ai-tasks/",
      "pubDate": "2025-11-25T16:10:39.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5f6e55795ef9",
      "title": "Announcing AWS Glue zero-ETL for self-managed Database Sources",
      "description": "AWS Glue now supports zero-ETL for self-managed database sources. Using Glue zero-ETL, you can now setup an integration to replicate data from Oracle, SQL Server, MySQL or PostgreSQL databases which are located on-premises or on AWS EC2 to Redshift with a simple experience that eliminates configuration complexity.\n  AWS zero-ETL for self-managed database sources will automatically create an integration for an on-going replication of data from your on-premises or EC2 databases through a simple, no-code interface. You can now replicate data from Oracle, SQL Server, MySQL and PostgreSQL databases into Redshift. This feature further reduces users' operational burden and saves weeks of engineering effort needed to design, build, and test data pipelines to ingest data from self-managed databases to Redshift.   \n  AWS Glue zero-ETL for self-managed database sources are available in the following AWS Regions: US East (Ohio), Europe (Stockholm), Europe (Ireland), Europe (Frankfurt),  Canada West (Calgary), US West (Oregon), and Asia Pacific (Seoul) regions. To get started, sign into the AWS Management Console.  For more information visit the AWS Glue page or review the AWS Glue zero-ETL documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/glue-zero-etl-selfmanaged",
      "pubDate": "2025-11-25T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "redshift",
        "eks",
        "glue"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "redshift",
        "eks",
        "glue",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-12f9dcde3208",
      "title": "AWS Lambda adds support for Node.js 24",
      "description": "AWS Lambda now supports creating serverless applications using Node.js 24. Developers can use Node.js 24 as both a managed runtime and a container base image, and AWS will automatically apply updates to the managed runtime and base image as they become available.\n  Node.js 24 is the latest long-term support release of Node.js and is expected to be supported for security and bug fixes until April 2028. With this release, Lambda has simplified the developer experience, focusing on the modern async/await programming pattern and no longer supports callback-based function handlers. You can use Node.js 24 with Lambda@Edge (in supported Regions), allowing you to customize low-latency content delivered through Amazon CloudFront. Powertools for AWS Lambda (TypeScript), a developer toolkit to implement serverless best practices and increase developer velocity, also supports Node.js 24. You can use the full range of AWS deployment tools, including the Lambda console, AWS CLI, AWS Serverless Application Model (AWS SAM), AWS CDK, and AWS CloudFormation to deploy and manage serverless applications written in Node.js 24.\n  The Node.js 24 runtime is available in all Regions, including the AWS GovCloud (US) Regions and China Regions.\n  For more information, including guidance on upgrading existing Lambda functions, see our blog post. For more information about AWS Lambda, visit our product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-lambda-nodejs-24/",
      "pubDate": "2025-11-25T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudformation",
        "cloudfront"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "cloudformation",
        "cloudfront",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-cda4c6a9f781",
      "title": "Amazon OpenSearch Service introduces Agentic Search",
      "description": "Amazon OpenSearch Service launches Agentic Search, transforming how users interact with their data through intelligent, agent-driven search. Agentic Search introduces an intelligent agent-driven system that understands user intent, orchestrates the right set of tools, generates OpenSearch DSL (domain-specific language) queries, and provides transparent summaries of its decision-making process through a simple 'agentic' query clause and natural language search terms.\n  Agentic Search automates OpenSearch query planning and execution, eliminating the need for complex search syntax. Users can ask questions in natural language like \"Find red cars under $30,000\" or \"Show last quarter's sales trends.\" The agent interprets intent, applies optimal search strategies, and delivers results while explaining its reasoning process. The feature provides two agent types: conversational agents, which handle complex interactions with the ability to store conversations in memory, and flow agents for efficient query processing. The built-in QueryPlanningTool uses large language models (LLMs) to create DSL queries, making search accessible regardless of technical expertise. Users can manage Agentic Search through APIs or OpenSearch Dashboards to configure and modify agents. Agentic Search’s advanced settings allow you to connect with external MCP servers and use custom search templates.\n  Support for agentic search is available for OpenSearch Service version 3.3 and later in all AWS Commercial and AWS GovCloud (US) Regions where OpenSearch Service is available. See here for a full listing of our Regions.\n  Build agents and run agentic searches using the new Agentic Search use case available in the AI Search Flows plugin. To learn more about Agentic Search, visit the OpenSearch technical documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/opensearch-service-agentic-search/",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5b3150523a07",
      "title": "AWS Service Quotas adds now support for automatic quota management",
      "description": "Today, we’re excited to announce the general availability of new capability of automatic quota management feature in AWS Service Quotas. Today, automatic quota management supports customers to receive notifications when their quota usage approaches their allocated quotas and configure their preferred notifications channel, such as email, SMS, or Slack, through Service Quotas console or API. Now, this feature adjusts values of AWS services’ quotas automatically and safely based on customer’s usage, which reduces operational burden from customers to constantly monitor their quota usage, and request quota increases across multiple AWS services in different AWS accounts and Regions. Customers can now confidently scale their applications on AWS to meet their growing customer demand without the risk of unexpected service interruptions due to quota exhaustion.\n  This new capability is now available at no additional cost in all AWS commercial regions. To explore this feature and for details, please visit Service Quotas console and AWS Service Quotas documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/automatic-quota-management-service-quota-management/",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-85f71202e763",
      "title": "Amazon SageMaker AI Inference now supports bidirectional streaming",
      "description": "Amazon SageMaker AI Inference now supports bidirectional streaming for real-time speech-to-text transcription, enabling continuous speech processing instead of batch input. Models can now receive audio streams and return partial transcripts simultaneously as users speak, enabling you to build voice agents that process speech with minimal latency.\n  As customers build AI voice agents, they need real-time speech transcription to minimize delays between user speech and agent responses. Data scientists and ML engineers lack managed infrastructure for bidirectional streaming, making it necessary to build custom WebSocket implementations and manage streaming protocols. Teams spend weeks developing and maintaining this infrastructure rather than focusing on model accuracy and agent capabilities. With bidirectional streaming on Amazon SageMaker AI Inference, you can deploy speech-to-text models by invoking your endpoint with the new Bidirectional Stream API. The client opens an HTTP2 connection to the SageMaker AI runtime, and SageMaker AI automatically creates a WebSocket connection to your container. This can process streaming audio frames and return partial transcripts as they are produced. Any container implementing a WebSocket handler following the SageMaker AI contract works automatically, with real-time speech models such as Deepgram running without modifications. This eliminates months of infrastructure development, enabling you to deploy voice agents with continuous transcription while focusing your time on improving model performance.\n  Bidirectional streaming is available in following AWS Regions - Canada (Central), South America (São Paulo), Africa (Cape Town), Europe (Paris), Asia Pacific (Hyderabad), Asia Pacific (Jakarta), Israel (Tel Aviv), Europe (Zurich), Asia Pacific (Tokyo), AWS GovCloud US (West), AWS GovCloud US (East), Asia Pacific (Mumbai), Middle East (Bahrain), US West (Oregon), China (Ningxia), US West (Northern California), Asia Pacific (Sydney), Europe (London), Asia Pacific (Seoul), US East (N. Virginia), Asia Pacific (Hong Kong), US East (Ohio), China (Beijing), Europe (Stockholm), Europe (Ireland), Middle East (UAE), Asia Pacific (Osaka), Asia Pacific (Melbourne), Europe (Spain), Europe (Frankfurt), Europe (Milan), Asia Pacific (Singapore).\n  To learn more, visit AWS News Blog here and SageMaker AI documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-ai-inference-bidirectional-streaming",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "eks"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "eks",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-6d9915f3633f",
      "title": "Amazon SageMaker AI now supports EAGLE speculative decoding",
      "description": "Amazon SageMaker AI now supports EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency) speculative decoding to improve large language model inference throughput by up to 2.5x. This capability enables models to predict and validate multiple tokens simultaneously rather than one at a time, improving response times for AI applications.\n  As customers deploy AI applications to production, they need capabilities to serve models with low latency and high throughput to deliver responsive user experiences. Data scientists and ML engineers lack efficient methods to accelerate token generation without sacrificing output quality or requiring complex model re-architecture, making it hard to meet performance expectations under real-world traffic. Teams spend significant time optimizing infrastructure rather than improving their AI applications. With EAGLE speculative decoding, SageMaker AI enables customers to accelerate inference throughput by allowing models to generate and verify multiple tokens in parallel rather than one at a time, maintaining the same output quality while dramatically increasing throughput. SageMaker AI automatically selects between EAGLE 2 and EAGLE 3 based on your model architecture, and provides built-in optimization jobs that use either curated datasets or your own application data to train specialized prediction heads. You can then deploy optimized models through your existing SageMaker AI inference workflow without infrastructure changes, enabling you to deliver faster AI applications with predictable performance.\n  You can use EAGLE speculative decoding in the following AWS Regions: US East (N. Virginia), US West (Oregon), US East (Ohio), Asia Pacific (Tokyo), Europe (Ireland), Asia Pacific (Singapore), and Europe (Frankfurt)\n  \n To learn more about EAGLE speculative decoding, visit AWS News Blog here, and SageMaker AI documentation here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-eagle-decoding/",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-675f93367035",
      "title": "AWS Glue Data Quality now supports rule labeling for enhanced reporting",
      "description": "Today, AWS announces the general availability of rule label, a feature of AWS Glue Data Quality, enabling you to apply custom key-value pair labels to your data quality rules for improved organization, filtering, and targeted reporting. This enhancement allows you to categorize data quality rules by business context, team ownership, compliance requirements, or any custom taxonomy that fits your data quality and governance needs.\n  Rule labels provide effective way to organize analyze data quality results. You can query results by specific labels to identify failing rules within particular categories, count rule outcomes by team or domain, and create focused reports for different stakeholders. For example, you can apply all rules that pertain to finance team with a label \"team=finance\" and generate a customized report to showcase quality metrics specific to finance team. You can label high priority rules with \"criticality=high\" to prioritize remediation efforts. Labels can be authored as part of the DQDL. You can query the labels as part of rule outcomes, row-level results, and API responses, making it easy to integrate with your existing monitoring and reporting workflows.\n  AWS Glue Data Quality rule labeling is available in all commercial AWS Regions where AWS Glue Data Quality is available. See the AWS Region Table for more details. To learn more about rule labeling, see the AWS Glue Data Quality documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/glue-data-quality-rule-labeling-enhanced-reporting/",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "glue"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "glue",
        "ga",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-416ce2e4bd57",
      "title": "AWS Glue Data Quality now supports pre-processing queries",
      "description": "Today, AWS announces the general availability of preprocessing queries for AWS Glue Data Quality, enabling you to transform your data before running data quality checks through AWS Glue Data Catalog APIs. This feature allows you to create derived columns, filter data based on specific conditions, perform calculations, and validate relationships between\n columns directly within your data quality evaluation process.\n \nPreprocessing queries provide enhanced flexibility for complex data quality scenarios that require data transformation before validation. You can create derived metrics like calculating total fees from tax and shipping columns, limiting number of columns that are considered for data quality recommendations or filter datasets to focus quality checks on specific data subsets. This capability eliminates the need for separate data pre-processing steps, streamlining your data quality workflows.\n \nAWS Glue Data Quality preprocessing queries are available through AWS Glue Data Catalog APIs - start-data-quality-rule-recommendation-run and start-data-quality-ruleset-evaluation-run, in all commercial AWS Regions where AWS Glue Data Quality is available. To learn more about preprocessing queries, see the Glue Data Quality documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-data-quality-pre-processing-queries/",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "glue"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lex",
        "glue",
        "support"
      ]
    },
    {
      "id": "aws-news-857014d66d68",
      "title": "Amazon Quick Suite introduces scheduling for Quick Flows",
      "description": "Amazon Quick Flows now supports scheduling, enabling you to automate repetitive workflows without requiring manual intervention. You can now configure Quick Flows to run automatically at specified times or intervals, improving operational efficiency and ensuring critical tasks execute consistently.\n  You can schedule Quick Flows to run daily, weekly, monthly, or on custom intervals. This capability is great for automating routine and administrative tasks such as generating recurring reports from dashboards, summarizing open items assigned to you in external services, or generating daily meeting briefings before you head out to work.\n  You can schedule any flow you have access to—whether you created it or it was shared with you. To schedule a flow, click the scheduling icon and configure your desired date, time, and frequency.\n  Scheduling in Quick Flows is available now in US East (N. Virginia), US West (Oregon), and Europe (Ireland) There are no additional charges for using scheduled execution beyond standard Quick Flows usage.\n  To learn more about configuring scheduled Quick Flows, please visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-suite-scheduling-quick-flows/",
      "pubDate": "2025-11-25T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-e5767083a6d4",
      "title": "Optimize unused capacity with Amazon EC2 interruptible capacity reservations",
      "description": "Organizations running critical workloads on Amazon Elastic Compute Cloud (Amazon EC2) reserve compute capacity using On-Demand Capacity Reservations (ODCR) to have availability when needed. However, reserved capacity can intermittently sit idle during off-peak periods, between deployments, or when workloads scale down. This unused capacity represents a missed opportunity for cost optimization and resource efficiency across the organization.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-unused-capacity-with-amazon-ec2-interruptible-capacity-reservations/",
      "pubDate": "2025-11-25T01:09:16.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-60262ac8a35f",
      "title": "Accelerate generative AI innovation in Canada with Amazon Bedrock cross-Region inference",
      "description": "We are excited to announce that customers in Canada can now access advanced foundation models including Anthropic's Claude Sonnet 4.5 and Claude Haiku 4.5 on Amazon Bedrock through cross-Region inference (CRIS). This post explores how Canadian organizations can use cross-Region inference profiles from the Canada (Central) Region to access the latest foundation models to accelerate AI initiatives. We will demonstrate how to get started with these new capabilities, provide guidance for migrating from older models, and share recommended practices for quota management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-generative-ai-innovation-in-canada-with-amazon-bedrock-cross-region-inference/",
      "pubDate": "2025-11-24T23:56:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-333d00155bd8",
      "title": "Power up your ML workflows with interactive IDEs on SageMaker HyperPod",
      "description": "Amazon SageMaker HyperPod clusters with Amazon Elastic Kubernetes Service (EKS) orchestration now support creating and managing interactive development environments such as JupyterLab and open source Visual Studio Code, streamlining the ML development lifecycle by providing managed environments for familiar tools to data scientists. This post shows how HyperPod administrators can configure Spaces for their clusters, and how data scientists can create and connect to these Spaces.",
      "link": "https://aws.amazon.com/blogs/machine-learning/power-up-your-ml-workflows-with-interactive-ides-on-sagemaker-hyperpod/",
      "pubDate": "2025-11-24T21:25:56.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-86ee5fc225bc",
      "title": "AWS Weekly Roundup: How to join AWS re:Invent 2025, plus Kiro GA, and lots of launches (Nov 24, 2025)",
      "description": "Next week, don’t miss AWS re:Invent, Dec. 1-5, 2025, for the latest AWS news, expert insights, and global cloud community connections! Our News Blog team is finalizing posts to introduce the most exciting launches from our service teams. If you’re joining us in person in Las Vegas, review the agenda, session catalog, and attendee guides […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-how-to-join-aws-reinvent-2025-plus-kiro-ga-and-lots-of-launches-nov-24-2025/",
      "pubDate": "2025-11-24T19:58:08.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-5403d33b1bbc",
      "title": "How potential performance upside with AWS Graviton helps reduce your costs further",
      "description": "Amazon Web Services (AWS) provides many mechanisms to optimize the price performance of workloads running on Amazon Elastic Compute Cloud (Amazon EC2), and the selection of the optimal infrastructure to run on can be one of the most impactful levers. When we started building the AWS Graviton processor, our goal was to optimize AWS Graviton […]",
      "link": "https://aws.amazon.com/blogs/compute/how-potential-performance-upside-with-aws-graviton-helps-reduce-your-costs-further/",
      "pubDate": "2025-11-24T19:11:55.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton"
      ]
    },
    {
      "id": "aws-news-4f096af20c37",
      "title": "OpenSearch Service Enhances Log Analytics with New PPL Experience",
      "description": "Today, AWS announces enhanced log analytics capabilities in Amazon OpenSearch Service, making Piped Processing Language (PPL) and natural language the default experience in OpenSearch UI's Observability workspace. This update combines proven pipeline syntax with simplified workflows to deliver an intuitive observability experience, helping customers analyze growing data volumes while controlling costs. The new experience includes 35+ new commands for deep analysis, faceted exploration, and natural language querying to help customers gain deeper insights across infrastructure, security, and business metrics.\n  With this enhancement, customers can streamline their log analytics workflows using familiar pipeline syntax while leveraging advanced analytics capabilities. The solution includes enterprise-grade query capabilities, supporting advanced event correlation using natural language that help teams uncover meaningful patterns faster. Users can seamlessly move from query to visualization within a single interface, reducing mean time to detect and resolve issues. Admins can quickly stand up an end-to-end OpenTelemetry solution using OpenSearch's Get Started workflow in the AWS console. The unified workflow includes out-of-the-box OpenSearch Ingestion pipelines for OpenTelemetry data, making it easier for teams to get started quickly.\n  Amazon OpenSearch UI is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Osaka), Asia Pacific (Hong Kong), Asia Pacific (Hyderabad), Europe (Ireland), Europe (London), Europe (Frankfurt), Europe (Paris), Europe (Stockholm), Europe (Milan), Europe (Spain), Europe (Zurich), South America (São Paulo), and Canada (Central).\n  To learn more about the new OpenSearch log analytics experience, visit the OpenSearch Service observability documentation and start using these enhanced capabilities today in OpenSearch UI.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/opensearch-service-log-analytics-ppl/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch",
        "opensearch service",
        "opensearch ingestion"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "opensearch ingestion",
        "ga",
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-250fe2a963fb",
      "title": "Amazon CloudFront announces support for mutual TLS authentication",
      "description": "Amazon CloudFront announces support for mutual TLS Authentication (mTLS), a security protocol that requires both the server and client to authenticate each other using X.509 certificates, enabling customers to validate client identities at CloudFront's edge locations. Customers can now ensure only clients presenting trusted certificates can access their distributions, helping protect against unauthorized access and security threats.\n  Previously, customers had to spend ongoing effort implementing and maintaining their own client access management solutions, leading to undifferentiated heavy lifting. Now with the support for mutual TLS, customers can easily validate client identities at the AWS edge before connections are established with their application servers or APIs. Example use cases include B2B secure API integrations for enterprises and client authentication for IoT. For B2B API security, enterprises can authenticate API requests from trusted third parties and partners using mutual TLS. For IoT use cases, enterprises can validate that devices are authorized to receive proprietary content such as firmware updates. Customers can leverage their existing third-party Certificate Authorities or AWS Private Certificate Authority to sign the X.509 certificates. With Mutual TLS, customers get the performance and scale benefits of CloudFront for workloads that require client authentication.\n  Mutual TLS authentication is available to all CloudFront customers at no additional cost. Customers can configure mutual TLS with CloudFront using the AWS Management Console, CLI, SDK, CDK, and CloudFormation. For detailed implementation guidance and best practices, visit CloudFront Mutual TLS (viewer) documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudfront-mutual-tls-authentication/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "cloudfront"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudformation",
        "cloudfront",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-492795cde0aa",
      "title": "Amazon EC2 announces interruptible Capacity Reservations",
      "description": "Today, Amazon EC2 announces interruptible Capacity Reservations to help you better utilize your reserved capacity and save costs. On-Demand Capacity Reservations (ODCRs) help you reserve compute capacity in a specific Availability Zone for any duration. When ODCRs are not in use, you can now make them temporarily available as interruptible ODCRs, enabling other workloads within your organization to utilize them while preserving your ability to reclaim the capacity for critical operations.\n  By repurposing unused capacity as interruptible ODCRs, workloads suitable for flexible, fault-tolerant operations—such as batch processing, data analysis, and machine learning training can benefit from temporarily available capacity. Reservation owners can reclaim their capacity at any time, while consumers of interruptible ODCRs will receive an interruption notice before termination to allow for graceful shutdown or checkpointing before.\n  Interruptible ODCRs are now available at no additional cost to all Capacity Reservations customers. Refer to the AWS Capabilities by Region website for the feature's regional availability. CloudFormation support will be coming soon. For more details, please refer to the Capacity Reservations user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-interruptible-capacity-reservations",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "cloudformation"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "cloudformation",
        "ga",
        "now-available",
        "support",
        "coming-soon"
      ]
    },
    {
      "id": "aws-news-8b58ac2defe5",
      "title": "AWS IoT Core now supports IoT thing registry data retrieval from IoT rules",
      "description": "AWS IoT Core announces a new capability to dynamically retrieve IoT thing registry data using an IoT rule, enhancing your ability to filter, enrich, and route IoT messages. Using the new get_registry_data() inline rule function, you can access IoT thing registry data, such as device attributes, device type, and group membership and leverage this information directly in IoT rules.\n  For example, your rule can filter AWS IoT Core connectivity lifecycle events and then retrieve thing attributes (such as \"test\" or \"production\" device) to inform routing of lifecycle events to different endpoints for downstream processing. You can also use this feature to enrich or route IoT messages with registry data from other devices. For instance, you can add a sensor’s threshold temperature from IoT thing registry to the messages relayed by its gateway.\n  To get started, connect your devices to AWS IoT Core and store your IoT device data in IoT thing registry. You can then use IoT rules to retrieve your registry data. This capability is available in all AWS regions where AWS IoT Core is present. For more information refer to the developer guide and API documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-core-thing-registry-data-retrieval/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-0dc775a80f99",
      "title": "AWS Elemental MediaTailor now supports HLS Interstitials for live streams",
      "description": "AWS Elemental MediaTailor now supports HTTP Live Streaming (HLS) Interstitials for live streams, enabling broadcasters and streaming service providers to deliver seamless, personalized ad experiences across a wide range of modern video players. This capability allows customers to insert interstitial advertisements and promotions directly into live streams using the HLS Interstitials specification (RFC 8216), which is natively supported by popular players including HLS.js, Shaka Player, Bitmovin Player, and Apple devices running iOS 16.4, iPadOS 16.4, tvOS 16.4, and later.\n  With HLS Interstitials, MediaTailor automatically generates the necessary metadata tags (Interstitial class EXT-X-DATERANGE with X-ASSET-LIST attributes) that signal to client players when and how to play interstitial content. This approach eliminates the need for custom player-side stitching logic, reducing development complexity and ensuring consistent playback behavior. The feature integrates with MediaTailor's existing server-side ad insertion (SSAI) capabilities, delivering frame-accurate transitions with no buffering between content and interstitials. Server-side beaconing continues to work with HLS Interstitials, ensuring ad tracking and measurement workflows remain intact.\n  HLS Interstitials for live streams is particularly valuable for sports broadcasts, live news, and event streaming where precise ad timing and minimal latency are critical. The feature supports pre-roll and mid-roll insertion, giving customers flexibility in how they monetize their live content. This launch complements MediaTailor's existing HLS Interstitials support for VOD, rounding out support across Linear, Live, FAST, and VOD workflows. MediaTailor makes it easy to test and deploy—customers can rapidly enable or disable HLS Interstitials with a simple query parameter on the multi-variant manifest request, providing per playback session control without changing the underlying MediaTailor configuration.\n  AWS Elemental MediaTailor HLS Interstitials for live streams is available today in all AWS Regions where MediaTailor operates. You pay only for the features you use, with no upfront commitments. To learn more and get started, visit the AWS Elemental MediaTailor documentation and the HLS Interstitials implementation guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-elemental-mediatailor-hls-interstitials-live-streams",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lex",
        "personalize",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-2c3433f02c16",
      "title": "Amazon Redshift now supports federated permissions across multi-warehouse architectures",
      "description": "Amazon Redshift now supports federated permissions across multi-warehouse architectures\n  Amazon Redshift now supports federated permissions, which simplify permissions management across multiple Redshift data warehouses. Customers are adopting multi-warehouse architectures to scale and isolate workloads and are looking for simplified, consistent permissions management across warehouses. With Redshift federated permissions, you define data permissions once from any Redshift warehouse and automatically enforce them across all warehouses in the account.\n  Amazon Redshift warehouses with federated permissions are auto-mounted in every Redshift warehouse, and you can use existing workforce identities with AWS IAM Identity Center or use existing IAM roles to query data across warehouses. Regardless of which warehouse is used for querying, row-level, column-level, and masking controls always apply automatically, delivering fine-grained access compliance. You can get started by registering a Redshift Serverless namespace or Redshift provisioned cluster with AWS Glue Data Catalog and start querying across warehouses using Redshift Query Editor V2, or any supported SQL client. You get horizontal scalability with multiple warehouses by allowing you to add new warehouses without increasing governance complexity, as new warehouses automatically enforce permission policies and analysts immediately see all databases from registered warehouses.\n  Amazon Redshift federated permissions is available at no additional cost in supported AWS regions. To learn more, visit the Amazon Redshift documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-redshift-federated-permissions-multi-warehouse-architectures",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "redshift",
        "iam",
        "iam identity center",
        "glue"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "redshift",
        "iam",
        "iam identity center",
        "glue",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-b70cf6c5ae33",
      "title": "Amazon U7i instances now available in Asia Pacific (Jakarta) Region",
      "description": "Starting today, Amazon EC2 High Memory U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in the Asia Pacific (Jakarta) region. U7i-6tb instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-u7i-instances-asia-pacific-jakarta-region",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f4fc0337cbad",
      "title": "Amazon Connect flow modules now support custom inputs, outputs, and version management",
      "description": "Amazon Connect flow modules now support custom inputs, outputs, and branches, along with version and alias management. With this launch, you can now define flexible parameters for your reusable flow modules to math your specific business logic. For example, you can create an authentication module that accepts a phone number and PIN as inputs, then returns the customer name and authentication status as outputs with branches such as \"authenticated\" or \"not authenticated\". All parameters are customizable to meet your specific needs.\n  Additionally, advanced versioning and aliasing capabilities allow you to manage module updates more seamlessly. You can create immutable version snapshots and map aliases to specific versions. When you update an alias to point to a new version, all flows using that module automatically reference the updated version. These new features make flow modules more powerful and reusable, allowing you to build and maintain flows more efficiently.\n  To learn more about these feature, see the Amazon Connect Administrator Guide. This feature is available in all AWS regions that offers Amazon Connect. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-flow-modules-custom-inputs-outputs-version-management",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "launch",
        "new-feature",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-fd016fec1803",
      "title": "AWS Glue announces catalog federation for remote Apache Iceberg catalogs",
      "description": "AWS Glue announces the general availability of catalog federation for remote Iceberg catalogs. This capability provides direct and secure access to Iceberg tables stored in Amazon S3 and cataloged in remote catalogs using AWS analytics engines.\n  With catalog federation, you can federate to remote Iceberg catalogs and query remote Iceberg tables using your preferred AWS analytics engines, without moving or copying tables. It synchronizes metadata real-time across AWS Glue Data Catalog and remote catalogs when data teams query remote tables, which means that query results are always completely up-to-date. You can now choose the best price-performance for your workloads when analyzing remote Iceberg tables using your preferred AWS analytics engines, while maintaining consistent security controls when discovering or querying data. Catalog federation is supported by a wide variety of analytics engines, including Amazon Redshift, Amazon EMR, Amazon Athena, AWS Glue, third-party engines like Apache Spark, and Amazon SageMaker with the serverless notebooks.\n  Catalog federation uses AWS Lake Formation for access controls, allowing you to use fine-grained access controls, cross-account sharing, and trusted identity propagation when sharing remote catalog tables with other data consumers. Catalog federation integrates with catalog implementations that support the Iceberg REST specifications.\n  Catalog federation is available in Lake Formation console and using AWS Glue and Lake Formation SDKs and APIs. This feature is generally available in all AWS commercial regions where AWS Glue and Lake Formation are available. With just a few clicks in the console, you can federate to remote catalogs, discover its databases and tables, grant permissions to access table data, and query remote Iceberg tables using AWS analytics engines. To learn more, visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-catalog-federation-remote-apache-iceberg-catalogs",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-2749db54abec",
      "title": "AWS IoT Core enhances IoT rules-SQL with variable setting and error handling capabilities",
      "description": "AWS IoT Core now supports a SET clause in IoT rules-SQL, which lets you set and reuse variables across SQL statements. This new feature provides a simpler SQL experience and ensures consistent content when variables are used multiple times. Additionally, a new get_or_default() function provides improved failure handling by returning default values while encountering data encoding or external dependency issues, ensuring IoT rules continue execution successfully.\n  AWS IoT Core is a fully managed service that securely connects millions of IoT devices to the AWS cloud. Rules for AWS IoT is a component of AWS IoT Core which enables you to filter, process, and decode IoT device data using SQL-like statements, and route the data to 20+ AWS and third-party services. As you define an IoT rule, these new capabilities help you eliminate complicated SQL statements and make it easy for you to manage IoT rules-SQL failures.\n \nThese new features are available in all AWS Regions where AWS IoT Core is available, including AWS GovCloud (US) and Amazon China Regions. For more information and getting started experience, visit the developer guides on SET clause and get_or_default() function.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-core-rules-sql/",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-5caa4bd88af7",
      "title": "Amazon Quick Suite Embedded Chat is now available",
      "description": "Today, AWS announces the general availability of Amazon Quick Suite Embedded Chat, enabling you to embed Quick Suite's conversational AI, which combines structured data and unstructured knowledge in a single conversation - directly into your applications, eliminating the need to build conversational interfaces, orchestration logic, or data access layers from scratch.\n \nQuick Suite Embedded Chat solves a fundamental problem: users want answers where they work, not in another tool. Whether in a CRM, support console, or analytics portal, they need instant, contextual responses. Most conversational tools excel at either structured data or documents, analytics or knowledge bases, answering questions or performing actions—rarely all of the above. Quick Suite closes this gap. Now, users can reference a KPI, pull details from a file, check customer feedback, and trigger actions in one continuous conversation without leaving the embedded chat.\n  Embedded Chat brings this unified experience into your applications with simple integration, either through 1-click embedding or through API-based iframes for registered users with your existing authentication. You can connect your Agentic Chat to your data through connectors to search SharePoint, websites, send Slack messages, or create Jira tasks and customize the Agent with your brand colors, communication style, and personalized greetings. Security always stays under your control as you choose what the agent accesses and explicitly scope all actions.\n  Quick Suite Embedded Chat is available the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland), and we'll expand availability to additional AWS Regions over the coming months. There is no additional cost for Quick Suite Embedded Chat. Existing Quick Suite pricing is available here.\n  To learn more, see Embedding Amazon Quick Suite launch blog. To get started with Amazon Quick Suite, visit the Amazon Quick Suite product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-suite-embedded-chat",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "launch",
        "ga",
        "now-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-ef2f09b21b66",
      "title": "Amazon MSK Replicator is now available in five additional AWS Regions",
      "description": "You can now use Amazon MSK Replicator to replicate streaming data across Amazon Managed Streaming for Apache Kafka (Amazon MSK) clusters in five additional AWS Regions: Asia Pacific (Thailand), Mexico (Central), Asia Pacific (Taipei), Canada West (Calgary), Europe (Spain).\n  MSK Replicator is a feature of Amazon MSK that enables you to reliably replicate data across Amazon MSK clusters in different or the same AWS Region(s) in a few clicks. With MSK Replicator, you can easily build regionally resilient streaming applications for increased availability and business continuity. MSK Replicator provides automatic asynchronous replication across MSK clusters, eliminating the need to write custom code, manage infrastructure, or setup cross-region networking. MSK Replicator automatically scales the underlying resources so that you can replicate data on-demand without having to monitor or scale capacity. MSK Replicator also replicates the necessary Kafka metadata including topic configurations, Access Control Lists (ACLs), and consumer group offsets. If an unexpected event occurs in a region, you can failover to the other AWS Region and seamlessly resume processing.\n  You can get started with MSK Replicator from the Amazon MSK console or the Amazon CLI. To learn more, visit the MSK Replicator product page, pricing page, and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-msk-replicator-additional-aws-regions",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "kafka",
        "msk",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-6f01ea89f53c",
      "title": "AWS Lambda announces enhanced error handling capabilities for Kafka event processing",
      "description": "AWS Lambda launches enhanced error handling capabilities for Amazon Managed Streaming for Apache Kafka (MSK) and self-managed Apache Kafka (SMK) event sources. These capabilities allow customers to build custom retry configurations, optimize retries of failed messages, and send failed events to a Kafka topic as an on-failure destination, enabling customers to build resilient Kafka workloads with robust error handling strategies.\n  Customers use Kafka event source mappings (ESM) with their Lambda functions to build their mission-critical Kafka applications. Kafka ESM offers robust error handling of failed events by retrying events with exponential backoff, and retaining failed events in on-failure destinations like Amazon SQS, Amazon S3, Amazon SNS. However, customers need customized error handling to meet stringent business and performance requirements. With this launch, developers can now exercise precise control over failed event processing and leverage Kafka topics as an additional on-failure destination when using Provisioned mode for Kafka ESM. Customers can now define specific retry limits and time boundaries for retry, automatically discarding failed records beyond these limits to customer-specified destination. They can now also set automatic retries of failed records in the batch and enhance their function code to report individual failed messages, optimizing the retry process.\n  This feature is available in all AWS Commercial Regions where AWS Lambda’s Provisioned mode for Kafka ESM is available.\n  To enable these capabilities, provide configuration parameters for your Kafka ESM in the ESM API, AWS Console, and AWS CLI. To learn more, read the Lambda ESM documentation and AWS Lambda pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-lambda-enhanced-error-handling-capabilities-kafka-event-processing",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "s3",
        "rds",
        "kafka",
        "msk",
        "sns",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "s3",
        "rds",
        "kafka",
        "msk",
        "sns",
        "sqs",
        "launch"
      ]
    },
    {
      "id": "aws-news-5d462e79f71b",
      "title": "Claude Opus 4.5 now available in Amazon Bedrock",
      "description": "Customers can now use Claude Opus 4.5 in Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models from leading AI companies. Opus 4.5 is Anthropic's newest model, setting new standards across coding, agentic workflows, computer use, and office tasks while making Opus-level intelligence accessible at one-third the cost.\n  Opus 4.5 excels at professional software engineering tasks, achieving state-of-the-art performance on SWE-bench. The model handles ambiguity, reasons about tradeoffs and can figure out fixes for bugs that require reasoning across multiple systems. It can help transform multi-day team development projects into hours-long tasks with improved multilingual coding capabilities. This generation of Claude spans the full development lifecycle: Opus 4.5 for production code and lead agents, Sonnet 4.5 for rapid iteration and scaled user experiences, Haiku 4.5 for sub-agents and free-tier products.\n  Beyond coding, the model powers agents that produce documents, spreadsheets, and presentations with consistency, professional polish, and domain awareness, making it ideal for finance and other precision-critical verticals. As Anthropic's best vision model yet, it unlocks workflows that depend on complex visual interpretation and multi-step navigation. Through the Amazon Bedrock API, Opus 4.5 introduces two new capabilities: tool search and tool use examples. Together, these updates enable Claude to navigate large tool libraries and accurately execute complex tasks. A new effort parameter, available in beta, lets you control how much effort Claude allocates across thinking, tool calls, and responses to balance performance with latency, and cost.\n  Claude Opus 4.5 is now available in Amazon Bedrock via global cross region inference in multiple locations. For the full list of available regions, refer to the documentation. To get started with the model in Amazon Bedrock, read the launch blog or visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/claude-opus-4-5-amazon-bedrock",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "rds"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "rds",
        "launch",
        "beta",
        "ga",
        "now-available",
        "update"
      ]
    },
    {
      "id": "aws-news-2a82d6f564ba",
      "title": "Amazon OpenSearch Service now supports OpenSearch version 3.3",
      "description": "You can now run OpenSearch version 3.3 in Amazon OpenSearch Service. OpenSearch 3.3 introduces several improvements in areas like search performance, observability and new functionality to make agentic AI integrations simpler and more powerful.\n \nThis launch includes several improvements in vector search capabilities. First, with agentic search, you can now achieve precise search results using natural language inputs without the need to construct complex domain-specific language (DSL) queries. Second, batch processing for semantic highlighter improves performance by reducing overhead latency and improving GPU utilization. Finally, enhancements to Neural Search plugin make semantic search more efficient and provide optimization options for your specific data, performance, and relevance needs.\n \nThis launch also introduces support for Apache Calcite as default query engine for PPL that delivers optimization capabilities, improvements to query processing efficiency, and an extensive library of new PPL commands and functions. Additionally, this launch includes enhancements to the approximation framework that improve the responsiveness of paginated search results, real-time dashboards, and applications requiring deep pagination through large time-series or numeric datasets. Finally, workload management plugin now allows you to group search traffic and isolate network resources. This prevents specific requests from overusing network resources and offers tenant-level isolation.\n \nFor information on upgrading to OpenSearch 3.3, please see the documentation. OpenSearch 3.3 is now available in all AWS Regions where Amazon OpenSearch Service is available.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-opensearch-service-opensearch-version-3-3/",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds",
        "launch",
        "now-available",
        "improvement",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-b33c849d838a",
      "title": "Amazon Aurora PostgreSQL introduces dynamic data masking",
      "description": "Amazon Aurora PostgreSQL-Compatible Edition now supports dynamic data masking through the new pg_columnmask extension, allowing you to simplify the protection of sensitive data in your database. pg_columnmask extends Aurora's security capabilities by enabling column-level protection that complements PostgreSQL's native row-level security and column level grants. Using pg_columnmask, you can control access to sensitive data through SQL-based masking policies and define how data appears to users at query time based on their roles, helping you comply with data privacy regulations like GDPR, HIPAA, and PCI DSS.\n \nWith pg_columnmask, you can create flexible masking policies using built-in or user-defined functions. You can completely hide information, replace partial values with wildcards, or define custom masking approaches. Further, you can apply multiple masking policies to a single column and control their precedence using weights. pg_columnmask helps protect data in complex queries with WHERE, JOIN, ORDER BY, or GROUP BY clauses. Data is masked at the database level during query processing, leaving stored data unmodified.\n \npg_columnmask is available for Aurora PostgreSQL version 16.10 and higher, and 17.6 and higher in all AWS Regions where Aurora PostgreSQL is available. To learn more, review our blog post and visit technical documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-aurora-postgresql-dynamic-data-masking",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-dcf28b462b4d",
      "title": "Amazon SageMaker HyperPod now supports Spot Instances",
      "description": "Amazon SageMaker HyperPod now supports Spot Instances, enabling customers to reduce GPU compute costs by up to 90% compared to on-demand instances on HyperPod . As AI workloads scale, optimizing infrastructure costs becomes increasingly critical. SageMaker HyperPod's Spot integration addresses this by allowing customers to automatically leverage spare EC2 capacity at significant discounts, while providing the managed AI experience customers enjoy on HyperPod. \n \nWith Spot Instances, organizations can run fault-tolerant workloads cost-effectively at scale. You can combine Spot with on-demand instances to balance cost optimization with guaranteed availability. The feature is available on HyperPod EKS clusters and integrates with Karpenter for intelligent auto-scaling, automatically discovering available Spot capacity and handling instance interruptions.\n \nYou can enable Spot Instances when creating instance groups through the CreateCluster API or AWS Console. The feature supports all instance types available on HyperPod, including CPUs and GPUs. Capacity availability depends on supply from EC2 and varies by region and instance type. Spot instance support is available in all regions where SageMaker HyperPod is currently available. To learn more, please refer to the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-hyperpod-spot-instances",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "ec2",
        "eks",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "ec2",
        "eks",
        "organizations",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-97ea49be4b86",
      "title": "Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) for generative AI tasks",
      "description": "Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) technology, enabling administrators to partition a single GPU into multiple isolated GPUs. This capability allows administrators to maximize resource utilization by running diverse, small generative AI (GenAI) tasks simultaneously on GPU partitions while maintaining performance and task isolation.\n  Administrators can choose either the easy-to-use configuration setup on the SageMaker HyperPod console or a custom setup approach to enable fine-grained, hardware-isolated resources for specific task requirements that don't require full GPU capacity. They can also allocate compute quota to ensure fair and efficient distribution of GPU partitions across teams. With real-time performance metrics and resource utilization monitoring dashboard across GPU partitions, administrators gain visibility to optimize resource allocation. Data scientists can now accelerate time-to-market by scheduling lightweight inference tasks and running interactive notebooks in parallel on GPU partitions, eliminating wait times for full GPU availability.\n  This capability is currently available for Amazon SageMaker HyperPod clusters using the EKS orchestrator across the following AWS Regions: US West (Oregon), US East (N.Virginia), US East (Ohio), US West (N. California), Canada (Central), South America (Sao Paulo), Europe (Stockholm), Europe (Spain), Europe (Ireland), Europe (Frankfurt), Europe (London), Asia Pacific (Mumbai), Asia Pacific (Jakarta), Asia Pacific (Melbourne), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Seoul), Asia Pacific (Singapore).\n  To learn more, visit SageMaker HyperPod webpage, and SageMaker HyperPod documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-hyperpod-nvidia-multi-instance-gpu/",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-2d34b7fdfada",
      "title": "New one-click onboarding and notebooks with a built-in AI agent in Amazon SageMaker Unified Studio",
      "description": "Amazon SageMaker Unified Studio introduces new one-click onboarding experiences and serverless notebooks with a built-in AI agent without any manual set up or provisioning of your domain or compute resources. You can launch SageMaker Unified Studio directly from Amazon SageMaker, Amazon Athena, Amazon Redshift, and Amazon S3 Tables console pages, giving a fast path to analytics and AI workloads.",
      "link": "https://aws.amazon.com/blogs/aws/new-one-click-onboarding-and-notebooks-with-ai-agent-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-22T01:23:12.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "athena"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "athena",
        "launch"
      ]
    },
    {
      "id": "aws-news-53da4fc00af6",
      "title": "Build production-ready applications without infrastructure complexity using Amazon ECS Express Mode",
      "description": "Amazon ECS Express Mode simplifies containerized application deployment by automating infrastructure setup through a single command, allowing developers to focus on building applications while following AWS best practices.",
      "link": "https://aws.amazon.com/blogs/aws/build-production-ready-applications-without-infrastructure-complexity-using-amazon-ecs-express-mode/",
      "pubDate": "2025-11-21T21:34:45.000Z",
      "source": "newsBlog",
      "services": [
        "lex",
        "ecs"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex",
        "ecs"
      ]
    },
    {
      "id": "aws-news-7d35cf5f9ae9",
      "title": "Enhancing API security with Amazon API Gateway TLS security policies",
      "description": "In this post, you will learn how the new Amazon API Gateway’s enhanced TLS security policies help you meet standards such as PCI DSS, Open Banking, and FIPS, while strengthening how your APIs handle TLS negotiation. This new capability increases your security posture without adding operational complexity, and provides you with a single, consistent way to standardize TLS configuration across your API Gateway infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/enhancing-api-security-with-amazon-api-gateway-tls-security-policies/",
      "pubDate": "2025-11-21T21:17:52.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "rds",
        "api gateway"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "api gateway",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-9d3d32287870",
      "title": "Improving throughput of serverless streaming workloads for Kafka",
      "description": "Event-driven applications often need to process data in real-time. When you use AWS Lambda to process records from Apache Kafka topics, you frequently encounter two typical requirements: you need to process very high volumes of records in close to real-time, and you want your consumers to have the ability to scale rapidly to handle traffic spikes. Achieving both necessitates understanding how Lambda consumes Kafka streams, where the potential bottlenecks are, and how to optimize configurations for high throughput and best performance.",
      "link": "https://aws.amazon.com/blogs/compute/improving-throughput-of-serverless-streaming-workloads-for-kafka/",
      "pubDate": "2025-11-21T20:02:57.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "rds",
        "kafka"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "rds",
        "kafka"
      ]
    },
    {
      "id": "aws-news-b3a3371e0c90",
      "title": "Build scalable REST APIs using Amazon API Gateway private integration with Application Load Balancer",
      "description": "Today, we announced \nAmazon API Gateway REST API’s support for private integration with \nApplication Load Balancers (ALBs). You can use this new capability to securely expose your VPC-based applications through your REST APIs without exposing your ALBs to the public internet.",
      "link": "https://aws.amazon.com/blogs/compute/build-scalable-rest-apis-using-amazon-api-gateway-private-integration-with-application-load-balancer/",
      "pubDate": "2025-11-21T19:28:04.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "api gateway",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-12b5ed99b30f",
      "title": "Introducing Cluster Insights: Unified monitoring dashboard for Amazon OpenSearch Service clusters",
      "description": "This blog will guide you through setting up and using Cluster Insights, including key features and metrics. By the conclusion, you'll understand how to use Cluster insights to recognize and address performance and resiliency issues within your OpenSearch Service clusters.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-cluster-insights-unified-monitoring-dashboard-for-amazon-opensearch-service-clusters/",
      "pubDate": "2025-11-21T16:38:56.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-77e4c24aff91",
      "title": "Introducing VPC encryption controls: Enforce encryption in transit within and across VPCs in a Region",
      "description": "AWS announces VPC encryption controls, a new capability that helps organizations audit and enforce encryption in transit for all traffic within and across VPCs in a Region, simplifying compliance with regulatory frameworks like HIPAA, PCI DSS, and FedRAMP through automated monitoring and enforcement modes.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-vpc-encryption-controls-enforce-encryption-in-transit-within-and-across-vpcs-in-a-region/",
      "pubDate": "2025-11-21T16:23:50.000Z",
      "source": "newsBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "organizations",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-73b319ca71d2",
      "title": "Introducing attribute-based access control for Amazon S3 general purpose buckets",
      "description": "AWS introduces Attribute-Based Access Control (ABAC) for S3 general purpose buckets, enabling administrators to automatically manage permissions through tag-based policies that match tags between users, roles, and buckets—eliminating the need to constantly update IAM policies as organizations scale.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-attribute-based-access-control-for-amazon-s3-general-purpose-buckets/",
      "pubDate": "2025-11-21T01:02:35.000Z",
      "source": "newsBlog",
      "services": [
        "s3",
        "iam",
        "organizations"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "iam",
        "organizations",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-c2a79337519c",
      "title": "Enforce business glossary classification rules in Amazon SageMaker Catalog",
      "description": "Amazon SageMaker Catalog now supports metadata enforcement rules for glossary terms classification (tagging) at the asset level. With this capability, administrators can require that assets include specific business terms or classifications. Data producers must apply required glossary terms or classifications before an asset can be published. In this post, we show how to enforce business glossary classification rules in SageMaker Catalog.",
      "link": "https://aws.amazon.com/blogs/big-data/enforce-business-glossary-classification-rules-in-amazon-sagemaker-catalog/",
      "pubDate": "2025-11-20T18:39:41.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-32281bfd2f59",
      "title": "Enhanced data discovery in Amazon SageMaker Catalog with custom metadata forms and rich text documentation",
      "description": "Amazon SageMaker Catalog now supports custom metadata forms and rich text descriptions at the column level, extending existing curation capabilities for business names, descriptions, and glossary term classifications. Column-level context is essential for understanding and trusting data. This release helps organizations improve data discoverability, collaboration, and governance by letting metadata stewards document columns using structured and formatted information that aligns with internal standards. In this post, we show how to enhance data discovery in SageMaker Catalog with custom metadata forms and rich text documentation at the schema level.",
      "link": "https://aws.amazon.com/blogs/big-data/enhanced-data-discovery-in-amazon-sagemaker-catalog-with-custom-metadata-forms-and-rich-text-documentation/",
      "pubDate": "2025-11-20T18:35:07.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "rds",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-df24f6f1c182",
      "title": "Building multi-tenant SaaS applications with AWS Lambda’s new tenant isolation mode",
      "description": "Today, AWS is announcing tenant isolation for AWS Lambda, enabling you to process function invocations in separate execution environments for each end-user or tenant invoking your Lambda function. This capability simplifies building secure multi-tenant SaaS applications by managing tenant-level compute environment isolation and request routing, allowing you to focus on core business logic rather than implementing tenant-aware compute environment isolation.",
      "link": "https://aws.amazon.com/blogs/compute/building-multi-tenant-saas-applications-with-aws-lambdas-new-tenant-isolation-mode/",
      "pubDate": "2025-11-20T17:47:17.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-b04be71f4d69",
      "title": "Improve API discoverability with the new Amazon API Gateway Portal",
      "description": "In this post, we will show how you can use the new portal feature to create customizable portals with enhanced security features in minutes, with APIs from multiple accounts, without managing any infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/improve-api-discoverability-with-the-new-amazon-api-gateway-portal/",
      "pubDate": "2025-11-20T00:41:25.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-9150859a247c",
      "title": "Building an AI gateway to Amazon Bedrock with Amazon API Gateway",
      "description": "In this post, we'll explore a reference architecture that helps enterprises govern their Amazon Bedrock implementations using Amazon API Gateway. This pattern enables key capabilities like authorization controls, usage quotas, and real-time response streaming. We'll examine the architecture, provide deployment steps, and discuss potential enhancements to help you implement AI governance at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/building-an-ai-gateway-to-amazon-bedrock-with-amazon-api-gateway/",
      "pubDate": "2025-11-19T23:33:41.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "api gateway"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "api gateway",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-e3fa9789b76a",
      "title": "Getting started with Amazon S3 Tables in Amazon SageMaker Unified Studio",
      "description": "In this post, you learn how to integrate SageMaker Unified Studio with S3 Tables and query your data using Amazon Athena, Amazon Redshift, or Apache Spark in EMR and AWS Glue.",
      "link": "https://aws.amazon.com/blogs/big-data/getting-started-with-amazon-s3-tables-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-19T23:26:57.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-4934fd40d9d8",
      "title": "Architecting for AI excellence: AWS launches three Well-Architected Lenses at re:Invent 2025",
      "description": "At re:Invent 2025, we introduce one new lens and two significant updates to the AWS Well-Architected Lenses specifically focused on AI workloads: the Responsible AI Lens, the Machine Learning (ML) Lens, and the Generative AI Lens. Together, these lenses provide comprehensive guidance for organizations at different stages of their AI journey, whether you're just starting to experiment with machine learning or already deploying complex AI applications at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-for-ai-excellence-aws-launches-three-well-architected-lenses-at-reinvent-2025/",
      "pubDate": "2025-11-19T19:36:31.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-61647c9310e0",
      "title": "Announcing the updated AWS Well-Architected Generative AI Lens",
      "description": "We are delighted to announce an update to the AWS Well-Architected Generative AI Lens. This update features several new sections of the Well-Architected Generative AI Lens, including new best practices, advanced scenario guidance, and improved preambles on responsible AI, data architecture, and agentic workflows.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-generative-ai-lens/",
      "pubDate": "2025-11-19T19:36:28.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-5044b6bc98c4",
      "title": "Announcing the updated AWS Well-Architected Machine Learning Lens",
      "description": "We are excited to announce the updated AWS Well-Architected Machine Learning Lens, now enhanced with the latest capabilities and best practices for building machine learning (ML) workloads on AWS.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-machine-learning-lens/",
      "pubDate": "2025-11-19T19:36:25.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-ef83678a3303",
      "title": "Streamlined multi-tenant application development with tenant isolation mode in AWS Lambda",
      "description": "AWS Lambda introduces tenant isolation mode, enabling separate execution environments for each tenant within a single function to meet strict security requirements without managing dedicated per-tenant infrastructure.",
      "link": "https://aws.amazon.com/blogs/aws/streamlined-multi-tenant-application-development-with-tenant-isolation-mode-in-aws-lambda/",
      "pubDate": "2025-11-19T19:12:27.000Z",
      "source": "newsBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-47fc10778da0",
      "title": "New business metadata features in Amazon SageMaker Catalog to improve discoverability across organizations",
      "description": "Amazon SageMaker Catalog now offers column-level metadata forms and enforced glossary requirements, enabling organizations to improve data classification, discoverability, and governance through standardized business metadata.",
      "link": "https://aws.amazon.com/blogs/aws/new-business-metadata-features-in-amazon-sagemaker-catalog-to-improve-discoverability-across-organizations/",
      "pubDate": "2025-11-19T19:09:27.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "organizations"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-0801d7b479dd",
      "title": "Cross-account lakehouse governance with Amazon S3 Tables and SageMaker Catalog",
      "description": "In this post, we walk you through a practical solution for secure, efficient cross-account data sharing and analysis. You’ll learn how to set up cross-account access to S3 Tables using federated catalogs in Amazon SageMaker, perform unified queries across accounts with Amazon Athena in Amazon SageMaker Unified Studio, and implement fine-grained access controls at the column level using AWS Lake Formation.",
      "link": "https://aws.amazon.com/blogs/big-data/cross-account-lakehouse-governance-with-amazon-s3-tables-and-sagemaker-catalog/",
      "pubDate": "2025-11-18T23:01:03.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "athena"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "athena"
      ]
    },
    {
      "id": "aws-news-05b9bc2e3644",
      "title": "Python 3.14 runtime now available in AWS Lambda",
      "description": "AWS Lambda now supports Python 3.14 as both a managed runtime and container base image. Python is a popular language for building serverless applications. Developers can now take advantage of new features and enhancements when creating serverless applications on Lambda.",
      "link": "https://aws.amazon.com/blogs/compute/python-3-14-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-18T21:29:50.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "new-feature",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-1c81acbb3316",
      "title": "Introducing Amazon MWAA Serverless",
      "description": "Today, AWS announced Amazon Managed Workflows for Apache Airflow (MWAA) Serverless. This is a new deployment option for MWAA that eliminates the operational overhead of managing Apache Airflow environments while optimizing costs through serverless scaling. In this post, we demonstrate how to use MWAA Serverless to build and deploy scalable workflow automation solutions.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-amazon-mwaa-serverless/",
      "pubDate": "2025-11-17T22:22:46.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-c36d51e13ef0",
      "title": "Building serverless applications with Rust on AWS Lambda",
      "description": "Today, AWS Lambda is promoting Rust support from Experimental to Generally Available. This means you can now use Rust to build business-critical serverless applications, backed by AWS Support and the Lambda availability SLA.",
      "link": "https://aws.amazon.com/blogs/compute/building-serverless-applications-with-rust-on-aws-lambda/",
      "pubDate": "2025-11-14T21:38:15.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "experimental",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-78f167df36fd",
      "title": "AWS Lambda now supports Java 25",
      "description": "You can now develop AWS Lambda functions using Java 25 either as a managed runtime or using the container base image. This blog post highlights notable Java language features, Java Lambda runtime updates, and how you can use the new Java 25 runtime in your serverless applications.",
      "link": "https://aws.amazon.com/blogs/compute/aws-lambda-now-supports-java-25/",
      "pubDate": "2025-11-14T20:51:20.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-525a7aa26225",
      "title": "Your guide to AWS Analytics at AWS re:Invent 2025",
      "description": "It’s that time of year again — AWS re:Invent is here! At re:Invent, bold ideas come to life. Get a front-row seat to hear inspiring stories from AWS experts, customers, and leaders as they explore today’s most impactful topics, from data analytics to AI. For all the data enthusiasts and professionals, we’ve curated a comprehensive […]",
      "link": "https://aws.amazon.com/blogs/big-data/your-guide-to-aws-analytics-at-aws-reinvent-2025/",
      "pubDate": "2025-11-13T20:06:19.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-d4d5eb413522",
      "title": "How Yelp modernized its data infrastructure with a streaming lakehouse on AWS",
      "description": "This is a guest post by Umesh Dangat, Senior Principal Engineer for Distributed Services and Systems at Yelp, and Toby Cole, Principle Engineer for Data Processing at Yelp, in partnership with AWS. Yelp processes massive amounts of user data daily—over 300 million business reviews, 100,000 photo uploads, and countless check-ins. Maintaining sub-minute data freshness with […]",
      "link": "https://aws.amazon.com/blogs/big-data/how-yelp-modernized-its-data-infrastructure-with-a-streaming-lakehouse-on-aws/",
      "pubDate": "2025-11-13T18:07:22.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-32e40b364aee",
      "title": "The attendee’s guide to the AWS re:Invent 2025 Compute track",
      "description": "From December 1st to December 5th, Amazon Web Services (AWS) will hold its annual premier learning event: re:Invent. There are over 2000+ learning sessions that focus on specific topics at various skill levels, and the compute team have created 76 unique sessions for you to choose. There are many sessions you can choose from, and we are here to help you choose the sessions that best fit your needs. Even if you cannot join in person, you can catch-up with many of the sessions on-demand and even watch the keynote and innovation sessions live.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-the-aws-reinvent-2025-compute-track/",
      "pubDate": "2025-11-12T20:58:36.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-a7184d7c3c1a",
      "title": "Introducing the Amazon OpenSearch Lens for the AWS Well-Architected Framework",
      "description": "In this post, we show you how to use the Amazon OpenSearch Service Lens to evaluate your OpenSearch Service workloads against architectural best practices.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-the-amazon-opensearch-lens-for-the-aws-well-architected-framework/",
      "pubDate": "2025-11-12T01:07:02.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "ga"
      ]
    },
    {
      "id": "aws-news-25fb32cc6ab1",
      "title": "AWS Lambda networking over IPv6",
      "description": "This post examines the benefits of transitioning Lambda functions to IPv6, provides practical guidance for implementing dual-stack support in your Lambda environment, and considerations for maintaining compatibility with existing systems during migration.",
      "link": "https://aws.amazon.com/blogs/compute/aws-lambda-networking-over-ipv6/",
      "pubDate": "2025-11-07T22:14:31.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "support"
      ]
    },
    {
      "id": "aws-news-360e834c997a",
      "title": "BASF Digital Farming builds a STAC-based solution on Amazon EKS",
      "description": "This post was co-written with Frederic Haase and Julian Blau with BASF Digital Farming GmbH. At xarvio – BASF Digital Farming, our mission is to empower farmers around the world with cutting-edge digital agronomic decision-making tools. Central to this mission is our crop optimization platform, xarvio FIELD MANAGER, which delivers actionable insights through a range […]",
      "link": "https://aws.amazon.com/blogs/architecture/basf-digital-farming-builds-a-stac-based-solution-on-amazon-eks/",
      "pubDate": "2025-10-22T16:21:09.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-24029d05087c",
      "title": "What’s New in the AWS Deploy Tool for .NET",
      "description": "Version 2.0 of the AWS Deploy Tool for .NET is now available. This new major version introduces several foundational upgrades to improve the deployment experience for .NET applications on AWS. The tool comes with new minimum runtime requirements. We have upgraded it to require .NET 8 because the predecessor, .NET 6, is now out of […]",
      "link": "https://aws.amazon.com/blogs/developer/whats-new-in-the-aws-deploy-tool-for-net/",
      "pubDate": "2025-10-14T13:25:42.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-2f3bd8791ed1",
      "title": "Modernization of real-time payment orchestration on AWS",
      "description": "The global real-time payments market is experiencing significant growth. According to Fortune Business Insights, the market was valued at USD 24.91 billion in 2024 and is projected to grow to USD 284.49 billion by 2032, with a CAGR of 35.4%. Similarly, Grand View Research reports that the global mobile payment market, valued at USD 88.50 […]",
      "link": "https://aws.amazon.com/blogs/architecture/modernization-of-real-time-payment-orchestration-on-aws/",
      "pubDate": "2025-10-01T23:34:00.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": []
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-4fbb29739c17",
      "title": "General Availability Release of the Migration Tool for the AWS SDK for Java 2.x",
      "description": "The AWS SDK for Java 1.x (v1) entered maintenance mode on July 31, 2024, and will reach end-of-support on December 31, 2025. We recommend that you migrate to the AWS SDK for Java 2.x (v2) to access new features, enhanced performance, and continued support from AWS. To help you migrate efficiently, we’ve created a migration […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-release-of-the-migration-tool-for-the-aws-sdk-for-java-2-x/",
      "pubDate": "2025-09-26T16:47:36.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-7e2f23dd38ac",
      "title": "Simplify multi-tenant encryption with a cost-conscious AWS KMS key strategy",
      "description": "In this post, we explore an efficient approach to managing encryption keys in a multi-tenant SaaS environment through centralization, addressing challenges like key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. We demonstrate how implementing a centralized key management strategy using a single AWS KMS key per tenant can maintain security and compliance while reducing operational overhead as organizations scale.",
      "link": "https://aws.amazon.com/blogs/architecture/simplify-multi-tenant-encryption-with-a-cost-conscious-aws-kms-key-strategy/",
      "pubDate": "2025-08-21T21:54:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-d1d1f77f887e",
      "title": "How Karrot built a feature platform on AWS, Part 1: Motivation and feature serving",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post starts by presenting our motivation, our requirements, and the solution architecture, focusing on feature serving.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-1-motivation-and-feature-serving/",
      "pubDate": "2025-08-14T15:16:29.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-40ebd26fef7f",
      "title": "How Karrot built a feature platform on AWS, Part 2: Feature ingestion",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post covers the process of collecting features in real-time and batch ingestion into an online store, and the technical approaches for stable operation.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-2-feature-ingestion/",
      "pubDate": "2025-08-14T15:16:27.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    },
    {
      "id": "aws-news-8b2281cd8002",
      "title": "Maximizing Business Value Through Strategic Cloud Optimization",
      "description": "As cloud spending continues to surge, organizations must focus on strategic cloud optimization to maximize business value. This blog post explores key insights from MIT Technology Review's publication on cloud optimization, highlighting the importance of viewing optimization as a continuous process that encompasses all six AWS Well-Architected pillars.",
      "link": "https://aws.amazon.com/blogs/architecture/maximizing-business-value-through-strategic-cloud-optimization/",
      "pubDate": "2025-08-01T15:33:28.000Z",
      "source": "architectureBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-9e63742dd9e4",
      "title": "How Zapier runs isolated tasks on AWS Lambda and upgrades functions at scale",
      "description": "In this post, you’ll learn how Zapier has built their serverless architecture focusing on three key aspects: using Lambda functions to build isolated Zaps, operating over a hundred thousand Lambda functions through Zapier's control plane infrastructure, and enhancing security posture while reducing maintenance efforts by introducing automated function upgrades and cleanup workflows into their platform architecture.",
      "link": "https://aws.amazon.com/blogs/architecture/how-zapier-runs-isolated-tasks-on-aws-lambda-and-upgrades-functions-at-scale/",
      "pubDate": "2025-07-25T13:30:06.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-11d98a88cbe1",
      "title": "Implement monitoring for Amazon EKS with managed services",
      "description": "In this post, we show you how to implement comprehensive monitoring for Amazon Elastic Kubernetes Service (Amazon EKS) workloads using AWS managed services. This solution demonstrates building an EKS platform that combines flexible compute options with enterprise-grade observability using AWS native services and OpenTelemetry.",
      "link": "https://aws.amazon.com/blogs/architecture/implement-monitoring-for-amazon-eks-with-managed-services/",
      "pubDate": "2025-07-18T15:47:13.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    },
    {
      "id": "aws-news-875544c87826",
      "title": "Preview Release of the AWS SDK Java 2.x HTTP Client built on Apache HttpClient 5.5.x",
      "description": "The AWS SDK for Java 2.x introduces the Apache 5 SDK HTTP client which is built on Apache HttpClient 5.5.x. This new SDK HTTP client is available alongside our existing SDK HTTP clients: Apache HttpClient 4.5.x, Netty, URL Connection, and AWS CRT HttpClient. To differentiate the use of Apache HttpClient 4.5.x and Apache HttpClient 5.5.x, […]",
      "link": "https://aws.amazon.com/blogs/developer/preview-release-of-theaws-sdk-java-2-x-http-client-built-on-apache-httpclient-5-5-x/",
      "pubDate": "2025-07-18T03:36:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-6606f79cd3d5",
      "title": "AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available",
      "description": "Today, we are excited to announce the general availability of the AWS .NET Distributed Cache Provider for Amazon DynamoDB. This is a seamless, serverless caching solution that enables .NET developers to efficiently manage their caching needs across distributed systems. Consistent caching is a difficult problem in distributed architectures, where maintaining data integrity and performance across […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-net-distributed-cache-provider-for-amazon-dynamodb-now-generally-available/",
      "pubDate": "2025-07-03T13:49:25.000Z",
      "source": "developersAndDevOps",
      "services": [
        "dynamodb"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "dynamodb",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-ae25b45e1a62",
      "title": "AWS Tools for PowerShell V5 now Generally Available",
      "description": "This blog was co-authored by Afroz Mohammed and Jonathan Nunn, Software Developers on the AWS PowerShell team. We’re excited to announce the general availability of the AWS Tools for PowerShell version 5, a major update that brings new features and improvements in security, along with a few breaking changes. New Features You can now cancel […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-tools-for-powershell-v5-now-generally-available/",
      "pubDate": "2025-06-23T22:59:33.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "new-feature",
        "update",
        "improvement"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-27b43a8f9a42",
      "title": "Deploy to ARM-Based Compute with AWS Deploy Tool for .NET",
      "description": "We’re excited to announce that the AWS Deploy Tool for .NET now supports deploying .NET applications to select ARM-based compute platforms on AWS! Whether you’re deploying from Visual Studio or using the .NET CLI, you can now target cost-effective ARM infrastructure like AWS Graviton with the same streamlined experience you’re used to. Why deploy to […]",
      "link": "https://aws.amazon.com/blogs/developer/deploy-to-arm-based-compute-with-aws-deploy-tool-for-net/",
      "pubDate": "2025-05-08T20:16:40.000Z",
      "source": "developersAndDevOps",
      "services": [
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "graviton",
        "support"
      ]
    },
    {
      "id": "aws-news-4d3126ea3a15",
      "title": "General Availability of AWS SDK for .NET V4.0",
      "description": "Version 4.0 of the AWS SDK for .NET has been released for general availability (GA). V4 has been in development for a little over a year in our SDK’s public GitHub repository with 13 previews being released. This new version contains performance improvements, consistency with other AWS SDKs, and bug and usability fixes that required […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-of-aws-sdk-for-net-v4-0/",
      "pubDate": "2025-04-28T20:05:16.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-49859f1bef68",
      "title": "Introducing the AWS IoT Device SDK for Swift (Developer Preview)",
      "description": "Today, AWS launches the developer preview of the AWS IoT Device SDK for Swift. The IoT Device SDK for Swift empowers Swift developers to create IoT applications for Linux and Apple macOS, iOS, and tvOS platforms using the MQTT 5 protocol. The SDK supports Swift 5.10+ and is designed to help developers easily integrate with […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-the-aws-iot-device-sdk-for-swift-developer-preview/",
      "pubDate": "2025-03-31T16:26:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-dd08a704e7e9",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 2)",
      "description": "In Part 1 of our blog posts for .NET Aspire and AWS Lambda, we showed you how .NET Aspire can be used for running and debugging .NET Lambda functions. In this part, Part 2, we’ll show you how to take advantage of the .NET Aspire programming model for best practices and for connecting dependent resources […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-2/",
      "pubDate": "2025-03-04T17:54:04.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-4185fb6b40aa",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 1)",
      "description": "In a recent post we gave some background on .NET Aspire and introduced our AWS integrations with .NET Aspire that integrate AWS into the .NET dev inner loop for building applications. The integrations included how to provision application resources with AWS CloudFormation or AWS Cloud Development Kit (AWS CDK) and using Amazon DynamoDB local for […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-1/",
      "pubDate": "2025-03-03T21:16:42.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda",
        "dynamodb",
        "cloudformation"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "dynamodb",
        "cloudformation",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-866c6557a5ec",
      "title": "Integrating AWS with .NET Aspire",
      "description": ".NET Aspire is a new way of building cloud-ready applications. In particular, it provides an orchestration for local environments in which to run, connect, and debug the components of distributed applications. Those components can be .NET projects, databases, containers, or executables. .NET Aspire is designed to have integrations with common components used in distributed applications. […]",
      "link": "https://aws.amazon.com/blogs/developer/integrating-aws-with-net-aspire/",
      "pubDate": "2025-02-11T20:39:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "integration"
      ]
    },
    {
      "id": "aws-news-9568575bd4f9",
      "title": "Updating AWS SDK defaults – AWS STS service endpoint and Retry Strategy",
      "description": "AWS announces important configuration updates coming July 31st, 2025, affecting AWS SDKs and CLIs default settings. Two key changes include switching the AWS Security Token Service (STS) endpoint to regional and updating the default retry strategy to standard. These updates aim to improve service availability and reliability by implementing regional endpoints to reduce cross-regional dependencies and introducing token-bucket throttling for standardized retry behavior. Organizations should test their applications before the release date and can opt-in early or temporarily opt-out of these changes. These updates align with AWS best practices for optimal service performance and security.",
      "link": "https://aws.amazon.com/blogs/developer/updating-aws-sdk-defaults-aws-sts-service-endpoint-and-retry-strategy/",
      "pubDate": "2025-02-11T05:37:32.000Z",
      "source": "developersAndDevOps",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga",
        "update"
      ]
    }
  ]
}