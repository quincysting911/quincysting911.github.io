{
  "lastUpdated": "2025-11-25T06:16:34.846Z",
  "totalItems": 200,
  "sources": {
    "whatsNew": 94,
    "mlBlog": 20,
    "newsBlog": 17,
    "bigDataBlog": 19,
    "architectureBlog": 16,
    "computeBlog": 18,
    "developersAndDevOps": 16
  },
  "items": [
    {
      "id": "aws-news-e5767083a6d4",
      "title": "Optimize unused capacity with Amazon EC2 interruptible capacity reservations",
      "description": "Organizations running critical workloads on Amazon Elastic Compute Cloud (Amazon EC2) reserve compute capacity using On-Demand Capacity Reservations (ODCR) to have availability when needed. However, reserved capacity can intermittently sit idle during off-peak periods, between deployments, or when workloads scale down. This unused capacity represents a missed opportunity for cost optimization and resource efficiency across the organization.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-unused-capacity-with-amazon-ec2-interruptible-capacity-reservations/",
      "pubDate": "2025-11-25T01:09:16.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-60262ac8a35f",
      "title": "Accelerate generative AI innovation in Canada with Amazon Bedrock cross-Region inference",
      "description": "We are excited to announce that customers in Canada can now access advanced foundation models including Anthropic's Claude Sonnet 4.5 and Claude Haiku 4.5 on Amazon Bedrock through cross-Region inference (CRIS). This post explores how Canadian organizations can use cross-Region inference profiles from the Canada (Central) Region to access the latest foundation models to accelerate AI initiatives. We will demonstrate how to get started with these new capabilities, provide guidance for migrating from older models, and share recommended practices for quota management.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-generative-ai-innovation-in-canada-with-amazon-bedrock-cross-region-inference/",
      "pubDate": "2025-11-24T23:56:58.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "nova",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-333d00155bd8",
      "title": "Power up your ML workflows with interactive IDEs on SageMaker HyperPod",
      "description": "Amazon SageMaker HyperPod clusters with Amazon Elastic Kubernetes Service (EKS) orchestration now support creating and managing interactive development environments such as JupyterLab and open source Visual Studio Code, streamlining the ML development lifecycle by providing managed environments for familiar tools to data scientists. This post shows how HyperPod administrators can configure Spaces for their clusters, and how data scientists can create and connect to these Spaces.",
      "link": "https://aws.amazon.com/blogs/machine-learning/power-up-your-ml-workflows-with-interactive-ides-on-sagemaker-hyperpod/",
      "pubDate": "2025-11-24T21:25:56.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-86ee5fc225bc",
      "title": "AWS Weekly Roundup: How to join AWS re:Invent 2025, plus Kiro GA, and lots of launches (Nov 24, 2025)",
      "description": "Next week, don’t miss AWS re:Invent, Dec. 1-5, 2025, for the latest AWS news, expert insights, and global cloud community connections! Our News Blog team is finalizing posts to introduce the most exciting launches from our service teams. If you’re joining us in person in Las Vegas, review the agenda, session catalog, and attendee guides […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-how-to-join-aws-reinvent-2025-plus-kiro-ga-and-lots-of-launches-nov-24-2025/",
      "pubDate": "2025-11-24T19:58:08.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": [
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-1fcfec9f0f23",
      "title": "Claude Opus 4.5 now in Amazon Bedrock",
      "description": "Anthropic's newest foundation model, Claude Opus 4.5, is now available in Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models from leading AI companies. In this post, I'll show you what makes this model different, walk through key business applications, and demonstrate how to use Opus 4.5's new tool use capabilities on Amazon Bedrock.",
      "link": "https://aws.amazon.com/blogs/machine-learning/claude-opus-4-5-now-in-amazon-bedrock/",
      "pubDate": "2025-11-24T19:22:59.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "now-available"
      ]
    },
    {
      "id": "aws-news-5403d33b1bbc",
      "title": "How potential performance upside with AWS Graviton helps reduce your costs further",
      "description": "Amazon Web Services (AWS) provides many mechanisms to optimize the price performance of workloads running on Amazon Elastic Compute Cloud (Amazon EC2), and the selection of the optimal infrastructure to run on can be one of the most impactful levers. When we started building the AWS Graviton processor, our goal was to optimize AWS Graviton […]",
      "link": "https://aws.amazon.com/blogs/compute/how-potential-performance-upside-with-aws-graviton-helps-reduce-your-costs-further/",
      "pubDate": "2025-11-24T19:11:55.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "graviton"
      ]
    },
    {
      "id": "aws-news-4f096af20c37",
      "title": "OpenSearch Service Enhances Log Analytics with New PPL Experience",
      "description": "Today, AWS announces enhanced log analytics capabilities in Amazon OpenSearch Service, making Piped Processing Language (PPL) and natural language the default experience in OpenSearch UI's Observability workspace. This update combines proven pipeline syntax with simplified workflows to deliver an intuitive observability experience, helping customers analyze growing data volumes while controlling costs. The new experience includes 35+ new commands for deep analysis, faceted exploration, and natural language querying to help customers gain deeper insights across infrastructure, security, and business metrics.\n  With this enhancement, customers can streamline their log analytics workflows using familiar pipeline syntax while leveraging advanced analytics capabilities. The solution includes enterprise-grade query capabilities, supporting advanced event correlation using natural language that help teams uncover meaningful patterns faster. Users can seamlessly move from query to visualization within a single interface, reducing mean time to detect and resolve issues. Admins can quickly stand up an end-to-end OpenTelemetry solution using OpenSearch's Get Started workflow in the AWS console. The unified workflow includes out-of-the-box OpenSearch Ingestion pipelines for OpenTelemetry data, making it easier for teams to get started quickly.\n  Amazon OpenSearch UI is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Osaka), Asia Pacific (Hong Kong), Asia Pacific (Hyderabad), Europe (Ireland), Europe (London), Europe (Frankfurt), Europe (Paris), Europe (Stockholm), Europe (Milan), Europe (Spain), Europe (Zurich), South America (São Paulo), and Canada (Central).\n  To learn more about the new OpenSearch log analytics experience, visit the OpenSearch Service observability documentation and start using these enhanced capabilities today in OpenSearch UI.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/opensearch-service-log-analytics-ppl/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch",
        "opensearch service",
        "opensearch ingestion"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "opensearch ingestion",
        "ga",
        "update",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-250fe2a963fb",
      "title": "Amazon CloudFront announces support for mutual TLS authentication",
      "description": "Amazon CloudFront announces support for mutual TLS Authentication (mTLS), a security protocol that requires both the server and client to authenticate each other using X.509 certificates, enabling customers to validate client identities at CloudFront's edge locations. Customers can now ensure only clients presenting trusted certificates can access their distributions, helping protect against unauthorized access and security threats.\n  Previously, customers had to spend ongoing effort implementing and maintaining their own client access management solutions, leading to undifferentiated heavy lifting. Now with the support for mutual TLS, customers can easily validate client identities at the AWS edge before connections are established with their application servers or APIs. Example use cases include B2B secure API integrations for enterprises and client authentication for IoT. For B2B API security, enterprises can authenticate API requests from trusted third parties and partners using mutual TLS. For IoT use cases, enterprises can validate that devices are authorized to receive proprietary content such as firmware updates. Customers can leverage their existing third-party Certificate Authorities or AWS Private Certificate Authority to sign the X.509 certificates. With Mutual TLS, customers get the performance and scale benefits of CloudFront for workloads that require client authentication.\n  Mutual TLS authentication is available to all CloudFront customers at no additional cost. Customers can configure mutual TLS with CloudFront using the AWS Management Console, CLI, SDK, CDK, and CloudFormation. For detailed implementation guidance and best practices, visit CloudFront Mutual TLS (viewer) documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudfront-mutual-tls-authentication/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "cloudfront"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudformation",
        "cloudfront",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-492795cde0aa",
      "title": "Amazon EC2 announces interruptible Capacity Reservations",
      "description": "Today, Amazon EC2 announces interruptible Capacity Reservations to help you better utilize your reserved capacity and save costs. On-Demand Capacity Reservations (ODCRs) help you reserve compute capacity in a specific Availability Zone for any duration. When ODCRs are not in use, you can now make them temporarily available as interruptible ODCRs, enabling other workloads within your organization to utilize them while preserving your ability to reclaim the capacity for critical operations.\n  By repurposing unused capacity as interruptible ODCRs, workloads suitable for flexible, fault-tolerant operations—such as batch processing, data analysis, and machine learning training can benefit from temporarily available capacity. Reservation owners can reclaim their capacity at any time, while consumers of interruptible ODCRs will receive an interruption notice before termination to allow for graceful shutdown or checkpointing before.\n  Interruptible ODCRs are now available at no additional cost to all Capacity Reservations customers. Refer to the AWS Capabilities by Region website for the feature's regional availability. CloudFormation support will be coming soon. For more details, please refer to the Capacity Reservations user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-interruptible-capacity-reservations",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "cloudformation"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "cloudformation",
        "ga",
        "now-available",
        "support",
        "coming-soon"
      ]
    },
    {
      "id": "aws-news-8b58ac2defe5",
      "title": "AWS IoT Core now supports IoT thing registry data retrieval from IoT rules",
      "description": "AWS IoT Core announces a new capability to dynamically retrieve IoT thing registry data using an IoT rule, enhancing your ability to filter, enrich, and route IoT messages. Using the new get_registry_data() inline rule function, you can access IoT thing registry data, such as device attributes, device type, and group membership and leverage this information directly in IoT rules.\n  For example, your rule can filter AWS IoT Core connectivity lifecycle events and then retrieve thing attributes (such as \"test\" or \"production\" device) to inform routing of lifecycle events to different endpoints for downstream processing. You can also use this feature to enrich or route IoT messages with registry data from other devices. For instance, you can add a sensor’s threshold temperature from IoT thing registry to the messages relayed by its gateway.\n  To get started, connect your devices to AWS IoT Core and store your IoT device data in IoT thing registry. You can then use IoT rules to retrieve your registry data. This capability is available in all AWS regions where AWS IoT Core is present. For more information refer to the developer guide and API documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-core-thing-registry-data-retrieval/",
      "pubDate": "2025-11-24T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-81729f0063bd",
      "title": "Deploy GPT-OSS models with Amazon Bedrock Custom Model Import",
      "description": "In this post, we show how to deploy the GPT-OSS-20B model on Amazon Bedrock using Custom Model Import while maintaining complete API compatibility with your current applications.",
      "link": "https://aws.amazon.com/blogs/machine-learning/deploy-gpt-oss-models-with-amazon-bedrock-custom-model-import/",
      "pubDate": "2025-11-24T17:49:05.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-0dc775a80f99",
      "title": "AWS Elemental MediaTailor now supports HLS Interstitials for live streams",
      "description": "AWS Elemental MediaTailor now supports HTTP Live Streaming (HLS) Interstitials for live streams, enabling broadcasters and streaming service providers to deliver seamless, personalized ad experiences across a wide range of modern video players. This capability allows customers to insert interstitial advertisements and promotions directly into live streams using the HLS Interstitials specification (RFC 8216), which is natively supported by popular players including HLS.js, Shaka Player, Bitmovin Player, and Apple devices running iOS 16.4, iPadOS 16.4, tvOS 16.4, and later.\n  With HLS Interstitials, MediaTailor automatically generates the necessary metadata tags (Interstitial class EXT-X-DATERANGE with X-ASSET-LIST attributes) that signal to client players when and how to play interstitial content. This approach eliminates the need for custom player-side stitching logic, reducing development complexity and ensuring consistent playback behavior. The feature integrates with MediaTailor's existing server-side ad insertion (SSAI) capabilities, delivering frame-accurate transitions with no buffering between content and interstitials. Server-side beaconing continues to work with HLS Interstitials, ensuring ad tracking and measurement workflows remain intact.\n  HLS Interstitials for live streams is particularly valuable for sports broadcasts, live news, and event streaming where precise ad timing and minimal latency are critical. The feature supports pre-roll and mid-roll insertion, giving customers flexibility in how they monetize their live content. This launch complements MediaTailor's existing HLS Interstitials support for VOD, rounding out support across Linear, Live, FAST, and VOD workflows. MediaTailor makes it easy to test and deploy—customers can rapidly enable or disable HLS Interstitials with a simple query parameter on the multi-variant manifest request, providing per playback session control without changing the underlying MediaTailor configuration.\n  AWS Elemental MediaTailor HLS Interstitials for live streams is available today in all AWS Regions where MediaTailor operates. You pay only for the features you use, with no upfront commitments. To learn more and get started, visit the AWS Elemental MediaTailor documentation and the HLS Interstitials implementation guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-elemental-mediatailor-hls-interstitials-live-streams",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "personalize"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lex",
        "personalize",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-2c3433f02c16",
      "title": "Amazon Redshift now supports federated permissions across multi-warehouse architectures",
      "description": "Amazon Redshift now supports federated permissions across multi-warehouse architectures\n  Amazon Redshift now supports federated permissions, which simplify permissions management across multiple Redshift data warehouses. Customers are adopting multi-warehouse architectures to scale and isolate workloads and are looking for simplified, consistent permissions management across warehouses. With Redshift federated permissions, you define data permissions once from any Redshift warehouse and automatically enforce them across all warehouses in the account.\n  Amazon Redshift warehouses with federated permissions are auto-mounted in every Redshift warehouse, and you can use existing workforce identities with AWS IAM Identity Center or use existing IAM roles to query data across warehouses. Regardless of which warehouse is used for querying, row-level, column-level, and masking controls always apply automatically, delivering fine-grained access compliance. You can get started by registering a Redshift Serverless namespace or Redshift provisioned cluster with AWS Glue Data Catalog and start querying across warehouses using Redshift Query Editor V2, or any supported SQL client. You get horizontal scalability with multiple warehouses by allowing you to add new warehouses without increasing governance complexity, as new warehouses automatically enforce permission policies and analysts immediately see all databases from registered warehouses.\n  Amazon Redshift federated permissions is available at no additional cost in supported AWS regions. To learn more, visit the Amazon Redshift documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-redshift-federated-permissions-multi-warehouse-architectures",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "redshift",
        "iam",
        "iam identity center",
        "glue"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "redshift",
        "iam",
        "iam identity center",
        "glue",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-b70cf6c5ae33",
      "title": "Amazon U7i instances now available in Asia Pacific (Jakarta) Region",
      "description": "Starting today, Amazon EC2 High Memory U7i instances with 6TB of memory (u7i-6tb.112xlarge) are now available in the Asia Pacific (Jakarta) region. U7i-6tb instances are part of AWS 7th generation and are powered by custom fourth generation Intel Xeon Scalable Processors (Sapphire Rapids). U7i-6tb instances offer 6TB of DDR5 memory, enabling customers to scale transaction processing throughput in a fast-growing data environment.\n  U7i-6tb instances offer 448 vCPUs, support up to 100Gbps Elastic Block Storage (EBS) for faster data loading and backups, deliver up to 100Gbps of network bandwidth, and support ENA Express. U7i instances are ideal for customers using mission-critical in-memory databases like SAP HANA, Oracle, and SQL Server.\n  To learn more about U7i instances, visit the High Memory instances page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-u7i-instances-asia-pacific-jakarta-region",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-f4fc0337cbad",
      "title": "Amazon Connect flow modules now support custom inputs, outputs, and version management",
      "description": "Amazon Connect flow modules now support custom inputs, outputs, and branches, along with version and alias management. With this launch, you can now define flexible parameters for your reusable flow modules to math your specific business logic. For example, you can create an authentication module that accepts a phone number and PIN as inputs, then returns the customer name and authentication status as outputs with branches such as \"authenticated\" or \"not authenticated\". All parameters are customizable to meet your specific needs.\n  Additionally, advanced versioning and aliasing capabilities allow you to manage module updates more seamlessly. You can create immutable version snapshots and map aliases to specific versions. When you update an alias to point to a new version, all flows using that module automatically reference the updated version. These new features make flow modules more powerful and reusable, allowing you to build and maintain flows more efficiently.\n  To learn more about these feature, see the Amazon Connect Administrator Guide. This feature is available in all AWS regions that offers Amazon Connect. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-flow-modules-custom-inputs-outputs-version-management",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "launch",
        "new-feature",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-fd016fec1803",
      "title": "AWS Glue announces catalog federation for remote Apache Iceberg catalogs",
      "description": "AWS Glue announces the general availability of catalog federation for remote Iceberg catalogs. This capability provides direct and secure access to Iceberg tables stored in Amazon S3 and cataloged in remote catalogs using AWS analytics engines.\n  With catalog federation, you can federate to remote Iceberg catalogs and query remote Iceberg tables using your preferred AWS analytics engines, without moving or copying tables. It synchronizes metadata real-time across AWS Glue Data Catalog and remote catalogs when data teams query remote tables, which means that query results are always completely up-to-date. You can now choose the best price-performance for your workloads when analyzing remote Iceberg tables using your preferred AWS analytics engines, while maintaining consistent security controls when discovering or querying data. Catalog federation is supported by a wide variety of analytics engines, including Amazon Redshift, Amazon EMR, Amazon Athena, AWS Glue, third-party engines like Apache Spark, and Amazon SageMaker with the serverless notebooks.\n  Catalog federation uses AWS Lake Formation for access controls, allowing you to use fine-grained access controls, cross-account sharing, and trusted identity propagation when sharing remote catalog tables with other data consumers. Catalog federation integrates with catalog implementations that support the Iceberg REST specifications.\n  Catalog federation is available in Lake Formation console and using AWS Glue and Lake Formation SDKs and APIs. This feature is generally available in all AWS commercial regions where AWS Glue and Lake Formation are available. With just a few clicks in the console, you can federate to remote catalogs, discover its databases and tables, grant permissions to access table data, and query remote Iceberg tables using AWS analytics engines. To learn more, visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-catalog-federation-remote-apache-iceberg-catalogs",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena",
        "generally-available",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5d462e79f71b",
      "title": "Claude Opus 4.5 now available in Amazon Bedrock",
      "description": "Customers can now use Claude Opus 4.5 in Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models from leading AI companies. Opus 4.5 is Anthropic's newest model, setting new standards across coding, agentic workflows, computer use, and office tasks while making Opus-level intelligence accessible at one-third the cost.\n  Opus 4.5 excels at professional software engineering tasks, achieving state-of-the-art performance on SWE-bench. The model handles ambiguity, reasons about tradeoffs and can figure out fixes for bugs that require reasoning across multiple systems. It can help transform multi-day team development projects into hours-long tasks with improved multilingual coding capabilities. This generation of Claude spans the full development lifecycle: Opus 4.5 for production code and lead agents, Sonnet 4.5 for rapid iteration and scaled user experiences, Haiku 4.5 for sub-agents and free-tier products.\n  Beyond coding, the model powers agents that produce documents, spreadsheets, and presentations with consistency, professional polish, and domain awareness, making it ideal for finance and other precision-critical verticals. As Anthropic's best vision model yet, it unlocks workflows that depend on complex visual interpretation and multi-step navigation. Through the Amazon Bedrock API, Opus 4.5 introduces two new capabilities: tool search and tool use examples. Together, these updates enable Claude to navigate large tool libraries and accurately execute complex tasks. A new effort parameter, available in beta, lets you control how much effort Claude allocates across thinking, tool calls, and responses to balance performance with latency, and cost.\n  Claude Opus 4.5 is now available in Amazon Bedrock via global cross region inference in multiple locations. For the full list of available regions, refer to the documentation. To get started with the model in Amazon Bedrock, read the launch blog or visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/claude-opus-4-5-amazon-bedrock",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex",
        "rds"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "bedrock",
        "lex",
        "rds",
        "launch",
        "beta",
        "ga",
        "now-available",
        "update"
      ]
    },
    {
      "id": "aws-news-6f01ea89f53c",
      "title": "AWS Lambda announces enhanced error handling capabilities for Kafka event processing",
      "description": "AWS Lambda launches enhanced error handling capabilities for Amazon Managed Streaming for Apache Kafka (MSK) and self-managed Apache Kafka (SMK) event sources. These capabilities allow customers to build custom retry configurations, optimize retries of failed messages, and send failed events to a Kafka topic as an on-failure destination, enabling customers to build resilient Kafka workloads with robust error handling strategies.\n  Customers use Kafka event source mappings (ESM) with their Lambda functions to build their mission-critical Kafka applications. Kafka ESM offers robust error handling of failed events by retrying events with exponential backoff, and retaining failed events in on-failure destinations like Amazon SQS, Amazon S3, Amazon SNS. However, customers need customized error handling to meet stringent business and performance requirements. With this launch, developers can now exercise precise control over failed event processing and leverage Kafka topics as an additional on-failure destination when using Provisioned mode for Kafka ESM. Customers can now define specific retry limits and time boundaries for retry, automatically discarding failed records beyond these limits to customer-specified destination. They can now also set automatic retries of failed records in the batch and enhance their function code to report individual failed messages, optimizing the retry process.\n  This feature is available in all AWS Commercial Regions where AWS Lambda’s Provisioned mode for Kafka ESM is available.\n  To enable these capabilities, provide configuration parameters for your Kafka ESM in the ESM API, AWS Console, and AWS CLI. To learn more, read the Lambda ESM documentation and AWS Lambda pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-lambda-enhanced-error-handling-capabilities-kafka-event-processing",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "s3",
        "rds",
        "kafka",
        "msk",
        "sns",
        "sqs"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "s3",
        "rds",
        "kafka",
        "msk",
        "sns",
        "sqs",
        "launch"
      ]
    },
    {
      "id": "aws-news-ef2f09b21b66",
      "title": "Amazon MSK Replicator is now available in five additional AWS Regions",
      "description": "You can now use Amazon MSK Replicator to replicate streaming data across Amazon Managed Streaming for Apache Kafka (Amazon MSK) clusters in five additional AWS Regions: Asia Pacific (Thailand), Mexico (Central), Asia Pacific (Taipei), Canada West (Calgary), Europe (Spain).\n  MSK Replicator is a feature of Amazon MSK that enables you to reliably replicate data across Amazon MSK clusters in different or the same AWS Region(s) in a few clicks. With MSK Replicator, you can easily build regionally resilient streaming applications for increased availability and business continuity. MSK Replicator provides automatic asynchronous replication across MSK clusters, eliminating the need to write custom code, manage infrastructure, or setup cross-region networking. MSK Replicator automatically scales the underlying resources so that you can replicate data on-demand without having to monitor or scale capacity. MSK Replicator also replicates the necessary Kafka metadata including topic configurations, Access Control Lists (ACLs), and consumer group offsets. If an unexpected event occurs in a region, you can failover to the other AWS Region and seamlessly resume processing.\n  You can get started with MSK Replicator from the Amazon MSK console or the Amazon CLI. To learn more, visit the MSK Replicator product page, pricing page, and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-msk-replicator-additional-aws-regions",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "kafka",
        "msk",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-5caa4bd88af7",
      "title": "Amazon Quick Suite Embedded Chat is now available",
      "description": "Today, AWS announces the general availability of Amazon Quick Suite Embedded Chat, enabling you to embed Quick Suite's conversational AI, which combines structured data and unstructured knowledge in a single conversation - directly into your applications, eliminating the need to build conversational interfaces, orchestration logic, or data access layers from scratch.\n \nQuick Suite Embedded Chat solves a fundamental problem: users want answers where they work, not in another tool. Whether in a CRM, support console, or analytics portal, they need instant, contextual responses. Most conversational tools excel at either structured data or documents, analytics or knowledge bases, answering questions or performing actions—rarely all of the above. Quick Suite closes this gap. Now, users can reference a KPI, pull details from a file, check customer feedback, and trigger actions in one continuous conversation without leaving the embedded chat.\n  Embedded Chat brings this unified experience into your applications with simple integration, either through 1-click embedding or through API-based iframes for registered users with your existing authentication. You can connect your Agentic Chat to your data through connectors to search SharePoint, websites, send Slack messages, or create Jira tasks and customize the Agent with your brand colors, communication style, and personalized greetings. Security always stays under your control as you choose what the agent accesses and explicitly scope all actions.\n  Quick Suite Embedded Chat is available the following AWS Regions: US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Ireland), and we'll expand availability to additional AWS Regions over the coming months. There is no additional cost for Quick Suite Embedded Chat. Existing Quick Suite pricing is available here.\n  To learn more, see Embedding Amazon Quick Suite launch blog. To get started with Amazon Quick Suite, visit the Amazon Quick Suite product page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-suite-embedded-chat",
      "pubDate": "2025-11-24T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "launch",
        "ga",
        "now-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-2a82d6f564ba",
      "title": "Amazon OpenSearch Service now supports OpenSearch version 3.3",
      "description": "You can now run OpenSearch version 3.3 in Amazon OpenSearch Service. OpenSearch 3.3 introduces several improvements in areas like search performance, observability and new functionality to make agentic AI integrations simpler and more powerful.\n \nThis launch includes several improvements in vector search capabilities. First, with agentic search, you can now achieve precise search results using natural language inputs without the need to construct complex domain-specific language (DSL) queries. Second, batch processing for semantic highlighter improves performance by reducing overhead latency and improving GPU utilization. Finally, enhancements to Neural Search plugin make semantic search more efficient and provide optimization options for your specific data, performance, and relevance needs.\n \nThis launch also introduces support for Apache Calcite as default query engine for PPL that delivers optimization capabilities, improvements to query processing efficiency, and an extensive library of new PPL commands and functions. Additionally, this launch includes enhancements to the approximation framework that improve the responsiveness of paginated search results, real-time dashboards, and applications requiring deep pagination through large time-series or numeric datasets. Finally, workload management plugin now allows you to group search traffic and isolate network resources. This prevents specific requests from overusing network resources and offers tenant-level isolation.\n \nFor information on upgrading to OpenSearch 3.3, please see the documentation. OpenSearch 3.3 is now available in all AWS Regions where Amazon OpenSearch Service is available.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-opensearch-service-opensearch-version-3-3/",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "opensearch",
        "opensearch service",
        "rds",
        "launch",
        "now-available",
        "improvement",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-b33c849d838a",
      "title": "Amazon Aurora PostgreSQL introduces dynamic data masking",
      "description": "Amazon Aurora PostgreSQL-Compatible Edition now supports dynamic data masking through the new pg_columnmask extension, allowing you to simplify the protection of sensitive data in your database. pg_columnmask extends Aurora's security capabilities by enabling column-level protection that complements PostgreSQL's native row-level security and column level grants. Using pg_columnmask, you can control access to sensitive data through SQL-based masking policies and define how data appears to users at query time based on their roles, helping you comply with data privacy regulations like GDPR, HIPAA, and PCI DSS.\n \nWith pg_columnmask, you can create flexible masking policies using built-in or user-defined functions. You can completely hide information, replace partial values with wildcards, or define custom masking approaches. Further, you can apply multiple masking policies to a single column and control their precedence using weights. pg_columnmask helps protect data in complex queries with WHERE, JOIN, ORDER BY, or GROUP BY clauses. Data is masked at the database level during query processing, leaving stored data unmodified.\n \npg_columnmask is available for Aurora PostgreSQL version 16.10 and higher, and 17.6 and higher in all AWS Regions where Aurora PostgreSQL is available. To learn more, review our blog post and visit technical documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-aurora-postgresql-dynamic-data-masking",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-97ea49be4b86",
      "title": "Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) for generative AI tasks",
      "description": "Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) technology, enabling administrators to partition a single GPU into multiple isolated GPUs. This capability allows administrators to maximize resource utilization by running diverse, small generative AI (GenAI) tasks simultaneously on GPU partitions while maintaining performance and task isolation.\n  Administrators can choose either the easy-to-use configuration setup on the SageMaker HyperPod console or a custom setup approach to enable fine-grained, hardware-isolated resources for specific task requirements that don't require full GPU capacity. They can also allocate compute quota to ensure fair and efficient distribution of GPU partitions across teams. With real-time performance metrics and resource utilization monitoring dashboard across GPU partitions, administrators gain visibility to optimize resource allocation. Data scientists can now accelerate time-to-market by scheduling lightweight inference tasks and running interactive notebooks in parallel on GPU partitions, eliminating wait times for full GPU availability.\n  This capability is currently available for Amazon SageMaker HyperPod clusters using the EKS orchestrator across the following AWS Regions: US West (Oregon), US East (N.Virginia), US East (Ohio), US West (N. California), Canada (Central), South America (Sao Paulo), Europe (Stockholm), Europe (Spain), Europe (Ireland), Europe (Frankfurt), Europe (London), Asia Pacific (Mumbai), Asia Pacific (Jakarta), Asia Pacific (Melbourne), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Seoul), Asia Pacific (Singapore).\n  To learn more, visit SageMaker HyperPod webpage, and SageMaker HyperPod documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-hyperpod-nvidia-multi-instance-gpu/",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-dcf28b462b4d",
      "title": "Amazon SageMaker HyperPod now supports Spot Instances",
      "description": "Amazon SageMaker HyperPod now supports Spot Instances, enabling customers to reduce GPU compute costs by up to 90% compared to on-demand instances on HyperPod . As AI workloads scale, optimizing infrastructure costs becomes increasingly critical. SageMaker HyperPod's Spot integration addresses this by allowing customers to automatically leverage spare EC2 capacity at significant discounts, while providing the managed AI experience customers enjoy on HyperPod. \n \nWith Spot Instances, organizations can run fault-tolerant workloads cost-effectively at scale. You can combine Spot with on-demand instances to balance cost optimization with guaranteed availability. The feature is available on HyperPod EKS clusters and integrates with Karpenter for intelligent auto-scaling, automatically discovering available Spot capacity and handling instance interruptions.\n \nYou can enable Spot Instances when creating instance groups through the CreateCluster API or AWS Console. The feature supports all instance types available on HyperPod, including CPUs and GPUs. Capacity availability depends on supply from EC2 and varies by region and instance type. Spot instance support is available in all regions where SageMaker HyperPod is currently available. To learn more, please refer to the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-hyperpod-spot-instances",
      "pubDate": "2025-11-24T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "ec2",
        "eks",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "ec2",
        "eks",
        "organizations",
        "ga",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-2d34b7fdfada",
      "title": "New one-click onboarding and notebooks with a built-in AI agent in Amazon SageMaker Unified Studio",
      "description": "Amazon SageMaker Unified Studio introduces new one-click onboarding experiences and serverless notebooks with a built-in AI agent without any manual set up or provisioning of your domain or compute resources. You can launch SageMaker Unified Studio directly from Amazon SageMaker, Amazon Athena, Amazon Redshift, and Amazon S3 Tables console pages, giving a fast path to analytics and AI workloads.",
      "link": "https://aws.amazon.com/blogs/aws/new-one-click-onboarding-and-notebooks-with-ai-agent-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-22T01:23:12.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "athena"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "athena",
        "launch"
      ]
    },
    {
      "id": "aws-news-d018583f9212",
      "title": "Amazon EMR Serverless now supports Apache Spark 4.0.1 (preview)",
      "description": "Amazon EMR Serverless now supports Apache Spark 4.0.1 (preview). With Spark 4.0.1, you can build and maintain data pipelines more easily with ANSI SQL and VARIANT data types, strengthen compliance and governance frameworks with Apache Iceberg v3 table format, and deploy new real-time applications faster with enhanced streaming capabilities. This enables your teams to reduce technical debt and iterate more quickly, while ensuring data accuracy and consistency.\n  With Spark 4.0.1, you can build data pipelines with standard ANSI SQL, making it accessible to a larger set of users who don't know programming languages like Python or Scala. Spark 4.0.1 natively supports JSON and semi-structured data through VARIANT data types, providing flexibility for handling diverse data formats. You can strengthen compliance and governance through Apache Iceberg v3 table format, which provides transaction guarantees and tracks how your data changes over time, creating the audit trails you need for regulatory requirements. You can deploy real-time applications faster with improved streaming controls that let you manage complex stateful operations and monitor streaming jobs more easily. With this capability, you can support use cases like fraud detection and real-time personalization.\n  Apache Spark 4.0.1 is available in preview in all regions where EMR Serverless is available, excluding China and AWS GovCloud (US) regions. To learn more about Apache Spark 4.0.1 on Amazon EMR, visit the Amazon EMR Serverless release notes, or get started by creating an EMR application with Spark 4.0.1 from the AWS Management Console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-emr-serverless-apache-spark/",
      "pubDate": "2025-11-21T22:50:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "emr"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "emr",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-76b0805f840d",
      "title": "Amazon Athena for Apache Spark is now available in Amazon SageMaker notebooks",
      "description": "Amazon SageMaker now supports Amazon Athena for Apache Spark, bringing a new notebook experience and fast serverless Spark experience together within a unified workspace. Now, data engineers, analysts, and data scientists can easily query data, run Python code, develop jobs, train models, visualize data, and work with AI from one place, with no infrastructure to manage and second-level billing.\n  Athena for Apache Spark scales in seconds to support any workload, from interactive queries to petabyte-scale jobs. Athena for Apache Spark now runs on Spark 3.5.6, the same high-performance Spark engine available across AWS, optimized for open table formats including Apache Iceberg and Delta Lake. It brings you new debugging features, real-time monitoring in the Spark UI, and secure interactive cluster communication through Spark Connect. As you use these capabilities to work with your data, Athena for Spark now enforces table-level access controls defined in AWS Lake Formation.\n \nAthena for Apache Spark is now available with Amazon SageMaker notebooks in US East (Ohio), US East (N. Virginia), US West (Oregon), Europe (Ireland), Europe (Frankfurt), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Singapore), and Asia Pacific (Sydney). To learn more, visit Apache Spark engine version 3.5, read the AWS News Blog or visit Amazon SageMaker documentation. Visit the Getting Started guide to try it from Amazon SageMaker notebooks.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-athena-apache-spark-sagemaker-notebooks/",
      "pubDate": "2025-11-21T21:40:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "athena"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "athena",
        "ga",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-53da4fc00af6",
      "title": "Build production-ready applications without infrastructure complexity using Amazon ECS Express Mode",
      "description": "Amazon ECS Express Mode simplifies containerized application deployment by automating infrastructure setup through a single command, allowing developers to focus on building applications while following AWS best practices.",
      "link": "https://aws.amazon.com/blogs/aws/build-production-ready-applications-without-infrastructure-complexity-using-amazon-ecs-express-mode/",
      "pubDate": "2025-11-21T21:34:45.000Z",
      "source": "newsBlog",
      "services": [
        "lex",
        "ecs"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lex",
        "ecs"
      ]
    },
    {
      "id": "aws-news-fd8d075255ea",
      "title": "AWS Payments Cryptography announces support for post-quantum cryptography to secure data in transit",
      "description": "Today, AWS Payments Cryptography announces support for hybrid post-quantum (PQ) TLS to secure API calls. With this launch, customers can future-proof transmissions of sensitive data and commands using ML-KEM post-quantum cryptography.\n  Enterprises operating highly regulated workloads wish to reduce post-quantum risks from “harvest now, decrypt later”. Long-lived data-in-transit can be recorded today, then decrypted in the future when a sufficiently capable quantum computer becomes available. With today’s launch, AWS Payment Cryptography joins data protection services such as AWS Key Management Service (KMS) in addressing this concern by supporting PQ-TLS.\n  To get started, simply ensure that your application depends on a version of AWS SDK or browser that supports PQ-TLS. For detailed guidance by language and platform, visit the PQ-TLS enablement documentation. Customers can also validate that ML-KEM was used to secure the TLS session for an API call by reviewing tlsDetails for the corresponding CloudTrail event in the console or a configured CloudTrail trail.\n  These capabilities are generally available in all AWS Regions at no added cost. To get started with PQ-TLS and Payment Cyptography, see our post-quantum TLS guide. For more information about PQC at AWS, please see PQC shared responsibility.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-payments-cryptography-post-quantum-data-transit",
      "pubDate": "2025-11-21T21:28:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "launch",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-7d35cf5f9ae9",
      "title": "Enhancing API security with Amazon API Gateway TLS security policies",
      "description": "In this post, you will learn how the new Amazon API Gateway’s enhanced TLS security policies help you meet standards such as PCI DSS, Open Banking, and FIPS, while strengthening how your APIs handle TLS negotiation. This new capability increases your security posture without adding operational complexity, and provides you with a single, consistent way to standardize TLS configuration across your API Gateway infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/enhancing-api-security-with-amazon-api-gateway-tls-security-policies/",
      "pubDate": "2025-11-21T21:17:52.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "rds",
        "api gateway"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "rds",
        "api gateway",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-7fec93fc1708",
      "title": "AWS Device Farm supports Managed Appium Endpoint and Environment Features",
      "description": "AWS Device Farm enables web and mobile developers to test their applications using real mobile devices and desktop browsers. Today, we are announcing three new capabilities that make it easier to build better web and mobile experiences: a fully-managed Appium endpoint, support for environment variables, and IAM role integration.\n \nWith the new Appium endpoint, you can connect using just a few lines of code and run interactive tests on multiple physical devices directly from your IDE or local host. This feature works seamlessly with Appium Inspector —both hosted and local versions—for all actions, including element inspection. Support for live video and log streaming enables faster feedback within your local workflow.\n  Environment variables enable test filtering, test sharding, dynamic software version selection, and granular configuration of your test environment. You can pass simple key-value pairs to our test scheduling APIs, which are then configured as environment variables on the test host during runtime. This eliminates the need to maintain multiple test specification yaml files for different test scenarios and simplifies CI/CD pipelines by enabling dynamic test environment configuration.\n  Additionally, Device Farm test hosts can now assume IAM roles to connect with other AWS services, enabling workflows such as uploading artifacts to Amazon S3 and logging test output to Amazon CloudWatch. Both environment variables and IAM roles can be persisted at the project level, reducing the maintenance overhead of passing them to each run.\n  These features complement our existing server-side execution capabilities, giving you the scale, customizability and controls needed to run secure enterprise-grade workloads. Together, they help you author, debug, and test your mobile apps faster, whether working from your IDE, AWS Console, or other environments.\n \nTo learn more, see Appium Testing, Accessing other AWS resources, and Environment variables in the AWS Device Farm Developer Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-device-farm-managed-appium-endpoint/",
      "pubDate": "2025-11-21T21:08:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "iam",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "iam",
        "cloudwatch",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-2e1c3c046458",
      "title": "Introducing Amazon S3 Transfer Manager for Swift (Developer Preview)",
      "description": "e are pleased to announce the Developer Preview release of the Amazon S3 Transfer Manager for Swift —a high-level file and directory transfer utility for \nAmazon Simple Storage Service (Amazon S3) built with the \nAWS SDK for Swift.",
      "link": "https://aws.amazon.com/blogs/developer/introducing-amazon-s3-transfer-manager-for-swift-developer-preview/",
      "pubDate": "2025-11-21T21:02:48.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-e7772104dcc0",
      "title": "Streamline AI operations with the Multi-Provider Generative AI Gateway reference architecture",
      "description": "In this post, we introduce the Multi-Provider Generative AI Gateway reference architecture, which provides guidance for deploying LiteLLM into an AWS environment to streamline the management and governance of production generative AI workloads across multiple model providers. This centralized gateway solution addresses common enterprise challenges including provider fragmentation, decentralized governance, operational complexity, and cost management by offering a unified interface that supports Amazon Bedrock, Amazon SageMaker AI, and external providers while maintaining comprehensive security, monitoring, and control capabilities.",
      "link": "https://aws.amazon.com/blogs/machine-learning/streamline-ai-operations-with-the-multi-provider-generative-ai-gateway-reference-architecture/",
      "pubDate": "2025-11-21T20:34:56.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "sagemaker",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "sagemaker",
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-9d3d32287870",
      "title": "Improving throughput of serverless streaming workloads for Kafka",
      "description": "Event-driven applications often need to process data in real-time. When you use AWS Lambda to process records from Apache Kafka topics, you frequently encounter two typical requirements: you need to process very high volumes of records in close to real-time, and you want your consumers to have the ability to scale rapidly to handle traffic spikes. Achieving both necessitates understanding how Lambda consumes Kafka streams, where the potential bottlenecks are, and how to optimize configurations for high throughput and best performance.",
      "link": "https://aws.amazon.com/blogs/compute/improving-throughput-of-serverless-streaming-workloads-for-kafka/",
      "pubDate": "2025-11-21T20:02:57.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "rds",
        "kafka"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "rds",
        "kafka"
      ]
    },
    {
      "id": "aws-news-3df36e265ef4",
      "title": "EC2 Image Builder now supports auto-versioning and enhances Infrastructure as Code experience",
      "description": "Amazon EC2 Image Builder now supports automatic versioning for recipes and automatic build version incrementing for components, reducing the overhead of managing versions manually. This enables you to increment versions automatically and dynamically reference the latest compatible versions in your pipelines without manual updates.\n  With automatic versioning, you no longer need to manually track and increment version numbers when creating new versions of your recipes. You can simply place a single 'x' placeholder in any position of the version number, and Image Builder detects the latest existing version and automatically increments that position. For components, Image Builder automatically increments the build version when you create a component with the same name and semantic version. When referencing resources in your configurations, wildcard patterns automatically resolve to the highest available version matching the specified pattern, ensuring your pipelines always use the latest versions.\n  Auto-versioning is available in all AWS regions including AWS China (Beijing) Region, operated by Sinnet, AWS China (Ningxia) Region, operated by NWCD, and AWS GovCloud (US) Regions. You can get started from the EC2 Image Builder Console, CLI, API, CloudFormation, or CDK. Refer to documentation to learn more about recipes, components and semantic versioning.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/ec2-image-builder-auto-versioning-infrastructure/",
      "pubDate": "2025-11-21T19:35:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "cloudformation"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "cloudformation",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-b3a3371e0c90",
      "title": "Build scalable REST APIs using Amazon API Gateway private integration with Application Load Balancer",
      "description": "Today, we announced \nAmazon API Gateway REST API’s support for private integration with \nApplication Load Balancers (ALBs). You can use this new capability to securely expose your VPC-based applications through your REST APIs without exposing your ALBs to the public internet.",
      "link": "https://aws.amazon.com/blogs/compute/build-scalable-rest-apis-using-amazon-api-gateway-private-integration-with-application-load-balancer/",
      "pubDate": "2025-11-21T19:28:04.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "api gateway",
        "ga",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2f9e2801a319",
      "title": "Automated Reasoning checks now include natural language test Q&A generation",
      "description": "AWS announces the launch of natural language test Q&A generation for Automated Reasoning checks in Amazon Bedrock Guardrails. Automated Reasoning checks uses formal verification techniques to validate the accuracy and policy compliance of outputs from generative AI models. Automated Reasoning checks deliver up to 99% accuracy at detecting correct responses from LLMs, giving you provable assurance in detecting AI hallucinations while also assisting with ambiguity detection in model responses. \n  To get started with Automated Reasoning checks, customers create and test Automated Reasoning policies using natural language documents and sample Q&As. Automated Reasoning checks generates up to N test Q&As for each policy using content from the input document, reducing the work required to go from initial policy generation to production-ready, refined policy.\n  Test generation for Automated Reasoning checks is now available in the US (N. Virginia), US (Ohio), US (Oregon), Europe (Frankfurt), Europe (Ireland), and Europe (Paris) Regions. Customers can access the service through the Amazon Bedrock console, as well as the Amazon Bedrock Python SDK. \n  To learn more about Automated Reasoning checks and how you can integrate it into your generative AI workflows, please read the Amazon Bedrock documentation, review the tutorials on the AWS AI blog, and visit the Bedrock Guardrails webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/automated-reasoning-checks-include-natural-language/",
      "pubDate": "2025-11-21T18:56:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-2749db54abec",
      "title": "AWS IoT Core enhances IoT rules-SQL with variable setting and error handling capabilities",
      "description": "AWS IoT Core now supports a SET clause in IoT rules-SQL, which lets you set and reuse variables across SQL statements. This new feature provides a simpler SQL experience and ensures consistent content when variables are used multiple times. Additionally, a new get_or_default() function provides improved failure handling by returning default values while encountering data encoding or external dependency issues, ensuring IoT rules continue execution successfully.\n  AWS IoT Core is a fully managed service that securely connects millions of IoT devices to the AWS cloud. Rules for AWS IoT is a component of AWS IoT Core which enables you to filter, process, and decode IoT device data using SQL-like statements, and route the data to 20+ AWS and third-party services. As you define an IoT rule, these new capabilities help you eliminate complicated SQL statements and make it easy for you to manage IoT rules-SQL failures.\n \nThese new features are available in all AWS Regions where AWS IoT Core is available, including AWS GovCloud (US) and Amazon China Regions. For more information and getting started experience, visit the developer guides on SET clause and get_or_default() function.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-iot-core-rules-sql/",
      "pubDate": "2025-11-21T18:38:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-8f78c4d252cc",
      "title": "Amazon Connect launches monitoring of contacts queued for callback",
      "description": "Amazon Connect now provides you with the ability to monitor which contacts are queued for callback. This feature enables you to search for contacts queued for callback and view additional details such as the customer’s phone number and duration of being queued within the Connect UI and APIs. You can now pro-actively route contacts to agents that are at risk of exceeding the callback timelines communicated to customers. Businesses can also identify customers that have already successfully connected with agents, and clear them from the callback queue to remove duplicative work.\n  This feature is available in all regions where Amazon Connect is offered. To learn more, please visit our documentation and our webpage.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-monitoring-contacts-queued-callback/",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch"
      ]
    },
    {
      "id": "aws-news-0ac37eed9302",
      "title": "Amazon EMR 7.12 now supports the Apache Iceberg v3 table format",
      "description": "Amazon EMR 7.12 is now available featuring the new Apache Iceberg v3 table format with Apache Iceberg 1.10. This release enables you to reduce costs when deleting data, strengthen governance and compliance through better tracking for row level changes, and enhance data security with more granular data access control.\n  With Iceberg v3, you can delete data cost-effectively because Iceberg v3 marks deleted rows without rewriting entire files - speeding up your data pipelines while reducing storage costs. You get better governance and compliance capabilities through automatic tracking of every row’s creation and modification history, creating the audit trails needed for regulatory requirements and change data capture. You can enhance data security with table-level encryption, helping you meet privacy regulations for your most sensitive data.\n  With Apache Spark 3.5.6 included in this release, you can leverage these Iceberg 1.10 capabilities for building robust data lakehouse architectures on Amazon S3. This release also includes support for data governance operations across your Iceberg tables using AWS Lake Formation. In addition, this release also includes Apache Trino 476.\n  Amazon EMR 7.12 is available in all AWS Regions that support Amazon EMR. To learn more about Amazon EMR 7.12 release, visit the Amazon EMR 7.12 release documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-emr-apache-iceberg-v3-table-format/",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "emr"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "s3",
        "emr",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-834e71048077",
      "title": "Amazon Connect now enables agents to send follow-up replies to email contacts",
      "description": "Amazon Connect now allows agents to send follow-up replies to email contacts, making it easier to share additional information or continue assisting customers without starting a new thread. This capability preserves the full conversation history, helping agents maintain context and deliver consistent, seamless support.\n  Amazon Connect Email is available in the US East (N. Virginia), US West (Oregon), Africa (Cape Town), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), and Europe (London) regions. To learn more and get started, please refer to the help documentation, pricing page, or visit the Amazon Connect website.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-enables-agents-send-followup-replies/",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-60019f8c9235",
      "title": "Second-generation AWS Outposts racks now supported in the AWS Asia Pacific (Tokyo) Region",
      "description": "Second-generation AWS Outposts racks are now supported in the AWS Asia Pacific (Tokyo) Region. Outposts racks extend AWS infrastructure, AWS services, APIs, and tools to virtually any on-premises data center or colocation space for a truly consistent hybrid experience.\n  Organizations from startups to enterprises and the public sector in and outside of Japan can now order their Outposts racks connected to this new supported region, optimizing for their latency and data residency needs. Outposts allows customers to run workloads that need low latency access to on-premises systems locally while connecting back to their home Region for application management. Customers can also use Outposts and AWS services to manage and process data that needs to remain on-premises to meet data residency requirements. This regional expansion provides additional flexibility in the AWS Regions that customers’ Outposts can connect to.\n  To learn more about second-generation Outposts racks, read this blog post and user guide. For the most updated list of countries and territories and the AWS Regions where second-generation Outposts racks are supported, check out the Outposts rack FAQs page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/second-generation-aws-outposts-racks-asia-pacific-tokyo-region",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations",
        "outposts"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "outposts",
        "ga",
        "update",
        "support",
        "expansion"
      ]
    },
    {
      "id": "aws-news-0b6f140782ce",
      "title": "Amazon Aurora DSQL database clusters now support up to 256 TiB of storage volume",
      "description": "Amazon Aurora DSQL now supports a maximum storage limit of 256 TiB, doubling the previous limit of 128 TiB. Now, customers can store and manage larger datasets within a single database cluster, simplifying data management for large-scale applications. With Aurora DSQL, customers only pay for the storage they use and storage automatically scales with usage, ensuring that customers do not need to provision storage upfront.\n  All Aurora DSQL clusters by default have a storage limit of 10 TiB. Customers that desire clusters with higher storage limits can request a limit increase using either the Service Quotas console or AWS CLI. Visit the Service Quotas documentation for a step-by-step guide to requesting a quota increase.\n  The increased storage limits are available in all Regions where Aurora DSQL is available. Get started with Aurora DSQL for free with the AWS Free Tier. To learn more about Aurora DSQL, visit the webpage and documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-aurora-dsql-database-clusters-up-to-256-tib",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-098aadb29a7c",
      "title": "AWS WAF announces Web Bot Auth support",
      "description": "Today, we're excited to announce the addition of Web Bot Auth (WBA) support in AWS WAF, providing a secure and standardized way to authenticate legitimate AI agents and automated tools accessing web applications.\n \nWeb Bot Auth is an authentication method that leverages cryptographic signatures in HTTP messages to verify that a request comes from an automated bot. Web Bot Auth is used as a verification method for verified bots and signed agents. It relies on two active IETF drafts: a directory draft allowing the crawler to share their public keys, and a protocol draft defining how these keys should be used to attach crawler's identity to HTTP requests.\n \nAWS WAF now automatically allows verified AI agent traffic. Verified WBA bots will now be automatically allowed by default. Previously, Category AI blocked unverified bots; this behavior is now refined to respect WBA verification. To learn more, please review the documentation. There is no additional cost for using this feature, however standard AWS WAF charges still apply. For details, visit the AWS WAF Pricing page. \n \nThis feature is currently available only for AWS WAF customers protecting Amazon CloudFront distributions.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-waf-web-bot-auth-support",
      "pubDate": "2025-11-21T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudfront",
        "waf"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "cloudfront",
        "waf",
        "support"
      ]
    },
    {
      "id": "aws-news-6a9e8f6e2ada",
      "title": "Deploy geospatial agents with Foursquare Spatial H3 Hub and Amazon SageMaker AI",
      "description": "In this post, you'll learn how to deploy geospatial AI agents that can answer complex spatial questions in minutes instead of months. By combining Foursquare Spatial H3 Hub's analysis-ready geospatial data with reasoning models deployed on Amazon SageMaker AI, you can build agents that enable nontechnical domain experts to perform sophisticated spatial analysis through natural language queries—without requiring geographic information system (GIS) expertise or custom data engineering pipelines.",
      "link": "https://aws.amazon.com/blogs/machine-learning/deploy-geospatial-agents-with-foursquare-spatial-h3-hub-and-amazon-sagemaker-ai/",
      "pubDate": "2025-11-21T17:15:31.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "lex"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "lex"
      ]
    },
    {
      "id": "aws-news-7493e15a81d7",
      "title": "AWS announces Flexible Cost Allocation on AWS Transit Gateway",
      "description": "AWS announces general availability of Flexible Cost Allocation on AWS Transit Gateway, enhancing how you can distribute Transit Gateway costs across your organization.\n \nPreviously, Transit Gateway only used a sender-pay model, where the source attachment account owner was responsible for all data usage related costs. The new Flexible Cost Allocation (FCA) feature provides more versatile cost allocation options through a central metering policy. Using FCA metering policy, you can choose to allocate all of your Transit Gateway data processing and data transfer usage to the source attachment account, the destination attachment account, or the central Transit Gateway account. FCA metering policies can be configured at an attachment-level or individual flow-level granularity. FCA also supports middle-box deployment models enabling you to allocate data processing usage on middle-box appliances such as AWS Network Firewall to the original source or destination attachment owners. This flexibility allows you to implement multiple cost allocation models on a single Transit Gateway, accommodating various chargeback scenarios within your AWS network infrastructure.\n  Flexible Cost Allocation is available in all commercial AWS Regions where Transit Gateway is available. You can enable these features using the AWS Management Console, AWS Command Line Interface (CLI) and the AWS Software Development Kit (SDK). There is no additional charge for using FCA on Transit Gateway. For more information, see the Transit Gateway documentation pages.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-transit-gateway-flexible-cost-allocation/",
      "pubDate": "2025-11-21T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-95c7e4f2dbf2",
      "title": "Amazon Athena adds cost and performance controls for Capacity Reservations",
      "description": "Amazon Athena now gives you control over Data Processing Unit (DPU) usage for queries running on Capacity Reservations. You can now configure DPU settings at the workgroup or query level to balance cost efficiency, concurrency, and query-level performance needs.\n  Capacity Reservations provides dedicated serverless processing capacity for your Athena queries. Capacity is measured in DPUs, and queries consume DPUs based on their complexity. Now you can set explicit DPU values for each query—ensuring small queries use only what they need while guaranteeing critical queries get sufficient resources for fast execution. The Athena console and API now return per-query DPU usage, helping you understand DPU usage and determine your capacity needs. These updates help you control per-query capacity usage, control query concurrency, reduce costs by eliminating over-provisioning, and deliver consistent performance for business-critical workloads.\n  Cost and performance controls are available today in AWS Regions where Capacity Reservations is supported. To learn more, see Control capacity usage in the Athena user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-athena-capacity-reservation-controls",
      "pubDate": "2025-11-21T16:39:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "athena"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "athena",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-12b5ed99b30f",
      "title": "Introducing Cluster Insights: Unified monitoring dashboard for Amazon OpenSearch Service clusters",
      "description": "This blog will guide you through setting up and using Cluster Insights, including key features and metrics. By the conclusion, you'll understand how to use Cluster insights to recognize and address performance and resiliency issues within your OpenSearch Service clusters.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-cluster-insights-unified-monitoring-dashboard-for-amazon-opensearch-service-clusters/",
      "pubDate": "2025-11-21T16:38:56.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "opensearch",
        "opensearch service"
      ]
    },
    {
      "id": "aws-news-77e4c24aff91",
      "title": "Introducing VPC encryption controls: Enforce encryption in transit within and across VPCs in a Region",
      "description": "AWS announces VPC encryption controls, a new capability that helps organizations audit and enforce encryption in transit for all traffic within and across VPCs in a Region, simplifying compliance with regulatory frameworks like HIPAA, PCI DSS, and FedRAMP through automated monitoring and enforcement modes.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-vpc-encryption-controls-enforce-encryption-in-transit-within-and-across-vpcs-in-a-region/",
      "pubDate": "2025-11-21T16:23:50.000Z",
      "source": "newsBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "organizations",
        "ga",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-5729127e8062",
      "title": "How Wipro PARI accelerates PLC code generation using Amazon Bedrock",
      "description": "In this post, we share how Wipro implemented advanced prompt engineering techniques, custom validation logic, and automated code rectification to streamline the development of industrial automation code at scale using Amazon Bedrock. We walk through the architecture along with the key use cases, explain core components and workflows, and share real-world results that show the transformative impact on manufacturing operations.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-wipro-pari-accelerates-plc-code-generation-using-amazon-bedrock/",
      "pubDate": "2025-11-21T16:10:26.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-fdac2e5fede0",
      "title": "AWS Security Incident Response now provides agentic AI-powered investigation",
      "description": "AWS Security Incident Response now provides agentic AI-powered investigation capabilities to help you prepare for, respond to, and recover from security events faster and more effectively. The new investigative agent automatically gathers evidence across multiple AWS data sources, correlates the data, then presents findings for you in clear, actionable summaries. This helps you reduce the time required to investigate and respond to potential security events, thereby minimizing business disruption.\n  When a security event case is created in the Security Incident Response console, the investigative agent immediately assesses the case details to identify missing information, such as potential indicators, resource names, and timeframes. It asks the case submitter clarifying questions to gather these details. This proactive approach helps minimize delays from back-and-forth communications that traditionally extend case resolution times. The investigative agent then collects relevant information from various data sources, such as AWS CloudTrail, AWS Identity and Access Management (IAM), Amazon EC2, and AWS Cost Explorer. It automatically correlates this data to provide you with a comprehensive analysis, reducing the need for manual evidence gathering and enabling faster investigation. Security teams can track all investigation activities directly through the AWS console and view summaries in their preferred integration tools.\n  This feature is automatically enabled for all Security Incident Response customers at no additional cost in all AWS Regions where the service is available.\n  To learn more and get started, visit the Security Incident Response overview page and console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-security-incident-response-agentic-ai-powered-investigation",
      "pubDate": "2025-11-21T16:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "iam",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-295b60803470",
      "title": "AWS Cost Anomaly Detection accelerates anomaly identification",
      "description": "AWS Cost Anomaly Detection now features an improved detection algorithm that enables faster identification of unusual spending patterns. The enhanced algorithm analyzes your AWS spend using rolling 24-hour windows, comparing current costs against equivalent time periods from previous days each time AWS receives updated cost and usage data.\n  The enhanced algorithm addresses two common challenges in cost pattern analysis. First, it removes the delay in anomaly detection caused by comparing incomplete calendar-day costs against historical daily totals. The rolling window always compares full 24-hour periods, enabling faster identification of unusual patterns. Second, it provides more accurate comparisons by evaluating costs against similar times of day, accounting for workloads that have different morning and evening usage patterns. These improvements help reduce false positives while enabling faster, more accurate anomaly detection.\n  This enhancement to AWS Cost Anomaly Detection is available in all AWS Regions, except the AWS GovCloud (US) Regions and the China Regions. To learn more about this new feature, AWS Cost Anomaly Detection, and how to reduce your risk of spend surprises, visit the AWS Cost Anomaly Detection product page and getting started guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-cost-anomaly-detection-accelerates-anomaly/",
      "pubDate": "2025-11-21T16:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "new-feature",
        "update",
        "improvement",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-5a7d6253df62",
      "title": "AWS Transfer Family announces Terraform module to integrate with a custom identity provider",
      "description": "The AWS Transfer Family Terraform module now supports deploying Transfer Family endpoints with a custom identity provider (IdP) for authentication and access control. This allows you to automate and streamline the deployment of Transfer Family servers integrated with your existing identity providers.\n  AWS Transfer Family provides fully-managed file transfers over SFTP, AS2, FTPS, FTP, and web browser-based interfaces for AWS storage services. Using this new module, you can now use Terraform to provision Transfer Family server resources using your custom authentication systems, eliminating manual configurations and enabling repeatable deployments that scale with your business needs. The module is built on the open source Custom IdP solution which provides standardized integration with widely-used identity providers and includes built-in security controls such as multi-factor authentication, audit logging, and per-user IP allowlisting. To help you get started, the Terraform module includes an end-to-end example using Amazon Cognito user pools. \n  Customers can get started by using the new module from the Terraform Registry. To learn more about the Transfer Family Custom IdP solution, visit the user guide. To see all the regions where Transfer Family is available, visit the AWS Region table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/transfer-family-terraform-custom-idp",
      "pubDate": "2025-11-21T16:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-4da479ed6f79",
      "title": "Introducing one-click onboarding of existing datasets to Amazon SageMaker",
      "description": "Amazon SageMaker introduces one-click onboarding of existing AWS datasets to Amazon SageMaker Unified Studio. This helps AWS customers to start working with their data in minutes, using their existing AWS Identity and Access Management (IAM) roles and permissions. Customers can start working with any data they have access to using a new serverless notebook with a built-in AI agent. This new notebook, which supports SQL, Python, Spark or natural language, gives data engineers, analysts, and data scientists a single high-performance interface to develop and run both SQL queries and code. Customers also have access to many other existing tools such as a Query Editor for SQL analysis, JupyterLab IDE, Visual ETL and workflows, and machine learning (ML) capabilities. The ML capabilities include the ability to discover foundation models from a centralized model hub, customize them with sample notebooks, use MLflow for experimentation, publish trained models in the model hub for discovery, and deploy them as inference endpoints for prediction.\n  Customers can start directly from Amazon SageMaker, Amazon Athena, Amazon Redshift, and Amazon S3 Tables console pages, giving them a fast path from their existing tools and data to the simple experience in SageMaker Unified Studio. After clicking ‘Get started’ and specifying an IAM role, SageMaker prompts for specific policy updates and then automatically creates a project in SageMaker Unified Studio. The project is set up with all existing data permissions from AWS Glue Data Catalog, AWS Lake Formation, and Amazon S3, and a notebook and serverless compute are pre-configured to accelerate first use.\n  To get started, simply click \"Get Started\" from the SageMaker console or open SageMaker Unified Studio from Amazon Athena, Amazon Redshift, or Amazon S3 Tables. One-click onboarding of existing datasets is available in US East (Ohio), US East (N. Virginia), US West (Oregon), Europe (Ireland), Europe (Frankfurt), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Singapore), and Asia Pacific (Sydney). To learn more read the AWS News Blog or visit the Amazon SageMaker documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-one-click-onboarding-existing-datasets",
      "pubDate": "2025-11-21T15:03:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "iam",
        "glue",
        "athena"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "redshift",
        "iam",
        "glue",
        "athena",
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-a827243fd875",
      "title": "Introducing Amazon SageMaker Data Agent for analytics and AI/ML development",
      "description": "Amazon SageMaker introduces a built-in AI agent that accelerates the development of data analytics and machine learning (ML) applications. SageMaker Data Agent is available in the new notebook experience in Amazon SageMaker Unified Studio and helps data engineers, analysts, and data scientists who spend significant time on manual setup tasks and boilerplate code when building analytics and ML applications. The agent generates code and execution plans from natural language prompts and integrates with data catalogs and business metadata to streamline the development process.\n  SageMaker Data Agent works within the new notebook experience to break down complex analytics and ML tasks into manageable steps. Customers can describe objectives in natural language and the agent creates a detailed execution plan and generates the required SQL and Python code. The agent maintains awareness of the notebook context, including available data sources and catalog information, accelerating common tasks including data transformation, statistical analysis, and model development.\n  To get started, log in to Amazon SageMaker and click on “Notebooks” on the left navigation. Amazon SageMaker Data Agent is available in US East (Ohio), US East (N. Virginia), US West (Oregon), Europe (Ireland), Europe (Frankfurt), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Singapore), and Asia Pacific (Sydney). To learn more, read the AWS News Blog or visit the Amazon SageMaker documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-data-agent-analytics-ai-ml-development",
      "pubDate": "2025-11-21T15:01:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "lex"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-8ac2562298da",
      "title": "AWS introduces new VPC Encryption Controls and further raises the bar on data encryption",
      "description": "AWS launches VPC Encryption Controls to make it easy to audit and enforce encryption in transit within and across Amazon Virtual Private Clouds (VPC), and demonstrate compliance with encryption standards. You can turn it on your existing VPCs to monitor encryption status of traffic flows and identify VPC resources that are unintentionally allowing plaintext traffic. This feature also makes it easy to enforce encryption across different network paths by automatically (and transparently) turning on hardware-based AES-256 encryption on traffic between multiple VPC resources including AWS Fargate, Network Load Balancers, and Application Load Balancers.\n  To meet stringent compliance standards like HIPAA and PCI DSS, customers rely on both application layer encryption and the hardware-based encryption that AWS offers across different network paths. AWS provides hardware-based AES-256 encryption transparently between modern EC2 Nitro instances. AWS also encrypts all network traffic between AWS data centers in and across Availability Zones, and AWS Regions before the traffic leaves our secure facilities. All inter-region traffic that uses VPC Peering, Transit Gateway Peering, or AWS Cloud WAN receives an additional layer of transparent encryption before leaving AWS data centers. Prior to this release, customers had to track and confirm encryption across all network paths. With VPC Encryption Controls, customers can now monitor, enforce and demonstrate encryption within and across Virtual Private Clouds (VPCs) in just a few clicks. Your information security team can turn it on centrally to maintain a secure and compliant environment, and generate audit logs for compliance and reporting.\n  VPC Encryption Controls is now available in the following AWS Commercial regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), Europe (Ireland), Europe (Frankfurt), Europe (London), Europe (Paris), Europe (Milan), Europe (Zurich), Europe (Stockholm), Asia Pacific (Sydney), Asia Pacific (Singapore), Asia Pacific (Tokyo), Asia Pacific (Melbourne), Asia Pacific (Hong Kong), Asia Pacific (Osaka), Asia Pacific (Mumbai), Asia Pacific (Hyderabad), Asia Pacific (Jakarta), Canada West (Calgary), Canada (Central), Middle East (UAE), Middle East (Bahrain), Africa (Cape Town) and South America (São Paulo). To learn more about this feature and its use cases, please see our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-vpc-encryption-controls",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "rds",
        "fargate"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ec2",
        "rds",
        "fargate",
        "launch",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-4b6ab9257ecf",
      "title": "AWS CloudFormation StackSets now supports deployment ordering",
      "description": "AWS CloudFormation StackSets offers deployment ordering for auto-deployment mode, enabling you to define the sequence in which your stack instances automatically deploy across accounts and regions. This capability allows you to coordinate complex multi-stack deployments where foundational infrastructure must be provisioned before dependent application components. Organizations managing large-scale deployments can now ensure proper deployment ordering without manual intervention.\n  When creating or updating a CloudFormation StackSet, you can specify up to 10 dependencies per stack instances using the new DependsOn parameter in the AutoDeployment configuration, allowing StackSets to automatically orchestrate deployments based on your defined relationships. For example, you can make sure that your networking and security stack instance complete deployment before your application stack instances begin, preventing deployment failures due to missing dependencies. StackSets includes built-in cycle detection to prevent circular dependencies and provides error messages to help resolve configuration issues.\n  This feature is available in all AWS Regions where CloudFormation StackSets is available at no additional cost.\n  Get started by creating or updating your StackSets auto-deployement option through the CLI, SDK or the CloudFormation Console to define dependencies using stack instances ARNs. To learn more about StackSets deployment ordering, check out the detailed feature walkthrough on the AWS DevOps Blog or visit the AWS CloudFormation User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-cloudformation-stacksets-deployment-ordering",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "cloudformation",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "cloudformation",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-a373609adb4b",
      "title": "AWS License Manager introduces license asset groups for centralized software asset management",
      "description": "AWS License Manager now provides centralized software asset management across AWS regions and accounts in an organization, reducing compliance risks and streamlines license tracking through automated license asset groups. Customers can now track license expiry dates, streamline audit responses, and make data-driven renewal decisions with a product-centric view of their commercial software portfolio.\n  With this launch, customers no longer need to manually track licenses across multiple regions and accounts in their organization. Now with license asset groups, customers can gain organization-wide visibility of their commercial software usage with customizable grouping and automated reporting. The new feature is available in all commercial regions where AWS License Manager is available.\n  To get started, visit the Licenses section of the AWS License Manager console, and the AWS License Manager User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-license-manager-license-asset-groups",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "launch",
        "ga",
        "new-feature"
      ]
    },
    {
      "id": "aws-news-0539e3184387",
      "title": "Amazon EKS add-ons now supports the AWS Secrets Store CSI Driver provider",
      "description": "Today, AWS announces the general availability of the AWS Secrets Store CSI Driver provider EKS add-on. This new integration allows customers to retrieve secrets from AWS Secrets Manager and parameters from AWS Systems Manager Parameter Store and mount them as files on their Kubernetes clusters running on Amazon Elastic Kubernetes Service (Amazon EKS). The add-on installs and manages the AWS provider for the Secrets Store CSI Driver.\n  Now, with the new Amazon EKS add-on, customers can quickly and easily set up new and existing clusters using automation to leverage AWS Secrets Manager and AWS Systems Manager Parameter Store, enhancing security and simplifying secrets management. Amazon EKS add-ons are curated extensions that automate the installation, configuration, and lifecycle management of operational software for Kubernetes clusters, simplifying the process of maintaining cluster functionality and security.\n  Customers rely on AWS Secrets Manager to securely store and manage secrets such as database credentials and API keys throughout their lifecycle. To learn more about Secrets Manager, visit the documentation. For a list of regions where Secrets Manager is available, see the AWS Region table. To get started with Secrets Manager, visit the Secrets Manager home page.\n  This new Amazon EKS add-on is available in all AWS commercial and AWS GovCloud (US) Regions.\n To get started, see the following resources:\n  \n \n \nAmazon EKS add-ons user guide\n \n \nAWS Secrets Manager user guide",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-add-ons-aws-secrets-store-csi-driver-provider",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "secrets manager"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "eks",
        "secrets manager",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-6150b92370c1",
      "title": "CloudWatch Database Insights adds cross-account cross-region monitoring",
      "description": "Amazon CloudWatch Database Insights now supports cross-account and cross-region database fleet monitoring, enabling centralized observability across your entire AWS database infrastructure. This enhancement allows DevOps engineers and database administrators to monitor, troubleshoot, and optimize databases spanning multiple AWS accounts and regions from a single unified console experience.\n  With this new capability, organizations can gain holistic visibility into their distributed database environments without account or regional boundaries. Teams can now correlate performance issues across their entire database fleet, streamline incident response workflows, and maintain consistent monitoring standards across complex multi-account architectures, significantly reducing operational overhead and improving mean time to resolution.\n  This feature is available in all AWS commercial regions where CloudWatch Database Insights is supported.\n  To learn more about cross-account and cross-region monitoring in CloudWatch Database Insights, as well as instructions to get started monitoring your databases across your entire organization and regions, visit the CloudWatch Database Insights documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/cloudwatch-database-insights-cross-account-region-monitoring",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds",
        "cloudwatch",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "rds",
        "cloudwatch",
        "organizations",
        "ga",
        "enhancement",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-b7916baad19a",
      "title": "AWS Control Tower now supports seven new compliance frameworks and 279 additional AWS Config rules",
      "description": "Today, AWS Control Tower announces support for an additional 279 managed Config rules in Control Catalog for various use cases such as security, cost, durability, and operations. With this launch, you can now search, discover, enable and manage these additional rules directly from AWS Control Tower and govern more use cases for your multi-account environment. AWS Control Tower also supports seven new compliance frameworks in Control Catalog. In addition to existing frameworks, most controls are now mapped to ACSC-Essential-Eight-Nov-2022, ACSC-ISM-02-Mar-2023, AWS-WAF-v10, CCCS-Medium-Cloud-Control-May-2019, CIS-AWS-Benchmark-v1.2, CIS-AWS-Benchmark-v1.3, CIS-v7.1\n  To get started, go to the Control Catalog and search for controls with the implementation filter AWS Config to view all AWS Config rules in the Catalog. You can enable relevant rules directly using the AWS Control Tower console or the ListControls, GetControl and EnableControl APIs. We've also enhanced control relationship mapping, helping you understand how different controls work together. The updated ListControlMappings API now reveals important relationships between controls - showing which ones complement each other, are alternatives, or are mutually exclusive. For instance, you can now easily identify when a Config Rule (detection) and a Service Control Policy (prevention) can work together for comprehensive security coverage.\n  These new features are available in AWS Regions where AWS Control Tower is available, including AWS GovCloud (US). Reference the list of supported regions for each Config rule to see where it can be enabled. To learn more, visit the AWS Control Tower User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-control-tower-new-compliance-frameworks-additional-aws-config-rules",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "waf"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "waf",
        "launch",
        "new-feature",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-b5fe1dd88b80",
      "title": "Amazon OpenSearch Service OR2 and OM2 now available in additional Regions",
      "description": "Amazon OpenSearch Service, expands availability of OR2 and OM2, OpenSearch Optimized Instance family to 11 additional regions. The OR2 instance delivers up to 26% higher indexing throughput compared to previous OR1 instances and 70% over R7g instances. The OM2 instance delivers up to 15% higher indexing throughput compared to OR1 instances and 66% over M7g instances in internal benchmarks.\n \nThe OpenSearch Optimized instances, leveraging best-in-class cloud technologies like Amazon S3, to provide high durability, and improved price-performance for higher indexing throughput better for indexing heavy workload. Each OpenSearch Optimized instance is provisioned with compute, local instance storage for caching, and remote Amazon S3-based managed storage. OR2 and OM2 offers pay-as-you-go pricing and reserved instances, with a simple hourly rate for the instance, local instance storage, as well as the managed storage provisioned. OR2 instances come in sizes ‘medium’ through ‘16xlarge’, and offer compute, memory, and storage flexibility. OM2 instances come in sizes ‘large’ through ‘16xlarge’ Please refer to the Amazon OpenSearch Service pricing page for pricing details.\n  OR2 instance family is now available on Amazon OpenSearch Service across 11 additional regions globally: US West (N. California), Canada (Central),  Asia Pacific (Hong Kong, Jakarta , Malaysia, Melbourne, Osaka , Seoul, Singapore), Europe (London), and South America (Sao Paulo). \n  OM2 instance family is now available on Amazon OpenSearch Service across 14 additional regions globally: US West (N. California), Canada (Central), Asia Pacific (Hong Kong, Hyderabad, Mumbai, Osaka, Seoul, Singapore, Sydney, Tokyo), Europe ( Paris, Spain), Middle East (Bahrain), South America (Sao Paulo).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-opensearch-service-or2-om2-instances-available-regions",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "s3",
        "opensearch",
        "opensearch service",
        "ga",
        "now-available"
      ]
    },
    {
      "id": "aws-news-a6455f7a8279",
      "title": "Amazon EKS and Amazon ECS announce fully managed MCP servers in preview",
      "description": "Today, Amazon Elastic Kubernetes Service (EKS) and Amazon Elastic Container Service (ECS) announced fully managed MCP servers enabling AI powered experiences for development and operations in preview. MCP (Model Context Protocol) provides a standardized interface that enriches AI applications with real-time, contextual knowledge of EKS and ECS clusters, enabling more accurate and tailored guidance throughout the application lifecycle, from development through operations. With this launch, EKS and ECS now offer fully managed MCP servers hosted in the AWS cloud, eliminating the need for local installation and maintenance. The fully managed MCP servers provide enterprise-grade capabilities like automatic updates and patching, centralized security through AWS IAM integration, comprehensive audit logging via AWS CloudTrail, and the proven scalability, reliability, and support of AWS.\n  The fully managed Amazon EKS and ECS MCP servers enable developers to easily configure AI coding assistants like Kiro CLI, Cursor, or Cline for guided development workflows, optimized code generation, and context-aware debugging. Operators gain access to a knowledge base of best practices and troubleshooting guidance derived from extensive operational experience managing clusters at scale.\n  To learn more about the Amazon EKS MCP server preview, visit EKS MCP server documentation and launch blog post. To learn more about the Amazon ECS MCP server preview, visit ECS MCP server documentation and launch blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-ecs-fully-managed-mcp-servers-preview",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ecs",
        "eks",
        "iam"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ecs",
        "eks",
        "iam",
        "launch",
        "preview",
        "ga",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-138216fa99de",
      "title": "Amazon ECR now supports managed container image signing",
      "description": "Amazon ECR now supports managed container image signing to enhance your security posture and eliminate the operational overhead of setting up signing. Container image signing allows you to verify that images are from trusted sources. With managed signing, ECR simplifies setting up container image signing to just a few clicks in the ECR Console or a single API call.\n  To get started, create a signing rule with an AWS Signer signing profile that specifies parameters such as signature validity period, and which repositories ECR should sign images for. Once configured, ECR automatically signs images as they are pushed using the identity of the entity pushing the image. ECR leverages AWS Signer for signing operations, which handles key material and certificate lifecycle management including generation, secure storage, and rotation. All signing operations are logged through CloudTrail for full auditability.\n  ECR managed signing is available in all AWS Regions where AWS Signer is available. To learn more, visit the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ecr-managed-container-image-signing",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "support"
      ]
    },
    {
      "id": "aws-news-f2c22f128259",
      "title": "AWS Organizations now supports upgrade rollout policy for Amazon Aurora and Amazon RDS",
      "description": "Today, AWS Organizations announces support for upgrade rollout policy, a new capability that helps customers stagger automatic upgrades across their Amazon Aurora (MySQL-Compatible Edition and PostgreSQL-Compatible Edition) and Amazon Relational Database Service (Amazon RDS) including RDS for MySQL, RDS for PostgreSQL, RDS for MariaDB, RDS for SQL Server, RDS for Oracle, and RDS for Db2 databases. This capability eliminates the operational overhead of coordinating automatic minor version upgrades either manually or through custom tools across hundreds of resources and accounts, while giving customers peace of mind by ensuring upgrades are first tested in less critical environments before being rolled out to production.\n  With upgrade rollout policy, you can define upgrade sequences using simple orders (first, second, last) applied through account-level policies or resource tags. When new minor versions become eligible for automatic upgrade, the policy ensures upgrades start with development environments, allowing you to validate changes before proceeding to more critical environments. AWS Health notifications between phases and built-in validation periods help you monitor progress and ensure stability throughout the upgrade process. You can also disable automatic progression at any time if issues are detected, giving you complete control over the upgrade journey.\n  This feature is available in all AWS commercial Regions and AWS GovCloud (US) Regions, supporting automatic minor version upgrades for Amazon Aurora and Amazon RDS database engines. You can manage upgrade policies using the AWS Management Console, AWS CLI, AWS SDKs, AWS CloudFormation, or AWS CDK. For Amazon RDS for Oracle, the upgrade rollout policy supports automatic minor version upgrades for engine versions released after January 2026.\n  To learn more about automatic minor version upgrades, see the Amazon RDS and Aurora user guide. For more information about upgrade rollout policy, see Managing organization policies with AWS Organizations (Upgrade rollout policy).",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-organizations-upgrade-rollout-policy-amazon-aurora-rds",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds",
        "cloudformation",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "rds",
        "cloudformation",
        "organizations",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-d5b5e2447564",
      "title": "Announcing AWS Compute Optimizer automation rules",
      "description": "Today, we are introducing automation rules, a new feature in AWS Compute Optimizer that enables you to optimize Amazon Elastic Block Store (EBS) volumes at scale. With automation rules, you can streamline the process of cleaning up unattached EBS volumes and upgrading volumes to the latest-generation volume types, saving cost and improving performance across your cloud infrastructure.\n  Automation rules let you automatically apply optimization recommendations on a recurring schedule when they match your criteria. You can set criteria like AWS Region to target specific geographies and Resource Tags to distinguish between production and development workloads. Configure rules to run daily, weekly, or monthly, and AWS Compute Optimizer will continuously evaluate new recommendations against your criteria. A new dashboard allows you to summarize automation events over time, examine detailed step history, and estimate savings achieved. If you need to reverse an action, you can do so directly from the same dashboard.\n  AWS Compute Optimizer automation rules are available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Osaka), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), and South America (São Paulo).\n  To get started, navigate to the new Automation section in the AWS Compute Optimizer console, visit the AWS Compute Optimizer user guide documentation, or read the announcement blog to learn more.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-compute-optimizer-automation-rules",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "ga",
        "new-feature",
        "announcement"
      ]
    },
    {
      "id": "aws-news-64f8a5908cf3",
      "title": "Amazon EKS introduces Provisioned Control Plane",
      "description": "Today, Amazon Elastic Kubernetes Service (EKS) introduced Provisioned Control Plane, a new feature that gives you the ability to select your cluster's control plane capacity to ensure predictable, high performance for the most demanding workloads. With Provisioned Control Plane, you can pre-provision the desired control plane capacity from a set of well-defined scaling tiers, ensuring the control plane is always ready to handle traffic spikes or unpredictable bursts. These new scaling tiers unlock significantly higher cluster performance and scalability, allowing you to run ultra-scale workloads in a single cluster.\n  Provisioned Control Plane ensures your cluster's control plane is ready to support workloads that require minimal latency and high performance during anticipated high-demand events like product launches, holiday sales, or major sporting and entertainment events. It also ensures consistent control plane performance across development, staging, production, and disaster recovery environments, so the behavior you observe during testing accurately reflects what you'll experience in production or during failover events. Finally, it enables you to run massive-scale workloads such as AI training/inference, high-performance computing, or large-scale data processing jobs that require thousands of worker nodes in a single cluster.\n  To get started with Amazon EKS Provisioned Control Plane, use the EKS APIs, AWS Console, or infrastructure as code tooling to enable it in a new or existing EKS cluster. To learn more about EKS Provisioned Control Plane , visit the EKS Provisioned Control plane documentation and EKS pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-eks-provisioned-control-plane/",
      "pubDate": "2025-11-21T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks",
        "launch",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-82f031df727e",
      "title": "Announcing notebooks with a built-in AI agent in Amazon SageMaker",
      "description": "Amazon SageMaker introduces a new notebook experience that provides data and AI teams a high-performance, serverless programming environment for analytics and machine learning (ML) jobs. This helps customers quickly get started working with data without pre-provisioning data processing infrastructure. The new notebook gives data engineers, analysts, and data scientists one place to perform SQL queries, execute Python code, process large-scale data jobs, run ML workloads and create visualizations. A built-in AI agent accelerates development by generating code and SQL statements from natural language prompts while it guides users through their tasks. The notebook is backed by Amazon Athena for Apache Spark to deliver high-performance results, scaling from interactive SQL queries to petabyte-scale data processing. It’s available in the new one-click onboarding experience for Amazon SageMaker Unified Studio.\n \nData engineers, analysts, and data scientists can flexibly combine SQL, Python, and natural language within a single interactive workspace. This removes the need to switch between different tools based on your workload. For example, you can start with SQL queries to explore your data, use Python for advanced analytics or to build ML models, or use natural language prompts to generate code automatically using the built-in AI agent. To get started, sign in to the console, find SageMaker, open SageMaker Unified Studio, and go to \"Notebooks\" in the navigation.\n \nYou can use the SageMaker notebook feature in the following Regions: US East (Ohio), US East (N. Virginia), US West (Oregon), Europe (Ireland), Europe (Frankfurt), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Singapore), and Asia Pacific (Sydney).\n \nTo learn more, read the AWS News Blog or see SageMaker documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/notebooks-built-in-ai-agent-amazon-sagemaker/",
      "pubDate": "2025-11-21T09:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "unified studio",
        "lex",
        "athena"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "lex",
        "athena",
        "ga"
      ]
    },
    {
      "id": "aws-news-73808c7d394f",
      "title": "Amazon CloudWatch Container Insights adds Sub-Minute GPU Metrics for Amazon EKS",
      "description": "Amazon CloudWatch Container Insights now supports collection of GPU metrics at sub-minute frequencies for AI and ML workloads running on Amazon EKS. Customers can configure the metric sample rate in seconds, enabling more granular monitoring of GPU resource utilization.\n  This enhancement enables customers to effectively monitor GPU-intensive workloads that run for less than 60 seconds, such as ML inference jobs that consume GPU resources for short durations. By increasing the sampling frequency, customers can maintain detailed visibility into short-lived GPU workloads. Sub-minute GPU metrics are sent to CloudWatch once per minute. This granular monitoring helps customers optimize their GPU resource utilization, troubleshoot performance issues, and ensure efficient operation of their containerized GPU applications.\n  Sub-Minute GPU metrics in Container Insights is available in all AWS Commercial Regions and the AWS GovCloud (US) Regions.\n  To learn more about Sub-Minute GPU metrics in Container Insights, visit the NVIDIA GPU metrics page in the Amazon CloudWatch User Guide. Sub-Minute GPU metrics in Container Insights are available for no addition cost. For Container Insights pricing, see the Amazon CloudWatch Pricing Page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/cloudwatch-container-sub-minute-gpu-metrics-eks/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks",
        "cloudwatch",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-393bf1df7dd1",
      "title": "AWS Control Tower introduces a controls-dedicated experience",
      "description": "AWS Control Tower offers the easiest way to manage and govern your environment with AWS managed controls. Starting today, customers can have direct access to these AWS managed controls without requiring a full Control Tower deployment. This new experience offers over 750 managed controls that customers can deploy within minutes while maintaining their existing account structure.\n  AWS Control Tower v4.0 introduces direct access to Control Catalog, allowing customers to review available managed controls and deploy them into their existing AWS Organization. With this release, customers now have more flexibility and autonomy over their organizational structure, as Control Tower will no longer enforce a mandatory structure. Additionally, customers will have improved operations such as cleaner resource and permissions management and cost attribution due to the separation of S3 buckets and SNS notifications for the AWS Config and AWS CloudTrail integrations.\n  This controls-focused experience is now available in all AWS Regions where AWS Control Tower is supported. For more information about this new capability see the AWS Control Tower User Guide or contact your AWS account team. For a full list of Regions where AWS Control Tower is available, see the AWS Region Table.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-control-tower-controls-dedicated-experience/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "s3",
        "sns"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "s3",
        "sns",
        "ga",
        "now-available",
        "integration",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2fff11f9fbf8",
      "title": "Amazon EC2 Fleet adds new encryption attribute for instance type selection",
      "description": "Amazon EC2 Fleet now supports a new encryption attribute for Attribute-Based Instance Type Selection (ABIS). Customers can use the RequireEncryptionInTransit parameter to specifically launch instance types that support encryption-in-transit, in addition to specifying resource requirements like vCPU cores and memory.\n  The new encryption attribute addresses critical compliance needs for customers who use VPC Encryption Controls in enforced mode and require all network traffic to be encrypted in transit. By combining encryption requirements with other instance attributes in ABIS, customers can achieve instance type diversification for better capacity fulfillment while meeting their security needs. Additionally, the GetInstanceTypesFromInstanceRequirements (GITFIR) allows you to preview which instance types you might be allocated based on your specified encryption requirements.\n  This feature is available in all AWS commercial and AWS GovCloud (US) Regions.\n  To get started, set the RequireEncryptionInTransit parameter to true in InstanceRequirements when calling the CreateFleet or GITFIR APIs. For more information, refer to the user guides for EC2 Fleet and GITFIR.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ec2-fleet-encryption-attribute-instance-type-selection/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-c9b4e1ce6dbf",
      "title": "Announcing flexible AMI distribution capabilities for EC2 Image Builder",
      "description": "Amazon EC2 Image Builder now allows you to distribute existing Amazon Machine Images(AMIs), retry distributions, and define custom distribution workflows. Distribution workflows are a new workflow type that complements existing build and test workflows, enabling you to define sequential distribution steps such as AMI copy operations, wait-for-action checkpoints, and AMI attribute modifications.\n  With enhanced distribution capabilities, you can now distribute an existing image to multiple regions and accounts without running a full Image Builder pipeline. Simply specify your AMI and distribution configuration, and Image Builder handles the copying and sharing process. Additionally, with distribution workflows, you can now customize distribution process by defining custom steps. For example, you can distribute AMIs to a test region first, add a wait-for-action step to pause for validation, and then continue distribution to production regions after approval. This provides the same step-level visibility and control you have with build and test workflows.\n  These capabilities are available to all customers at no additional costs, in all AWS regions including AWS China (Beijing) Region, operated by Sinnet, AWS China (Ningxia) Region, operated by NWCD, and AWS GovCloud (US) Regions.\n You can get started from the EC2 Image Builder Console, CLI, API, CloudFormation, or CDK, and learn more in the EC2 Image Builder documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/announcing-flexible-ami-distribution-ec2-image-builder/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2",
        "cloudformation"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "cloudformation"
      ]
    },
    {
      "id": "aws-news-ffe32c223a6e",
      "title": "AWS Glue supports AWS CloudFormation and AWS CDK for zero-ETL integrations",
      "description": "AWS Glue zero-ETL integrations now support AWS CloudFormation and AWS Cloud Development Kit (AWS CDK), through which you can create Zero-ETL integrations using infrastructure as code. Zero-ETL integrations are fully managed by AWS and minimize the need to build ETL data pipelines.\n  Using AWS Glue zero-ETL, you can ingest data from AWS DynamoDB or enterprise SaaS sources, including Salesforce, ServiceNow, SAP, and Zendesk, into Amazon Redshift, Amazon S3, and Amazon S3 Tables. CloudFormation and CDK support for these Glue zero-ETL integrations simplifies the way you can create, update, and manage zero-ETL integrations using infrastructure as code. With CloudFormation and CDK support, data engineering teams can now consistently deploy any zero-ETL integration across multiple AWS accounts while maintaining version control of their configurations.\n  This feature is available in all AWS Regions where AWS Glue zero-ETL is currently available.\n  To get started with the new AWS Glue zero-ETL infrastructure as code capabilities, visit the CloudFormation documentation for AWS Glue, CDK documentation, or the AWS Glue zero-ETL user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-cloudformation-cdk-zero-etl-integrations/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3",
        "redshift",
        "dynamodb",
        "cloudformation",
        "glue"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "s3",
        "redshift",
        "dynamodb",
        "cloudformation",
        "glue",
        "update",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-9a9239214a06",
      "title": "Amazon SageMaker HyperPod now supports running IDEs and Notebooks to accelerate AI development",
      "description": "Amazon SageMaker HyperPod now supports IDEs and Notebooks, enabling AI developers to run JupyterLab, Code Editor, or connect local IDEs to run their interactive AI workloads directly on HyperPod clusters.\n  AI developers can now run IDEs and notebooks on the same persistent HyperPod EKS clusters used for training and inference. This enables developers to leverage HyperPod's scalable GPU capacity with familiar tools like HyperPod CLI, while sharing data across IDEs and training jobs through mounted file systems such as FSx, EFS, etc..\n  Administrators can maximize CPU/GPU investments through unified governance across IDEs, training, and inference workloads using HyperPod Task Governance. HyperPod Observability provides usage metrics including CPU, GPU, and memory consumption, enabling cost-efficient cluster utilization.\n  This feature is available in all AWS Regions where Amazon SageMaker HyperPod is currently available, excluding China and GovCloud (US) regions. To learn more, visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-sagemaker-hyperpod-ides-notebooks-ai/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "hyperpod",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-2c36a717bd9f",
      "title": "Amazon Lightsail expands blueprint selection with updated support for Nginx Blueprint",
      "description": "Amazon Lightsail now offers a new Nginx blueprint. This new blueprint has Instance Metadata Service Version 2 (IMDSv2) enforced by default, and supports IPv6-only instances. With just a few clicks, you can create a Lightsail virtual private server (VPS) of your preferred size that comes with Nginx preinstalled.\n  With Lightsail, you can easily get started on the cloud by choosing a blueprint and an instance bundle to build your web application. Lightsail instance bundles include instances preinstalled with your preferred operating system, storage, and monthly data transfer allowance, giving you everything you need to get up and running quickly\n  This new blueprint is now available in all AWS Regions where Lightsail is available. For more information on blueprints supported on Lightsail, see Lightsail documentation. For more information on pricing, or to get started with your free trial, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/announcing-nginx-blueprint-by-amazon-lightsail/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-157fb77af8ec",
      "title": "Oracle Database@AWS now supports AWS KMS integration with Oracle Transparent Data Encryption",
      "description": "Oracle Database@AWS is now integrated with AWS Key Management Service (KMS) to manage database encryption keys. KMS is an AWS managed service to create and control keys used to encrypt and sign data. With this integration, customers can now use KMS to encrypt Oracle Transparent Data Encryption (TDE) master keys in Oracle Database@AWS. This provides customers a consistent mechanism to create and control keys used for encrypting data in AWS, and meet security and compliance requirements.\n  Thousands of customers use KMS to manage keys for encrypting their data in AWS. KMS provides robust key management and control through central policies and granular access, comprehensive logging and auditing via AWS CloudTrail, and automatic key rotation for enhanced security. By using KMS to encrypt Oracle TDE master keys, customers can get the same benefits for database encryption keys for Oracle Database@AWS, and apply consistent auditing and compliance procedures for data in AWS.\n  AWS KMS integration with TDE is available in all AWS regions where Oracle Database@AWS are available. Other than standard AWS KMS pricing, there is no additional Oracle Database@AWS charge for the feature. To get started, see Oracle Database@AWS and documentation to use KMS.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/oracle-database-aws-kms-integration-oracle-transparent-data-encryption/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-6d3bb702367e",
      "title": "Amazon Bedrock Data Automation now supports synchronous image processing",
      "description": "Amazon Bedrock Data Automation (BDA) now supports synchronous API processing for images, enabling you to receive structured insights from visual content with low latency. Synchronous processing for images complements the existing asynchronous API, giving you the flexibility to choose the right approach based on your application's latency requirements.\n  BDA automates the generation of insights from unstructured multimodal content such as documents, images, audio, and videos for your GenAI-powered applications. With synchronous image processing, you can build interactive experiences—such as social media platforms that moderate user-uploaded photos, e-commerce apps that identify products from customer images, or travel applications that recognize landmarks and provide contextual information. This eliminates polling or callback handling, simplifying your application architecture and reducing development complexity. Synchronous processing supports both Standard Output for common image analysis tasks like summarization and text extraction, and Custom Output using Blueprints for industry-specific field extraction. You now get the high-quality, structured results you expect from BDA with low-latency response times that enable more responsive user experiences.\n  Amazon Bedrock Data Automation is available in 8 AWS regions: Europe (Frankfurt), Europe (London), Europe (Ireland), Asia Pacific (Mumbai), Asia Pacific (Sydney), US West (Oregon) and US East (N. Virginia), and AWS GovCloud (US-West) AWS Regions.\n  To learn more, see the Bedrock Data Automation User Guide and the Amazon Bedrock Pricing page. To get started with using Bedrock Data Automation, visit the Amazon Bedrock console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/bedrock-data-automation-synchronous-image-processing/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-faa7282965ce",
      "title": "AWS Application and Network Load Balancers Now Support Post-Quantum Key Exchange for TLS",
      "description": "AWS Application Load Balancers (ALB) and Network Load Balancers (NLB) now support post-quantum key exchange options for the Transport Layer Security (TLS) protocol. This opt-in feature introduces new TLS security policies with hybrid post-quantum key agreement, combining classical key exchange algorithms with post-quantum key encapsulation methods, including the standardized Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM) algorithm.\n  Post-quantum TLS (PQ-TLS) security policies protect your data in transit against potential \"Harvest Now, Decrypt Later\" (HNDL) attacks, where adversaries collect encrypted data today with the intention to decrypt it once quantum computing capabilities mature. This quantum-resistant encryption ensures long-term security for your applications and data transmissions, future-proofing your infrastructure against emerging quantum computing threats.\n  This feature is available for ALB and NLB in all AWS Commercial Regions, AWS GovCloud (US) Regions and AWS China Regions at no additional cost. To use this capability, you must explicitly update your existing ALB HTTPS listeners or NLB TLS listeners to use a PQ-TLS security policy, or select a PQ-TLS policy when creating new listeners through the AWS Management Console, CLI, API or SDK. You can monitor the use of classical or quantum-safe key exchange using ALB connection logs or NLB access logs.\n  For more information, please visit ALB User Guide, NLB User Guide, and AWS Post-Quantum Cryptography documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/network-load-balancers-post-quantum-key-exchange-tls/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-7a4173797a90",
      "title": "Amazon Lex extends wait & continue feature in 10 new languages",
      "description": "Amazon Lex now supports wait & continue functionality in 10 new languages, enabling more natural conversational experiences in Chinese, Japanese, Korean, Cantonese, Spanish, French, Italian, Portuguese, Catalan, and German. This feature allows deterministic voice and chat bots to pause while customers gather additional information, then seamlessly resume when ready. For example, when asked for payment details, customers can say \"hold on a second\" to retrieve their credit card, and the bot will wait before continuing.\n  This feature is available in all AWS Regions where Amazon Lex operates. To learn more, visit the Amazon Lex documentation or explore the Amazon Connect website to learn how Amazon Connect and Amazon Lex deliver seamless end-customer self-service experiences.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-lex-wait-continue-feature-10-languages/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-8a3db6cc0a81",
      "title": "Amazon ECR dual-stack endpoints now support AWS PrivateLink",
      "description": "Amazon Elastic Container Registry (ECR) announces AWS PrivateLink support for its dual-stack endpoints. This makes it easier to standardize on IPv6 and enhance your security posture.\n  Previously, ECR announced IPv6 support for API and Docker/OCI requests via the new dual-stack endpoints. With these dual-stack endpoints, you can make requests from either an IPv4 or an IPv6 network. With today’s launch, you can now make requests to these dual-stack endpoints using AWS PrivateLink to limit all network traffic between your Amazon Virtual Private Cloud (VPC) and ECR to the Amazon network, thereby improving your security posture.\n  This feature is generally available in all AWS commercial and AWS GovCloud (US) regions at no additional cost. To get started, visit ECR documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/ecr-dual-stack-endpoints-privatelink/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-8ea0dfacb966",
      "title": "Amazon WorkSpaces Applications now supports IPv6",
      "description": "Amazon WorkSpaces Applications now supports IPv6 for WorkSpaces Applications domains and external endpoints, allowing end users to connect to WorkSpaces Applications over IPv6 from IPv6 compatible devices (except SAML authentication). This helps you meet IPv6 compliance requirements and eliminates the need for expensive networking equipment to handle address translation between IPv4 and IPv6.\n \nThe Internet's growth is consuming IPv4 addresses quickly. WorkSpaces Applications, by supporting IPv6, assists customers in streamlining their network architecture. This support offers a much larger address space and removes the necessity to manage overlapping address spaces in their VPCs. Customers can now base their applications on IPv6, ensuring their infrastructure is future-ready and compatible with existing IPv4 systems via a fallback mechanism.\n \nThis feature is available at no additional cost in 16 AWS Regions, including US East (N. Virginia, Ohio), US West (Oregon), Canada (Central), Europe (Paris, Frankfurt, London, Ireland), Asia Pacific (Tokyo, Mumbai, Sydney, Seoul, Singapore), and South America (Sao Paulo) and AWS GovCloud (US-West, US-East). WorkSpaces Applications offers pay-as-you go pricing.\n \nTo get started with WorkSpaces Applications, see Getting Started with Amazon WorkSpaces Applications. To enable this feature for your users, you must use the latest WorkSpaces Applications client for Windows, macOS or directly through web access. To learn more about the feature, please refer to the service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-appstream-2-0-supports-ipv6/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-c658c6a75caf",
      "title": "Amazon API Gateway REST APIs now supports private integration with Application Load Balancer",
      "description": "Amazon API Gateway REST APIs now support direct private integration with Application Load Balancer (ALB), enabling inter-VPC connectivity to internal ALBs. This enhancement extends API Gateways existing VPC connectivity, providing you with more flexible and efficient architecture choices for your REST API implementations.\n  This direct ALB integration delivers multiple advantages: reduced latency by eliminating the additional network hop previously required through Network Load Balancer, lower infrastructure costs through simplified architecture, and enhanced Layer 7 capabilities including HTTP/HTTPS health checks, advanced request-based routing, and native container service integration. You can still use API Gateway's integration with Network Load Balancers for layer-4 connectivity.\n  Amazon API Gateway private integration with ALB is available in all AWS GovCloud (US) regions and the following AWS commercial regions US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Africa (Cape Town), Asia Pacific (Hong Kong), Asia Pacific (Hyderabad), Asia Pacific (Jakarta), Asia Pacific (Malaysia), Asia Pacific (Melbourne), Asia Pacific (Mumbai), Asia Pacific (Osaka), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Canada West (Calgary), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Milan), Europe (Paris), Europe (Spain), Europe (Stockholm), Europe (Zurich), Israel (Tel Aviv), Middle East (Bahrain), Middle East (UAE), South America (São Paulo). For more information, visit the Amazon API Gateway documentation and blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/api-gateway-rest-apis-integration-load-balancer/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "api gateway"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "api gateway",
        "ga",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-d574c6d1d540",
      "title": "Announcing Amazon ECS Express Mode",
      "description": "Today, AWS announces Amazon Elastic Container Service (Amazon ECS) Express Mode, a new feature that empowers developers to rapidly launch containerized applications, including web applications and APIs. ECS Express Mode makes it easy to orchestrate and manage the cloud architecture for your application, while maintaining full control over your infrastructure resources.\n  Amazon ECS Express Mode streamlines the deployment and management of containerized applications on AWS, allowing developers to focus on delivering business value through their containerized applications. Every Express Mode service automatically receives an AWS-provided domain name, making your application immediately accessible without additional configuration. Applications using ECS Express Mode incorporate AWS operational best practices, serve either public or private HTTPS requests, and scale in response to traffic patterns. Traffic is distributed through Application Load Balancer (ALB)s, and automatically consolidates up to 25 Express Mode services behind a single ALB when appropriate. ECS Express uses intelligent rule-based routing to maintain isolation between services while efficiently utilizing the ALB resource. All resources provisioned by ECS Express Mode remain fully accessible in your account, ensuring you never sacrifice control or flexibility. As your application requirements evolve, you can directly access and modify any infrastructure resource, leveraging the complete feature set of Amazon ECS and related services without disruption to your running applications.\n  To get started just provide your container image, and ECS Express Mode handles the rest by deploying your application in Amazon ECS and auto-generating a URL. Amazon ECS Express Mode is available now in all AWS Regions at no additional charge. You pay only for the AWS resources created to run your application. To deploy a new ECS Express Mode service, use the Amazon ECS Console, SDK, CLI, CloudFormation, CDK and Terraform. For more information, see the AWS News blog, or the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/announcing-amazon-ecs-express-mode",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ecs",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ecs",
        "cloudformation",
        "launch",
        "new-feature"
      ]
    },
    {
      "id": "aws-news-8f83d9fc597b",
      "title": "Announcing AWS Lambda Kafka event source mapping integration in Amazon MSK Console",
      "description": "AWS announces Lambda’s Kafka event source mapping (ESM) integration in the Amazon MSK Console, streamlining the process of connecting MSK topics to Lambda functions. This capability allows you to simply provide your topic and target function in the MSK Console while the integration handles ESM configuration automatically, enabling you to trigger Lambda functions from MSK topics without switching consoles.\n  Customers use MSK as an event source for Lambda functions to build responsive event-driven Kafka applications. Previously, configuring MSK as an event source required navigating between MSK and Lambda consoles to provide parameters like cluster details, authentication method, and network configuration. The new integrated experience brings Lambda ESM configuration directly into the MSK Console with a simplified interface requiring only target function and topic name as mandatory fields. The integration handles ESM creation with optimized defaults for authentication and event polling configurations, and can automatically generate the required Lambda execution role permissions for MSK cluster access. To optimize latency and throughput, and to remove the need for networking setup, the integration uses Provisioned Mode for ESM as the recommended default. These improvements streamline MSK integration with Lambda and reduce configuration errors, enabling you to quickly get started with your MSK and Lambda applications.\n  This feature is generally available in all AWS Commercial Regions where both Amazon MSK and AWS Lambda are available, except Asia Pacific (Thailand), Asia Pacific (Malaysia), Israel (Tel Aviv), Asia Pacific (Taipei), and Canada West (Calgary).\n  You can configure Lambda’s Kafka event source mapping from the MSK Console by navigating to your MSK cluster and providing the topic, Lambda function, and optional fields under the Lambda integration tab. Standard Lambda pricing and MSK pricing applies. To learn more, read Lambda developer guide and MSK developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/integration-lambda-source-mapping-configuration/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "kafka",
        "msk"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "kafka",
        "msk",
        "generally-available",
        "ga",
        "improvement",
        "integration"
      ]
    },
    {
      "id": "aws-news-7737759ca591",
      "title": "AWS Lambda announces new capabilities to optimize costs up to 90% for Provisioned mode for Kafka ESM",
      "description": "AWS Lambda announces new capabilities for Provisioned mode for Kafka event source mappings (ESMs) that allow you to group your Kafka ESMs and support higher density of event pollers, enabling you to optimize costs up to 90% for your Kafka ESMs. With these cost optimization capabilities, you can now use Provisioned mode for all your Kafka workloads, including those with lower throughput requirements, while benefiting from features like throughput controls, schema validation, filtering of Avro/Protobuf events, low-latency invocations, and enhanced error handling.\n  Customers use Provisioned mode for Kafka ESM to fine-tune the throughput of the ESM by provisioning and auto-scaling polling resources called event pollers. Charges are calculated using a billing unit called Event Poller Unit (EPU). Each EPU supports up to 20 MB/s of throughput capacity, and a default of 4 event pollers per EPU. With this launch, each EPU automatically supports a default of 10 event pollers for low-throughput use cases, improving utilization of your EPU capacity. Additionally, you can now group multiple Kafka ESMs within the same Amazon VPC to share EPU capacity by configuring the new PollerGroupName parameter. With these enhancements, you can reduce your EPU costs up to 90% for your low throughput workloads. These optimizations enable you to maintain the performance benefits of Provisioned mode while significantly reducing costs for applications with varying throughput requirements.\n  This feature is available in all AWS Commercial Regions where AWS Lambda’s Provisioned mode for Kafka ESM is available. \n  Starting today, existing Provisioned mode for Kafka ESMs will automatically benefit from improved packing of low-throughput event pollers. You can implement ESM grouping through the Lambda ESM API, AWS Console, CLI, SDK, CloudFormation, and SAM by configuring the PollerGroupName parameter along with minimum and maximum event poller settings. For more information about these new capabilities and pricing details, visit the Lambda ESM documentation and AWS Lambda pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-lambda-optimize-costs-provisioned-mode-kafka/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "cloudformation",
        "kafka"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda",
        "cloudformation",
        "kafka",
        "launch",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-d0209dd90f91",
      "title": "Amazon Route 53 DNS service adds support for IPv6 API service endpoint",
      "description": "Starting today, Amazon Route 53 supports dual stack for the Route 53 DNS service API endpoint at route53.global.api.aws, enabling you to connect from Internet Protocol Version 6 (IPv6), Internet Protocol Version 4 (IPv4), or dual stack clients. The existing Route 53 DNS service IPv4 API endpoint will remain available for backwards compatibility.\n  Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service that allows customers to register a domain, setup DNS records corresponding to your infrastructure, perform global traffic routing using Traffic Flow, and use Route 53 health checks to monitor the health and performance of your applications and resources. Due to the continued growth of the internet, IPv4 address space is being exhausted and customers are transitioning to IPv6 addresses. Now, clients can connect via IPv6 to the Route 53 DNS service API endpoint, enabling organizations to meet compliance requirements and removing the added complexity of IP address translation between IPv4 and IPv6.\n  Support for IPv6 on the Route 53 DNS service API endpoint is available in all Commercial Regions and available at no additional cost. You can get started with this feature through the AWS CLI or AWS Management Console. To learn more about which Route 53 features are accessible via the route53.amazon.aws service endpoint, visit this page and to learn more about the Route 53 DNS service, visit our documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-route-53-dns-service-ipv6-api-endpoint/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "rds",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-fe1425322358",
      "title": "Amazon Connect now supports multi skill agent scheduling",
      "description": "Amazon Connect now enables you to optimize scheduling based on agent’s multiple specialized skills. You can now maximize agent utilization across multiple dimensions such as departments, languages, and customer tiers by intelligently matching agents with multiple skills to forecasted demand. You can now also preserve multi-skilled agents for high-value interactions when needed most. For example, bilingual agents can now be strategically scheduled to cover peak periods for high-value French language queues that frequently experience staffing shortages, while handling general inquiries during off-peak times.\n  This feature is available in all AWS Regions where Amazon Connect agent scheduling is available. To learn more about multi skill agent scheduling, visit the blog and admin guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-multi-skill-agent-scheduling",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "forecast"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "forecast",
        "support"
      ]
    },
    {
      "id": "aws-news-196cf0862d39",
      "title": "Amazon Athena launches auto-scaling solution for Capacity Reservations",
      "description": "Amazon Athena now offers an auto-scaling solution for Capacity Reservations that dynamically adjusts your reserved capacity based on workload demand. The solution uses AWS Step Functions to monitor utilization metrics and scale your Data Processing Units (DPUs) up or down according to the thresholds and limits you configure, helping you optimize costs while maintaining query performance and eliminating the need for manual capacity adjustments.\n  You can customize scaling behavior by setting utilization thresholds, measurement frequency, and capacity limits to match your workload needs. The solution uses Step Functions to add or remove DPUs to any active Capacity Reservation based on capacity utilization metrics in Amazon CloudWatch. Capacity automatically scales up when utilization exceeds your high threshold and scales down when it falls below your low threshold - all while adhering to your defined limits. You can further customize the solution by modifying the Amazon CloudFormation template to fit your specific requirements.\n  The auto-scaling solution for Athena Capacity Reservations is available in AWS Regions where Capacity Reservations is supported. To get started, see Automatically adjust capacity in the Athena user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-athena-capacity-auto-scaling",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "cloudformation",
        "athena",
        "step functions",
        "cloudwatch"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "cloudformation",
        "athena",
        "step functions",
        "cloudwatch",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-bfa79d7ad5e5",
      "title": "AWS Glue launches Amazon DynamoDB connector with Spark DataFrame support",
      "description": "AWS Glue now supports a new Amazon DynamoDB connector that works natively with Apache Spark DataFrames. This enhancement allows Spark developers to work directly with Spark DataFrames, to share code easily across AWS Glue, Amazon EMR, and other Spark environments.\n  Previously, developers working with DynamoDB data in AWS Glue were required to use the Glue-specific DynamicFrame object. With this new connector, developers can now reuse their existing Spark DataFrame code with minimal modifications. This change streamlines the process of migrating jobs to AWS Glue and simplifies data pipeline development. Additionally, the connector unlocks access to the full range of Spark DataFrame operations and the latest performance optimizations.\n  The new connector is available in all AWS Commercial Regions where AWS Glue is available. To get started, visit AWS Glue documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/glue-dynamodb-connector",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "emr",
        "dynamodb",
        "glue"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "emr",
        "dynamodb",
        "glue",
        "launch",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-8b260ff8c405",
      "title": "Amazon CloudWatch Application Signals adds GitHub Action and MCP server improvements",
      "description": "AWS announces the general availability of a new GitHub Action and improvements to CloudWatch Application Signals MCP server that bring application observability into developer tools, making troubleshooting issues faster and more convenient. Previously, developers had to leave GitHub to triage production issues, look up trace data, and ensure observability coverage, often switching between consoles, dashboards, and source code. Starting today, Application observability for AWS GitHub Action helps you catch breaching SLOs or critical service errors, in GitHub workflows. In addition, now you can use the CloudWatch Application Signals MCP server in AI coding agents such as Kiro to identify the exact file, function, and line of code responsible for latency, errors, or SLO violations. Furthermore, you can get instrumentation guidance that ensures comprehensive observability coverage.\n  With this new GitHub Action, developers can mention @awsapm in GitHub Issues with prompts like \"Why is my checkout service experiencing high latency?\" and receive intelligent, observability-based responses without switching between consoles, saving time and effort. In addition, with improvements in CloudWatch Application Signals MCP server, developers can now ask questions like \"Which line of code caused the latency spike in my service?\". Furthermore, when instrumentation is missing, the MCP server can modify infrastructure-as-code (e.g., CDK, Terraform) to help teams set up OTel-based application performance monitoring for ECS, EKS, Lambda, and EC2 without requiring coding effort.\n  Together, these features bring observability into development workflows, reduce context switching, and power intelligent, agent-assisted debugging from code to production. To get started, visit Application Observability for AWS GitHub Action documentation and the CloudWatch Application Signals MCP server documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-cloudwatch-application-signals-adds-github-action-mcp-server-improvements",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lambda",
        "ec2",
        "rds",
        "ecs",
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lambda",
        "ec2",
        "rds",
        "ecs",
        "eks",
        "cloudwatch",
        "improvement"
      ]
    },
    {
      "id": "aws-news-19f26c5c37ab",
      "title": "AWS Network Firewall now supports flexible cost allocation via Transit Gateway",
      "description": "AWS Network Firewall now supports flexible cost allocation through AWS Transit Gateway native attachments, enabling you to automatically distribute data processing costs across different AWS accounts. Customers can create metering policies to apply data processing charges based on their organization's chargeback requirements instead of consolidating all expenses in the firewall owner account.\n  This capability helps security and network teams better manage centralized firewall costs by distributing charges to application teams based on actual usage. Organizations can now maintain centralized security controls while automatically allocating inspection costs to the appropriate business units or application owners, eliminating the need for custom cost management solutions.\n  Flexible cost allocation is available in all AWS Commercial Regions and Amazon China Regions where both AWS Network Firewall and Transit Gateway attachments are supported. There are no additional charges for using this attachment or flexible cost allocation beyond standard pricing of AWS Network Firewall and AWS Transit Gateway.\n  To learn more, visit the AWS Network Firewall service documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/network-firewall-flexible-cost-allocation/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-7397a704b760",
      "title": "Amazon CloudWatch Introduces In-Console Agent Management on EC2",
      "description": "Amazon CloudWatch now offers an in-console experience for automated installation and configuration of the Amazon CloudWatch agent on EC2 instances. Amazon CloudWatch agent is used by developers and SREs to collect infrastructure and application metrics, logs, and traces from EC2 and send them to CloudWatch and AWS X-Ray. This new experience provides visibility into agent status across your EC2 fleet, performs automatic detection of supported workloads, and leverages CloudWatch observability solutions to recommend monitoring configurations based on detected workloads.\n  Customers can now deploy the CloudWatch agent through one-click installation to individual instances or by creating tag-based policies for automated fleet-wide management. The automated policies ensure newly launched instances, including those created through auto-scaling, are automatically configured with the appropriate monitoring settings. By simplifying agent deployment and providing intelligent configuration recommendations, customers can ensure consistent monitoring across their environment while reducing setup time from hours to minutes.\n  Amazon CloudWatch agent is available in the following AWS regions: Europe (Stockholm), Asia Pacific (Mumbai), Europe (Paris), US East (Ohio), Europe (Ireland), Europe (Frankfurt), South America (Sao Paulo), US East (N. Virginia), Asia Pacific (Seoul), Asia Pacific (Tokyo), US West (Oregon), US West (N. California), Asia Pacific (Singapore), Asia Pacific (Sydney), and Canada (Central).\n  To get starting with Amazon CloudWatch agent in the CloudWatch console, see Installing the CloudWatch agent in the Amazon CloudWatch User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/cloudwatch-in-console-agent-management-ec2/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch",
        "launch",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-c81f71906b53",
      "title": "AWS Security Incident Response now offers metered pricing with free tier",
      "description": "Today, AWS Security Incident Response announces a new metered pricing model that charges customers based on the number of security findings ingested, making automated security incident response capabilities and expert guidance from the AWS Customer Incident Response Team (CIRT) more flexible and scalable for organizations of all sizes.\n  The new pricing model introduces a free tier covering the first 10,000 findings per month, allowing security teams to explore and validate the service's value at no cost. Customers pay $0.000676 per finding after the free tier, with tiered discounts that reduce rates as volume increases. This consumption-based approach enables customers to scale their security incident response capabilities as their needs evolve, without upfront commitments or minimum fees. Customers can monitor the number of monthly findings through Amazon CloudWatch at no additional cost, making it easy to track usage against the free tier and any applicable charges.\n  The new pricing model automatically applies to all AWS Regions where Security Incident Response is available starting November 21, 2025, requiring no action from customers. \n  To learn more, visit the Security Incident Response pricing page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/security-incident-response-metered-pricing-free-tier/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "cloudwatch",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "cloudwatch",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-4d94683bb916",
      "title": "Amazon Simple Email Service is now available in two new AWS Regions",
      "description": "Amazon Simple Email Service (Amazon SES) is now available in the Asia Pacific (Malaysia), Canada West (Calgary) Regions. Customers can now use these new Regions to leverage Amazon SES to send emails and, if needed, to help manage data sovereignty requirements.\n  Amazon SES is a scalable, cost-effective, and flexible cloud-based email service that allows digital marketers and application developers to send marketing, notification, and transactional emails from within any application. To learn more about Amazon SES, visit this page.\n  With this launch, Amazon SES is available in 29 AWS Regions globally: US East (Virginia, Ohio), US West (N. California, Oregon), AWS GovCloud (US-West, US-East), Asia Pacific (Osaka, Mumbai, Hyderabad, Sydney, Singapore, Seoul, Tokyo, Jakarta, Malaysia), Canada (Central, Calgary), Europe (Ireland, Frankfurt, London, Paris, Stockholm, Milan, Zurich), Israel (Tel Aviv), Middle East (Bahrain, UAE), South America (São Paulo), and Africa (Cape Town).\n  For a complete list of all of the regional endpoints for Amazon SES, see AWS Service Endpoints in the AWS General Reference.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ses-available-in-two-new-regions",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "launch",
        "ga",
        "now-available",
        "new-region"
      ]
    },
    {
      "id": "aws-news-334b22c260de",
      "title": "Amazon ECS and Amazon EKS now offer enhanced AI-powered troubleshooting in the Console",
      "description": "Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS) now offer enhanced AI-powered troubleshooting experiences in the AWS Management Console through Amazon Q Developer. The new AI-powered experiences appear contextually alongside error or status messages in the console, helping customers root cause issues and view mitigation suggestions with a single click.\n  In the ECS Console, customers can use the new “Inspect with Amazon Q” button to troubleshoot issues such as failed tasks, container health check failures, or deployment rollbacks. Simply click the status reason on task details, task definition details, or deployment details page, and click “Inspect with Amazon Q” from the popover to start troubleshooting with context from the issue provided to the agent for you. Once clicked, Amazon Q automatically uses appropriate AI tools to analyze the issue, gather the relevant logs and metrics, help you understand the root cause, and recommend mitigation actions.\n  The Amazon EKS console integrates Amazon Q throughout the observability dashboard, enabling you to inspect and troubleshoot cluster, control plane, and node health issues with contextual AI assistance. Simply click \"Inspect with Amazon Q\" directly from tables that outline issues, or click on an issue to view details and then select \"Inspect with Amazon Q\" to begin your investigation. The Q-powered experience provides deeper understanding of cluster-level insights, such as upgrade insights, helping you proactively identify and mitigate potential issues. Amazon Q also streamlines workload troubleshooting by helping you investigate Kubernetes events on pods that indicate issues, accelerating root cause identification and resolution.\n  Amazon Q integration in the Amazon ECS and Amazon EKS consoles is now available in all AWS commercial regions. To learn more, visit the ECS developer guide and EKS user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-ecs-eks-ai-powered-troubleshooting-console/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "q developer",
        "ecs",
        "eks"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer",
        "ecs",
        "eks",
        "ga",
        "now-available",
        "integration"
      ]
    },
    {
      "id": "aws-news-77f3836159eb",
      "title": "AWS Backup now supports Amazon FSx Intelligent-Tiering",
      "description": "AWS Backup now supports Amazon FSx Intelligent-Tiering, a storage class which delivers fully elastic file storage that automatically scales up and down with your workloads.\n \nThe FSx Intelligent-Tiering storage class is available for FSx for Lustre and Amazon FSx for OpenZFS file systems and combines performance, pay-for-what-you-use elasticity, with automated cost optimization in a single solution. With this integration, you can now protect OpenZFS and Lustre file systems using FSx Intelligent-Tiering through AWS Backup's centralized backup management capabilities. Customers with existing backup plans for Amazon FSx do not need to make any changes, as all scheduled backups will continue to work as expected.\n \nAWS Backup support is available in all AWS Regons where FSx Intelligent Tiering is available. For a full list of supported Regions see region availability documentation for Amazon FSx for OpenZFS and Amazon FSx for Lustre.\n \nTo learn more about AWS Backup for Amazon FSx, visit the AWS Backup product page, technical documentation, and pricing page. For more information on the AWS Backup features available across AWS Regions, see AWS Backup documentation. To get started, visit the AWS Backup console.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-backup-amazon-fsx-intelligent-tiering/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-bc64fccd13cf",
      "title": "AWS Application Load Balancer now supports Health Check Logs",
      "description": "AWS Application Load Balancers (ALB) now supports Health Check Logs that allows you to send detailed target health check log data directly to your designated Amazon S3 bucket. This optional feature captures comprehensive target health check status, timestamp, target identification data, and failure reasons.\n  Health Check Logs provide complete visibility into target health status with precise failure diagnostics, enabling faster troubleshooting without contacting AWS Support. You can analyze target’s health patterns over time, determine exactly why instances were marked unhealthy, and significantly reduce mean time to resolution for target health investigations. Logs are automatically delivered to your S3 bucket every 5 minutes with no additional charges beyond standard S3 storage costs.\n  This feature is available in all AWS Commercial Regions, AWS GovCloud (US) Regions and AWS China Regions where Application Load Balancer is offered. You can enable Health Check Logs through the AWS Management Console, AWS CLI, or programmatically using the AWS SDK. Learn more about Health Check Logs for ALBs in the AWS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/application-load-balancer-health-check-logs/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-f260f044f173",
      "title": "Amazon ECS Managed Instances now available in AWS GovCloud (US) Regions",
      "description": "Amazon Elastic Container Service (Amazon ECS) Managed Instances is now available in the AWS GovCloud (US-East) and AWS GovCloud (US-West) Regions. ECS Managed Instances is a fully managed compute option designed to eliminate infrastructure management overhead while giving you access to the full capabilities of Amazon EC2. By offloading infrastructure operations to AWS, you get the application performance you want and the simplicity you need while reducing your total cost of ownership.\n  Managed Instances dynamically scales EC2 instances to match your workload requirements and continuously optimizes task placement to reduce infrastructure costs. It also enhances your security posture through regular security patching initiated every 14 days. You can simply define your task requirements such as the number of vCPUs, memory size, and CPU architecture, and Amazon ECS automatically provisions, configures and operates most optimal EC2 instances within your AWS account using AWS-controlled access. You can also specify desired instance types in Managed Instances Capacity Provider configuration, including GPU-accelerated, network-optimized, and burstable performance, to run your workloads on the instance families you prefer.\n  To get started with ECS Managed Instances, use the AWS Console, Amazon ECS MCP Server, or your favorite infrastructure-as-code tooling to enable it in a new or existing Amazon ECS cluster. You will be charged for the management of compute provisioned, in addition to your regular Amazon EC2 costs. To learn more about ECS Managed Instances, visit the feature page, documentation, and AWS News launch blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/ecs-managed-instances-govcloud-us-regions/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "ecs"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "ec2",
        "ecs",
        "launch",
        "now-available"
      ]
    },
    {
      "id": "aws-news-c81911906ddc",
      "title": "Amazon CloudWatch Container Insights now supports Neuron UltraServers on Amazon EKS",
      "description": "Amazon CloudWatch Container Insights now supports Neuron UltraServers on Amazon EKS, providing enhanced observability for customers running large-scale, high-performance machine learning workloads on multi-instance nodes. This new capability enables data scientists and ML engineers to efficiently monitor and troubleshoot their containerized ML applications, offering aggregated metrics and simplified management across Neuron UltraServer groups.\n \nNeuron UltraServers combine multiple EC2 instances into a single logical server unit, optimized for machine learning workloads using AWS Trainium and Inferentia accelerators. Container Insights, a monitoring and diagnostics feature in Amazon CloudWatch, automatically collects metrics from containerized applications. With this launch, Container Insights introduces a new filter specifically for UltraServers in EKS environments. You can now select an UltraServer ID to view new aggregate metrics across all instances within that server, replacing the need to monitor individual instances separately. In addition to per-instance metrics, you can now view consolidated performance data for the entire UltraServer group, streamlining the monitoring of ML workloads running on AWS Neuron.\n \nAmazon CloudWatch Container Insights is available in all commercial AWS Regions, and the AWS GovCloud (US).\n \nTo get started, see AWS Neuron metrics for AWS Trainium and AWS Inferentia in the Amazon CloudWatch User Guide",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/cloudwatch-container-insights-neuron-ultraservers-eks/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "trainium",
        "inferentia",
        "neuron",
        "ec2",
        "eks",
        "cloudwatch"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "trainium",
        "inferentia",
        "neuron",
        "ec2",
        "eks",
        "cloudwatch",
        "launch",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-4da517056174",
      "title": "Amazon RDS for Oracle is now available with Oracle Database Standard Edition 2 (SE2) License Included instances in Asia Pacific (Taipei) region",
      "description": "Amazon Relational Database Service (Amazon RDS) for Oracle now offers Oracle Database Standard Edition 2 (SE2) License Included R7i and M7i instances in Asia Pacific (Taipei) region.\n  With Amazon RDS for Oracle SE2 License Included instances, you do not need to purchase Oracle Database licenses. You simply launch Amazon RDS for Oracle instances through the AWS Management Console, AWS CLI, or AWS SDKs, and there are no separate license or support charges. Review the AWS blog Rethink Oracle Standard Edition Two on Amazon RDS for Oracle to explore how you can lower cost and simplify operations by using Amazon RDS Oracle SE2 License Included instances for your Oracle databases.\n  To learn more about pricing and regional availability, see Amazon RDS for Oracle pricing.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-rds-oracle-se2-license-included-taipei-region",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "launch",
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-fc0fa46be7cd",
      "title": "Amazon Quick Sight dashboard customization now includes tables and pivot tables",
      "description": "Amazon Quick Sight has expanded customization capabilities to include tables and pivot tables in dashboards. This update enables readers to personalize their data views by sorting, reordering, hiding/showing, and freezing columns—all without requiring updates from dashboard authors.\n  These capabilities are especially valuable for teams that need to tailor dashboard views for different analytical needs and collaborate across departments. For example, sales managers can quickly sort by revenue to identify top performers, while finance teams can freeze account columns to maintain context in large datasets.\n  These new customization features are now available in Amazon Quick Sight Enterprise Edition across all supported Amazon Quick Sight regions. Learn how to get started with these new customization features in our blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-quick-sight-dashboard-tables-pivot-tables/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "amazon q",
        "personalize",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "personalize",
        "rds",
        "now-available",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-b1cb91f9fe96",
      "title": "AWS Transfer Family web apps now support VPC endpoints",
      "description": "AWS Transfer Family web apps now supports Virtual Private Cloud (VPC) endpoints, enabling private access to your web app at no additional charge. This allows your users to securely access and manage files in Amazon S3 through a web browser while maintaining all traffic within your VPC.\n  Transfer Family web apps provide a simple and secure web interface for accessing your data in Amazon S3. With this launch, your workforce users can connect through your VPC directly, AWS Direct Connect, or VPN connections. This enables you to support internal use cases requiring strict security controls, such as regulated document workflows and sensitive data sharing, while leveraging the security controls and network configurations already defined in your VPC. You can manage access using security groups based on source IP addresses, implement subnet-level filtering through NACLs, and ensure all file transfers remain within your private network boundary, maintaining full visibility and control over all network traffic. \n  VPC endpoints for web apps are available in select AWS Regions at no additional charge. To get started, visit the AWS Transfer Family console, or use AWS CLI/SDK. To learn more, visit the Transfer Family User Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/transfer-family-web-apps-vpc-endpoints/",
      "pubDate": "2025-11-21T08:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "s3"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "s3",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-d48c6bab49bb",
      "title": "Serverless strategies for streaming LLM responses",
      "description": "Modern generative AI applications often need to stream large language model (LLM) outputs to users in real-time. Instead of waiting for a complete response, streaming delivers partial results as they become available, which significantly improves the user experience for chat interfaces and long-running AI tasks. This post compares three serverless approaches to handle Amazon Bedrock LLM streaming on Amazon Web Services (AWS), which helps you choose the best fit for your application.",
      "link": "https://aws.amazon.com/blogs/compute/serverless-strategies-for-streaming-llm-responses/",
      "pubDate": "2025-11-21T03:42:56.000Z",
      "source": "computeBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-73b319ca71d2",
      "title": "Introducing attribute-based access control for Amazon S3 general purpose buckets",
      "description": "AWS introduces Attribute-Based Access Control (ABAC) for S3 general purpose buckets, enabling administrators to automatically manage permissions through tag-based policies that match tags between users, roles, and buckets—eliminating the need to constantly update IAM policies as organizations scale.",
      "link": "https://aws.amazon.com/blogs/aws/introducing-attribute-based-access-control-for-amazon-s3-general-purpose-buckets/",
      "pubDate": "2025-11-21T01:02:35.000Z",
      "source": "newsBlog",
      "services": [
        "s3",
        "iam",
        "organizations"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "s3",
        "iam",
        "organizations",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-c48032d4f03b",
      "title": "Amazon Connect now offers persistent agent connections for faster call handling",
      "description": "Amazon Connect now offers the ability to maintain an open communication channel between your agents and Amazon Connect, helping reduce the time it takes to establish a connection with a customer. Contact center administrators can configure an agent’s user profile to maintain a persistent connection after a conversation ends, allowing for subsequent calls to connect faster. Amazon Connect persistent agent connection makes it easier to support compliance requirements with telemarketing laws such as the U.S. Telephone Consumer Protection Act (TCPA) for outbound campaigns’ calling by reducing the time it takes for a customer to connect with your agents.\n  Amazon Connect persistent connection is now available in all AWS regions where Amazon Connect is offered, and there is no additional charge beyond standard pricing for the Amazon Connect service usage and associated telephony charges. To learn more, visit our product page or refer to our Admin Guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-connect-persistent-agent-connections",
      "pubDate": "2025-11-20T22:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-7f65f9fc8258",
      "title": "Validate and enforce required tags in CloudFormation, Terraform and Pulumi with Tag Policies",
      "description": "AWS Organizations Tag Policies announces Reporting for Required Tags, a new validation check that proactively ensures your CloudFormation, Terraform, and Pulumi deployments include the required tags critical to your business. Your infrastructure-as-code (IaC) operations can now be automatically validated against tag policies to ensure tagging consistency across your AWS environments. With this, you can ensure compliance for your IaC deployments in two simple steps: 1) define your tag policy, and 2) enable validation in each IaC tool.\n  Tag Policies enables you to enforce consistent tagging across your AWS accounts with proactive compliance, governance, and control. With this launch, you can specify mandatory tag keys in your tag policies, and enforce guardrails for your IaC deployments. For example, you can define a tag policy that all EC2 instances in your IaC templates must have “Environment”, “Owner”, and “Application” as required tag keys. You can start validation by activating AWS::TagPolicies::TaggingComplianceValidator Hook in CloudFormation, adding validation logic in your Terraform plan, or activating aws-organizations-tag-policies pre-built policy pack in Pulumi. Once configured, all CloudFormation, Terraform, and Pulumi deployments in the target account will be automatically validated and/or enforced against your tag policies, ensuring that resources like EC2 instances include the required \"Environment\", \"Owner\", and \"Application\" tags.\n  You can use Reporting for Required Tags feature via AWS Management Console, AWS Command Line Interface, and AWS Software Development Kit. This feature is available with AWS Organizations Tag Policies in AWS Regions where Tag Policies is available. To learn more, visit Tag Policies documentation. To learn how to set up validation and enforcement, see the user guide for CloudFormation, this user guide for Terraform, and this blog post for Pulumi.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/validate-enforce-required-tags-cloudformation-terraform-pulumi/",
      "pubDate": "2025-11-20T19:28:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "cloudformation",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "ec2",
        "cloudformation",
        "organizations",
        "launch",
        "ga"
      ]
    },
    {
      "id": "aws-news-5d5e12cf24b1",
      "title": "AWS DMS Schema Conversion adds SAP (Sybase) ASE to PostgreSQL support with generative AI",
      "description": "AWS Database Migration Service (DMS) Schema Conversion is a fully managed feature of DMS that automatically assesses and converts database schemas to formats compatible with AWS target database services. Today, we're excited to announce that Schema Conversion now supports conversions from SAP Adaptive Server Enterprise (ASE) database (formerly known as Sybase) to Amazon RDS PostgreSQL and Amazon Aurora PostgreSQL, powered by Generative AI capability.\n  Using Schema Conversion, you can automatically convert database objects from your SAP (Sybase) ASE source to an to Amazon RDS PostgreSQL and Amazon Aurora PostgreSQL target. The integrated generative AI capability intelligently handles complex code conversions that typically require manual effort, such as stored procedures, functions, and triggers. Schema Conversion also provides detailed assessment reports to help you plan and execute your migration effectively.\n  To learn more about this feature, see the documentation for using SAP (Sybase) ASE as a source for AWS DMS Schema Conversion and using SAP (Sybase) ASE as a source for AWS DMS for data migration. For details about the generative AI capability, please refer to the User Guide. For AWS DMS Schema Conversion regional availability, please refer to the Supported AWS Regions page.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-dms-schema-conversion-sap-sybase-ase-postgresql/",
      "pubDate": "2025-11-20T19:11:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "rds",
        "support"
      ]
    },
    {
      "id": "aws-news-c2a79337519c",
      "title": "Enforce business glossary classification rules in Amazon SageMaker Catalog",
      "description": "Amazon SageMaker Catalog now supports metadata enforcement rules for glossary terms classification (tagging) at the asset level. With this capability, administrators can require that assets include specific business terms or classifications. Data producers must apply required glossary terms or classifications before an asset can be published. In this post, we show how to enforce business glossary classification rules in SageMaker Catalog.",
      "link": "https://aws.amazon.com/blogs/big-data/enforce-business-glossary-classification-rules-in-amazon-sagemaker-catalog/",
      "pubDate": "2025-11-20T18:39:41.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "support"
      ]
    },
    {
      "id": "aws-news-32281bfd2f59",
      "title": "Enhanced data discovery in Amazon SageMaker Catalog with custom metadata forms and rich text documentation",
      "description": "Amazon SageMaker Catalog now supports custom metadata forms and rich text descriptions at the column level, extending existing curation capabilities for business names, descriptions, and glossary term classifications. Column-level context is essential for understanding and trusting data. This release helps organizations improve data discoverability, collaboration, and governance by letting metadata stewards document columns using structured and formatted information that aligns with internal standards. In this post, we show how to enhance data discovery in SageMaker Catalog with custom metadata forms and rich text documentation at the schema level.",
      "link": "https://aws.amazon.com/blogs/big-data/enhanced-data-discovery-in-amazon-sagemaker-catalog-with-custom-metadata-forms-and-rich-text-documentation/",
      "pubDate": "2025-11-20T18:35:07.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "rds",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "rds",
        "organizations",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-e746385d2aa7",
      "title": "MSD explores applying generative Al to improve the deviation management process using AWS services",
      "description": "This blog post has explores how MSD is harnessing the power of generative AI and databases to optimize and transform its manufacturing deviation management process. By creating an accurate and multifaceted knowledge base of past events, deviations, and findings, the company aims to significantly reduce the time and effort required for each new case while maintaining the highest standards of quality and compliance.",
      "link": "https://aws.amazon.com/blogs/machine-learning/msd-explores-applying-generative-al-to-improve-the-deviation-management-process-using-aws-services/",
      "pubDate": "2025-11-20T18:21:49.000Z",
      "source": "mlBlog",
      "services": [
        "rds"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "rds"
      ]
    },
    {
      "id": "aws-news-82390b5e23c0",
      "title": "Accelerating genomics variant interpretation with AWS HealthOmics and Amazon Bedrock AgentCore",
      "description": "In this blog post, we show you how agentic workflows can accelerate the processing and interpretation of genomics pipelines at scale with a natural language interface. We demonstrate a comprehensive genomic variant interpreter agent that combines automated data processing with intelligent analysis to address the entire workflow from raw VCF file ingestion to conversational query interfaces.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerating-genomics-variant-interpretation-with-aws-healthomics-and-amazon-bedrock-agentcore/",
      "pubDate": "2025-11-20T18:18:21.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "agentcore"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "agentcore"
      ]
    },
    {
      "id": "aws-news-efa2bd21663c",
      "title": "How Rufus scales conversational shopping experiences to millions of Amazon customers with Amazon Bedrock",
      "description": "Our team at Amazon builds Rufus, an AI-powered shopping assistant which delivers intelligent, conversational experiences to delight our customers. More than 250 million customers have used Rufus this year. Monthly users are up 140% YoY and interactions are up 210% YoY. Additionally, customers that use Rufus during a shopping journey are 60% more likely to […]",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-rufus-scales-conversational-shopping-experiences-to-millions-of-amazon-customers-with-amazon-bedrock/",
      "pubDate": "2025-11-20T18:13:39.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock"
      ]
    },
    {
      "id": "aws-news-84643ea6bd7f",
      "title": "Amazon RDS supports Multi-AZ for SQL Server Web Edition",
      "description": "Amazon Relational Database Service (Amazon RDS) for SQL Server now supports Multi-AZ deployment for SQL Server Web Edition. SQL Server Web Edition is specifically designed to support public and internet-accessible web pages, websites, web applications, and web services, and is used by web hosters and web value-added providers (VAPs). These applications need high availability, and automated failover to recover from hardware and database failures. Now customers can use SQL Server Web Edition with Amazon RDS Multi-AZ deployment option, which provides a high availability solution. The new feature eliminates the need for customers to use more expensive options for high availability, such as using SQL Server Standard Edition or Enterprise Edition.\n  To use the feature, customers simply configure their Amazon RDS for SQL Server Web Edition instance with Multi-AZ deployment option. Amazon RDS automatically provisions and maintains a standby replica in a different Availability Zone (AZ), and synchronously replicates data across the two AZs. In situations where your Multi-AZ primary database becomes unavailable, Amazon RDS automatically fails over to the standby replica, so customers can resume database operations quickly and without any administrative intervention.\n  For more information about Multi-AZ deployment for RDS SQL Server Web Edition, refer to the Amazon RDS for SQL Server User Guide. See Amazon RDS for SQL Server Pricing for pricing details and regional availability.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-rds-sql-server-multi-az-web-edition/",
      "pubDate": "2025-11-20T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "rds"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "rds",
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4d26789d0872",
      "title": "Amazon OpenSearch Serverless adds AWS PrivateLink for management console",
      "description": "Amazon OpenSearch Serverless now supports AWS PrivateLink for secure and private connectivity to management console. With AWS PrivateLink, you can establish a private connection between your virtual private cloud (VPC) and Amazon OpenSearch Serverless to create, manage, and configure your OpenSearch Serverless resources without using the public internet. By enabling private network connectivity, this enhancement eliminates the need to use public IP addresses or relying solely on firewall rules to access OpenSearch Serverless. With this feature release the OpenSearch Serverless management and data operations can be securely accessed through PrivateLinks. Data ingestion and query operations on collections still requires OpenSearch Serverless provided VPC endpoint configuration for private connectivity as described in the OpenSearch Serverless VPC developer guide.\n  You can use PrivateLink connections in all AWS Regions where Amazon OpenSearch Serverless is available. Creating VPC endpoints on AWS PrivateLink will incur additional charges; refer to AWS PrivateLink pricing page for details. You can get started by creating an AWS PrivateLink interface endpoint for Amazon OpenSearch Serverless using the AWS Management Console, AWS Command Line Interface (CLI), AWS Software Development Kits (SDKs), AWS Cloud Development Kit (CDK), or AWS CloudFormation. To learn more, refer to the documentation on creating an interface VPC endpoint for management console.\n  Please refer to the AWS Regional Services List for more information about Amazon OpenSearch Service availability. To learn more about OpenSearch Serverless, see the documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-opensearch-serverless-privatelink-mgmt",
      "pubDate": "2025-11-20T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "opensearch",
        "opensearch service",
        "cloudformation"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "cloudformation",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-30f53d85874d",
      "title": "Recycle Bin adds support for Amazon EBS Volumes",
      "description": "Recycle Bin for Amazon EBS, which helps you recover accidentally deleted snapshots and EBS-backed AMIs, now supports EBS Volumes. If you accidentally delete a volume, you can now recover it directly from Recycle Bin instead of restoring from a snapshot, reducing your recovery point objective with no data loss between the last snapshot and deletion. Your recovered volume can immediately achieve the full performance without waiting for data to download from snapshots.\n  To use Recycle Bin, you can set a retention period for deleted volumes, and you can recover any volume within that period. Recovered volumes are immediately available and will retain all attributes—tags, permissions, and encryption status. Volumes not recovered are deleted permanently when the retention period expires. You create retention rules to enable Recycle Bin for all volumes or specific volumes, using tags to target which volumes to protect.\n  EBS Volumes in Recycle Bin are billed at the same price as EBS Volumes, read more on the pricing page. To get started, read the documentation. The feature is now available through the AWS Command Line Interface (CLI), AWS SDKs, or the AWS Console in all AWS commercial, China, and AWS GovCloud (US) Regions.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/recycle-bin-support-amazon-ebs-volumes",
      "pubDate": "2025-11-20T18:00:00.000Z",
      "source": "whatsNew",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available",
        "support"
      ]
    },
    {
      "id": "aws-news-df24f6f1c182",
      "title": "Building multi-tenant SaaS applications with AWS Lambda’s new tenant isolation mode",
      "description": "Today, AWS is announcing tenant isolation for AWS Lambda, enabling you to process function invocations in separate execution environments for each end-user or tenant invoking your Lambda function. This capability simplifies building secure multi-tenant SaaS applications by managing tenant-level compute environment isolation and request routing, allowing you to focus on core business logic rather than implementing tenant-aware compute environment isolation.",
      "link": "https://aws.amazon.com/blogs/compute/building-multi-tenant-saas-applications-with-aws-lambdas-new-tenant-isolation-mode/",
      "pubDate": "2025-11-20T17:47:17.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-a1513f336f89",
      "title": "AWS Cloud WAN adds Routing Policy for advanced traffic control and flexible network deployments",
      "description": "AWS announces the general availability of Cloud WAN Routing Policy providing customers fine-grained controls to optimize route management, control traffic patterns, and customize network behavior across their global wide-area networks.\n  AWS Cloud WAN allows you to build, monitor, and manage a unified global network that interconnects your resources in the AWS cloud and your on-premises environments. Using the new Routing Policy feature, customers can perform advanced routing techniques such as route filtering and summarization to have better control on routes exchanged between AWS Cloud WAN and external networks. This feature enables customers to build controlled routing environments to minimize route reachability blast radius, prevent sub-optimal or asymmetric connectivity patterns, and avoid over-running of route-tables due to propagation of unnecessary routes in global networks. In addition, this feature allows customers to set advanced Border Gateway Protocol (BGP) attributes to customize network traffic behavior per their individual needs and build highly resilient hybrid-cloud network architectures. This feature also provides advanced visibility in the routing databases to allow rapid troubleshooting of network issues in complex multi-path environments.\n  The new Routing Policy feature is available in all AWS Regions where AWS Cloud WAN is available. You can enable these features using the AWS Management Console, AWS Command Line Interface (CLI) and the AWS Software Development Kit (SDK). There is no additional charge for enabling Routing Policy on AWS Cloud WAN. For more information, see the AWS Cloud WAN documentation pages and blog.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-cloud-wan-routing-policy/",
      "pubDate": "2025-11-20T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ga"
      ]
    },
    {
      "id": "aws-news-1497bc03310e",
      "title": "How Care Access achieved 86% data processing cost reductions and 66% faster data processing with Amazon Bedrock prompt caching",
      "description": "In this post, we demonstrate how healthcare organizations can securely implement prompt caching technology to streamline medical record processing while maintaining compliance requirements.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-care-access-achieved-86-data-processing-cost-reductions-and-66-faster-data-processing-with-amazon-bedrock-prompt-caching/",
      "pubDate": "2025-11-20T16:15:04.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-65756aeea0bc",
      "title": "AWS Glue supports additional SAP entities as zero-ETL integration sources",
      "description": "AWS Glue now supports full snapshot and incremental load ingestion for new SAP entities using zero-ETL integrations. This enhancement introduces full snapshot data ingestion for SAP entities that lack complete change data capture (CDC) functionality, while also providing incremental data loading capabilities for SAP entities that don't support the Operational Data Provisioning (ODP) framework. These new features work alongside existing capabilities for ODP-supported SAP entities, to give customers the flexibility to implement zero-ETL data ingestion strategies across diverse SAP environments.\n  Fully managed AWS zero-ETL integrations eliminate the engineering overhead associated with building custom ETL data pipelines. This new zero-ETL functionality enables organizations to ingest data from multiple SAP applications into Amazon Redshift or the lakehouse architecture of Amazon SageMaker to address scenarios where SAP entities lack deletion tracking flags or don't support the Operational Data Provisioning (ODP) framework. Through full snapshot ingestion for entities without deletion tracking and timestamp-based incremental loading for non-ODP systems, zero-ETL integrations reduce operational complexity while saving organizations weeks of engineering effort that would otherwise be required to design, build, and test custom data pipelines across diverse SAP application environments.\n  This feature is available in all AWS Regions where AWS Glue zero-ETL is currently available.\n  To get started with the enhanced zero-ETL coverage for SAP sources refer to the AWS Glue zero-ETL user guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-glue-additional-sap-entities-zero-etl-integration-sources",
      "pubDate": "2025-11-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "sagemaker",
        "lex",
        "redshift",
        "eks",
        "glue",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "lex",
        "redshift",
        "eks",
        "glue",
        "organizations",
        "ga",
        "new-feature",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-26ac62f98cf7",
      "title": "Amazon MSK Serverless expands availability to South America (São Paulo) region",
      "description": "You can now connect your Apache Kafka applications to Amazon MSK Serverless in the South America (São Paulo) AWS Regions.\n  Amazon MSK is a fully managed service for Apache Kafka and Kafka Connect that makes it easier for you to build and run applications that use Apache Kafka as a data store. Amazon MSK Serverless is a cluster type for Amazon MSK that allows you to run Apache Kafka without having to manage and scale cluster capacity. MSK Serverless automatically provisions and scales compute and storage resources, so you can use Apache Kafka on demand.\n  With these launches, Amazon MSK Serverless is now generally available in Asia Pacific (Sydney), Asia Pacific (Singapore), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Seoul), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (Stockholm), Europe (Paris), Europe (London), South America (São Paulo), US East (N. Virginia), US East (Ohio), and US West (Oregon) AWS regions. To learn more and get started, see our developer guide.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-msk-serverless-south-america-sao-paulo-region",
      "pubDate": "2025-11-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "kafka",
        "msk",
        "launch",
        "generally-available",
        "ga"
      ]
    },
    {
      "id": "aws-news-608d845b559d",
      "title": "AWS announces availability of Microsoft SQL Server 2025 images on Amazon EC2",
      "description": "Amazon EC2 now supports Microsoft SQL Server 2025 with License-Included (LI) Amazon Machine Images (AMIs), providing a quick way to launch the latest version of SQL Server. By running SQL Server 2025 on Amazon EC2, customers can take advantage of the security, performance, and reliability of AWS with the latest SQL Server features.\n  Amazon creates and manages Microsoft SQL Server 2025 AMIs to simplify the provisioning and management of SQL Server 2025 on EC2 Windows instances. These images support version 1.3 of the Transport Layer Security (TLS) protocol by default for enhanced performance and security. These images also come with pre-installed software such as AWS Tools for Windows PowerShell, AWS Systems Manager, AWS CloudFormation, and various network and storage drivers to make your management easier.\n  SQL Server 2025 AMIs are available in all commercial AWS Regions and the AWS GovCloud (US) Regions.\n  To learn more about the new AMIs, see SQL Server AMIs User Guide or read the blog post.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-availability-microsoft-sql-server-2025-images-amazon-ec2",
      "pubDate": "2025-11-20T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "ec2",
        "cloudformation"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudformation",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-b04be71f4d69",
      "title": "Improve API discoverability with the new Amazon API Gateway Portal",
      "description": "In this post, we will show how you can use the new portal feature to create customizable portals with enhanced security features in minutes, with APIs from multiple accounts, without managing any infrastructure.",
      "link": "https://aws.amazon.com/blogs/compute/improve-api-discoverability-with-the-new-amazon-api-gateway-portal/",
      "pubDate": "2025-11-20T00:41:25.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "api gateway",
        "ga"
      ]
    },
    {
      "id": "aws-news-9150859a247c",
      "title": "Building an AI gateway to Amazon Bedrock with Amazon API Gateway",
      "description": "In this post, we'll explore a reference architecture that helps enterprises govern their Amazon Bedrock implementations using Amazon API Gateway. This pattern enables key capabilities like authorization controls, usage quotas, and real-time response streaming. We'll examine the architecture, provide deployment steps, and discuss potential enhancements to help you implement AI governance at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/building-an-ai-gateway-to-amazon-bedrock-with-amazon-api-gateway/",
      "pubDate": "2025-11-19T23:33:41.000Z",
      "source": "architectureBlog",
      "services": [
        "bedrock",
        "api gateway"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "api gateway",
        "ga",
        "enhancement"
      ]
    },
    {
      "id": "aws-news-e3fa9789b76a",
      "title": "Getting started with Amazon S3 Tables in Amazon SageMaker Unified Studio",
      "description": "In this post, you learn how to integrate SageMaker Unified Studio with S3 Tables and query your data using Amazon Athena, Amazon Redshift, or Apache Spark in EMR and AWS Glue.",
      "link": "https://aws.amazon.com/blogs/big-data/getting-started-with-amazon-s3-tables-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-11-19T23:26:57.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "emr",
        "redshift",
        "glue",
        "athena"
      ]
    },
    {
      "id": "aws-news-c2cf5f1cc0c8",
      "title": "Claude Code deployment patterns and best practices with Amazon Bedrock",
      "description": "In this post, we explore deployment patterns and best practices for Claude Code with Amazon Bedrock, covering authentication methods, infrastructure decisions, and monitoring strategies to help enterprises deploy securely at scale. We recommend using Direct IdP integration for authentication, a dedicated AWS account for infrastructure, and OpenTelemetry with CloudWatch dashboards for comprehensive monitoring to ensure secure access, capacity management, and visibility into costs and developer productivity .",
      "link": "https://aws.amazon.com/blogs/machine-learning/claude-code-deployment-patterns-and-best-practices-with-amazon-bedrock/",
      "pubDate": "2025-11-19T23:17:38.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock",
        "rds",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "bedrock",
        "rds",
        "cloudwatch",
        "integration"
      ]
    },
    {
      "id": "aws-news-547c9eb92bd7",
      "title": "Building responsive APIs with Amazon API Gateway response streaming",
      "description": "Today, AWS announced support for response streaming in Amazon API Gateway to significantly improve the responsiveness of your REST APIs by progressively streaming response payloads back to the client. With this new capability, you can use streamed responses to enhance user experience when building LLM-driven applications (such as AI agents and chatbots), improve time-to-first-byte (TTFB) performance for web and mobile applications, stream large files, and perform long-running operations while reporting incremental progress using protocols such as server-sent events (SSE).",
      "link": "https://aws.amazon.com/blogs/compute/building-responsive-apis-with-amazon-api-gateway-response-streaming/",
      "pubDate": "2025-11-19T23:10:51.000Z",
      "source": "computeBlog",
      "services": [
        "api gateway"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "api gateway",
        "ga",
        "support",
        "new-capability"
      ]
    },
    {
      "id": "aws-news-2b846b60e936",
      "title": "Amazon Bedrock Guardrails expands support for code domain",
      "description": "Amazon Bedrock Guardrails now extends its safety controls to protect code generation across twelve programming languages, addressing critical security challenges in AI-assisted software development. In this post, we explore how to configure content filters, prompt attack detection, denied topics, and sensitive information filters to safeguard against threats like prompt injection, data exfiltration, and malicious code generation while maintaining developer productivity .",
      "link": "https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-guardrails-expands-support-for-code-domain/",
      "pubDate": "2025-11-19T22:27:14.000Z",
      "source": "mlBlog",
      "services": [
        "bedrock"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "bedrock",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-053825de2c68",
      "title": "Optimize latency-sensitive workloads with Amazon EC2 detailed NVMe statistics",
      "description": "Amazon Elastic Cloud Compute (Amazon EC2) instances with locally attached NVMe storage can provide the performance needed for workloads demanding ultra-low latency and high I/O throughput. High-performance workloads, from high-frequency trading applications and in-memory databases to real-time analytics engines and AI/ML inference, need comprehensive performance tracking. Operating system tools like iostat and sar provide valuable system-level insights, and Amazon CloudWatch offers important disk IOPs and throughput measurements, but high-performance workloads can benefit from even more detailed visibility into instance store performance.",
      "link": "https://aws.amazon.com/blogs/compute/optimize-latency-sensitive-workloads-with-amazon-ec2-detailed-nvme-statistics/",
      "pubDate": "2025-11-19T21:13:06.000Z",
      "source": "computeBlog",
      "services": [
        "ec2",
        "cloudwatch"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ec2",
        "cloudwatch"
      ]
    },
    {
      "id": "aws-news-cfb4396f0c51",
      "title": "Announcing the AWS Well-Architected Responsible AI Lens",
      "description": "Today, we're announcing the AWS Well-Architected Responsible AI Lens—a set of thoughtful questions and corresponding best practices that help builders address responsible AI concerns throughout development and operation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/announcing-the-aws-well-architected-responsible-ai-lens/",
      "pubDate": "2025-11-19T20:03:54.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": []
    },
    {
      "id": "aws-news-20066356eddb",
      "title": "How Amazon uses AI agents to support compliance screening of billions of transactions per day",
      "description": "Amazon's AI-powered Amazon Compliance Screening system tackles complex compliance challenges through autonomous agents that analyze, reason through, and resolve cases with precision. This blog post explores how Amazon’s Compliance team built its AI-powered investigation system through a series of AI agents built on AWS.",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-uses-ai-agents-to-support-compliance-screening-of-billions-of-transactions-per-day/",
      "pubDate": "2025-11-19T19:39:18.000Z",
      "source": "mlBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "lex",
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-4934fd40d9d8",
      "title": "Architecting for AI excellence: AWS launches three Well-Architected Lenses at re:Invent 2025",
      "description": "At re:Invent 2025, we introduce one new lens and two significant updates to the AWS Well-Architected Lenses specifically focused on AI workloads: the Responsible AI Lens, the Machine Learning (ML) Lens, and the Generative AI Lens. Together, these lenses provide comprehensive guidance for organizations at different stages of their AI journey, whether you're just starting to experiment with machine learning or already deploying complex AI applications at scale.",
      "link": "https://aws.amazon.com/blogs/architecture/architecting-for-ai-excellence-aws-launches-three-well-architected-lenses-at-reinvent-2025/",
      "pubDate": "2025-11-19T19:36:31.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "launch",
        "ga",
        "update"
      ]
    },
    {
      "id": "aws-news-61647c9310e0",
      "title": "Announcing the updated AWS Well-Architected Generative AI Lens",
      "description": "We are delighted to announce an update to the AWS Well-Architected Generative AI Lens. This update features several new sections of the Well-Architected Generative AI Lens, including new best practices, advanced scenario guidance, and improved preambles on responsible AI, data architecture, and agentic workflows.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-generative-ai-lens/",
      "pubDate": "2025-11-19T19:36:28.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-5044b6bc98c4",
      "title": "Announcing the updated AWS Well-Architected Machine Learning Lens",
      "description": "We are excited to announce the updated AWS Well-Architected Machine Learning Lens, now enhanced with the latest capabilities and best practices for building machine learning (ML) workloads on AWS.",
      "link": "https://aws.amazon.com/blogs/architecture/announcing-the-updated-aws-well-architected-machine-learning-lens/",
      "pubDate": "2025-11-19T19:36:25.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "update"
      ]
    },
    {
      "id": "aws-news-ef83678a3303",
      "title": "Streamlined multi-tenant application development with tenant isolation mode in AWS Lambda",
      "description": "AWS Lambda introduces tenant isolation mode, enabling separate execution environments for each tenant within a single function to meet strict security requirements without managing dedicated per-tenant infrastructure.",
      "link": "https://aws.amazon.com/blogs/aws/streamlined-multi-tenant-application-development-with-tenant-isolation-mode-in-aws-lambda/",
      "pubDate": "2025-11-19T19:12:27.000Z",
      "source": "newsBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-47fc10778da0",
      "title": "New business metadata features in Amazon SageMaker Catalog to improve discoverability across organizations",
      "description": "Amazon SageMaker Catalog now offers column-level metadata forms and enforced glossary requirements, enabling organizations to improve data classification, discoverability, and governance through standardized business metadata.",
      "link": "https://aws.amazon.com/blogs/aws/new-business-metadata-features-in-amazon-sagemaker-catalog-to-improve-discoverability-across-organizations/",
      "pubDate": "2025-11-19T19:09:27.000Z",
      "source": "newsBlog",
      "services": [
        "sagemaker",
        "organizations"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "sagemaker",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-4c7b0f7e2194",
      "title": "AWS Control Tower introduces a Controls Dedicated experience",
      "description": "AWS Control Tower now offers Control Only Experience, enabling faster governance setup for established multi-account environments by providing access to AWS managed controls without requiring a full landing zone implementation.",
      "link": "https://aws.amazon.com/blogs/aws/aws-control-tower-introduces-a-controls-dedicated-experience/",
      "pubDate": "2025-11-19T19:07:46.000Z",
      "source": "newsBlog",
      "services": [],
      "categories": [
        "news"
      ],
      "tags": []
    },
    {
      "id": "aws-news-9963d8402f47",
      "title": "New: AWS Billing Transfer for centrally managing AWS billing and costs across multiple organizations",
      "description": "AWS Billing Transfer enables customers to centrally manage and pay bills across multiple AWS organizations by allowing billing administrators to transfer payment responsibility while maintaining individual security and governance autonomy over their accounts.",
      "link": "https://aws.amazon.com/blogs/aws/new-aws-billing-transfer-for-centrally-managing-aws-billing-and-costs-across-multiple-organizations/",
      "pubDate": "2025-11-19T19:06:48.000Z",
      "source": "newsBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-3ae58d42c875",
      "title": "Monitor network performance and traffic across your EKS clusters with Container Network Observability",
      "description": "Amazon EKS introduces Container Network Observability, providing enhanced visibility into Kubernetes workload traffic and performance insights to help teams monitor and troubleshoot microservice environments.",
      "link": "https://aws.amazon.com/blogs/aws/monitor-network-performance-and-traffic-across-your-eks-clusters-with-container-network-observability/",
      "pubDate": "2025-11-19T19:05:59.000Z",
      "source": "newsBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-68402400a8cb",
      "title": "Build an agentic solution with Amazon Nova, Snowflake, and LangGraph",
      "description": "In this post, we cover how you can use tools from Snowflake AI Data Cloud and Amazon Web Services (AWS) to build generative AI solutions that organizations can use to make data-driven decisions, increase operational efficiency, and ultimately gain a competitive edge.",
      "link": "https://aws.amazon.com/blogs/machine-learning/build-an-agentic-solution-with-amazon-nova-snowflake-and-langgraph/",
      "pubDate": "2025-11-19T16:16:49.000Z",
      "source": "mlBlog",
      "services": [
        "nova",
        "organizations"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "nova",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-2f588c5f0196",
      "title": "Using Spectrum fine-tuning to improve FM training efficiency on Amazon SageMaker AI",
      "description": "In this post you will learn how to use Spectrum to optimize resource use and shorten training times without sacrificing quality, as well as how to implement Spectrum fine-tuning with Amazon SageMaker AI training jobs. We will also discuss the tradeoff between QLoRA and Spectrum fine-tuning, showing that while QLoRA is more resource efficient, Spectrum results in higher performance overall.",
      "link": "https://aws.amazon.com/blogs/machine-learning/using-spectrum-fine-tuning-to-improve-fm-training-efficiency-on-amazon-sagemaker-ai/",
      "pubDate": "2025-11-19T15:51:40.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker"
      ]
    },
    {
      "id": "aws-news-0801d7b479dd",
      "title": "Cross-account lakehouse governance with Amazon S3 Tables and SageMaker Catalog",
      "description": "In this post, we walk you through a practical solution for secure, efficient cross-account data sharing and analysis. You’ll learn how to set up cross-account access to S3 Tables using federated catalogs in Amazon SageMaker, perform unified queries across accounts with Amazon Athena in Amazon SageMaker Unified Studio, and implement fine-grained access controls at the column level using AWS Lake Formation.",
      "link": "https://aws.amazon.com/blogs/big-data/cross-account-lakehouse-governance-with-amazon-s3-tables-and-sagemaker-catalog/",
      "pubDate": "2025-11-18T23:01:03.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "s3",
        "athena"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "s3",
        "athena"
      ]
    },
    {
      "id": "aws-news-c38ecc4d691a",
      "title": "New Amazon Bedrock service tiers help you match AI workload performance with cost",
      "description": "Amazon Bedrock introduces three service tiers—Priority, Standard, and Flex—allowing you to optimize AI workload costs by matching performance requirements with pricing for different application needs.",
      "link": "https://aws.amazon.com/blogs/aws/new-amazon-bedrock-service-tiers-help-you-match-ai-workload-performance-with-cost/",
      "pubDate": "2025-11-18T22:29:46.000Z",
      "source": "newsBlog",
      "services": [
        "bedrock",
        "lex"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "bedrock",
        "lex"
      ]
    },
    {
      "id": "aws-news-14979180522f",
      "title": "Accelerate large-scale AI applications with the new Amazon EC2 P6-B300 instances",
      "description": "Amazon announces the general availability of EC2 P6-B300 instances, powered by NVIDIA Blackwell Ultra GPUs, which deliver 2x networking bandwidth and 1.5x GPU memory than previous generations, making them well suited for training and serving large-scale AI models with trillion parameters across distributed GPU clusters",
      "link": "https://aws.amazon.com/blogs/aws/accelerate-large-scale-ai-applications-with-the-new-amazon-ec2-p6-b300-instances/",
      "pubDate": "2025-11-18T22:16:16.000Z",
      "source": "newsBlog",
      "services": [
        "ec2"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "ec2"
      ]
    },
    {
      "id": "aws-news-19ca6df7eeca",
      "title": "Bringing tic-tac-toe to life with AWS AI services",
      "description": "RoboTic-Tac-Toe is an interactive game where two physical robots move around a tic-tac-toe board, with both the gameplay and robots’ movements orchestrated by LLMs. Players can control the robots using natural language commands, directing them to place their markers on the game board. In this post, we explore the architecture and prompt engineering techniques used to reason about a tic-tac-toe game and decide the next best game strategy and movement plan for the current player.",
      "link": "https://aws.amazon.com/blogs/machine-learning/bringing-tic-tac-toe-to-life-with-aws-ai-services/",
      "pubDate": "2025-11-18T22:08:57.000Z",
      "source": "mlBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-05b9bc2e3644",
      "title": "Python 3.14 runtime now available in AWS Lambda",
      "description": "AWS Lambda now supports Python 3.14 as both a managed runtime and container base image. Python is a popular language for building serverless applications. Developers can now take advantage of new features and enhancements when creating serverless applications on Lambda.",
      "link": "https://aws.amazon.com/blogs/compute/python-3-14-runtime-now-available-in-aws-lambda/",
      "pubDate": "2025-11-18T21:29:50.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "now-available",
        "new-feature",
        "enhancement",
        "support"
      ]
    },
    {
      "id": "aws-news-8a70ac885513",
      "title": "HyperPod enhances ML infrastructure with security and storage",
      "description": "This blog post introduces two major enhancements to Amazon SageMaker HyperPod that strengthen security and storage capabilities for large-scale machine learning infrastructure. The new features include customer managed key (CMK) support for encrypting EBS volumes with organization-controlled encryption keys, and Amazon EBS CSI driver integration that enables dynamic storage management for Kubernetes volumes in AI workloads.",
      "link": "https://aws.amazon.com/blogs/machine-learning/hyperpod-enhances-ml-infrastructure-with-security-and-storage/",
      "pubDate": "2025-11-18T17:54:27.000Z",
      "source": "mlBlog",
      "services": [
        "sagemaker",
        "hyperpod"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "sagemaker",
        "hyperpod",
        "ga",
        "new-feature",
        "enhancement",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-39ca3e902331",
      "title": "Accelerating generative AI applications with a platform engineering approach",
      "description": "In this post, I will illustrate how applying platform engineering principles to generative AI unlocks faster time-to-value, cost control, and scalable innovation.",
      "link": "https://aws.amazon.com/blogs/machine-learning/accelerating-generative-ai-applications-with-a-platform-engineering-approach/",
      "pubDate": "2025-11-18T17:04:13.000Z",
      "source": "mlBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-1c81acbb3316",
      "title": "Introducing Amazon MWAA Serverless",
      "description": "Today, AWS announced Amazon Managed Workflows for Apache Airflow (MWAA) Serverless. This is a new deployment option for MWAA that eliminates the operational overhead of managing Apache Airflow environments while optimizing costs through serverless scaling. In this post, we demonstrate how to use MWAA Serverless to build and deploy scalable workflow automation solutions.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-amazon-mwaa-serverless/",
      "pubDate": "2025-11-17T22:22:46.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-317bf6461345",
      "title": "AWS Weekly Roundup: AWS Lambda for Rust, NLB for QUIC protocol, Amazon DCV for Mac, and more (November 17, 2025)",
      "description": "The weeks before AWS re:Invent, my team is full steam ahead preparing content for the conference. I can’t wait to meet you at one of my three talks: CMP346 : Supercharge AI/ML on Apple Silicon with EC2 Mac, CMP344: Speed up Apple application builds with CI/CD on EC2 Mac, and DEV416: Develop your AI Agents […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-lambda-load-balancers-amazon-dcv-amazon-linux-2023-and-more-november-17-2025/",
      "pubDate": "2025-11-17T17:59:08.000Z",
      "source": "newsBlog",
      "services": [
        "lambda",
        "ec2",
        "eks"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda",
        "ec2",
        "eks"
      ]
    },
    {
      "id": "aws-news-c36d51e13ef0",
      "title": "Building serverless applications with Rust on AWS Lambda",
      "description": "Today, AWS Lambda is promoting Rust support from Experimental to Generally Available. This means you can now use Rust to build business-critical serverless applications, backed by AWS Support and the Lambda availability SLA.",
      "link": "https://aws.amazon.com/blogs/compute/building-serverless-applications-with-rust-on-aws-lambda/",
      "pubDate": "2025-11-14T21:38:15.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "experimental",
        "generally-available",
        "support"
      ]
    },
    {
      "id": "aws-news-78f167df36fd",
      "title": "AWS Lambda now supports Java 25",
      "description": "You can now develop AWS Lambda functions using Java 25 either as a managed runtime or using the container base image. This blog post highlights notable Java language features, Java Lambda runtime updates, and how you can use the new Java 25 runtime in your serverless applications.",
      "link": "https://aws.amazon.com/blogs/compute/aws-lambda-now-supports-java-25/",
      "pubDate": "2025-11-14T20:51:20.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "update",
        "support"
      ]
    },
    {
      "id": "aws-news-050e6bf7fbc0",
      "title": "AWS Lambda enhances event processing with provisioned mode for SQS event-source mapping",
      "description": "AWS Lambda's new provisioned mode for Amazon SQS event source mapping offers dedicated polling resources that provide 3x faster scaling and 10x higher concurrency, enabling lower latency processing, better handling of traffic spikes, and greater control over event processing resources.",
      "link": "https://aws.amazon.com/blogs/aws/aws-lambda-enhances-sqs-processing-with-new-provisioned-mode-3x-faster-scaling-16x-higher-capacity/",
      "pubDate": "2025-11-14T17:45:04.000Z",
      "source": "newsBlog",
      "services": [
        "lambda",
        "sqs"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "lambda",
        "sqs"
      ]
    },
    {
      "id": "aws-news-525a7aa26225",
      "title": "Your guide to AWS Analytics at AWS re:Invent 2025",
      "description": "It’s that time of year again — AWS re:Invent is here! At re:Invent, bold ideas come to life. Get a front-row seat to hear inspiring stories from AWS experts, customers, and leaders as they explore today’s most impactful topics, from data analytics to AI. For all the data enthusiasts and professionals, we’ve curated a comprehensive […]",
      "link": "https://aws.amazon.com/blogs/big-data/your-guide-to-aws-analytics-at-aws-reinvent-2025/",
      "pubDate": "2025-11-13T20:06:19.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-d4d5eb413522",
      "title": "How Yelp modernized its data infrastructure with a streaming lakehouse on AWS",
      "description": "This is a guest post by Umesh Dangat, Senior Principal Engineer for Distributed Services and Systems at Yelp, and Toby Cole, Principle Engineer for Data Processing at Yelp, in partnership with AWS. Yelp processes massive amounts of user data daily—over 300 million business reviews, 100,000 photo uploads, and countless check-ins. Maintaining sub-minute data freshness with […]",
      "link": "https://aws.amazon.com/blogs/big-data/how-yelp-modernized-its-data-infrastructure-with-a-streaming-lakehouse-on-aws/",
      "pubDate": "2025-11-13T18:07:22.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "ga"
      ]
    },
    {
      "id": "aws-news-32e40b364aee",
      "title": "The attendee’s guide to the AWS re:Invent 2025 Compute track",
      "description": "From December 1st to December 5th, Amazon Web Services (AWS) will hold its annual premier learning event: re:Invent. There are over 2000+ learning sessions that focus on specific topics at various skill levels, and the compute team have created 76 unique sessions for you to choose. There are many sessions you can choose from, and we are here to help you choose the sessions that best fit your needs. Even if you cannot join in person, you can catch-up with many of the sessions on-demand and even watch the keynote and innovation sessions live.",
      "link": "https://aws.amazon.com/blogs/compute/the-attendees-guide-to-the-aws-reinvent-2025-compute-track/",
      "pubDate": "2025-11-12T20:58:36.000Z",
      "source": "computeBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-550cb96aa581",
      "title": "Introducing Our Final AWS Heroes of 2025",
      "description": "With AWS re:Invent approaching, we’re celebrating three exceptional AWS Heroes whose diverse journeys and commitment to knowledge sharing are empowering builders worldwide. From advancing women in tech and rural communities to bridging academic and industry expertise and pioneering enterprise AI solutions, these leaders exemplify the innovative spirit that drives our community forward. Their stories showcase […]",
      "link": "https://aws.amazon.com/blogs/aws/introducing-our-final-aws-heroes-of-2025/",
      "pubDate": "2025-11-12T20:05:01.000Z",
      "source": "newsBlog",
      "services": [
        "nova"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "nova"
      ]
    },
    {
      "id": "aws-news-a7184d7c3c1a",
      "title": "Introducing the Amazon OpenSearch Lens for the AWS Well-Architected Framework",
      "description": "In this post, we show you how to use the Amazon OpenSearch Service Lens to evaluate your OpenSearch Service workloads against architectural best practices.",
      "link": "https://aws.amazon.com/blogs/big-data/introducing-the-amazon-opensearch-lens-for-the-aws-well-architected-framework/",
      "pubDate": "2025-11-12T01:07:02.000Z",
      "source": "bigDataBlog",
      "services": [
        "opensearch",
        "opensearch service"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "opensearch",
        "opensearch service",
        "ga"
      ]
    },
    {
      "id": "aws-news-e14e83f5b2a7",
      "title": "Amazon MSK Express brokers now support Intelligent Rebalancing for 180 times faster operation performance",
      "description": "Effective today, all new Amazon Managed Streaming for Apache Kafka (Amazon MSK) Provisioned clusters with Express brokers will support Intelligent Rebalancing at no additional cost. In this post we’ll introduce the Intelligent Rebalancing feature and show an example of how it works to improve operation performance.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-msk-express-brokers-now-support-intelligent-rebalancing-for-180-times-faster-operation-performance/",
      "pubDate": "2025-11-10T23:15:45.000Z",
      "source": "bigDataBlog",
      "services": [
        "kafka",
        "msk"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "kafka",
        "msk",
        "support"
      ]
    },
    {
      "id": "aws-news-a104392c9b46",
      "title": "Analyzing Amazon EC2 Spot instance interruptions by using event-driven architecture",
      "description": "In this post, you'll learn how to build this comprehensive monitoring solution step-by-step. You'll gain practical experience designing an event-driven pipeline, implementing data processing workflows, and creating insightful dashboards that help you track interruption trends, optimize ASG configurations, and improve the resilience of your Spot Instance workloads.",
      "link": "https://aws.amazon.com/blogs/big-data/analyzing-amazon-ec2-spot-instance-interruptions-by-using-event-driven-architecture/",
      "pubDate": "2025-11-10T22:05:20.000Z",
      "source": "bigDataBlog",
      "services": [
        "ec2",
        "rds"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "ec2",
        "rds",
        "ga"
      ]
    },
    {
      "id": "aws-news-ab4858c18742",
      "title": "Secure EKS clusters with the new support for Amazon EKS in AWS Backup",
      "description": "AWS Backup now supports Amazon EKS, providing a fully managed, centralized solution to back up and restore Kubernetes clusters and application data without requiring custom scripts or third-party tools.",
      "link": "https://aws.amazon.com/blogs/aws/secure-eks-clusters-with-the-new-support-for-amazon-eks-in-aws-backup/",
      "pubDate": "2025-11-10T21:30:29.000Z",
      "source": "newsBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "eks",
        "support"
      ]
    },
    {
      "id": "aws-news-5f7e69567c35",
      "title": "AWS Weekly Roundup: OpenAI partnership, Jane Goodall Institute research archive, and more (November 10, 2025)",
      "description": "AWS re:Invent 2025 is only 3 weeks away and I’m already looking forward to the new launches and announcements at the conference. Last year brought 60,000 attendees from across the globe to Las Vegas, Nevada, and the atmosphere was amazing. Registration is still open for AWS re:Invent 2025. We hope you’ll join us in Las Vegas […]",
      "link": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-s3-amazon-ec2-and-more-november-10-2025/",
      "pubDate": "2025-11-10T16:38:38.000Z",
      "source": "newsBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "news"
      ],
      "tags": [
        "eks",
        "launch",
        "ga",
        "announcement"
      ]
    },
    {
      "id": "aws-news-25fb32cc6ab1",
      "title": "AWS Lambda networking over IPv6",
      "description": "This post examines the benefits of transitioning Lambda functions to IPv6, provides practical guidance for implementing dual-stack support in your Lambda environment, and considerations for maintaining compatibility with existing systems during migration.",
      "link": "https://aws.amazon.com/blogs/compute/aws-lambda-networking-over-ipv6/",
      "pubDate": "2025-11-07T22:14:31.000Z",
      "source": "computeBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "support"
      ]
    },
    {
      "id": "aws-news-a14aa54b7cee",
      "title": "Orchestrating big data processing with AWS Step Functions Distributed Map",
      "description": "In this post, you'll learn how to use AWS Step Functions Distributed Map to process Amazon Athena data manifest and Parquet files through a step-by-step demonstration.",
      "link": "https://aws.amazon.com/blogs/compute/orchestrating-big-data-processing-with-aws-step-functions-distributed-map/",
      "pubDate": "2025-11-04T23:42:01.000Z",
      "source": "computeBlog",
      "services": [
        "athena",
        "step functions"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "athena",
        "step functions"
      ]
    },
    {
      "id": "aws-news-f838bd828ecc",
      "title": "Optimizing nested JSON array processing using AWS Step Functions Distributed Map",
      "description": "In this post, we explore how to optimize processing array data embedded within complex JSON structures using AWS Step Functions Distributed Map. You’ll learn how to use ItemsPointer to reduce the complexity of your state machine definitions, create more flexible workflow designs, and streamline your data processing pipelines—all without writing additional transformation code or AWS Lambda functions.",
      "link": "https://aws.amazon.com/blogs/compute/optimizing-nested-json-array-processing-using-aws-step-functions-distributed-map/",
      "pubDate": "2025-11-04T23:41:28.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "lambda",
        "step functions"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "lambda",
        "step functions"
      ]
    },
    {
      "id": "aws-news-cbb99686390b",
      "title": "Enhanced search with match highlights and explanations in Amazon SageMaker",
      "description": "Amazon SageMaker now enhances search results in Amazon SageMaker Unified Studio with additional context that improves transparency and interpretability. The capability introduces inline highlighting for matched terms and an explanation panel that details where and how each match occurred across metadata fields such as name, description, glossary, and schema. In this post, we demonstrate how to use enhanced search in Amazon SageMaker.",
      "link": "https://aws.amazon.com/blogs/big-data/enhanced-search-with-match-highlights-and-explanations-in-amazon-sagemaker/",
      "pubDate": "2025-11-04T22:57:29.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "unified studio"
      ]
    },
    {
      "id": "aws-news-5625caee948f",
      "title": "Amazon Kinesis Data Streams launches On-demand Advantage for instant throughput increases and streaming at scale",
      "description": "Today, AWS announced the new Amazon Kinesis Data Streams On-demand Advantage mode, which includes warm throughput capability and an updated pricing structure. With this feature you can enable instant scaling for traffic surges while optimizing costs for consistent streaming workloads. In this post, we explore this new feature, including key use cases, configuration options, pricing considerations, and best practices for optimal performance.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-kinesis-data-streams-launches-on-demand-advantage-for-instant-throughput-increases-and-streaming-at-scale/",
      "pubDate": "2025-11-03T22:00:31.000Z",
      "source": "bigDataBlog",
      "services": [
        "kinesis"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "kinesis",
        "launch",
        "new-feature",
        "update"
      ]
    },
    {
      "id": "aws-news-1998e227992a",
      "title": "Scaling data governance with Amazon DataZone: Covestro success story",
      "description": "In this post, we show you how Covestro transformed its data architecture by implementing Amazon DataZone and AWS Serverless Data Lake Framework, transitioning from a centralized data lake to a data mesh architecture. The implementation enabled streamlined data access, better data quality, and stronger governance at scale, achieving a 70% reduction in time-to-market for over 1,000 data pipelines.",
      "link": "https://aws.amazon.com/blogs/big-data/scaling-data-governance-with-amazon-datazone-covestro-success-story/",
      "pubDate": "2025-11-03T21:02:06.000Z",
      "source": "bigDataBlog",
      "services": [],
      "categories": [
        "industry-cases"
      ],
      "tags": []
    },
    {
      "id": "aws-news-d8165ac29c81",
      "title": "Use trusted identity propagation for Apache Spark interactive sessions in Amazon SageMaker Unified Studio",
      "description": "In this post, we provide step-by-step instructions to set up Amazon EMR on EC2, EMR Serverless, and AWS Glue within SageMaker Unified Studio, enabled with trusted identity propagation. We use the setup to illustrate how different IAM Identity Center users can run their Spark sessions, using each compute setup, within the same project in SageMaker Unified Studio. We show how each user will see only tables or part of tables that they’re granted access to in Lake Formation.",
      "link": "https://aws.amazon.com/blogs/big-data/use-trusted-identity-propagation-for-apache-spark-interactive-sessions-in-amazon-sagemaker-unified-studio/",
      "pubDate": "2025-10-31T20:55:40.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "ec2",
        "emr",
        "iam",
        "iam identity center",
        "glue"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "ec2",
        "emr",
        "iam",
        "iam identity center",
        "glue",
        "ga"
      ]
    },
    {
      "id": "aws-news-084a1116597e",
      "title": "Introducing AWS Lambda event source mapping tools in the AWS Serverless MCP Server",
      "description": "Modern serverless applications increasingly rely on event-driven architectures, where AWS Lambda functions process events from various sources like Amazon Kinesis, Amazon DynamoDB Streams, Amazon Simple Queue Service (Amazon SQS), Amazon Managed Streaming for Apache Kafka (Amazon MSK), and self-managed Apache Kafka. Although event source mappings (ESM) offer a powerful mechanism for integrating AWS Lambda with […]",
      "link": "https://aws.amazon.com/blogs/compute/introducing-aws-lambda-event-source-mapping-tools-in-the-aws-serverless-mcp-server/",
      "pubDate": "2025-10-30T16:53:19.000Z",
      "source": "computeBlog",
      "services": [
        "lambda",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk",
        "sqs"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "dynamodb",
        "kinesis",
        "kafka",
        "msk",
        "sqs"
      ]
    },
    {
      "id": "aws-news-062c835cf136",
      "title": "Amazon Kinesis Data Streams now supports 10x larger record sizes: Simplifying real-time data processing",
      "description": "Today, AWS announced that Amazon Kinesis Data Streams now supports record sizes up to 10MiB – a tenfold increase from the previous limit. In this post, we explore Amazon Kinesis Data Streams large record support, including key use cases, configuration of maximum record sizes, throttling considerations, and best practices for optimal performance.",
      "link": "https://aws.amazon.com/blogs/big-data/amazon-kinesis-data-streams-now-supports-10x-larger-record-sizes-simplifying-real-time-data-processing/",
      "pubDate": "2025-10-28T19:23:30.000Z",
      "source": "bigDataBlog",
      "services": [
        "kinesis"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "kinesis",
        "support"
      ]
    },
    {
      "id": "aws-news-29fb262a0808",
      "title": "Federate access to SageMaker Unified Studio with AWS IAM Identity Center and Okta",
      "description": "This post shows step-by-step guidance to setup workforce access to Amazon SageMaker Unified Studio using Okta as an external Identity provider with AWS IAM Identity Center.",
      "link": "https://aws.amazon.com/blogs/big-data/federate-access-to-sagemaker-unified-studio-with-aws-iam-identity-center-and-okta/",
      "pubDate": "2025-10-27T21:11:07.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "unified studio",
        "iam",
        "iam identity center"
      ],
      "categories": [
        "machine-learning"
      ],
      "tags": [
        "sagemaker",
        "unified studio",
        "iam",
        "iam identity center"
      ]
    },
    {
      "id": "aws-news-6ab33ada19c8",
      "title": "Accelerate data governance with custom subscription workflows in Amazon SageMaker",
      "description": "Organizations need to efficiently manage data assets while maintaining governance controls in their data marketplaces. Although manual approval workflows remain important for sensitive datasets and production systems, there’s an increasing need for automated approval processes with less sensitive datasets. In this post, we show you how to automate subscription request approvals within SageMaker, accelerating data access for data consumers.",
      "link": "https://aws.amazon.com/blogs/big-data/accelerate-data-governance-with-custom-subscription-workflows-in-amazon-sagemaker/",
      "pubDate": "2025-10-24T20:41:19.000Z",
      "source": "bigDataBlog",
      "services": [
        "sagemaker",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "sagemaker",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-c9717e0cdb77",
      "title": "Implement fine-grained access control for Iceberg tables using Amazon EMR on EKS integrated with AWS Lake Formation",
      "description": "On February 6th 2025, AWS introduced fine-grained access control based on AWS Lake Formation for EMR on EKS from Amazon EMR 7.7 and higher version. You can now significantly enhance your data governance and security frameworks using this feature. In this post, we demonstrate how to implement FGAC on Apache Iceberg tables using EMR on EKS with Lake Formation.",
      "link": "https://aws.amazon.com/blogs/big-data/implement-fine-grained-access-control-for-iceberg-tables-using-amazon-emr-on-eks-integrated-with-aws-lake-formation/",
      "pubDate": "2025-10-24T20:39:25.000Z",
      "source": "bigDataBlog",
      "services": [
        "emr",
        "eks"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "emr",
        "eks",
        "ga"
      ]
    },
    {
      "id": "aws-news-360e834c997a",
      "title": "BASF Digital Farming builds a STAC-based solution on Amazon EKS",
      "description": "This post was co-written with Frederic Haase and Julian Blau with BASF Digital Farming GmbH. At xarvio – BASF Digital Farming, our mission is to empower farmers around the world with cutting-edge digital agronomic decision-making tools. Central to this mission is our crop optimization platform, xarvio FIELD MANAGER, which delivers actionable insights through a range […]",
      "link": "https://aws.amazon.com/blogs/architecture/basf-digital-farming-builds-a-stac-based-solution-on-amazon-eks/",
      "pubDate": "2025-10-22T16:21:09.000Z",
      "source": "architectureBlog",
      "services": [
        "eks"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "eks"
      ]
    },
    {
      "id": "aws-news-24029d05087c",
      "title": "What’s New in the AWS Deploy Tool for .NET",
      "description": "Version 2.0 of the AWS Deploy Tool for .NET is now available. This new major version introduces several foundational upgrades to improve the deployment experience for .NET applications on AWS. The tool comes with new minimum runtime requirements. We have upgraded it to require .NET 8 because the predecessor, .NET 6, is now out of […]",
      "link": "https://aws.amazon.com/blogs/developer/whats-new-in-the-aws-deploy-tool-for-net/",
      "pubDate": "2025-10-14T13:25:42.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "now-available"
      ]
    },
    {
      "id": "aws-news-2f3bd8791ed1",
      "title": "Modernization of real-time payment orchestration on AWS",
      "description": "The global real-time payments market is experiencing significant growth. According to Fortune Business Insights, the market was valued at USD 24.91 billion in 2024 and is projected to grow to USD 284.49 billion by 2032, with a CAGR of 35.4%. Similarly, Grand View Research reports that the global mobile payment market, valued at USD 88.50 […]",
      "link": "https://aws.amazon.com/blogs/architecture/modernization-of-real-time-payment-orchestration-on-aws/",
      "pubDate": "2025-10-01T23:34:00.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": []
    },
    {
      "id": "aws-news-089334445f81",
      "title": "Build resilient generative AI agents",
      "description": "Generative AI agents in production environments demand resilience strategies that go beyond traditional software patterns. AI agents make autonomous decisions, consume substantial computational resources, and interact with external systems in unpredictable ways. These characteristics create failure modes that conventional resilience approaches might not address. This post presents a framework for AI agent resilience risk analysis […]",
      "link": "https://aws.amazon.com/blogs/architecture/build-resilient-generative-ai-agents/",
      "pubDate": "2025-09-30T15:11:51.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": []
    },
    {
      "id": "aws-news-4fbb29739c17",
      "title": "General Availability Release of the Migration Tool for the AWS SDK for Java 2.x",
      "description": "The AWS SDK for Java 1.x (v1) entered maintenance mode on July 31, 2024, and will reach end-of-support on December 31, 2025. We recommend that you migrate to the AWS SDK for Java 2.x (v2) to access new features, enhanced performance, and continued support from AWS. To help you migrate efficiently, we’ve created a migration […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-release-of-the-migration-tool-for-the-aws-sdk-for-java-2-x/",
      "pubDate": "2025-09-26T16:47:36.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature",
        "support"
      ]
    },
    {
      "id": "aws-news-4711328feee4",
      "title": "A scalable, elastic database and search solution for 1B+ vectors built on LanceDB and Amazon S3",
      "description": "In this post, we explore how Metagenomi built a scalable database and search solution for over 1 billion protein vectors using LanceDB and Amazon S3. The solution enables rapid enzyme discovery by transforming proteins into vector embeddings and implementing a serverless architecture that combines AWS Lambda, AWS Step Functions, and Amazon S3 for efficient nearest neighbor searches.",
      "link": "https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/",
      "pubDate": "2025-09-22T17:15:44.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda",
        "s3",
        "step functions"
      ],
      "categories": [
        "ai-services"
      ],
      "tags": [
        "lambda",
        "s3",
        "step functions"
      ]
    },
    {
      "id": "aws-news-7e2f23dd38ac",
      "title": "Simplify multi-tenant encryption with a cost-conscious AWS KMS key strategy",
      "description": "In this post, we explore an efficient approach to managing encryption keys in a multi-tenant SaaS environment through centralization, addressing challenges like key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. We demonstrate how implementing a centralized key management strategy using a single AWS KMS key per tenant can maintain security and compliance while reducing operational overhead as organizations scale.",
      "link": "https://aws.amazon.com/blogs/architecture/simplify-multi-tenant-encryption-with-a-cost-conscious-aws-kms-key-strategy/",
      "pubDate": "2025-08-21T21:54:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "lex",
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-d1d1f77f887e",
      "title": "How Karrot built a feature platform on AWS, Part 1: Motivation and feature serving",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post starts by presenting our motivation, our requirements, and the solution architecture, focusing on feature serving.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-1-motivation-and-feature-serving/",
      "pubDate": "2025-08-14T15:16:29.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-40ebd26fef7f",
      "title": "How Karrot built a feature platform on AWS, Part 2: Feature ingestion",
      "description": "This two-part series shows how Karrot developed a new feature platform, which consists of three main components: feature serving, a stream ingestion pipeline, and a batch ingestion pipeline. This post covers the process of collecting features in real-time and batch ingestion into an online store, and the technical approaches for stable operation.",
      "link": "https://aws.amazon.com/blogs/architecture/how-karrot-built-a-feature-platform-on-aws-part-2-feature-ingestion/",
      "pubDate": "2025-08-14T15:16:27.000Z",
      "source": "architectureBlog",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "new-feature"
      ]
    },
    {
      "id": "aws-news-b1018aefba54",
      "title": "Deploy LLMs on Amazon EKS using vLLM Deep Learning Containers",
      "description": "In this post, we demonstrate how to deploy the DeepSeek-R1-Distill-Qwen-32B model using AWS DLCs for vLLMs on Amazon EKS, showcasing how these purpose-built containers simplify deployment of this powerful open source inference engine. This solution can help you solve the complex infrastructure challenges of deploying LLMs while maintaining performance and cost-efficiency.",
      "link": "https://aws.amazon.com/blogs/architecture/deploy-llms-on-amazon-eks-using-vllm-deep-learning-containers/",
      "pubDate": "2025-08-14T15:09:51.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "foundation-models"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    },
    {
      "id": "aws-news-8b2281cd8002",
      "title": "Maximizing Business Value Through Strategic Cloud Optimization",
      "description": "As cloud spending continues to surge, organizations must focus on strategic cloud optimization to maximize business value. This blog post explores key insights from MIT Technology Review's publication on cloud optimization, highlighting the importance of viewing optimization as a continuous process that encompasses all six AWS Well-Architected pillars.",
      "link": "https://aws.amazon.com/blogs/architecture/maximizing-business-value-through-strategic-cloud-optimization/",
      "pubDate": "2025-08-01T15:33:28.000Z",
      "source": "architectureBlog",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga"
      ]
    },
    {
      "id": "aws-news-9e63742dd9e4",
      "title": "How Zapier runs isolated tasks on AWS Lambda and upgrades functions at scale",
      "description": "In this post, you’ll learn how Zapier has built their serverless architecture focusing on three key aspects: using Lambda functions to build isolated Zaps, operating over a hundred thousand Lambda functions through Zapier's control plane infrastructure, and enhancing security posture while reducing maintenance efforts by introducing automated function upgrades and cleanup workflows into their platform architecture.",
      "link": "https://aws.amazon.com/blogs/architecture/how-zapier-runs-isolated-tasks-on-aws-lambda-and-upgrades-functions-at-scale/",
      "pubDate": "2025-07-25T13:30:06.000Z",
      "source": "architectureBlog",
      "services": [
        "lambda"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-11d98a88cbe1",
      "title": "Implement monitoring for Amazon EKS with managed services",
      "description": "In this post, we show you how to implement comprehensive monitoring for Amazon Elastic Kubernetes Service (Amazon EKS) workloads using AWS managed services. This solution demonstrates building an EKS platform that combines flexible compute options with enterprise-grade observability using AWS native services and OpenTelemetry.",
      "link": "https://aws.amazon.com/blogs/architecture/implement-monitoring-for-amazon-eks-with-managed-services/",
      "pubDate": "2025-07-18T15:47:13.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    },
    {
      "id": "aws-news-875544c87826",
      "title": "Preview Release of the AWS SDK Java 2.x HTTP Client built on Apache HttpClient 5.5.x",
      "description": "The AWS SDK for Java 2.x introduces the Apache 5 SDK HTTP client which is built on Apache HttpClient 5.5.x. This new SDK HTTP client is available alongside our existing SDK HTTP clients: Apache HttpClient 4.5.x, Netty, URL Connection, and AWS CRT HttpClient. To differentiate the use of Apache HttpClient 4.5.x and Apache HttpClient 5.5.x, […]",
      "link": "https://aws.amazon.com/blogs/developer/preview-release-of-theaws-sdk-java-2-x-http-client-built-on-apache-httpclient-5-5-x/",
      "pubDate": "2025-07-18T03:36:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview"
      ]
    },
    {
      "id": "aws-news-9eb0f60de1a7",
      "title": "How Scale to Win uses AWS WAF to block DDoS events",
      "description": "In this post, you'll learn how Scale to Win configured their network topology and AWS WAF to protect against DDoS events that reached peaks of over 2 million requests per second during the 2024 US presidential election campaign season. The post details how they implemented comprehensive DDoS protection by segmenting human and machine traffic, using tiered rate limits with CAPTCHA, and preventing CAPTCHA token reuse through AWS WAF Bot Control.",
      "link": "https://aws.amazon.com/blogs/architecture/how-scale-to-win-uses-aws-waf-to-block-ddos-events/",
      "pubDate": "2025-07-14T19:12:38.000Z",
      "source": "architectureBlog",
      "services": [
        "waf"
      ],
      "categories": [
        "industry-cases"
      ],
      "tags": [
        "waf",
        "ga"
      ]
    },
    {
      "id": "aws-news-6606f79cd3d5",
      "title": "AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available",
      "description": "Today, we are excited to announce the general availability of the AWS .NET Distributed Cache Provider for Amazon DynamoDB. This is a seamless, serverless caching solution that enables .NET developers to efficiently manage their caching needs across distributed systems. Consistent caching is a difficult problem in distributed architectures, where maintaining data integrity and performance across […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-net-distributed-cache-provider-for-amazon-dynamodb-now-generally-available/",
      "pubDate": "2025-07-03T13:49:25.000Z",
      "source": "developersAndDevOps",
      "services": [
        "dynamodb"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "dynamodb",
        "generally-available"
      ]
    },
    {
      "id": "aws-news-ae25b45e1a62",
      "title": "AWS Tools for PowerShell V5 now Generally Available",
      "description": "This blog was co-authored by Afroz Mohammed and Jonathan Nunn, Software Developers on the AWS PowerShell team. We’re excited to announce the general availability of the AWS Tools for PowerShell version 5, a major update that brings new features and improvements in security, along with a few breaking changes. New Features You can now cancel […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-tools-for-powershell-v5-now-generally-available/",
      "pubDate": "2025-06-23T22:59:33.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "generally-available",
        "new-feature",
        "update",
        "improvement"
      ]
    },
    {
      "id": "aws-news-54c273e45b01",
      "title": "Upgrading your AWS SDK for Go from V1 to V2 with Amazon Q Developer",
      "description": "Software development is far more than just writing code. In reality, a developer spends a large amount of time maintaining existing applications and fixing bugs. For example, migrating a Go application from the older AWS SDK for Go v1 to the newer v2 can be a significant undertaking, but it’s a crucial step to future-proof […]",
      "link": "https://aws.amazon.com/blogs/developer/upgrading-your-aws-sdk-for-go-from-v1-to-v2-with-amazon-q-developer/",
      "pubDate": "2025-06-18T06:38:24.000Z",
      "source": "developersAndDevOps",
      "services": [
        "amazon q",
        "q developer"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "amazon q",
        "q developer"
      ]
    },
    {
      "id": "aws-news-27b43a8f9a42",
      "title": "Deploy to ARM-Based Compute with AWS Deploy Tool for .NET",
      "description": "We’re excited to announce that the AWS Deploy Tool for .NET now supports deploying .NET applications to select ARM-based compute platforms on AWS! Whether you’re deploying from Visual Studio or using the .NET CLI, you can now target cost-effective ARM infrastructure like AWS Graviton with the same streamlined experience you’re used to. Why deploy to […]",
      "link": "https://aws.amazon.com/blogs/developer/deploy-to-arm-based-compute-with-aws-deploy-tool-for-net/",
      "pubDate": "2025-05-08T20:16:40.000Z",
      "source": "developersAndDevOps",
      "services": [
        "graviton"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "graviton",
        "support"
      ]
    },
    {
      "id": "aws-news-4d3126ea3a15",
      "title": "General Availability of AWS SDK for .NET V4.0",
      "description": "Version 4.0 of the AWS SDK for .NET has been released for general availability (GA). V4 has been in development for a little over a year in our SDK’s public GitHub repository with 13 previews being released. This new version contains performance improvements, consistency with other AWS SDKs, and bug and usability fixes that required […]",
      "link": "https://aws.amazon.com/blogs/developer/general-availability-of-aws-sdk-for-net-v4-0/",
      "pubDate": "2025-04-28T20:05:16.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "preview",
        "ga",
        "improvement"
      ]
    },
    {
      "id": "aws-news-49859f1bef68",
      "title": "Introducing the AWS IoT Device SDK for Swift (Developer Preview)",
      "description": "Today, AWS launches the developer preview of the AWS IoT Device SDK for Swift. The IoT Device SDK for Swift empowers Swift developers to create IoT applications for Linux and Apple macOS, iOS, and tvOS platforms using the MQTT 5 protocol. The SDK supports Swift 5.10+ and is designed to help developers easily integrate with […]",
      "link": "https://aws.amazon.com/blogs/developer/introducing-the-aws-iot-device-sdk-for-swift-developer-preview/",
      "pubDate": "2025-03-31T16:26:05.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "launch",
        "preview",
        "support"
      ]
    },
    {
      "id": "aws-news-c4f514e85eef",
      "title": "AWS SDK for Ruby: Deprecating Ruby 2.5 & 2.6 Runtime Supports and Future Compatibility",
      "description": "Effective June 2, 2025, AWS SDK for Ruby Version 3 will no longer support following end-of-life (EOL) Ruby runtime versions: Ruby 2.5 (EOL began on 2021-04-05) Ruby 2.6 (EOL began on 2022-04-12) To ensure your applications and services remain secure, we strongly encourage you to upgrade to Ruby 2.7 or later. Moving forward, AWS SDK […]",
      "link": "https://aws.amazon.com/blogs/developer/aws-sdk-for-ruby-deprecating-ruby-2-5-2-6-runtime-supports-and-future-compatibility/",
      "pubDate": "2025-03-27T15:08:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "ga",
        "support"
      ]
    },
    {
      "id": "aws-news-5cf08af5aca4",
      "title": "Announcing the Developer Preview of Amazon S3 Transfer Manager in Rust",
      "description": "We are excited to announce the Developer Preview of the Amazon S3 Transfer Manager for Rust, a high-level utility that speeds up and simplifies uploads and downloads with Amazon Simple Storage Service (Amazon S3). Using this new library, developers can efficiently transfer data between Amazon S3 and various sources, including files, in-memory buffers, memory streams, […]",
      "link": "https://aws.amazon.com/blogs/developer/announcing-the-developer-preview-of-amazon-s3-transfer-manager-in-rust/",
      "pubDate": "2025-03-26T15:52:22.000Z",
      "source": "developersAndDevOps",
      "services": [
        "s3"
      ],
      "categories": [
        "generative-ai"
      ],
      "tags": [
        "s3",
        "preview"
      ]
    },
    {
      "id": "aws-news-dd08a704e7e9",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 2)",
      "description": "In Part 1 of our blog posts for .NET Aspire and AWS Lambda, we showed you how .NET Aspire can be used for running and debugging .NET Lambda functions. In this part, Part 2, we’ll show you how to take advantage of the .NET Aspire programming model for best practices and for connecting dependent resources […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-2/",
      "pubDate": "2025-03-04T17:54:04.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda"
      ]
    },
    {
      "id": "aws-news-4185fb6b40aa",
      "title": "Building and Debugging .NET Lambda applications with .NET Aspire (Part 1)",
      "description": "In a recent post we gave some background on .NET Aspire and introduced our AWS integrations with .NET Aspire that integrate AWS into the .NET dev inner loop for building applications. The integrations included how to provision application resources with AWS CloudFormation or AWS Cloud Development Kit (AWS CDK) and using Amazon DynamoDB local for […]",
      "link": "https://aws.amazon.com/blogs/developer/building-lambda-with-aspire-part-1/",
      "pubDate": "2025-03-03T21:16:42.000Z",
      "source": "developersAndDevOps",
      "services": [
        "lambda",
        "dynamodb",
        "cloudformation"
      ],
      "categories": [
        "general"
      ],
      "tags": [
        "lambda",
        "dynamodb",
        "cloudformation",
        "ga",
        "integration"
      ]
    },
    {
      "id": "aws-news-866c6557a5ec",
      "title": "Integrating AWS with .NET Aspire",
      "description": ".NET Aspire is a new way of building cloud-ready applications. In particular, it provides an orchestration for local environments in which to run, connect, and debug the components of distributed applications. Those components can be .NET projects, databases, containers, or executables. .NET Aspire is designed to have integrations with common components used in distributed applications. […]",
      "link": "https://aws.amazon.com/blogs/developer/integrating-aws-with-net-aspire/",
      "pubDate": "2025-02-11T20:39:27.000Z",
      "source": "developersAndDevOps",
      "services": [],
      "categories": [
        "general"
      ],
      "tags": [
        "integration"
      ]
    },
    {
      "id": "aws-news-9568575bd4f9",
      "title": "Updating AWS SDK defaults – AWS STS service endpoint and Retry Strategy",
      "description": "AWS announces important configuration updates coming July 31st, 2025, affecting AWS SDKs and CLIs default settings. Two key changes include switching the AWS Security Token Service (STS) endpoint to regional and updating the default retry strategy to standard. These updates aim to improve service availability and reliability by implementing regional endpoints to reduce cross-regional dependencies and introducing token-bucket throttling for standardized retry behavior. Organizations should test their applications before the release date and can opt-in early or temporarily opt-out of these changes. These updates align with AWS best practices for optimal service performance and security.",
      "link": "https://aws.amazon.com/blogs/developer/updating-aws-sdk-defaults-aws-sts-service-endpoint-and-retry-strategy/",
      "pubDate": "2025-02-11T05:37:32.000Z",
      "source": "developersAndDevOps",
      "services": [
        "organizations"
      ],
      "categories": [
        "ai-safety"
      ],
      "tags": [
        "organizations",
        "ga",
        "update"
      ]
    }
  ]
}