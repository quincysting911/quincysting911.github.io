{
  "lastUpdated": "2025-11-13T06:16:46.503Z",
  "category": "natural-language",
  "totalItems": 13,
  "items": [
    {
      "id": "aws-news-edbbed0f81d9",
      "title": "Application loadbalancer support client credential flow with JWT verification",
      "description": "Amazon Web Services (AWS) announces JWT Verification for Application Load Balancer (ALB), enabling secure machine-to-machine (M2M) and service-to-service (S2S) communications. This feature allows ALB to verify JSON Web Tokens (JWTs) included in request headers, validating token signatures, expiration times, and claims without requiring modifications to application code.\n  By offloading OAuth 2.0 token validation to ALB, customers can significantly reduce architectural complexity and streamline their security implementation. This capability is particularly valuable for microservices architectures, API security, and enterprise service integration scenarios where secure service-to-service communication is critical. The feature supports tokens issued through various OAuth 2.0 flows, including Client Credentials Flow, enabling centralized token validation with minimal operational overhead.\n  The JWT Verification feature is now available in all AWS Regions where Application Load Balancer is supported.\n \nTo learn more, visit the ALB Documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/application-load-balancer-jwt-verification",
      "pubDate": "2025-11-12T19:39:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "now-available",
        "integration",
        "support"
      ]
    },
    {
      "id": "aws-news-7b95b04458ba",
      "title": "AWS Site-to-Site VPN announces 5 Gbps bandwidth tunnels",
      "description": "AWS Site-to-Site VPN now supports VPN connections with up to 5 Gbps bandwidth per tunnel, a 4x improvement from existing limit of 1.25 Gbps. This increased bandwidth benefits customers who require high-capacity connections for bandwidth-intensive hybrid applications, big data migrations, and disaster recovery architectures while maintaining traffic encryption between AWS and their remote sites. Customers can also use 5 Gbps VPN connections as a backup or overlay for their high capacity AWS Direct Connect connections.\n  AWS Site-to-Site VPN is a fully managed service that allows you to create a secure connection between your data center or branch office and your AWS resources using IP Security (IPSec) tunnels. Until now, Site-to-Site VPN supported a maximum of 1.25Gbps bandwidth per tunnel and customers had to rely on ECMP (Equal cost multi path) to logically bond multiple tunnels to achieve higher bandwidth. With this launch, customers can now configure their tunnel bandwidth to 5 Gbps, reducing the need to deploy complex protocols such as ECMP while ensuring consistent bandwidth performance.\n  This capability is available in all AWS commercial Regions and AWS GovCloud (US) Regions where AWS Site-to-Site VPN is available, except Asia Pacific (Melbourne), Israel (Tel Aviv), Europe (Zurich), Canada West (Calgary), and Middle East (UAE) Regions. To learn more and get started, visit the AWS Site-to-Site VPN documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/aws-site-to-site-vpn-5-gbps-bandwidth-tunnels",
      "pubDate": "2025-11-12T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "launch",
        "ga",
        "improvement",
        "support"
      ]
    },
    {
      "id": "aws-news-8119cadea768",
      "title": "Amazon VPC Lattice now supports custom domain names for resource configurations",
      "description": "Starting today, VPC Lattice allows you to specify a custom domain name for a resource configuration. Resource configurations enable layer-4 access to resources such as databases, clusters, domain names, etc. across VPCs and accounts. With this feature, you can use resource configurations for cluster-based and TLS-based resources.\n  Resource owners can use this feature by specifying a custom domain for a resource configuration and sharing the resource configuration with consumers. Consumers can then access the resource using the custom domain, with VPC Lattice managing a private hosted zone in the consumer’s VPC.\n  This feature also provides resource owners and consumers control and flexibility over the domains they want to use. Resource owners can use a custom domain owned by them, or AWS, or a third-party. Consumers can use granular controls to choose which domains they want VPC Lattice to manage private hosted zones for.\n \nThis feature is available at no additional cost in all AWS Regions where VPC Lattice resource configuration is available. For more information, please read our blog or visit the Amazon VPC Lattice product detail page and Amazon VPC Lattice documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/amazon-vpc-lattice-custom-domain-name-resource-configuration",
      "pubDate": "2025-11-07T18:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-f838bd828ecc",
      "title": "Optimizing nested JSON array processing using AWS Step Functions Distributed Map",
      "description": "In this post, we explore how to optimize processing array data embedded within complex JSON structures using AWS Step Functions Distributed Map. You’ll learn how to use ItemsPointer to reduce the complexity of your state machine definitions, create more flexible workflow designs, and streamline your data processing pipelines—all without writing additional transformation code or AWS Lambda functions.",
      "link": "https://aws.amazon.com/blogs/compute/optimizing-nested-json-array-processing-using-aws-step-functions-distributed-map/",
      "pubDate": "2025-11-04T23:41:28.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "lambda",
        "step functions"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "lambda",
        "step functions"
      ]
    },
    {
      "id": "aws-news-f8b80d2313fc",
      "title": "EC2 Auto Scaling announces warm pool support for Auto Scaling groups that have mixed instances policies",
      "description": "Starting today, you can add warm pools to Auto Scaling groups (ASGs) that have mixed instances policies. With warm pools, customers can improve the elasticity of their applications by creating a pool of pre-initialized EC2 instances that are ready to quickly serve application traffic. By combining warm pools with instance type flexibility, an ASG can rapidly scale out to its maximum size at any time, deploying applications across multiple instance types to enhance availability.\n  Warm pools are particularly beneficial for applications with lengthy initialization processes, such as writing large amounts of data to disk, running complex custom scripts, or other time-consuming setup procedures that can take several minutes or longer to serve traffic. With this new release, the warm pool feature now works seamlessly with ASGs configured for multiple On-Demand instance types, whether specified through manual instance type lists or attribute-based instance type selection. The combination of instance type flexibility and warm pools provides a powerful solution that helps customers scale out efficiently while maximizing availability.\n  The warm pool feature is available through the AWS Management Console, the AWS SDKs, and the AWS Command Line Interface (CLI). It is available in all public AWS Regions and AWS GovCloud (US) Regions. To learn more about warm pools, visit this AWS documentation.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/11/ec2-auto-scaling-warm-pool-mixed-instances-policies/",
      "pubDate": "2025-11-04T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ec2"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ec2",
        "support"
      ]
    },
    {
      "id": "aws-news-e7f08dca9bc5",
      "title": "Amazon Connect now supports scheduling of individual agents",
      "description": "Amazon Connect now supports scheduling of individual agents, giving you more flexibility in scheduling your workforce. For example, when onboarding 100 new agents to a business unit with schedules already published for next two months, you can create schedules for only those new agents and automatically merge them with existing schedules. This eliminates the need for workarounds such as manually copying schedules from existing agents to new agents or regenerating schedules for entire business unit, thus improving manager productivity and operational efficiency.\n  This feature is available in all AWS Regions where Amazon Connect agent scheduling is available. To learn more about Amazon Connect agent scheduling, click here.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-connect-scheduling-individual-agents/",
      "pubDate": "2025-10-31T15:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-eaa9d80ce2c9",
      "title": "Amazon ECS now supports built-in Linear and Canary deployments",
      "description": "Amazon Elastic Container Service (Amazon ECS) announces support for linear and canary deployment strategies, giving you more flexibility and control when deploying containerized applications. These new strategies complement ECS built-in blue/green deployments, enabling you to choose the traffic shifting approach that best matches your application's risk profile and validation requirements.\n \nWith linear deployments, you can gradually shift traffic from your current service revision to the new revision in equal percentage increments over a specified time period. You configure the step percentage (for example, 10%) to control how much traffic shifts at each increment, and set a step bake time to wait between each traffic shift for monitoring and validation. This allows you to validate your new application version at multiple stages with increasing amounts of production traffic. With canary deployments, you can route a small percentage of production traffic to your new service revision while the majority of traffic remains on the current stable version. You set a canary bake time to monitor the new revision's performance, after which Amazon ECS shifts the remaining traffic to the new revision. Both strategies support a deployment bake time that waits after all production traffic has shifted to the new revision before terminating the old revision, enabling quick rollback without downtime if issues are detected. You can configure deployment lifecycle hooks to perform custom validation steps, and use Amazon CloudWatch alarms to automatically detect failures and trigger rollbacks.\n \nThe feature is available in all commercial AWS Regions where Amazon ECS is available. You can use linear and canary deployment strategies for new and existing Amazon ECS services that use Application Load Balancer (ALB) or ECS Service Connect, using the Console, SDK, CLI, CloudFormation, CDK, and Terraform. To learn more, see our documentation on Amazon ECS linear deployments and Amazon ECS canary deployments.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ecs-built-in-linear-canary-deployments",
      "pubDate": "2025-10-30T17:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex",
        "ecs",
        "cloudformation",
        "cloudwatch"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "ecs",
        "cloudformation",
        "cloudwatch",
        "support"
      ]
    },
    {
      "id": "aws-news-8a1fee702148",
      "title": "AWS Clean Rooms launches advanced configurations to optimize SQL performance",
      "description": "Today, AWS Clean Rooms announces support for advanced configurations to improve the performance of Spark SQL queries. This launch enables you to customize Spark properties and compute sizes for SQL queries at runtime, offering increased flexibility to meet your performance, scale, and cost requirements. \n  With AWS Clean Rooms, you can configure Spark properties—such as shuffle partition settings for parallel processing and autoBroadcastJoinThreshold for optimizing join operations—to help you better control the behavior and tuning of SQL queries in a Clean Rooms collaboration. Additionally, you can choose to cache an existing table’s data containing results from a SQL query or create and cache a new table, which help improve the performance and reduce costs for complex queries using large datasets. For example, an advertiser running lift analysis on their advertising campaigns can specify a custom number of workers for an instance type and configure Spark properties—without editing their SQL query—to optimize costs.\n  With AWS Clean Rooms, customers can create a secure data clean room in minutes and collaborate with any company on AWS or Snowflake to generate unique insights about advertising campaigns, investment decisions, and research and development. For more information about the AWS Regions where AWS Clean Rooms is available, see the AWS Regions table. To learn more about collaborating with AWS Clean Rooms, visit AWS Clean Rooms.",
      "link": "https://aws.amazon.com/about-aws/whats-new/2025/10/aws-clean-rooms-advanced-configurations-optimize-sql-performance",
      "pubDate": "2025-10-30T14:00:00.000Z",
      "source": "whatsNew",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "launch",
        "support"
      ]
    },
    {
      "id": "aws-news-6b8927b02983",
      "title": "Breaking down monolith workflows: Modularizing AWS Step Functions workflows",
      "description": "You can use AWS Step Functions to orchestrate complex business problems. However, as workflows grow and evolve, you can find yourself grappling with monolithic state machines that become increasingly difficult to maintain and update. In this post, we show you strategies for decomposing large Step Functions workflows into modular, maintainable components.",
      "link": "https://aws.amazon.com/blogs/compute/breaking-down-monolith-workflows-modularizing-aws-step-functions-workflows/",
      "pubDate": "2025-10-22T21:02:22.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "step functions"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "step functions",
        "update"
      ]
    },
    {
      "id": "aws-news-e7f28cce076c",
      "title": "Stifel’s approach to scalable Data Pipeline Orchestration in Data Mesh",
      "description": "Stifel Financial Corp, a diversified financial services holding company is expanding its data landscape that requires an orchestration solution capable of managing increasingly complex data pipeline operations across multiple business domains. Traditional time-based scheduling systems fall short in addressing the dynamic interdependencies between data products, requires event-driven orchestration. Key challenges include coordinating cross-domain dependencies, maintaining data consistency across business units, meeting stringent SLAs, and scaling effectively as data volumes grow. Without a flexible orchestration solution, these issues can lead to delayed business operations and insights, increased operational overhead, and heightened compliance risks due to manual interventions and rigid scheduling mechanisms that cannot adapt to evolving business needs. In this post, we walk through how Stifel Financial Corp, in collaboration with AWS ProServe, has addressed these challenges by building a modular, event-driven orchestration solution using AWS native services that enables precise triggering of data pipelines based on dependency satisfaction, supporting near real-time responsiveness and cross-domain coordination.",
      "link": "https://aws.amazon.com/blogs/big-data/stifels-approach-to-scalable-data-pipeline-orchestration-in-data-mesh/",
      "pubDate": "2025-10-21T21:02:00.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "support"
      ]
    },
    {
      "id": "aws-news-c83bf77ed8b8",
      "title": "Stream mainframe data to AWS in near real time with Precisely and Amazon MSK",
      "description": "In this post, we introduce an alternative architecture to synchronize mainframe data to the cloud using Amazon Managed Streaming for Apache Kafka (Amazon MSK) for greater flexibility and scalability. This event-driven approach provides additional possibilities for mainframe data integration and modernization strategies.",
      "link": "https://aws.amazon.com/blogs/big-data/stream-mainframe-data-to-aws-in-near-real-time-with-precisely-and-amazon-msk/",
      "pubDate": "2025-10-16T18:55:25.000Z",
      "source": "bigDataBlog",
      "services": [
        "lex",
        "kafka",
        "msk"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "kafka",
        "msk",
        "integration"
      ]
    },
    {
      "id": "aws-news-cb8062515dfa",
      "title": "Accelerating local serverless development with console to IDE and remote debugging for AWS Lambda",
      "description": "Delightful developer experience is an important part of building serverless applications efficiently, whether you’re creating an automation script or developing a complex enterprise application. While AWS Lambda has transformed modern application development in the cloud with its serverless computing model, developers spend significant time working in their local environments. They rely on familiar IDEs, debugging […]",
      "link": "https://aws.amazon.com/blogs/compute/accelerating-local-serverless-development-with-console-to-ide-and-remote-debugging-for-aws-lambda/",
      "pubDate": "2025-09-09T18:00:39.000Z",
      "source": "computeBlog",
      "services": [
        "lex",
        "lambda"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "lambda"
      ]
    },
    {
      "id": "aws-news-11d98a88cbe1",
      "title": "Implement monitoring for Amazon EKS with managed services",
      "description": "In this post, we show you how to implement comprehensive monitoring for Amazon Elastic Kubernetes Service (Amazon EKS) workloads using AWS managed services. This solution demonstrates building an EKS platform that combines flexible compute options with enterprise-grade observability using AWS native services and OpenTelemetry.",
      "link": "https://aws.amazon.com/blogs/architecture/implement-monitoring-for-amazon-eks-with-managed-services/",
      "pubDate": "2025-07-18T15:47:13.000Z",
      "source": "architectureBlog",
      "services": [
        "lex",
        "eks"
      ],
      "categories": [
        "natural-language"
      ],
      "tags": [
        "lex",
        "eks"
      ]
    }
  ]
}